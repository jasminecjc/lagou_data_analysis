
数美领先的大数据技术、产品与服务提供商
 
我们正在经历一个IT到DT的变革时代。大数据已经渗透到各个环节，各个角落。
这个世界，就是掩藏在表象之下，被数据所揭示的世界！
数美依托积累的海量数据、科技前沿技术， 极致的工匠精神和对数据的深度理解，提供领先的大数据产品与服务。 
我们正在寻找不平凡的你，和我们一起“发现数据之美”
欢迎投递简历
 
你将负责
1. 主导数美大数据平台的设计与开发，解决海量数据面临的挑战；
2. 管理、优化并维护Hadoop、Spark等集群，保证集群规模持续、稳定；
3. 负责HDFS/hive/HBase的功能、性能和扩展，解决并实现业务需求；
4. 协助建立数据模型，对数据进行挖掘、优化及统计。
 
我们希望你
1、本科生及以上学历，3年及以上相关经验；
2、熟悉Hadoop/HBase/Spark/Storm/Hive，熟悉数据挖掘策略与算法；
3、熟悉分布式系统设计范型，有大规模系统设计和工程实现的经验 ；
4、数据控，善于发现问题、解决问题；
5、对新兴技术有好奇心，有利用技术解决实际问题的热情，开源社区积极参与者优先
 
 
【Our Team】
 一、国内最早一批从事大数据平台与应用研发的团队
2006年进入大数据领域，全球范围亦处领先地方
时刻站在大数据领域的前沿，正对大数据挖掘应用场景，提供业界独有的解决方案与专利技术
 
二、超大规模大数据平台研发与建设，居全球前十
服务器适量：50000+台
存储数据量：1EB+
结构化数据条目：百万亿条
 
三、丰富大数据应用的成功实践经验
数美团队拥有丰富的行业积淀，具有大数据方案整体架构能力
善于解决用户在大数据领域的痛点，在百度、360、小米、乐视、中信银行等拥有超过100个成功案例
 
 
【你将得到】
薪酬——有竞争力的薪酬，丰厚季度奖，年终奖
股票——飞速发展、全员持股
多种福利——8天年假；餐补、交通补助、通讯补助等多种形式补助、丰富体育活动（固定瑜伽课程、丰富体育活动）、各种零食、不定期outing、一年一度健康体检
办公环境——geek式办公环境、宽敞明亮的办公室
技术成长——每周一次技术分享与培训，技术专家review代码、导师制度关注员工的发展与成长
 
 
【关于数美】www.ishumei.com
Next Data数美是大数据综合解决方案提供商，由360首席架构师，360大数据、云服务、语音识别部门负责人唐会军创立，是基于大数据技术和产品来“挖掘”数据价值的创新型互联网高科技公司。
数美专注于金融、电商、直播、社交和支付领域，以解决场景化的大数据问题作为核心切入点，提供基于开放架构的风险控制、SaaS反欺诈云服务、精准营销等大数据整体解决方案，基于日渐成熟的大数据技术（例如：Hadoop、 Spark、机器学习、深度学习、强化学习、图像识别、搜索引擎和自然语言处理等）挖掘数据内部的价值。
     目前已服务数千家客户,覆盖直播、金融、支付、社交、电商、游戏、O2O等行业。 
    我们致力于成为世界顶尖的专业大数据技术、产品、服务提供商。


岗位职责
1. 梳理业务线的业务及数据指标，设计开发数据产品所需的底层数据模型；
2. 搭建数据收集、查询、分析平台，综合利用相关业务数据，为产品运营提供数据分析支持；
3. 积极推进跨部门合作，配合各类项目如期保质保量实施执行。

任职要求
1. 两年以上后台开发经验，熟悉java或python语言；
2. 熟悉Mysql数据库、ElasticSearch、MongoDB等产品；
3. 熟悉 Linux 系统管理，熟练使用 Linux 工具，熟练掌握 Shell 编程；
4. 熟悉Web开发，至少熟练使用一种Web开发框架，包括SpinrgMVC/Spring/Servlet等；
5. 较扎实的算法和数据结构功底；
6.精通SQL，有数据清洗、分析，Hadoop、Hive、Spark等使用经验者优先考虑
7.有责任心，工作细心耐心，学习能力强，具备良好的沟通能力，逻辑能力好，能充分理解业务逻辑和目的，有清晰的数据分析思路和方法
8. 有很强的压力承担能力及团队合作能力，有主动性和上进心；
9. 优秀的分析问题和解决问题的能力，对解决具有挑战性的问题充满激情。

岗位描述：
1、负责公司数据中心开发工作；
2、针对公司海量数据进行管理、分析、挖掘；
3、维护和开发公司BI系统，提供考核和决策参考。

技能要求：
1、大专及以上学历，有2年以上工作经验； 
2、熟练掌握mysql、mongodb等数据库技术，熟练掌握spring相关开发框架；
3、熟练掌握redis缓存技术，socket、thrift编程；
4、熟练掌握并行、异步、多线程等开发技能；
5、有良好的clean code习惯，有过高并发、海量数据处理的经验。

岗位职责：
1.负责Hadoop、HBase、Spark、Storm等系统的搭建、优化、维护及升级工作，保证平台的稳定运行
2.负责数据的清洗、加工、分类等开发工作，并能响应数据分析师对数据提取的要求
3.负责大数据平台的底层平台的整体架构设计，确保系统能支持业务不断发展过程中对数据存储及计算的要求

任职资格：
1.熟悉分布式系统的架构，有分布式系统架构设计的经验，有Hadoop系统架构设计经验，至少1个以上大型成熟项目的经验；
2.精通Hive，并有相当优化经验，理解 Hbase 体系架构，并有相当开发经验。
3.熟悉数据仓库的ETL的开发,有海量数据处理相关经验；
4.熟悉Hadoop、HBase、Hive、Spark、Storm等软件，至少精读过一个源码。
5.有数据挖掘及java开发3年及以上的经验优先。

1. 精通Java，Scala;
2. Hadoop：熟悉HDFS、MR、Yarn的原理，精通MR作业的开发;
3. Spark：熟悉Spark原理，精通Spark作业、Spark Streaming作业的开发;
4. 精通Kafka加分;
5. 精通kylin加分;
6. 精通HBase加分;
7. 精通Elasticsearch加分;
8. 学历本科;
9. 工作年限1年以上.

任职资格：
1. 负责MR，Spark业务开发;
2. 负责集群搭建及监控运维;
3. 负责技术选型及架构规划.

行业标杆，高速成长， 团队活跃，平台广阔，交通便利！
前景，专注于本地生活最大的领域——餐饮O2O；
晋升，广阔的职业发展空间，越努力你就越幸运；
氛围，那是年轻人的世界，公司营造各种交流机会，帅哥MM你懂的；
环境，舒适高大上的办公环境，西直门地标建筑，没有雾霾还可看见西山落日。
哗啦啦期待你的加入！

岗位职责：
1、基于hadoop/spark平台架构设计及开发工作
2、大数据平台的框架设计及核心代码编写
3、基于spark Streaming流式计算的设计及开发
4、对海量数据进行收集、存储、管理、分析、建模
5、对海量用户数据进行统计分析挖掘，不断提升系统系统运行效率
6、负责大数据平台的监控及优化，针对持续增长的数据提供相应的解决方案
岗位要求：
1、三年以上开发经验，一年以上大数据开发经验
2、扎实的Java/Scala或Python语言基础，可开发高效可利用的代码，了解虚拟机性能优化策略，熟练代码管理工具。
3、具有丰富的Spark开发经验
4、熟练使用Hive/Impala/Hbase/Kafka/Flume等大数据相关组件,对分布式储存计算有较深入了解
5、熟练编写Shell，Sql,具有Sql优化能力
6、严密的数学思维、突出的分析和归纳能力、优秀的沟通表达能

职责：                                 
• 按照规范及设计文档完成编码工作，并对代码质量负责；
• 编写及维护技术开发相关文档；
• 能够对自己开发的代码设计并编写单元测试及功能测试代码；
• 学习和研究新技术以满足产品的需求；
• 为产品改进、优化、效率提升设计开发产品内部工具。
 
要求：
• 计算机相关专业本科及以上；
• 软件基础理论知识扎实，具有良好的数据结构、算法功底；
• 熟悉Hadoop等分布式开发，了解Hadoop相关各种开源项目，如：Hive、Hbase等，并有实际应用，熟悉Storm、Spark者优先；
• 熟练应用Spring、Java Cache等开源框架；
• 熟悉MySQL等关系型数据库，熟悉NoSQL数据库者优先；
• 对新技术敏感，有一定独立分析，技术研究能力；
• 熟练使用Linux环境下开发者优先；
• 熟悉至少一种版本控制工具，如：SVN，熟悉分布式版本控制工具Mercurial或Git者优先；
• 有个人开源项目或参与开源项目者优先；
• 有代码洁癖和自发组织Code Review的开发者优先；
• 提供本人半年内写过的代码，不限开发语言；
 
工作态度：
• 具备良好的人际交往、语言表达和沟通能力；
• 具备高度的责任心、诚信的工作作风、优秀沟通能力及团队精神；
• 愿意接受挑战性的工作，能够高效及时完成工作；

岗位描述：  
1. 参与数据挖掘产品的日常开发及维护；
2. 和产品经理密切合作，保证产品研发的按时发布；
3. 参与数据产品ETL设计. 开发及自动化工作；  
 
任职要求: 
1.  计算机或相关专业，本科及以上学历，2年以上工作经验；
2. 熟悉Hadoop/HBASE/Hive/Spark等分布式计算平台，有大数据应用系统开发经验者优先。;
3. 熟悉JAVA，熟悉linux;
4. 有spark scala编程基础优先，有mahout，mllib算法包开发经验的优先；


工作职责：
1、参与大数据风控平台和产品的规划设计与开发
2、根据上层业务逻辑整合优化平台数据流程，技术难点攻关
3、对数据挖掘业务提供技术支持，协助方案规划
4、跟踪业界技术动态，推动技术的持续进步

任职要求
1、本科及以上学历，计算机相关专业，大数据处理、数据仓库、数据挖掘方向2年以上相关工作经验
2、熟悉Linux系统环境以及Shell、SQL脚本开发能力
3、熟悉Java语言，有Java开发经验，对数据结构和算法设计有一定的理解
4、熟悉Hadoop、Hbase、Hive、Pig、Storm等至少一种以上，有Hadoop开发经验，熟悉Map/Reduce，熟悉Spark编程优先
5、良好的逻辑思维能力，良好的业务解读能力
6、有人工智能、机器学习、大数据风控及其他大数据系统建设经验者优先
7、具有较强的沟通、表达及文档编写能力

福利待遇：
1.提供五险一金，享受国家规定的带薪假期，节假日礼品福利，年终奖，项目奖金。
2.自有产品开发项目多样化，拥有庞大的高端技术团队（纯技术开发人员达100多号人），加入我们，你将获得前所未有的技术交流氛围及成长空间。
3.不定期举行户外团队活动或旅行。
4.定期组织专业技能及职业素养等培训课程，让你比一般人获的更多的成长机会。

工作职责：1、业务数据分析和处理，进行汇总统计，输出报表；2、参与数据产品的迭代工作，并且在一定程度上给予评估和建议；3、分析用户的特征和行为数据，挖掘不同类型用户的行为特性，为产品设计和用户运营提供数据支持。

任职资格：1.本科及以上学历，计算机相关专业者优先，2年以上数据分析相关工作经验； 2.对工作有富有热情，工作责任心强； 3.熟悉Hadoop，r,python，shell java c++等语言，熟悉常用数据分析方法；4..对数据有敏感、熟悉数据挖掘算法包括常用的分类、聚类、关联、推荐算法等；5.有互联网、金融或者航司等相关工作背景优先。


全国统招全日制高校计算机、数学及相关专业本科（一本）学历及以上，211、985院校毕业生；硕士研究生优先； 
精通SQL，熟悉SQL优化基本技术, 至少使用过一种大型关系型数据库（如ORACLE、DB2）、了解linux、unix操作系统
具备Oracle，Sybase，Hadoop 有相关数据库的脚本编写能力，有良好的编码习惯和技术文档编写能力；
掌握数据抽取、数据库设计等知识、数据仓库理论，熟练使用PLSQL、Powerdisign、CRT等相关数据库开发工具；
工作积极主动，具有良好沟通能力，学习钻研和团队合作精神 、能够承受较强的工作压力和强度，有极强的工作责任心；
对大数据及商业智能领域有浓厚的兴趣；
有电信行业工作经验、海量数据处理经验者优先；
有Hardoop平台开发维护、主机运维经验者优先


 
工作职责：
1、PoC（Proof of Concept，原型验证），在客户业务场景下验证产品的功能与性能。
2、在客户现场搭建大数据产品平台，与客户沟通，根据客户的需求或业务场景在大数据平台上实现大数据平台软件的项目实施与安装部署。
3、现场提供专业服务，包括故障分析与诊断，数据分析服务，业务应用对接迁移，完善提供整体解决方案。
4、完善大数据生态，架构设计等。
 
职位要求：
1、计算机或相关专业本科一本（或以上）学历
2、熟悉Linux操作系统，熟练使用基础命令，熟悉shell语言，系统诊断等
3、精通Java语言，具有良好的编程能力。
4、熟悉数据库、数据仓库相关概念与使用，会编写Oracle/DB2 存储过程，有数据库的调优思路 
5、做事认真负责，沟通能力良好，自学能力较强，能够接受出差。
（公司有hadoop和spark相关培训的计划和机会）
6、善于沟通总结，逻辑思维能力较强，表达能力较强

岗位职责：
* 大数据开发与分析
* 任务调度与监控
* hql编写与优化
* 数据核对

岗位要求：
* 两年以上工作经验；
* 熟练掌握oracle pl/sql基本语法，熟悉hadoop,熟练掌握hive、spark等,了解hive脚本优化方法；
* 良好的逻辑思维能力、团队合作精神与沟通能力；
* 了解java或者shell；
* 海量数据处理经验优先；

福利待遇：
年终奖（至少一个月工资）+生日礼物+节日礼物+五险一金+带薪年假+团体聚餐 +团体旅游+技能培训+零食+考证补贴+其它福利等

1. 四年以上大数据相关项目开发经验，并在项目组中承担过leader的角色； 
2、熟悉Scala语言，对Scala原理，底层技术有深入研究者优先；
3. 熟练使用spark BDAS各组件，对基于内存的计算框架有一定的研究与理解；
4. 精通Hadoop，Hive，Storm，Spark，Hbase，Zookeeper，Kafka，Flume等分布式框架；
5. 熟悉常用的设计模式;了解常用数据结构与算法和设计能力；对大数量的并发计算有一定的研发经验。
6. 了解Linux环境以及操作，熟练使用svn，maven等工具； 

岗位职责：
1、基于大数据技术实现业务Service的重构；
2、从事大数据平台化的开发，提升海量数据的处理性能；
3、电子商务数据平台的维护优化和重构；
4、集群运维，解决各种疑难杂症，对系统进行性能调优; 
任职要求：
1、计算机相关专业本科及以上学历；
2、两年以上java开发经验，有网站/数据平台架构经验尤佳；
3、熟悉JavaScript、html、css等web前端常用开发技术；
4、精通Spring、Hibernate、iBatis开发，对虚拟机及Linux下的开发环境有较深厚的开发经验；
5、熟悉网络编程，具有设计和开发对外API接口经验和能力。
6、熟悉Hadoop、Redis、Spark、HBase、Storm、Kafka、Flume等类框架技术者优先；
7、有开源代码或项目经验优先。

岗位职责：
1、负责大数据平台基础环境的搭建；
2、负责大数据核心技术的攻关和系统优化，协助解决开发过程中的技术难题；
3、参与大数据技术标准、规范等制定；
4、完成领导交代的其他工作。
任职要求：
1. 211、985大学研究生、博士学历；
2. 大数据开发三年以上工作经验；
3. 需要对各版本大数据组件有一定认识、能搞定hive，最好有spark实际经验；
4.熟悉hdfs、hbase、hive等组件的原理并具备配置开发经验；
5.熟悉cdh、hdp、apache hadoop中的任意一个； 6.了解并掌握大数据平台搭建； 7.熟悉Java语言、R语言、scala语言中的两种；
8.能够按照业务逻辑开发相关脚本。

岗位职责：
1. 面向多来源、多系统进行数据读取、整合、校验与清洗；
2. 参与大数据分析平台的需求沟通，设计面向市场的数据分析模型、开发数据产品并维护。
任职条件：
1. 本科及以上学历，3年以上大数据领域工作经验；
2. 熟悉大数据系统的搭建原理，熟悉Spark/Hadoop；
3. 熟悉Scala、Python、Java和Linux系统优先；
4. 了解数据挖掘算法，具备大数据建模功底； 
5. 能够熟练查阅英文文献。

Supply Chain Automation is responsible for predicting what customers want to buy and automate the ordering process. We create a daily demand forecast for all Coupang’s Retail SKUs, every day. We work with internal stakeholders to solve challenging Supply Chain problems at scale. Our systems ensure Coupang’s customers are delighted with consistently available products. Automation supports scale and efficiency of our Supply Chain processes
We use Big Data processes to generate our daily forecast and buying decisions. Our systems are built on Hadoop and Spark, with forecasting models implemented in Python using SciPy, NumPy, etc. Our Automated Buying systems combine machine learning with human oversight. Software Engineers work with a cross-functional team of Data Scientists, Analysts and Product Owners to build world-class systems that keep our Supply Chain running smoothly
Responsibilities:
Cooperate with  data scientists: Verify and implement models to predict customer demand, recommend supplier order quantities and make inventory management      recommendations
Build and maintain our Big Data infrastructure to scale and support new use cases
Explore new Machine Learning applications to Time Series prediction
Analyze information acquired and compare solutions and weight them against the actual needs, provide root cause analysis affecting key business problems;
Mentor junior engineers 
Qualifications:
8 years  software development experience
Masters in Computer Science or Engineering
Expertise in Python or Java
Working experience with Python ML libraries (SciKit, Pandas) a plus
Working  experience with R, Scala a plus
Experience with  big data ecosystem (Spark, Hive, Pig, Sqoop, Oozie);
Experience with both Relational DBs and NoSQL

岗位职责:
1. 负责大数据及搜索平台的架构、研发和持续优化；
2.从事分布式存储，并行计算，数据挖掘相关的功能的设计和开发。
3.负责从数据中挖掘出有价值的信息，帮助提升运营效率
 
岗位要求:
1.3年以上系统研发经验，从事过大型分布式系统的搭建、研发工作；
2.熟悉linux平台，精通Java，具有良好的编程习惯和算法基础；
3.有大规模分布式系统理论基础和实践经验，熟悉分布式存储、并行计算、搜索等技术；
4.基于Solr／ElasticSearch的搜索系统开发经验；
5.分布式存储系统开发经验；
6.有良好的沟通表达能力和团队合作精神，热衷技术，乐于寻求挑战和突破自我。
 

工作职责
1. 负责搜狐广告投放平台数据体系的建设；
2. 商业智能(BI)系统的建模与开发；
3. 负责系统性能优化，主导技术难题攻关，持续提升系统在大规模分布式系统环境下高并发、海量请求数下的高处理性能，解决各类潜在系统技术风险，保证系统的安全、稳定、快速运行；
4．为精准营销提供快捷灵活的数据支持；
5. 用户画像的构建；
 
任职要求
1. 3年以上互联网行业数据仓库，数据分析或挖掘相关工作经验；
2. 熟悉数据仓库和数据建模的相关技术细节，熟悉传统关系型数据库，熟悉Hive，HBase，MapReduce等大数据处理技术；
3. 参与过完整的数据采集、数据清洗、分析和建模工作；
4. 熟悉常见机器学习或数据挖掘类的算法原理，熟悉常见的统计原理及方法为佳；
5. 优秀的分析问题和解决问题的能力，勇于解决难题；强烈的上进心和求知欲，较强的学习能力和沟通能力，具备良好的团队合作精神；
6. 热爱互联网，对互联网产品和技术有浓厚的兴趣，热衷于追求技术极致与创新。

 
主要工作职责：
1.负责公司的大数据处理平台框架及相关数据模块产品的设计、研发及架构工作； 
2.负责设计、构建和优化基于实时流处理Storm或Spark等大数据架构技术；整体提升大数据集群的高可用性、高性能、高扩展特性； 
3.负责大数据系统架构的规划，并制定实施标准和规范，确保得到有效的执行。
 
岗位要求：
1、工作经验（包括年限、职责、工作行业性质）：
1年以上Hadoop实际项目研发经验；能自主完成功能模块的开发、性能调优；深度掌握hadoop、spark、storm、hbase,、kafka等分布式实时数据存储和分布式计算平台原理，具有相关系统的调优、运维、开发经验；
2、专业知识与技能：
熟悉Java、Shell或Python等技术，可以熟练使用Linux操作系统，有实时大数据开发经验，熟悉MapReduce、Storm或Spark、Hbase、MongoDB等技术，有系统调优经验者优先。
3、性格及能力：
有较强的自我学习能力


岗位职责：

1、负责数据收集平台的建设，保证从几千个节点收集来的数据的实时性和一致性；
2、负责分布式数据处理平台的建设，保证离线计算、实时计算系统的性能和稳定性；
3、理解数据分析和挖掘的应用场景，对数据进行合理的建模；
4、理解各产品线的业务，提炼为数据产品的需求，完善数据产品，以数据推动业务发展。
 

任职资格：

1、掌握java, python, scala等高级语言一种以上；
2、熟悉SQL语句，熟悉主流关系型数据库MS SQL Server、Oracle、MySQL其中一种；
3、熟悉大数据平台生态如hadoop, spark, storm, hive, elasticsearch, kafka, flume者优先；
4、有数据统计、机器学习基础者优先。


岗位职责：

1、负责数据收集平台的建设，保证从几千个节点收集来的数据的实时性和一致性；
2、负责分布式数据处理平台的建设，保证离线计算、实时计算系统的性能和稳定性；
3、理解数据分析和挖掘的应用场景，对数据进行合理的建模；
4、理解各产品线的业务，提炼为数据产品的需求，完善数据产品，以数据推动业务发展。
 

任职资格：

1、掌握java, python, scala等高级语言一种以上；
2、熟悉SQL语句，熟悉主流关系型数据库MS SQL Server、Oracle、MySQL其中一种；
3、熟悉大数据平台生态如hadoop, spark, storm, hive, elasticsearch, kafka, flume者优先；
4、有数据统计、机器学习基础者优先。

岗位职责：
1. 大数据技术堆栈维护
2. BI数据统计分析
3. 对已有的数据进行挖掘分析，寻找数据价值
具体要求：
1. 统招本科以上学历毕业，计算机相关专业（如电子、自动化、数学等专业）；
2. 具有扎实的数据结构和算法功底，熟练掌握Python，Scala，Java 中至少一门语言。
3. 3年以上软件或互联网项目设计和开发经验，熟练掌握Hive，熟悉Hbase与Redis等NoSQL数据库原理及应用；
4. 具备良好的逻辑分析能力和解决实际问题的能力;
5. 有数据分析或算法实施经验，熟悉大规模数据挖掘、机器学习、分布式计算等技术优先。
6. 熟悉Hadoop生态系统组件，有线上实施运维经验优先
7. 有TB-PB级数据处理实际工作经验者开发经验优先

【岗位职责】：  1、大数据开发，负责公司数据体系的搭建和工程开发、分布式数据存储及计算；  2、参与公司的数据产品研发，大数据平台应用及规划，支撑业务需求增长;
3、调研新技术在业务中的可行性，参与数据基础架构规划和数据治理规范制定，并实施推广；   【技术要求】：  1、计算机、通信、数学相关专业本科及以上；  2、三到五年工作经验；  3、熟悉java，有较强的工程能力； 
4、熟悉数据结构及算法； 5、熟悉Hadoop(HDFS/MapReduce/Hive)、Spark、HBase、Kafka、Flume等常见框架；
6、具有良好的逻辑分析能力、沟通能力和协调能力；  

岗位职责1、理解业务，建设数据仓库，包括底层数据仓库、数据集市以及业务数据模型持续优化；2、负责业务数据开发、表设计和架构，现有业务数据（Hadoop、Oracle、MY SQL )优化和维护；3、负责数据的收集，清洗，分析，挖掘等产品方案设计和实现，设计报表并完成报表开发。4、协助业务开展实施深层次、多结构的业务数据贯穿数据，为业务发展和算法优化提供指导意见。
岗位要求1、全日制本科及以上学历，计算机相关专业；2、3年以上相关工作经验；3、精通SQL，有较好的SQL性能调优经验；4、熟悉Hadoop、Hive、Spark等分布式计算平台，有大数据应用系统开发经验者优先； 5、熟悉Linux；6、至少熟练使用Shell、Python、Perl等脚本语言之一。

职位描述：岗位职责：1、 分布式数据库、大数据相关产品预研、研究、研发；2、参与产品的规划、分析、设计；3、经验丰富者带领团队成员进行产品研发。任职资格：1、国家正规院校大学本科或以上学历，计算机或相关专业毕业；2、掌握Java分布式、多线程及高性能的设计与编码及性能调优，有高并发应用和后台应用开发经验；3、熟练使用Linux系统的常用命令；4、具备以下任一技能者优先：（1）有分布式数据库研发经验者优先考虑；（2）有基于MySQL数据库的应用开发、优化经验者优先；（3）有大数据hadoop、spark等相关组件使用经验者优先；（4）熟悉Python或R语言者优先；（5）具备数据挖掘、机器学习、商业智能等技能的优先；5、具备较强的责任心、主动沟通能力、团队合作能力、分析问题解决问题的能力，6、具有优秀的自学能力及自我管理能力，工作态度积极主动；7、能适应3周以内的短期出差。
职能类别：高级软件工程师

岗位职责： 
1.参与公司大数据相关产品的设计与开发，包括架构设计、编程、维护优化等，以及相关技术文档的编写；
2.跟踪大数据技术领域趋势并能结合实际业务做好应用。
任职要求： 
1.两年以上Java实际开发经验，扎实的Java基础并熟练掌握Linux常规命令与工具；
2.熟练使用Mysql/Redis 等常用SQL和NoSQL数据库；
3.一年以上大数据实际开发经验，熟练掌握Hadoop或Spark生态系统组件（MR、HBase、Hive、 ZooKeeper、Spark SQL、Spark Mlib等），有相关大数据架构及开发成功案例者优先；
4.对海量数据的分析、挖掘有浓厚兴趣，有大数据分析挖掘平台开发经验者优先，能熟练使用 Python或R语言者优先；


职位描述
·  负责基于 Hadoop/Spark 生态的系统研发
·  负责基于搜索引擎（如 ElasticSearch、Lucene 等）的研发
·  负责 Hadoop/Spark 集群调优
·  负责对数据进行建模分析
 
职位要求
·  熟悉 Hadoop/Spark 生态系统组件（HBase、Hive、ZooKeeper、Mahout 等）
·  熟悉 Flume、Kafka、Akka、Spark Streaming/Spark MLlib
·  熟悉 Linux，熟练使用 Java/Scala 语言以及 Python/Shell/R 等脚本语言
·  熟悉Cassandra、Redis等NoSQL数据库
·  有 Hadoop/Spark 调优、统计学知识加分
·  有机器学习经验者加分
·  熟悉 ElasticSearch、Lucene 加分
·  理解英文文档，对新技术有持续的热情


岗位职责：
1、大数据开发与分析
2、任务调度与监控
3、hql编写与优化
4、数据核对 

任职要求：
1、大学本科及以上学历，两年以上工作经验；
2、熟练掌握oracle pl/sql基本语法，熟悉hadoop,熟练掌握hive、spark等,了解hive脚本优化方法；
3、良好的逻辑思维能力、团队合作精神与沟通能力
4、了解java或者shell；5、海量数据处理经验优先； 

岗位职责：
1、主做数据建模、算法相关，尤其是基于时间序列的预测/
2、负责风控、财务、清结算相关的大数据平台的调研、架构、设计、研发。

任职要求：
1、全日制统招本科及以上学历，至少2年以上大数据相关工作经验（必备）；
2、熟悉linux和Windows的开发环境；
3、熟悉Hadoop/Spark生态系统组件（HBase、Hive、Pig、ZooKeeper、Mahout等）的使用；
4、熟悉分布式平台（Hadoop/Spark）工作原理与系统开发；
5、有Hadoop/Spark调优能力者优先；
6、有统计学知识，有海量数据处理、数据分析和挖掘经验者优先；
7、有风险控制、财会相关工作经验者优先；
8、对新技术有孜孜不倦的热情，具有良好的学习能力、团队协作能力和沟通能力；
9、责任心强，善于思考，能独立分析和解决问题。

1. 负责大数据平台的架构规划与开发，解决海量数据面临的挑战；    
2.   管理、优化并维护Hadoop、Spark等集群，保证集群规模持续、稳定；    
3.   负责HDFS/HBase的功能、性能和扩展，解决并实现业务需求；    
4.   协助建立数据模型，对数据进行挖掘、优化及统计。    

任职要求：
1. 本科生及以上学历，2年及以上相关经验；    
2. 熟悉Hadoop/HBase/Spark，熟悉数据统计与挖掘；    
3. 具备Java、Scala、python等开发经验；    
4. 善于发现问题、解决问题。    

岗位职责：
负责数据仓库架构、BI系统架构的持续优化设计。
主导大数据平台相关组件的架构设计研发。
主导大数据平台数据质量监控体系的设计研发。

岗位要求：
1,3年以上大数据开发经验，对各种大数据架构模型有深入理解，了解模型的优缺点。
2,扎实的java开发基础，熟悉常用设计模式；熟悉Linux开发，熟练使用shell/python。
3,熟悉Hadoop生态技术，包括但不限于hive/MapReduce/HBase/Spark等。
4，熟悉Mysql/Postgresql,精通sql，深谙sql优化技巧。
5，有互联网数据仓库，BI系统、OLAP开发经验者优先。
6，有数据质量监控系统开发经验者优先。
7，有Hadoop/spark集群维护调优经验者优先
8，熟悉ElasticSearch、kylin、java web开发者优先

岗位职责：
负责风控、财务、清结算相关的大数据平台的调研、架构、设计、研发。

任职要求：
1、全日制统招本科及以上学历；
2、熟悉linux和Windows的开发环境；
3、熟悉Hadoop/Spark生态系统组件（HBase、Hive、Pig、ZooKeeper、Mahout等）的使用；
4、熟悉分布式平台（Hadoop/Spark）工作原理与系统开发；
5、有Hadoop/Spark调优能力者优先；
6、有统计学知识，有海量数据处理、数据分析和挖掘经验者优先；
7、有风险控制、财会相关工作经验者优先；
8、对新技术有孜孜不倦的热情，具有良好的学习能力、团队协作能力和沟通能力；
9、责任心强，善于思考，能独立分析和解决问题。

岗位职责：1.参与公司大数据相关产品的设计与开发，包括架构设计、编程、维护优化等，以及相关技术文档的编写；2.跟踪大数据技术领域趋势并能结合实际业务做好应用。
任职要求：1.两年以上Java实际开发经验，扎实的Java基础并熟练掌握Linux常规命令与工具；2.熟练使用Mysql/Redis 等常用SQL和NoSQL数据库；3.一年以上大数据实际开发经验，熟练掌握Hadoop或Spark生态系统组件（MR、HBase、Hive、 ZooKeeper、Spark SQL、Spark Mlib等），有相关大数据架构及开发成功案例者优先；4.对海量数据的分析、挖掘有浓厚兴趣，有大数据分析挖掘平台开发经验者优先，能熟练使用 Python或R语言者优先；

岗位职责：
1、负责大数据产品线的架构设计和研发；
2、根据业务需求，制定系统的整体技术框架、业务框架和系统架构；
3、和团队成员一起完成大数据研发工作的流程、规范和方法建立；
4、对系统框架相关技术和业务进行培训，指导开发人员开发，解决系统开发、运行中出现的各种问题。
任职要求：
1、对各种大数据架构模型有深入理解，了解模型的优缺点；
2、熟悉大数据生态相关技术，包括但不限于Hadoop，Spark，YARN，MapReduce，Impala，Flume，Kafaka等；
3、Java基础扎实，熟练使用Shell、Python、R等语言；
4、掌握数据仓库(DW)/ 商业智能(BI)/ 数据统计理论，并灵活的应用；
5、精通SQL，有较好的SQL性能调优经验，理解Hive/Mysql 基本原理和调优策略；
6、算法基础扎实，熟悉常见的数据结构，了解分布式算法和分布式系统；
7、有互联网产品BI开发经验，有网站数据、用户数据、电商、点击流、精准营销等相关经验。


岗位职责：参与大数据平台的架构设计及相关文档的编写负责大数据采集、清洗、传输、存储、计算等全方位设计与开发预研大数据领域的前沿技术，优化现有架构任职要求：1、计算机及其相关专业，本科以上学历2、熟练大数据相关技术，Hadoop/MapReduce/Spark/Hive/HBase/Kafka/Flume等3、熟练Java/Scala/Python编程语言至少一种4、熟练SQL语言，熟练使用MySQL等数据库，熟悉Redis、MongoDB等NOSQL数据库5、深入研究过大数据框架的运行机制、实现原理、源码者优先6、有数据统计分析、机器学习、推荐系统、数据挖掘经验者优先7、对大数据技术有钻研热情，具备高度的责任心及团结协作精神
 

工作职责： 1、参与日活3亿的在线系统的数据挖掘、推荐服务； 2、对海量数据进行清洗、建模、分析、挖掘； 3、配合和支援内外团队，提取共性需求，并设计开发； 工作要求： 1、对机器学习，大数据挖掘，大型分布式服务系统有兴趣，有热情，并有相关工作经验； 2、扎实的计算机基础知识，大数据挖掘知识和机器学习知识； 3、本科及以上学历，计算机或者数学相关专业，3年以上相关工作经验； 4、良好的团队意识、沟通能力，出色的执行力和良好的责任心；

职位要求 
1．计算机或相关专业本科及以上学历
2．对Hadoop(HDFS/YARN)、Hive、HBase、MapReduce、Storm、Spark一种或几种技术架构有一定的理解及相关开发经验，并能够独立安装部署系统，独立分析解决集群的运行故障
3．熟练使用Java语言，3年以上JAVA/Python开发经验，数理逻辑思维强
4．熟练掌握JAVA WEB开发技术（HTML/CSS/JS等），了解前沿WEB技术（HTML5等）
5．熟悉网页爬取开发框架Webmagic/Scrapy，及http通讯协议，包括协议认证及状态代码含义
6．熟悉Linux操作系统，对shell有一定了解
7．能流畅并准确阅读相关英文技术文档
8．有强烈的上进心和求知欲，善于学习和运用新知识
9．善于沟通和逻辑表达，良好的团队合作精神和积极主动的沟通意识
有以下一项或多项技能者优先
1. 有新闻传媒聚合和大数据清洗、分析、建模经验
有数据挖掘及机器学习方面的经验
岗位职责
完成部门经理、研发项目经理下发的各类任务，包括：
1.负责Hadoop、HBase、Spark、Storm等系统搭建、优化、维护及升级工作，保证平台稳定运行
2.负责大数据底层平台的整体架构设计，确保系统支持业务发展过程中对数据存储及计算的要求
3.负责搭建并维护分布式数据爬取平台，并对爬虫的日常运行进行监控
4.负责数据的清洗、加工、分类等开发工作，并能对数据进行提取分析

岗位职责：
1.  负责大数据平台和应用产品的开发工作，包括算法设计及实现
2.  深入发掘和分析业务需求，通独立完成小型项目的系统分析、 设计，并主导完成详细设计和编码的任务，确保项目的进度和质量；
3.  能够在团队中完成Code Review的任务，确保相关代码的有效性和正确性，并能够通过Code Review提供相关性能以及安全的建议；
4.  能够有效地对新人或普通开发工程师进行辅导，帮助其快速成长；
岗位要求：
1.  三年以上Java开发及设计经验，优秀的编程能力及良好的开发习惯。具备独立沟通需求，设计，架构，开发的能力；或者，熟悉数据仓库模型设计，具备海量数据加工处理（ETL）相关经验；
2.   至少熟悉一种关系型数据库如sqlserver、mysql等，熟练掌握Hive/SQL，熟悉Hadoop/Map-Reduce/MPI分布式计算框架，有海量数据处理经验者优先; 
3.   聪明和自我学习。对数据敏感，擅于的发现关键问题；
4.   优秀的沟通和表达能力，清楚的表达个人想法、理解他人观点，具备团队合作意识和推动协作达成的能力。
5.   具有良好的商业敏感度和优秀的数据分析技能，采用实用的分析方法以解决商业问题；
6.   有舆情分析/搜索/CRM系统研发相关项目经验者优先

岗位职责：
1、负责公司数据平台（数据仓库和集市）的架构设计和开发；；
2、负责业务相关报表的开发和数据挖掘；
任职要求：
1、熟练使用主流数据库MYSQL，ORACLE进行程序开发；
2、熟悉ETL开发流程，有hadoop和ETL工作经验，熟悉mapreduce原理者优先；
3、熟练使用脚本语言：如perl、python等任意一种；
4、熟悉数据仓库、BI基本理论，有分布式数据仓库项目经验更佳。
5、有很强的与客户沟通和理解能力，有良好的团队协作精神、环境适应能力和执行力，在较大压力下保持工作激情。

岗位职责：
1、大数据开发与分析
2、任务调度与监控
3、hql编写与优化
    4、数据核对
技能要求： 
1、大学本科及以上学历，两年以上工作经验；
2、熟练掌握oracle pl/sql基本语法，熟悉hadoop,熟练掌握hive、spark等,了解hive脚本优化方法；
3、良好的逻辑思维能力、团队合作精神与沟通能力；
4、了解java或者shell；
5、海量数据处理经验优先；

岗位职责：
1. 基于Spark、hadoop等大数据平台的建设、开发、维护与优化；
2. 协助完成大数据项目需求分析、设计、业务建模；
3. 负责大数据实施过程中相关技术问题解决；
4. 完成与工作相关的技术文档编写工作。
 
任职要求：
1. 本科及以上学历，3年以上编程经验，熟悉Spark、hadoop开发、熟悉大数据集群的搭建、管理及优化。
2. 对数字，数据敏感，具备良好的逻辑思维能力，能够从海量数据中发现有价值的规律；
3. 熟悉BI流程，参与过大型数据仓库类项目，精通SQL；
4. 熟悉JAVA，熟悉linux，至少熟练使用Shell、Python等脚本语言之一；
5. 熟悉当前主流MQ, NoSql ，如redis,mongodb，Hbase等。
6. 个性乐观开朗，激情、愿意分享，自驱能力强，良好的结果导向和抗压能力；
7. 有大型互联网、金融行业经验的优先考虑；
8. 对业务有敏锐的洞察力，有较强的业务理解与分析能力。
 

【工作职责】：
1.负责公司Hadoop系统的底层搭建，构建公司统一的离线和实时计算平台。 
2.负责公司日志系统及ETL系统的设计和实现。 
3.负责公司数据体系的架构设计和规划，充分发挥公司的数据价值。 
4.跟踪Hadoop生态环境的最新进展。 
【岗位要求】： 
1、本科以上学历，3年以上相关工作经验，熟悉Hadoop生态环境，对Hadoop, Hbase, Hive, Storm等至少一个项目有着深入的了解。 
2.扎实的Java基础，对至少一门动态语言有过使用经验。 
3.熟悉Linux系统常用操作。 
4.对数据有着强烈兴趣，有部署大规模Hadoop集群的经验者优先。 
5.良好的学习能力，保持对新技术的敏感性。

【岗位职责】
1、研究大数据项目分析方法和大数据系统解决方案；
2、负责公司教育产品的机器翻译、机器学习、智能化识别等课题的研究和开发；
【岗位要求】1、硕士及以上学历，计算机、软件、通信、模式识别等相关专业；2、熟悉机器学习、人工智能等常用算法、具有数据挖掘等相关知识；3、有较好的机器学习和模式分类等相关方面的理论基础和实践经验；4、积极主动，有良好的沟通能力、团队协作精神和钻研精神。

福利
1.免费员工公寓（提供热水器、免费wifi等）
2.员工餐厅供应三餐；
3.五险一金齐全，社保体系完善；
4.处于业界较高水平的薪资待遇，每年1-2次的薪资晋升；
5.篮球场、羽毛球场、台球室、乒乓球室等休闲设施场所供应；
6.定期健康检查、贴心的生日礼物、节日礼物；
7.五天工作制，带薪假期（年假、病假、婚假、产假）；
8.花园式的工作环境，宽敞明亮的办公环境。

发展平台
1.国家大力支持的朝阳行业，博士后工作站，蓝鸽科研院，重视技术发展，培训、交流机会多；
2.新员工参加一个月的培训，一对一导师制，表现优秀可以进入公司战略人才培养计划；
3.公司大力启用优秀人才，两年带项目不是梦；
4.开发人员往“技术专家”和“高层管理”双线发展，公司百分之八十的技术高管和管理人才都是从内部选拔提升。


工作地点:海外菲律宾首都马尼拉.包吃包住.税后薪资.

工作内容:
1）主导公司监控平台的信息收集、汇总、分析、报警。
2）主导公司业务线上日志的汇总，以及海量日志的分析。

任职资格:
1）5年以上大数据运维和管理经验。
2）有较强的架构能力，能独立负责产品的架构规划和架构演进。
3）熟悉主流的分布式存储方案 (ceph Torus GlusterFS 等)。
4）熟悉 coreos+kubernetes，centos+mesos的docker架构方案，能够独立主导架构的搭建和演练！
5）熟悉 hadoop，storm，spark，kafka，Flink等分布式系统的工作原理，具备较强的架构，性能优化能力！
6）有主导完成优秀应用或大型数据项目开发经验者优先。
7）具有良好的团队协作能力和沟通能力。

360、小米、百度等顶级互联网公司联合投资，顶级大数据公司

你将负责
1. 主导数美大数据平台的设计与开发，解决海量数据面临的挑战；
2. 管理、优化并维护Hadoop、Spark等集群，保证集群规模持续、稳定；
3. 负责HDFS/hive/HBase的功能、性能和扩展，解决并实现业务需求；
4. 协助建立数据模型，对数据进行挖掘、优化及统计。
 
我们希望你
1、本科生及以上学历，1年及以上相关经验；
2、熟悉Hadoop/HBase/Spark/Storm/Hive，熟悉数据挖掘策略与算法；
3、熟悉分布式系统设计范型，有大规模系统设计和工程实现的经验 ；
4、数据控，善于发现问题、解决问题；
5、对新兴技术有好奇心，有利用技术解决实际问题的热情，开源社区积极参与者优先
  
数美领先的大数据技术、产品与服务提供商
我们正在经历一个IT到DT的变革时代。大数据已经渗透到各个环节，各个角落。
这个世界，就是掩藏在表象之下，被数据所揭示的世界！
数美依托积累的海量数据、科技前沿技术， 极致的工匠精神和对数据的深度理解，提供领先的大数据产品与服务。 
我们正在寻找不平凡的你，和我们一起“发现数据之美”
欢迎投递简历

【关于数美】www.ishumei.com
      数美由百度、小米、360等顶尖互联网公司联合投资的大数据公司，致力于利用人工智能技术和海量数据解决金融、互联网等领域广泛存在的欺诈问题，先后推出了信贷反欺诈、内容反欺诈、行为反欺诈等系列产品，      
     目前已服务数百家客户，覆盖直播、金融、支付、社交、电商、游戏、O2O等行业。其中包括中信银行、360、小米、58同城、爱奇艺、酷狗、用钱宝、点融、挖财、闪银、熊猫TV、花椒、唱吧等知名企业，并与腾讯云、金山云、七牛云等云服务提供商展开深度合作。
    数美的创始人唐会军在搜索、安全、语音识别等大数据领域拥有十余年研发经验，曾历任百度系统技术负责人、360高级技术总监等职位。创始团队均来自百度、360、小米、宜信、FICO等知名互联网公司，数美核心团队是国内最早一批从事大数据平台与应用研发的团队，曾负责过的大数据平台规模居全球前十。国际顶尖反欺诈技术，拥有十余项专利，同时在安全，反作弊、推荐，广告，语音识别等领域有着丰富的大数据成功应用经验。
           www.ishumei.com


1. 负责大数据平台和应用产品的开发工作，包括算法设计及实现
2. 深入发掘和分析业务需求，通独立完成小型项目的系统分析、 设计，并主导完成详细设计和编码的任务，确保项目的进度和质量；
3. 能够在团队中完成Code Review的任务，确保相关代码的有效性和正确性，并能够通过Code Review提供相关性能以及安全的建议；
4. 能够有效地对新人或普通开发工程师进行辅导，帮助其快速成长；
 
任职要求：
1. 三年以上Java开发及设计经验，优秀的编程能力及良好的开发习惯。具备独立沟通需求，设计，架构，开发的能力；或者，熟悉数据仓库模型设计，具备海量数据加工处理（ETL）相关经验；
2. 至少熟悉一种关系型数据库如sqlserver、mysql等，熟练掌握Hive/SQL，熟悉Hadoop/Map-Reduce/MPI分布式计算框架，有海量数据处理经验者优先;
3. 聪明和自我学习。对数据敏感，擅于的发现关键问题；
4. 优秀的沟通和表达能力，清楚的表达个人想法、理解他人观点，具备团队合作意识和推动协作达成的能力。
5. 具有良好的商业敏感度和优秀的数据分析技能，采用实用的分析方法以解决商业问题；

招聘要求
3年以上后端服务器开发经验。
参与过互联网相关工程项目，熟练掌握Javascript(Node.js), Java,PHP,Python,C/C++中的1~2种。
熟悉linux操作系统命令，会简单的使用shell脚本完成日常的运维工作； 
使用过至少一种云平台(包括但不限于AWS，QCloud，Aliyun，UCloud...)。
自我驱动以及行动力，认为今日的行动大于夸夸其谈的计划。
对新技术敏感，权衡用何种技术能最有效率的实现目标。
团队合作能力／乐于帮助别人并分享自己的经验和知识。
岗位职责
持续改进基于SOA的后台服务架构，使服务部署，运行方式更具弹性。
对所有游戏数据，进行自动ETL抽取，分析，并持续改进分析速度，分析指标，分析质量。
持续改进运营数据分析系统（BI Report 和 Data Visualization）
Growth Hack，做一些非常酷的横跨各种技术栈的实验性产品。
其他
第一天，你就有权利贡献代码到production上。
第一周，你就可以贡献一个上线运行并实际使用的功能。
在你入职的第一个月, 你就能接触到各个技术栈，从后端的 web servers ,big data, 到前端的Bootstrap, AngularJS，到线上各种云服务等。
在你入职的半年内, 你将会主导并重构公司某一个重要的技术，以适应公司高速增长的需要

岗位职责：
1.参与公司hadoop/spark平台的扩展、运维及优化；
2.负责公司内部hadoop/spark平台数据进行导出、清洗、转换、导入及数据统计；
3.持续改进优化ETL过程，开发公司内部业务模块；
岗位要求：
1、熟悉Hadoop、spark生态产品及工具，有一年以上的实际应用经验；
2、熟悉Linux开发环境；
3、熟练使用shell命令，熟悉Java/Python/Scala中的一种或更多；
4、掌握集群的安装和部署，有集群运维和优化经验者优先 ；
5、思维敏捷，有较强的钻研学习能力；较好的沟通能力、团队合作；

岗位职责： 
1. 负责旅游数据采集，数据清洗，数据挖掘等大数据处理任务 
2. 海量数据上的数据挖掘 ，发现站点和页面中有价值的规律 
 
技能要求:
1、精通Hadoop/MapReduce/Spark,熟悉linux、shell、awk、python等脚本处理。
2、有日志采集、海量数据处理、数据库查询优化、文本挖掘等经验者优先，熟悉storm、hbase、hive、mysql；
3、计算机相关专业，有一定编程基础，对数据结构和算法设计有较为深刻的理解，熟悉C++ /Java/Python至少一种语言；
4. 具有以下任一领域相关经验者优先：机器学习/数据挖掘/信息检索/中文自然语言处理/文本分类与聚类/统计数学
5、有较强的业务理解能力，能快速将业务问题转化成具体的技术解决方案; 有较好的沟通交流能力,善于主动思考和行动,乐于解决具有挑战性的问题。

任职资格：
1. 精通ORACLE及MYSQL数据库，有扎实的数据库基础2. 精通Hadoop，Mapreduce，Hbase，Yarn，Spark等技术并有3年以上的开发经验。3. 精通impala和Hive的SQL性能优化。4. 熟悉Cloudera Hadoop的管理和维护尤佳。5. 精通Java开发语言，熟悉Shell，Python，Perl至少一种脚本语言。6. 熟悉UNIX/LINUX操作系统的使用。7. 有数据仓库和ETL工具开发经验。8. 有较强的学习能力和问题解决能力并对从事互联网行业工作具有较大兴趣。9. 良好的沟通能力，有团队协作精神，工作积极主动，认真负责。 

工作职责：
1、负责公司核心集群的运维工作,保证其高可用和稳定性。2、负责集群容量规划、扩容及集群性能优化。3、深入研究大数据业务相关运维技术，持续优化集群服务架构，探索新的Hadoop运维技术及发展方向。4、设计实现分布式集群的运维、监控和管理平台。

工作职责：
1. 负责数据分析、加工、清理、处理程序的开发；
2. 负责数据相关平台的搭建、维护和优化。
 
任职资格：
1. 了解linux常规命令与工具,具有简单的Shell脚本编写能力；
2. 熟悉Java或Scala语言,理解面向对象知识；
3. 熟悉关系数据库,具有一定的SQL优化技巧；
4. 了解Hadoop、Hbase、Hive、Spark、Storm等大数据生态相关技术；
5. 有数据挖掘、数据分析、机器学习研发实践经验者优先。

岗位职责：
1.大数据开发三年以上工作经验；
2.熟悉hdfs、hbase、hive等组件的原理并具备配置开发经验；
3.熟悉cdh、hdp、apache hadoop中的任意一个；
4.了解并掌握大数据平台搭建；
5.熟悉Java语言、R语言、scala语言中的两种；
6.有数据收集、挖掘、报表展示经验。
任职要求：
1.统招本科及以上学历；
2.有使用MR或者spark做过数据分析；熟练使用spark者优先；
3.熟悉hive、hbase等的API调用；
4.能够按照业务逻辑开发相关脚本；
5.求编写etl代码及其调用脚本，计算输出各类报表；
6.熟悉R语言者优先；
7.有平台优化经验者优先；
8.有大数据平台开发经验者优先；
9.有海量数据处理经验者优先。

职位诱惑：
O2O行业领导者 发展空间大 技术氛围浓厚

岗位职责：
1、负责大数据产品线的架构设计和研发；
2、根据业务需求，制定系统的整体技术框架、业务框架和系统架构；
3、和团队成员一起完成大数据研发工作的流程、规范和方法建立；
4、对系统框架相关技术和业务进行培训，指导开发人员开发，解决系统开发、运行中出现的各种问题。

任职要求：
1、对各种大数据架构模型有深入理解，了解模型的优缺点；
2、熟悉大数据生态相关技术，包括但不限于Hadoop，Spark，YARN，MapReduce，Impala，Flume，Kafaka等；
3、Java基础扎实，熟练使用Shell、Python、R等语言；
4、掌握数据仓库(DW)/ 商业智能(BI)/ 数据统计理论，并灵活的应用；
5、精通SQL，有较好的SQL性能调优经验，理解Hive/Mysql 基本原理和调优策略；
6、算法基础扎实，熟悉常见的数据结构，了解分布式算法和分布式系统；
7、有互联网产品BI开发经验，有网站数据、用户数据、电商、点击流、精准营销等相关经验。

岗位职责
1、负责大数据数据平台建设，带领团队建设数据采集平台及计算平台；
2、负责分布式数据平台框架下，大数据开发和应用架构的研究和设计；
3、理解用户数据分析和挖掘应用场景，抽象为数据产品需求，不断完善基础数据的建设。
   


任职要求
1、五年以上大数据开发经验，具备较强的数据抽象能力和架构设计能力；
2、熟悉大数据平台生态如hadoop、spark、storm、kalfa、flume等；
3、有丰富的大型平台的架构及设计经验，精通数据结构和算法；
4、对技术有持续追求，强烈的技术领导力和责任心。

我们是处于快速发展期的行业独角兽，A轮融资2.5亿创行业之最，目前正在扩充核心技术和产品团队，急需最高端的瓜子仁和我们一起勇攀高峰，创造奇迹。这里有最顶尖的技术团队、最好的个人发展平台以及给力高薪，足够优秀的公司需要足够优秀的你，期待你的加入。

你可能将负责： 1. 负责大数据存储，计算相关平台的设计开发 2. 管理维护上百台hadoop，spark，presto等集群，保证集群稳定 3. 负责新技术的研究，搭建 4. 负责设计基于大数据的各种计算，etl流程设计和开发  我们希望你： 1. 本科以上学历，计算机或数学相关专业 2. 熟悉Hadoop/HBase/Spark/Storm/Hive等相关技术 3. 聪明，积极，善于发现问题，并有独立解决问题的能力 4. 精通数据结构和常用的算法，有很强的编程能力 5. 对新兴技术有好奇心，有利用技术解决实际问题的热情，开源社区积极参与者优先 

1、大专及以上学历，3年以上工作经验，来自互联网、金融等还有各种数据分析行业优先；
2、熟悉主流数据库oracle、sql server，mysql，mongodb等数据库中至少一种，有hadoop开发经验；
3、具有数据仓库和数据平台项目工作经验；
4、态度端正，工作积极主动，有责任心，耐心，并具有很强的团队合作意识。

1.熟练掌握Hive，熟练在hive平台下进行代码开发，支持金融业务需求; 2.熟悉在hive平台下进行调优; 3.能解决hadoop平台下的故障、性能等问题; 4. 有过海量数据系统开发 经验者优先; 5.掌握Linux操作系统,并具备shell编程能力; 6.有Spark SQL、Hbase、Python编程经验优先; 
任职资格 1.在hive环境下有较强的撰写SQL能力; 2.至少一年HIVE数据开发项目经历，有较强的开发调优能力; 3.了解LINUX脚本编程; 4.对数据敏感，有较强的逻辑分析能力，对(大)数据处理和分析技术有强烈热情; 5.有互联网金融项目经历者优先 

工作职责

负责公司内部数据平台的设计和开发
负责关键业务数据的实时化可视化展现
参与智能推荐系统的架构设计、开发、部署和数据分析等工作

 技能要求

至少精通一门服务器端编程语言，Python、Java、Scala或Go
熟悉Hadoop生态圈（Spark, Hive, Pig, Oozie, Impala, MapReduce）
精通SQL
有良好的沟通能力，能够理解业务部门、产品部门以及研发工程师的不同角度的需求
有良好的学习能力，关注业界最新技术和动态
计算机专业，本科及以上学历


岗位职责：
1、对公司产品的各项运营、产品数据进行汇总分析，建立一套完整的采集-存储-分析体系；
2、协同运营人员对各种日常业务数据进行统计，为数据管理平台提供数据支持； 
3、利用大数据分析工具，进行用户行为分析，对产品功能改进提供数据支持。

任职要求 
1、本科以上学历，熟悉Mysql，Mongodb数据库，熟练使用SQL语言，具有集群数据库的开发经验； 
2、能使用Linux系统，有海量数据处理相关经验，有大数据集、分布式计算工具（Map/Reduce，Hadoop，Hive等）工作经历；
3、熟练使用SPSS、R、SAS、Python等任一统计分析工具；
4、从事大数据工作3年以上，移动医疗相关工作经历者优先。

工作职责：
- 负责公司个性化推荐系统算法和架构的优化，给用户提供高质量精准个性化推荐结果；
- 负责用户兴趣建模、用户行为建模、商品画像、商家画像等内容的研发实现，形成完整的用户画像、商品画像体系；
- 负责卷皮App在线推荐/搜索/广告/精准化运营等场景下的相关特征挖掘、算法实施，同时优化数据使用流程和方法
- 负责数据挖掘/机器学习基础平台和工具的开发；
职位要求：
5年以上推荐系统、数据挖掘、搜索引擎相关从业经验；
- 熟悉Hadoop，Spark, Hive, Lucene, ElasticSearch等开源工具并有实际使用经验；
- 熟悉机器学习、数据挖掘、自然语言处理等相关技术，在相关领域有2年以上工作经验；
- 理解机器学习基本算法的设计思想和求解手段，如CF, SVM, LR, RF, GBDT等，有大规模机器学习系统研发经验或机器学习算法优化理论的研究经验者优先；
- 熟悉Python/R/Matlab并有实际使用经验者优先；
- 在搜索，推荐，广告等相关方向有经验者优先;
- 有较强的创新能力，勤于思考，关注前沿技术，喜欢用技术来解决实际问题，能够迅速熟悉业务、融入团队；

岗位职责:职位描述：1. 负责数据分析、加工、清理、处理程序的开发;2. 负责数据相关平台的搭建、维护和优化;岗位要求：1. 计算机相关专业本科学历以上；2. 熟练掌握linux常规命令与工具,具有简单的Shell脚本编写能力;3. 熟悉Java和Scala语言;4. 熟悉HDFS、Hbase，Hive、Spark等大数据生态相关技术;5. 熟悉MySQL数据库,具有一定的SQL优化技巧;6. 有数据挖掘、数据分析、机器学习研发实践经验者优先;

岗位职责

负责大数据平台/推荐系统/等产品的架构、研发和持续优化
和业务团队深入合作，解决在业务发展中遇到的产品和平台架构问题；具备一定的前瞻性；
具体领域包括但不限于推荐算法开发、分布式存储、大规模分布式计算、实时计算、跨平台资源调度、大规模分布式算法平台等；
负责搭建效果监控平台，数据质量监控平台，数据中心建设，算法模型平台化建设；
基于Hadoop生态圈进行扩展研发，构建统一的Data Infrastructure，在开源的基础上研发统一支持Batch和Streaming的计算引擎，SQL、NoSQL、Queue和Cache等分布式存储系统，以及自动化运维平台管理超大规模集群。
根据公司的搜索和推荐业务需求，基于上述Data Infrastructure，开发海量电商数据处理和机器学习流程，为搜索和推荐引擎输送实时数据更新，直接影响在线排序，提升成交转化。

任职要求
1.3年以上，对Linux操作系统熟练掌握，熟悉shell脚本编程；
2.深入理解 Hadoop/Hive/Oracle 等数据管理系统的原理、运维、性能调优方法； 
3.深刻理解hadoop相关技术的原理和开发方法，熟练hadoop平台的搭建部署、调优、故障诊断、运行维护的方法和工具； 
4.精通storm及其开发 5.熟练掌握Map/Reduce、HBASE、HIVE、PIG、Mahout中两种以上开发技术，并有实际产品的上线应用； 
5.对集群有着深刻的了解，能深入的了解hadoop集群及其周边常用各个模块； 
6.搭建维护hadoop集群并进行必要的troubleshooting, 保障系统正常运行； 
7.能利用集群实现对数据的分析和处理。

 工作职责：
1、参与公司大数据平台研发；
2、参与大数据集群部署和运维；
3、参与公司搜索平台的研发。

任职要求：
1、本科及以上学历，具有3年以上大型项目研发经验；
2、熟悉并行计算、分布式计算；
3、熟悉ZooKeeper、kafka、Hadoop、HBase、Flume等架构；
4、有深厚的操作系统，数据结构和算法基础；
5、做事严谨踏实，责任心强，条理清楚，善于学习总结，有良好的团队合作精神和沟通协调能力。

岗位职责：
1.负责大数据平台的搭建；2.负责各种业务数据的采集和存储；3.负责实现数据统计和分析需求的实现和图形化展。岗位要求:1.计算机相关专业,3-5年工作，物流快递行业优先；
2.熟悉数据仓库的ETL的开发和数据建模；3.精通Hadoop/Spark平台的配置和搭建,具有基础运维经验优先；4.精通MapReduce原理；5.熟悉Java, Hbase/Hive, Linux Shell编程；6.熟悉Flume配置,具有Kafka经验优先；7.具有数据可视化经验优先。
联系方式：021-69787568/69787567          
如有意向，欢迎来电！

岗位职责：1、负责大数据部主动推荐等大数据相关项目设计与开发；2、负责大数据部项目算法工程化实现；3、与用户沟通项目需求, 对项目质量跟踪控制；4、负责部分项目员工的代码审核。任职要求：1、计算机相关专业，全日制本科以上学历； 2、3年以上Java 及大数据应用开发经验；3、熟悉大数据开发框架，Hadoop、Hive、HBase、Spark、Kafka等大数据主流工具和技术，熟悉Linux操作系统，Shell编程等；4、熟悉数据挖掘常用算法，如SVM，K-Means，决策树等等；5、掌握常用的设计模式和架构模式，能够熟练使用建模工具进行系統设计；6、对工作有热情，富有团队协作精神、责任心强。 

岗位职责：
1、负责分布式数据仓库的主题模型设计和宽表开发工作；
2、负责大数据分析需求设计和开发，承担数据抽取、清洗、转化等数据处理程序开发；
3、负责大数据平台中实时计算和分布式并行计算的程序开发，以及开源技术组件的二次开发；
4、负责BI平台数据分析、报表开发工作。
任职要求：
1、本科及以上学历，有金融类的用户画像和规则引擎的设计与实施的工作经验优先；
2、精通分布式大数据平台架构；
3、精通Hadoop、Hive、Spark等大数据技术，对大数据技术的发展有深入的研究；
4、能够根据具体需求进行可行性研究、技术选型、系统架构设计、系统功能设计等；
5、能够带领团队进行系统开发，并给团队人员提供方法和技术指导优先。

主要职责：
1、基于采集数据提炼、分析、归纳用户属性、行为等信息，输出分析报告； 
2、处理用户海量数据，挖掘用户行为特征，为运营、风控和产品提供参考依据； 
3、针对具体业务问题，研究影响用户的潜在因素，进行数据分析验证并提出改善举措； 
4、参与各业务部门的重点项目，负责从数据的角度给出决策建议； 
5、参与实现业务所需的应用系统开发。
职位要求：
1、2至3年java开发经验，具备扎实的程序设计基本功和学习能力；
2、熟练使用Spark、MapReduce以及相关组件，对源代码或系统优化有一定研究者优先； 
3、熟练掌握scala/python其中一种语言； 
4、有3年以上的数据挖掘或者互联金融用户行为分析相关工作经验优先； 
5、有较强的人际沟通、协调能力，具备与技术人员沟通数据需求的能力； 
6、有海量数据分析经验者优先；统计学、概率学、计算机信息管理等相关专业研究生以上学历优先考虑； 
7、具备很强的软件开发能力和背景，能根据业务数据要求提供解决方案。

工作内容：
1、负责公司的数据平台的开发建设；
2、开发基于大数据技术的数据统计分析平台，OLAP引擎及大数据报表系统；
3、设计和研发数据分析相关的工具平台；
4、研究和设计公司的大数据仓库平台，负责数据仓库中的数据计算ETL pipeline的设计和开发，管理和维护。
任职要求：
1. 3年以上的大数据研发经验；
2. 熟悉Linux操作环境，有良好的至少一门语言 (Java、Python或者C++) 开发调试经验；
3. 熟悉大数据开发相关技术，如hadoop、hive、spark、storm等 ；
4. 熟练数据仓库，对多维数据建模有深入理解；
5. 有olap引擎相关开发经验优先；
5. 熟悉amazon aws, 包括但不限于s3, emr等技术优先；
5. 熟悉常用数据挖掘与机器学习算法优先；
6. 思维敏捷，有较强的钻研学习能力，较好的沟通能力、团队合作。

1、参与公司大数据数据仓库的搭建、设计与开发。2、根据业务部门提出的需求进行数据仓库模型设计并进行大数据作业的开发。3、负责日常的跑批调度开发。4、负责数据质量检验和监控。5、参与需求分析，引导业务人员。

任职要求：
1、熟悉数据分析与数据挖掘理论；有海量数据分析经验，熟练使用SQL；2、对数字，数据敏感，具备良好的逻辑思维能力，能够从海量数据中发现有价值的规律；3、具备专业的业务研究、分析能力，能够独立开展业务调研、数据分析、数据建模、报告编写工作；4、有分布式运算相关开发经验Hadoop、Hive、Mapreduce、Storm、Spark等相关开发经验者优；5、具备大型数据仓库架构设计、模型设计和处理性能调优等相关经验者优先

岗位职责：1. 负责大数据平台建设与维护2. 负责报表，搜索，推荐，多维分析等数据相关系统的开发工作3.负责数据提取工作
任职要求：1. 深刻理解大数据处理(流计算、分布式计算、分布式文件系统、分布式存储等)相关技术和实现方法，有架构和设计实践经验；2. 有互联网产品BI开发经验，有网站数据、用户数据、电商、点击流、精准营销等相关经验优先；3. 熟悉Hadoop/Hbase/hive等，掌握MapReduce, Storm或者Spark编程,，熟悉数据挖掘策略与算法。4. 熟悉数据模型建模，以及常用ETL工具；5. 具备Java/C++/Python等开发经验。6. 良好的逻辑思维能力，熟悉业务抽象和数据模型设计，具有很强的分析问题和解决问题的能力，对解决具有挑战性问题充满激情；

 职位描述1、参与大数据处理分析平台的设计与开发。2、产品相关的用户、运营数据的统计分析、挖掘、预测。3、负责平台的优化工作，包括存储、计算、内存占用等。4、研究了解前沿的大数据平台技术，并推进内部应用。岗位要求1、计算机、数学或统计等相关专业本科及以上学历，有2年及以上工作经验。2、熟练掌握Java语言，有面向对象编程思想。3、熟悉HADOOP、HBASE、HIVE、STORM等原理并具备管理，配置，运维经验，了解Mapreduce编程；有spark开发经验者优先。4、熟练掌握MYSQL等常用数据库及常用SQL。5、深入理解 Linux 系统，2年以上大数据平台使用维护经验。6、对大数据技术有钻研热情，具备高度的责任心及团结协作精神，善于沟通交流。 

请3年以上大数据开发经验的候选人投递，谢谢！
职责：
1、负责公司数据处理系统的研发。
2、理解产品需求分析、独立开展部分功能模块的设计、开发任务。
 
任职要求：
1、3年及以上java开发经验。
2、熟悉hadoop体系(sqoop，flume，hbase，hive)，storm，kafka，spark等技术。
3、熟悉MR算法。
4、具有很强的学习和分析能力，具有较强的逻辑思维能力，善于分析、解决问题，良好的沟通能力和团体合作精神。

岗位职责：
1、负责大数据系统的设计和开发工作；
2、负责分布式数据仓库的主题模型设计和宽表开发工作；
3、支撑日常业务数据需求，负责系统优化，问题跟进并及时解决。 
岗位要求：
1、熟悉Java或Python开发，具有2年及以上Java开发经验，熟悉linux操作；
2、具有3年以上大数据或分布式数据仓库系统开发经验；
3、熟悉Hadoop、Hive、HBase、Spark等相关技术，具有多个以上大数据平台项目实施经验；
4、具有丰富的数据仓库系统的开发实施经验，熟练设计数据模型、ETL设计、Cube多维建模、OLAP开发、报表开发等；具有良好的编程习惯和文档编写习惯；
5、有较强的学习能力，对技术有钻研精神，并有较高的热情，热衷于新技术学习和实践；
6、优秀的团队合作精神，对工作有热情，能够承受住压力。

职位描述：
1、参与公司大数据系统平台与应用的设计、开发、维护；
2、参与构建日志收集、数据仓库、ETL、调度系统、分析系统等环节；
3、参与机器学习相关的研发工作，我们有高质量数据可供挖掘。
 
任职条件：
1、2 年及以上 Hadoop 相关工具使用经验；
2、熟悉 Java/Scala/Python 其中之一或者全部皆可，具有熟练的编程能力是必要条件；
3、熟悉常用的数据指标、数据分析工具和平台（Hadoop、Hive、Spark、Kafka 等），了解数据分析的基本方法和常见问题；
4、做过机器学习/NLP相关的可加分。

岗位职责：1. 负责计算全国云仓库存分布，计算市内配送路线；2. 通过对现有数据的分析预测订单分布，分析生鲜订单市场喜好；3. 参与数据抽取、加载、转换和脚本开发；4. 负责BI展现的开发；5. 使用Hadoop, Hive等对海量日志进行统计分析
任职要求：
1、有大数据处理、数据分析、数据平台搭建等相关工作经验优先。
2、掌握数学、统计学和计算机相关知识。
3、掌握Excel，R，SAS等至少一种数据分析工具，具有良好的分析报告撰写能力。
4、熟悉MongoDB, MySQL, Oracle等至少一种数据库及查询语言。
5、熟悉脚本语言、数据建模或拥有海量数据处理和挖掘经验者优先。
6、优秀的团队合作精神、诚实、勤奋、严谨，能够积极创新，乐于沟通，负责敬业。
 

工作职责：
-负责百度账号数据仓库、数据集市的建设
-负责百度账号产品相关运营数据的统计分析挖掘
-负责百度账号数据分析平台的设计、研发及应用
-基于账号行为的分析、建模，利用模型进行产品的评测、改进及推荐

职责要求：
-计算机或相关专业本科及以上学历
-掌握数据仓库基本理论，精通hadoop/hive开发等
-具有良好的编程能力，熟悉Java/Python/php/shell等编程语言
-熟悉SQL/HQL，有较好的SQL性能调优经验
-敏锐的数据感觉，学习能力强，优秀的逻辑思维能力和业务需求分析能力，较好的沟通交流能力，能够迅速融入团队
-良好的逻辑思维能力，能够从海量数据中发现有价值的规律
具有以下条件者优先：
-具有数据分析和数据挖掘方面经验
-具备很强的数学建模能力, 能从复杂用户行为数据建立数学模型
-有数据仓库大型项目经验
-具备一定前端开发能力

【岗位职责】:
1、负责公司Hadoop/Hive/Spark等大数据基础设施的研发与运维，提升运行效率、稳定性和可用性；
2、负责大数据集群部署和管理平台的研发和改进；
3、责完善大数据平台相关制度及应用规范，指导开发人员编写代码；
4、配合产品经理与项目经理规划设计与实施大数据应用。

【任职要求】：
1、本科或以上学历，计算机软件或相关专业，3年以上Java开发经验，1年以上大数据项目经验；
2、对于Java基础技术体系（包括JVM、类装载机制、多线程并发、IO、网络）有一定的掌握和应用经验；
3、对Hadoop、Hive、Hbase、Storm、Spark一种或者几种有一定的理解；熟悉基于Hadoop、Spark平台的典型算法实现，有用户画像、推荐系统、数据挖掘等实际项目经验优先；
4、熟练使用Mysql、Tomcat、Redis、Kafka等中间件，熟悉Linux/Unix shell 及常用命令。


岗位职责：
1、负责和参与公司大数据基础架构平台的运维，保障数据平台服务的稳定性和可用性；
2、负责和参与超大规模数据存储与计算任务的精细化管理系统的设计，选型和开发；
3、负责和参与大数据基础架构平台的监控、资源管理、数据流管理；
4、负责和参与自动化运维系统及平台的建设；
5、负责和参与基于数据分析的可预测的云平台弹性扩展解决方案。

任职要求：
1、掌握 Linux 操作系统的配置，管理及优化，能够独立排查及解决操作系统层的各类问题；
2、掌握 Hadoop、Kafka、Zookeeper、Hbase、Spark 的安装与调试；
3、掌握Scala语言，至少精通 Python、Perl、Ruby、Bash 脚本语言中的一种；
4、有良好的系统性能优化及故障排除能力；
5、熟悉 Puppet、Chef、Ansible 等配置管理工具；
6、熟悉大数据周边相关的数据库系统，关系型数据库和 NoSQL。

大数据开发工程师
工作职责：

负责数据平台后台数据采集、处理设计及开发
负责数据平台后台数据采集、处理设计文档编写
负责数据平台大数据服务器运维工作

职责要求：

计算机相关专业本科以上学历
工作经验不少于7年，5年java，2年spark开发经验（spark 开发经验3中语言不限）
熟悉日志采集（kafka、flume 等）
熟练使用任1种脚本语言
熟悉 linux 命令，可独立部署运维 spark 集群
熟悉缓存机制及应用场景，项目应用过 redis 等缓存产品
熟悉函数式编程者优先
代码编写规范，思维清晰。
有协作开发经验，理解代码版本控制及管理的重要性。
理解产品业务设计思路，能提出建设性修改意见
有良好的学习能力、执行力和团队合作精神
乐于接受挑战，能在较大的压力下保持良好工作状态


岗位职责：
1. 参与大数据平台的设计与开发，解决海量数据面临的挑战；
2. 管理、优化并维护Hadoop、Flink、Cassandra等集群，保证集群规模持续、稳定；
3. 负责大数据平台的功能、性能和扩展，解决并实现业务需求；
4. 协助组内同学建立数据模型，对数据进行挖掘、优化及统计。
岗位要求：
1. 本科生及以上学历，2年及以上互联网系统或者其他企业应用系统开发相关经验；
2. 熟悉Hadoop/Flink/Cassandra等，熟悉数据挖掘策略与算法；
3. 具备Java开发经验，Java编程基础扎实，熟练使用struts2、spring、MyBatis或Hibernate等框架；
4. 数据控，善于发现问题、解决问题,具备良好的分析和解决问题的能力，具备一定的钻研精神和持续学习的意愿，强烈的责任感和团队感，对负有挑战性的工作充满热情.

岗位职责-深入研究支撑大数据业务相关技术，持续优化服务架构-深度参与数据处理和存储的业务系统的设计与实施-分布式存储计算框架的bug修正、二次开发及性能优化-大数据技术前瞻性研究与实现-大数据相关产品调研、优化和功能开发
任职要求- 本科或以上学历，计算机相关专业，有操作系统、数据库等专业知识基础- 良好的系统分析、代码编写能力- 需要有较强的学习能力和思考问题能力，责任心强，有良好的沟通适应能力- 熟悉Java，熟悉IO、多线程、RPC等基础技术- 实践并较熟悉一个以上大数据计算框架（Hadoop、Spark、Storm、Flink等）- 实践并较熟悉一个以上大数据数据库或查询引擎（HBase、Hive、Cassandra、ElasticSearch等）加分项：- 有大数据或高性能项目的源码阅读和修改经验- 有参与过自研大数据或高性能项目- 有开源社区代码贡献经验- 有技术负责过较大数据规模的项目经验- 有非常强的自我驱动和学习能力，自信能弥补一定程度的经验不足

1. 至少有2年Hadoop， MapReduce、Spark， Storm，HBase一种或者几种技术实际开发经验，有Spark开发经验优先；
2. 熟悉大并发、高性能的分布式系统设计及应用调优，有JVM调优、GC调优经验，有过海量数据系统开发经验者优先；
3. 熟悉ZooKeeper/Kafka；
4. 扎实的Java语言基础，熟练使用Scala加分； 
6. 良好的编码规范 ；
7. 能够阅读英文技术文档 ；
8. 有开源社区代码贡献的加分。

岗位职责： 

负责公司游戏运营数据仓库的建设
负责数据仓库模型设计
负责数据仓库项目的开发与管理
负责项目技术架构中数据仓库部分的规划和设计实施
编写和维护项目开发文档

岗位要求：

计算机或相关专业，本科及以上学历，3年以上的工作经验，1年以上团队管理经验
熟悉Hadoop、HBase、Hive、Storm,Spark等分布式计算平台，有大数据应用系统开发经验者优先
熟悉JAVA，熟悉linux。至少熟练使用Shell、Python、Perl等脚本语言之一
精通SQL，有较好的SQL性能调优经验
精通分布式、缓存、消息、NoSQL等机制，熟悉redis,mongodb等NoSQL数据库
熟悉BI开发流程，参与过大型数据仓库类项目，熟悉Aws Redshift/EMR者优先
具有业务分析及建模能力,熟游戏发行/电子商务相关业务流程者优先
良好的逻辑分析能力、分析问题和解决问题的能力，对数据敏感，良好的沟通能力跟执行力


岗位职责：
1.基于象理数据和客户数据，深度分析数据中的规律，挖掘数据价值；
2.参与数据、工具平台相关的功能接口、数据接口，实现业务功能；
3.参与数据平台、工具平台的架构、设计以及实现；
4.与数据计算/存储团队合作，优化数据平台的性能，解决兼容性、功能性Bug，提高稳定性。

职位要求：
1、精通Java语言、熟悉Spring、Spring MVC、Mybatis等常用Java框架。
2、熟悉RDBMS（比如MySQL）的开发，熟悉SQL语言。
3、熟悉Java并发编程，有优良的Trouble Shooting能力，能解决各种性能瓶颈（比如IO、CPU、Memory等）。
4、熟悉NoSql应用（比如MongoDB、Redis等）的开发经验者优先。
5、熟悉常用大数据中间件，有Zookeeper、Kafka、Elasticsearch等开发经验者优先。
6、掌握Hadoop、Spark、Storm中至少一种大数据技术，阅读过源代码者优先；
7、对大数据技术有钻研热情，乐于分享；
8、有金融行业经验者优先；
9、出色的沟通技巧和团队合作精神。

岗位职责：
1.负责大数据平台的建立、维护；
2.参与基于大数据平台建立相关的数据整合清洗、数据应用的设计和开发等。
3.参与跨部门协作，提升数据质量、稳定性和性能；
4.负责处理推荐系统相关数据流和数据整合。

任职要求：
1.统招二本及以上学历，计算机相关专业，2年及以上大数据相关开发经验；
2.熟练Java开发，了解 Spark, HBase, hadoop、Kafka，flume等相关技术和原理；
3.必备一定的沟通、协调能力和抗压能力，良好的自我学习驱动；
4.加分项：熟悉Python、Scala等其中一种编程语言，可用python做数据分析；熟悉统计学原理或机器学习等理论。

【岗位职责】
1.负责运维管理平台的开发和维护
2.负责运维工具的开发和维护
3.负责数据报表的统计
【岗位要求】
1.本科及以上学历，1年以上运维工作经验；
2.Linux操作系统的管理和运维以及网络相关知识；
3.熟练掌握python/perl/ruby/等任意一种语言开发，开发过相应项目；
4.有互联网公司运维经验，saltstack/ansible/puppet等工具使用经验的优先；

负责业务相关数据指标的抽取、转换、加载，数据维护相关工作；
数据质量控制和元数据整合相关工作；
分析业务需求、数据建模以及数据仓库应用产品的设计、开发；
制定数据质量维护制度、流程，数据质量例行检查；
 
任职要求：
有大型数据仓库或数据挖掘项目实施经验，精通数据仓库方法论和ETL架构，理解元数据管理；
至少熟悉MySQL、Oracle其中一种数据库，有动手操作能力；
熟悉Linux平台，掌握Shell、Python至少一种脚本；
熟悉SQL/MapReduce/Spark/Storm等任何一种大数据计算工具的编程
熟悉大数据调度系统的架构设计和开发实现
了解常用算法，有推荐系统/知识图谱/反欺诈等任何一种实际的算法工程应用的研发经验
熟悉Python，熟悉scipy/numpy/scikit-learn/matplotlib等模块的应用
熟悉数据可视化的基本方法，有数据可视化的开发经验
对数据敏感，具有良好的逻辑分析；
喜欢创业氛围、责任心强、良好的对外沟通和团队协作能力
能接受短期出差

岗位职责
1.负责大数据平台软件需求分析、设计；
2.参与产品需求讨论、应用产品系统架构的设计、开发；
3.负责编写相应的需求、设计与技术文档；
4.参与线上系统环境的升级、运维监控、性能调优,向系统使用者提供技术支持服务。
 
岗位要求
1.本科以上学历，3年以上大数据相关设计或研发经验；
2.熟悉分布式系统的架构，有分布式系统架构设计、大数据架构设计的经验，至少1个以上大型成熟项目的经验；
3.精通 Java、HFDS、MapReduce，并有相关的开发及优化经验；
4. 熟悉Spring、Spring Batch，Solr全文检索与推荐引擎开发；
5.熟悉MySql、SqlServer等数据库系统，有数据库编程经验、熟悉数据仓库的ETL的开发,有海量数据处理相关经验；
6.熟悉Hadoop、HBase、Hive、Spark、Storm等软件，至少精读过一个源码；
7.有电商大数据开发经验；
8.强烈的责任心，良好的沟通协调能力,较强的学习能力。

岗位职责:职位描述：1. 参与公司大数据产品规划,大数据处理分析平台的设计;2. 负责数据分析、加工、清理、处理程序的开发;3. 负责数据相关平台的搭建、维护和优化;岗位要求：1. 计算机相关专业本科学历以上；2. 5+年以上相关大数据工作经验；3. 熟悉Hadoop、Hbase、Hive、Spark集群搭建维护、优化及异常问题解决;4. 能够发现系统性能瓶颈,并能对IO、网络通讯、任务调度调优;5. 熟悉Java和Scala语言、熟悉常用设计模式、具有代码重构意识;6. 使用Spark Streaming和Spark SQL进行数据处理, 并具有SPARK SQL优化经验;7. 熟悉MySQL数据库性能优化方法, 了解常见NO-SQL数据库;8. 有数据挖掘、数据分析、机器学习研发实践经验者优先;

岗位职责：
1、参与大数据计算平台（Hadoop/Spark/storm）相关的系统研发、维护、优化工作。
2、数据清洗转换的方案设计和实现；
3、发布上线和故障处理；系统维护；优化、改进既有系统；
4、设计和维护文档撰写。
 
任职要求：
1、  计算机及相关专业本科及以上学历；
2、精通JAVA语言，熟悉Linux开发环境，具有实际系统开发经验；
3、熟悉MapReduce工作原理，具有Hadoop相关开发经验；
4.  基于Hadoop的海量数据的ETL开发经验，熟悉主流的分布式开源大数据产品包括Hadoop、Hive、sqoop、Hbase等并有企业级大数据平台设计或开发经验
5.  熟悉scala和spark优先 
6. 具有很强的学习能力、钻研精神、较强的沟通能力以及团队精神。

工作职责
1.    负责建设大数据分析系统，从大数据中挖掘信息指导业务发展；
2.    负责用户行为挖掘、构建用户画像以及AI相关数据挖掘工作；
3.    应用先进的统计建模、数据挖掘等算法建立数据模型，解决实际问题；
4.    将数据挖掘算法等人工智能相关研究成果固化成数据产品。
职位要求
1.    熟悉大规模数据挖掘、机器学习、分布式计算等技术，2年以上工作经验；
2.    具备处理大数据集的经验，熟悉hadoop、spark、storm等分布式计算工具；
3.    熟悉聚类算法、关联挖掘算法、topic模型，以及一些常用判别模型；
4.    优秀的分析和解决问题能力，对挑战性问题充满激情，对AI领域充满好奇。

岗位职责:
1.参与数据平台的建设,根据需求合理的实现落地。
2.参与数据实时处理及数据分析。
3.参与数据分析及可视化产品的研发。
4.参与实时数据分析及新产品的研发
5.编写相关技术文档。


岗位要求:

大学本科或以上学历。
精通java多线程,nio网络编程。
熟悉linux开发环境，掌握shell编程。
熟悉分布式系统/微服务开发,了解并发编程。
有hadoop,hive,spark,druid 等开发经验。
熟悉mysql/mongodb/redis/cassandra等数据库。
有数据挖掘,数据仓库背景优先。


岗位职责：
1、负责大数据分析平台的搭建及原型开发；
2、负责业务数据的挖掘、运营、业务模型的设计开发工作；
岗位要求：
1、统招本科及以上学历，计算机、软件工程等相关专业；
2、2年以上机器学习和数据挖掘经验；
3、具有良好的机器学习算法相关知识，如朴素贝叶斯、决策树、支持向量机、Logistic回归、分类等；
4、具有较强的问题解决能力，分析复杂的多变量问题的能力。
5、具有在数据挖掘、信息检索等大数据相关经验者优先；
6、熟悉企业用户网络模型者优先考虑；
7、具有较强的事业心、责任心、以及对新技术的好奇心和钻研能力；
8、具有较强的抗压能力、主动性、及团队合作精神。

技术热情，超强的学习能力、自我驱动

3年以上的大数据架构设计、实施经验
熟练运用一门编程语言，并能快速的切换实现语言（go、c++、java、php、python ……）
熟悉Hadoop生态技术，包括但不限于Yarn，HDDS，HBase，Impala，Flume ，Spark，kafka、Beam等
熟悉实时计算框架Storm、Flink、Spark Streaming其中之一
熟悉常规数据挖掘分析的方法、算法、建模、画像理念
数据敏感，对数据有自己的理解，数据之于商务的思考
熟练的英文读写能力、英文文档阅读能力

加分项：
熟悉Java、Python
熟悉SOA/微服务架构体系
有敏捷研发、持续集成、DevOps等相关实践经验优先
有广告系统研发经验、广告投放机制、用户体验建模经验者优先

如果你觉得和以上要求不符，但你对这个岗位很感兴趣，


并且确认你以往的其他经历或经验能给团队带来自己独特的价值，那么也欢迎投递简历

工作职责：
1.OpenStack运维，高可用测试。
2.POC测试(HDFS、MapReduce、实时流、非结构化数据等大数据技术)。
3.Spark，机器学习预研。
职位要求：
1.全国统招全日制高校计算机软件及相关专业本科（一本）学历及以上，211、985院校毕业生；硕士研究生优先； 
2.理解Hadoop/HDFS/MapReduce原理，熟悉分布式计算模型或有高效索引技术，HDFS、MapReduce、实时流、非结构化数据处理经验；
3.熟悉Linux系统、Shell编程；
4.熟悉JVM运行机制及内存管理
5.熟悉Hadoop、Hive、Sqoop、HBase等相关开源项目，从事过分布式相关系统的设计、开发工作优先考虑；
6.具备快速学习能力，思路清晰，善于思考。具备良好的沟通能力；工作严谨细致、责任心强；勤奋踏实，善于思考问题；有良好的团队合作观念。有电信行业经验优先。 
7.可接受短期出差支援。

岗位职责：
·       构建数据仓库，服务于用户画像、推荐、广告系统等系统。
·       支持运营、销售对业务上相关的需求，提供数据驱动和决策的能力。
·       对用户数据进行高效的ETL，通过数据挖掘构建用户画像。
·       核心类数据的可视化展示。
·       客户端数据收集的相关工作。

 最低需求
·       统计、计算机或相关专业的学士学位。
·       2年以上的大数据处理、数据挖掘等相关领域的科研/开发经验。
·       有数据分析的相关工作经验。
·       熟练使用Linux或者类似POSIX系统。
·       熟悉MapReduce, Hadoop, Pig, Spark, HBase, Hive等分布式相关的技术及组件。
·       极强的编程能力：熟练掌握Python，具备迅速处理复杂的数据和实现复杂的算法的能力。
·       很强的自我驱动力、结果导向并极具责任感。
·       有激情、毅力，正能量。
·       有良好沟通能力和团队协作精神。
·       有合格的英文能力。

锦上添花的需求
·       数据可视化相关的技术。
·       有机器学习相关方面的经验。
·       有很强的数据结构和算法知识。
·       熟悉Hadoop生态圈的各开源系统。
·       统计、计算机及相关专业的硕士或博士学位。
·       有一定的Android或iOS的开发经验。

岗位职责：
1、负责大数据平台产品开发；
2、负责高并发、大存储的数据系统，实时计算处理系统的研发；
3、负责海量数据的处理、分析、挖掘；
4、负责SQL on Hadoop 组件、BI引擎开发与优化。
岗位要求：
1、具备扎实的JAVA语言基础，拥有JAVA项目开发经验；
2、熟悉Hadoop、Hive、Spark开发编程，或者具有其他并行计算的实践经验；
3、至少熟练使用Hive、Impala、Presto、SparkSQL其中一种，能够理解内部运行逻辑；
4、至少熟练使用主流关系数据库（Oracle、Mysql、DB2、SqlServer等）中的一种，熟悉SQL优化，熟悉PL/SQL编程；
5、理解分布式缓存机制，熟悉或使用过Redis、Memcached；
6、具备良好的逻辑思维，学习能力强，有创新精神，善于学习钻研新技术，良好的团队合作意识。
 
具有以下条件者优先：
1、一年以上大数据处理、大数据分析经验；
2、一年以上Hadoop 相关项目实际研发经验，如Hadoop、Hive、Spark等；
3、熟悉Hadoop、Hive、Spark 底层API调用，或者对Hadoop、Hive、Spark源码有深入研究和工作经验者；
4、熟悉开源多维分析工具，如Kylin、Mondrian，具有BI引擎开发与优化。
 

岗位职责：
1）结合公司业务特点，研发高质量的搜索、个性化推荐算法和内容处理算法；  
2）追踪搜索引擎、个性化推荐、NLP和机器学习领域的前沿技术，将前沿技术应用于实际业务。


岗位要求：
1，具备扎实的算法及代码实现能力；
2，在以下至少一个领域有深入的研究： 
（1）搜索技术，如信息检索、索引、分词、相关性等；
（2）统计机器学习相关方法，如深度神经网络、概率图模型，最优化方法等； 
（3）语义理解技术，如知识图谱、语义解析、知识挖掘等； 
3.良好的分析问题与发现问题的能力，善于归纳技术方案的特性，并找出其不足与改进方法； 
4.熟悉Hadoop、Spark等分布式计算框架者更佳； 
5.具有良好的沟通能力，和良好的团队合作精神。


我们的福利：
1、与业内顶尖大牛过招+各种内部分享活动，提升自己不等闲~~2、超出同行业的薪酬水平+优秀人才配备期权，保证荷包鼓鼓~~3、餐补+无限零食饮料下午茶，满足你挑剔的味蕾~~4、私教健身+macbook pro+加班打车报销+年底奖金+图书馆，各种好玩的part等你来~~5、弹性工作+soho办公+扁平管理的企业文化~~6、五险一金是必须的~~~~

岗位职责：
1、负责分布式数据仓库的主题模型设计和宽表开发工作；
2、负责大数据分析需求设计和开发，承担数据抽取、清洗、转化等数据处理程序开发；
3、负责大数据平台中实时计算和分布式并行计算的程序开发，以及开源技术组件的二次开发；
4、负责BI平台数据分析、报表开发工作。
 
岗位要求：
1、本科及以上学历，计算机/数学等相关专业，具有3年及以上大数据开发经验；
2、熟悉Java或scala开发，熟悉linux操作；
3、熟悉Hadoop、Hive、HBase、Spark等相关技术，具有多个以上大数据平台项目实施经验；
4、具有丰富的数据仓库系统的开发实施经验，熟练设计数据模型、ETL设计、Cube多维建模、OLAP开发、报表开发等；具有良好的编程习惯和文档编写习惯；
5、有较强的学习能力，对技术有钻研精神，并有较高的热情，热衷于新技术学习和实践；
6、优秀的团队合作精神，对工作有热情，能够承受住压力；
7、具有大数据金融风控开发经验的优先。


福利待遇：
1、工作制：弹性工作制 ；
2、假期福利：除法定的节假日之外，还可享有年假，婚假，丧假，生育假；
3、社保与公积金：公司依法为员工缴纳社会保险和住房公积金；
4、丰厚的年终奖；
5、额外福利：提供免费下午茶，寿星有神秘的生日礼物，公司提供团队建设费用，员工旅行活动，员工体检；
6、员工活动：俱乐部活动如羽毛球，篮球等。

加入我们理由：
业务模式：不是P2P，不是高利贷，是帮助银行管理资产；
团队空间：班底来自银行，领导非常重视才能，有能力你就必须来；
薪资待遇：高固定薪资、薪资取决你的能力，老板讲义气，公司薪酬最具竞争力。
职业发展：起步阶段、空间巨大，晋升不按照一个萝卜一个坑，能力决定你的专业级别。

 

岗位职责：
a）参与大数据平台的建设维护，持续稳定支撑业务发展
b）实时／离线数据ETL过程设计和开发
c）多维度海量数据的分析应用
岗位要求：
a）对数据敏感，有意愿投身大数据事业
b）基础扎实，熟练掌握java／sql／shell等技能
c）熟悉至少一个开源框架(hdfs/yarn/hive/hbase/storm/sqoop/kafka/elasticsearch)，有运维和hack源码更佳
d）1～3年工作经验，资深3年以上，有互联网，出行行业经验者优先
e）团队合作无障碍，强烈的自我驱动力和抗压力

资产管理行业从2000年的百亿规模，发展到今天已经超过150万亿，每年仍以30%以上的复合增长率高速增长！云计算，大数据，智能投顾，机器人自动化运营等所有最新的金融科技都在这个行业得到大量的应用和实践，市场前景广阔！览众科技2016年新三板上市(股票代码:837881)！专注资产管理行业超过12年的金融科技专家！超过30个资管行业的标杆客户！2016年我们业绩增长超过5倍,人员规模增长超过50%！加入我们,将获得资管行业金融科技最专业的训练,和最富激情的团队一起开拓新天地！激动人心的薪酬体系+股权激励平台,高手呼唤高手！等你来!

【招聘说明】
岗位职责：
 1、负责完成数据抽取、转换和装载过程
 2、支持技术方案编写，完成DW/ETL部分的技术方案内容的编写；
 3、与客户沟通业务需求，完成数据处理设计与开发工作
 4、数据集市或ETL数据模型设计工作
任职要求：
1、本科及以上学历、计算机及相关专业；
2、熟悉oracle数据库；
3、熟悉linux系统,至少撑握一门脚本语言，如 shell,perl,python；
4、有数据集市、数据仓库经验优先考虑；
5、有一年以上相关工作经验
6、善于学习新技术，对新技术有较强的接受能力；



岗位要求
1、搭建分布式的海量数据处理平台，提取关键特征，建立数据模型，提升数据质量；                        2、搭建运营数据平台，建立数据分析/数据挖掘模型，指导产品日常运营；
3、分析海量用户的行为数据，搭建个性化的数据推荐系统，优化产品效果。

任职资格
1、本科及以上学历，计算机、统计和应用数学等相关专业；
2、三年以上大规模数据分析、挖掘相关工作经验；
3、熟悉Linux/Unix平台上的开发环境；
4、熟悉聚类、分类、回归等机器学习算法；
5、对常见的核心算法理解透彻，有实际建模经验者或者熟悉智能业务者优先；
6、具有Hadoop/Spark等大数据分析工具相关使用经验；
7、熟悉至少一种脚本语言（Shell，Python等），能独立完成相关的数据分析、挖掘工作；
8、了解数理统计、数据分析及挖掘，熟知常用算法，有数据仓库和建模理论基础或实际经验；
9、具有良好的数据敏感度，能从海量数据提炼核心结果；
10、具备高度的责任心，对数据分析及挖掘有浓厚兴趣；
11、具备良好的沟通交流能力和文字语言表达能力，较好的逻辑分析能力。

360、小米、百度等顶级互联网公司联合投资，顶级大数据公司 

你将负责
1   设计和开发数美大数据处理系统基础框架和业务组件
2   主导数美大数据平台的设计与开发，解决海量数据面临的挑战；
3   提供充分的系统底层组件，提升整个系统的通用性、性能、可扩展性

我们希望你
1   计算机或相关专业本科（或以上）学历
2   熟练掌握Java或Scala语言和常用数据结构与算法
3   熟悉Hadoop/ Spark/ Storm等框架的机制，具备在Hadoop/ Spark/ Storm上开发软件系统的经验
4   熟练掌握Linux、网络等计算机基础知识，熟练掌握至少一门脚本语言
5、对新兴技术有好奇心，有利用技术解决实际问题的热情，开源社区积极参与者优先
 

数美领先的大数据技术、产品与服务提供商
我们正在经历一个IT到DT的变革时代。大数据已经渗透到各个环节，各个角落。
这个世界，就是掩藏在表象之下，被数据所揭示的世界！
数美依托积累的海量数据、科技前沿技术， 极致的工匠精神和对数据的深度理解，提供领先的大数据产品与服务。 
我们正在寻找不平凡的你，和我们一起“发现数据之美”
欢迎投递简历

【关于数美】www.ishumei.com
      数美由百度、小米、360等顶尖互联网公司联合投资的大数据公司，致力于利用人工智能技术和海量数据解决金融、互联网等领域广泛存在的欺诈问题，先后推出了信贷反欺诈、内容反欺诈、行为反欺诈等系列产品，      
     目前已服务数百家客户，覆盖直播、金融、支付、社交、电商、游戏、O2O等行业。其中包括中信银行、360、小米、58同城、爱奇艺、酷狗、用钱宝、点融、挖财、闪银、熊猫TV、花椒、唱吧等知名企业，并与腾讯云、金山云、七牛云等云服务提供商展开深度合作。
    数美的创始人唐会军在搜索、安全、语音识别等大数据领域拥有十余年研发经验，曾历任百度系统技术负责人、360高级技术总监等职位。创始团队均来自百度、360、小米、宜信、FICO等知名互联网公司，数美核心团队是国内最早一批从事大数据平台与应用研发的团队，曾负责过的大数据平台规模居全球前十。国际顶尖反欺诈技术，拥有十余项专利，同时在安全，反作弊、推荐，广告，语音识别等领域有着丰富的大数据成功应用经验。
           www.ishumei.com


岗位职责:
1. 负责搜索平台的架构、研发和持续优化；
2. 从事分布式存储，并行计算，数据挖掘相关的功能的设计和开发。

岗位要求:
1.5年以上系统研发经验，从事过大型分布式系统的架构、研发工作；
2.熟悉linux平台，精通Java，具有良好的编程习惯和算法基础；
3.有大规模分布式系统理论基础和实践经验，熟悉分布式存储、并行计算、搜索等技术；
4.大于2年的基于Solr／ElasticSearch的搜索系统开发经验；
5.大于2年的分布式存储系统开发经验；
6.有良好的沟通表达能力和团队合作精神，热衷技术，乐于寻求挑战和突破自我。

岗位职责：
1、负责数据分析工具平台的设计和研发；
2、维护公司HADOOP, Spark等相关大数据处理集群；
3、负责公司业务数据的分析挖掘、预测。

任职要求：
1、对大数据处理和数据分析挖掘有浓厚的兴趣；
2、拥有海量数据处理和并行计算开发2年以上经验，熟悉Hadoop，storm，spark，HBase等分布式系统，有开发相关功能的优先，掌握HADOOP，SPARK集群维护相关知识。
3、精通Java，至少2年以上开发经验，精通io，网络通讯、多线程，缓存、消息队列、索引查询等机制，对数据结构和数据统计分析算法有较为深刻理解；
4、掌握redis、Memcache缓存、mongoDB等进行开发；
5、有较好的应用系统设计和开发经验，具有大型数据分析系统开发经验者优先；
6、熟悉数据库和数据仓库，有一定数据建模能力；
7、良好的沟通能力、团队精神和服务意识；
8、良好的逻辑思维能力，能够从海量数据中发现有价值的规律，对数据敏感，能够发现关键数据、发现关键问题；
9、具有强烈的上进心和求知欲，优秀的自主学习能力，自我管理能力。

职责
1.构建数据仓库，udf/udaf等的开发
2.搭建实时计算系统
3.针对开源系统进行二次开发,构建固化及自助查询系统
4.进行数据应用开发，从海量数据中挖掘用户偏好、关联信息，完成用户端的精准推广 
要求：
1、至少1年大数据工作经验，熟练掌握Python/Java/PHP中/C#至少一种编程语言；
2、擅长hadoop，具有M/R程序开发经验、具备分布式数据存储与计算平台搭建/应用开发/运维 相关实践经验；
3、熟练掌握SQL，理解 Hive/Mysql/Sqlserver 基本原理和调优策略；
5、具有storm/spark/kafka/flume/kylin等的开发经验优先
6、了解数据仓库开发流程，有数据仓库(DW)/商业智能(BI)/数据统计 相关工作经验者优先

岗位职责：
1.  负责大数据平台和应用产品的开发工作，包括算法设计及实现
2.  深入发掘和分析业务需求，通独立完成小型项目的系统分析、 设计，并主导完成详细设计和编码的任务，确保项目的进度和质量；
3.  能够在团队中完成Code Review的任务，确保相关代码的有效性和正确性，并能够通过Code Review提供相关性能以及安全的建议；
4.  能够有效地对新人或普通开发工程师进行辅导，帮助其快速成长；
岗位要求：
1.   三年以上Java开发及设计经验，优秀的编程能力及良好的开发习惯。具备独立沟通需求，设计，架构，开发的能力；或者，熟悉数据仓库模型设计，具备海量数据加工处理（ETL）相关经验；
2.   至少熟悉一种关系型数据库如sqlserver、mysql等，熟练掌握Hive/SQL，熟悉Hadoop/Map-Reduce/MPI分布式计算框架，有海量数据处理经验者优先; 
3.   聪明和自我学习。对数据敏感，擅于的发现关键问题；
4.   优秀的沟通和表达能力，清楚的表达个人想法、理解他人观点，具备团队合作意识和推动协作达成的能力。
5.   具有良好的商业敏感度和优秀的数据分析技能，采用实用的分析方法以解决商业问题；
6.   有舆情分析/搜索/CRM系统研发相关项目经验者优先

工作职责：    
    1、负责公司业务数据分析和挖掘、大数据平台设计及研发工作；     2、负责设计、构建、优化基于hadoop/Hbase/Hive的存储平台架构；     3、负责设计构建数据采集框架、网络爬虫、解析处理；     4、根据业务需求，提出最优的数据分析技术解决方案；分解详细的开发任务，能配合其他项目制定开发计划、开发文档、开发流程图；     5、负责带领项目及培训团队，组织技术团队完成数据规则的定义、数据模型的建立、数据清洗、数据迁移、应用实施及推广等工作；     6、负责数据分析架构规划，并制定实施标准和规范，及推进实施；负责编制相关项目资料、技术等工作文档；     7、按要求完成上级领导交办的各项临时性工作任务。    

任职要求：
    1、心胸开阔，具有高度的工作责任心和工作投入精神，坚毅、百折不挠，优秀的个人综合素质、职业素养；     2、具有良好的沟通、组织能力，优秀的分析和解决问题能力，对工作充满激情，具备强烈的进取心和团队合作精神；     3、乐于接受新工作及挑战，学习能力、可塑性强；     4、5年以上软件开发经验，3年以上Hadoop相关开发经验；     5、具备数据库系统基本理论知识，至少掌握一种主流商业数据库产品如Oralce的管理和应用，精通SQL语言，精通存储过程；     6、对hadoop的Map/Reduce原理有深入研究，有相关项目的实际开发经验；     7、熟悉Hadoop、Hive和hbase、storm等开源项目；     8、对基于hadoop的大数据处理体系有深入认识，具备相关产品（hadoop/storm   /hive/hbase）项目应用研发经验，大数据等架构设计和开发经验；     9、具有丰富的数据分析、挖掘和数据仓库建模的项目实践经验。    



参与超大规模数据快速查询系统的架构设计和开发；
大规模数据挖掘和机器学习算法的实现和维护；
在线和离线海量数据分析平台的开发；
研究大数据前沿技术，提升系统的运维效率；
实现大数据基础架构平台（Hadoop/Spark/MPP DB）的自动部署和维护。 

任职要求：

具有3年以上大数据开发经验，至少熟悉一种编程语言（Python/Java/Scala）；
熟悉Hadoop等分布式系统开发，数据仓库技术；
熟悉HDFS/HBase/Hive/MapReduce，掌握Mapreduce程序开发；
熟悉分布式系统概念、架构，有大规模分布式系统设计、实现、部署等经验；
有较强的书面与口头沟通表达能力，独立分析、解决问题的能力，良好的英文读写能力良好。 

加分项：

对安全体系结构有一定了解，有身份认证和权限管理开发经验；
有分布式计算和搜索引擎(如Elasticsearch/Solr/Lucene等)开发经验者；
熟悉报表工具，ETL工具和数据同步工具；
熟悉编译原理，具备良好的数据结构和算法功底；
熟悉SQL语言，了解存储过程和函数；
熟悉JDBC/ODBC标准。

 


职位描述:
1. 负责大数据平台软件的搭建、设计、开发，以及系统问题的解决和性能调优
2. 负责金融大数据中心数据产品的方案设计、开发、维护 


岗位要求：
1. 软件、计算机及相关专业,三年以上工作经验，其中大数据方向至少一年以上。
2. 熟悉Java，Scala，Python 一种或多种语言（一定要有Java及J2EE相关的开发经验）
3. 至少一个或者多个完整大数据实际项目的开发经验
4. 熟悉linux操作，熟练使用shell、python等脚本，了解分布式环境和分布式工作原理。
5. 熟悉Hadoop生态系统组件（HDFS、MapReduce、HBase、Hive、ZooKeeper、Oozie、Yarn、Mahout等）
6. 熟悉Flume、Kafka、sqoop等工具；
7. 熟悉Spark/JStorm
8. 工作认真，负责，具有较好的沟通表达能力和团队合作精神，学习能力强，有较好的逻辑分析能力。钻研技术克服困难，勇于挑战
9. 对大数据分析和处理计算有强烈兴趣。责任心强，能够接受适度加班。

岗位职责： 1、全面负责部门工作，制定部门工作计划以及进度目标2、负责公司产品线相关数据指标统计需求沟通及开发计划安排3、负责平台的搭建及技术框架的选型,新引入技术的预研与培训4、负责核心业务的开发与维护任职资格：1.计算机或相关专业本科以上学历，五年以上Java EE开发经验2. 丰富的互联网网站及后端系统开发设计经验，熟悉相应的技术、运维解决方案3. 熟悉web集群、分布式缓存、数据库集群技术4. 精通Spring、MyBatis、ActiveMQ、Redis、MySQL集群等主流开源框架和技术5. 精通面向对象的分析和设计、设计模式，有设计通用框架及模块的能力6.有大数据处理平台经验7.良好的沟通能力和团队合作精神;有团队管理经验

工作职责：
 
1、负责参与数据平台的设计和开发工作。
2、负责大规模业务数据的建模、分析和挖掘。
3、负责计算和数据分析相关系统的产品化和开放平台的搭建。
 
职位要求：
 
1、本科以上学历，2年以上大数据领域工作经验。
2、至少精通/Java/Scala/Python几种开发语言中的一种。
3、熟悉Hadoop/HDFS以及Hadoop生态相关产品（Hive,Kafka,Storm,Spark...)。
4、良好的沟通、组织协调能力和强烈的责任心，具备很强的分析和解决问题的能力。

岗位职责:1. 本科生及以上学历，2年及以上互联网系统或者其他企业应用系统开发相关经验；2. 熟悉Hadoop/HBase/Spark/Storm/Hive，熟悉数据挖掘策略与算法；3. 具备Java开发经验，Java编程基础扎实，熟练使用struts2、spring、ibatis或hibernate等框架；4. 数据控，善于发现问题、解决问题,具备良好的分析和解决问题的能力，具备一定的钻研精神和持续学习的意愿，强烈的责任感和团队感，对负有挑战性的工作充满热情.

任职条件:
1.全日制本科及以上学历，计算机相关专业，硕士学历优先考虑
2.三年以上Java开发经验，至少1年基于Hadoop的大数据平台开发经验。
3.具有很强的学习能力，分析能力和沟通能力；
4.工作细致，性格稳定，有贡献精神，责任心强；有良好的系统分析能力。
5.具备基于Hadoop大数据处理和分析的多项技术的应用技能，包括但不限于HDFS，Yarn，MapReduce，Hive，Spark，Hbase等
6.熟悉ETL相关开发工具和技术，精通Flume，Kafka，Storm等技术
7.了解主流关系型数据库，精通SQL
 
工作职责
1.负责大数据平台的搭建、问题解决和调优
2.负责项目中和公司已有系统及外部系统的数据对接和ETL工作
3.负责大数据平台上的模型构建和数据挖掘算法的实现
4.负责其他和大数据平台相关的项目的设计和实现
5.维护大数据平台的稳定和可靠

基本条件：
 学历：计算机、通信、电子、自动化及相关专业本科及以上学历。
 工作经验：2年以上相关工作经验。
能力要求：
 具有良好的语言沟通能力,有强烈的团队合作意识及主人翁精神。
技能与素质：
 熟悉Java主流体系架构和设计模式； 
ü 熟悉Struts、Spring、Hibernate等技术； 
ü 熟练使用Oracle、MySQL等关系型数据库系统；
ü 熟悉JavaScript、jQuery、ajax等前端技术； 
ü 熟悉Linux/Unix平台，熟悉tomcat、Resin、nginx 有分布式、高并发情况、海量数据下的开发和调优经验；
ü 有MongoDB、Redis 等NoSQL数据库开发经验优先考虑。
 有以下开发大数据经验者优先：
 熟悉Hadoop以及相关开源的大数据技术，如Hive、Hbase、Storm、Spark、kafka、Zookeeper、机器学习等技术框架；

岗位职责：
1. 负责大数据分析平台的学习、练习、竞赛等模块的开发
2. 与数据分析师沟通，根据需求设计研发平台模块
3. 参与大数据课程产品的开发
任职要求：
1. 信息科学、计算机、数学、统计或相关专业
2. 有很强的编程能力，熟练掌握Python
3. 熟悉机器学习基本模型，如线性回归、逻辑回归、SVM、AdaBoost、神经网络、随机森林等
4. 有Hadoop、Spark等大数据工具使用经验者优先

大数据工程师（基础数据方向） 
岗位职责

协助数据提取，数据开发;
协助数据产品开发。

技能要求

熟悉sql；

  2.熟悉一种语言（java/python等），有快速学习一门新语言的能力；
  3.开发过web项目的优先，有过数据分析和数据挖掘的经验优先；
  4.良好的团队合作精神，较强的沟通能力和钻研能力 。

岗位职责： 1. 负责对客户云应用数据系统进行多维度组合建模，挖掘、分析、提出优化建议； 2. 对用户场景数据进行挖掘、统计建模分析，并提交有效的分析报告。岗位要求：1.熟悉Linux开发环境，主导或参与多个企业级应用开发；2. 至少 3年及以上JAVA或C/C++的开发经验；2. 至少 3年及以上大数据分析建模和应用经验；3. 熟练使用Hive、HDFS、Hbase、Kafka等框架及工具；4. 深入理解MapReduce，要求具备Spark/Hadoop/Storm等大型分布式计算组件使用和开发经验 5. 熟悉数理统计、数据分析、数据挖掘，熟知常用算法；6. 熟悉Mongodb、Redis等常用NoSql数据库7. 具有安全行业就业背景及安全日志数据分析与建模经验者优先8. 具有云应用(SaaS)产品相关数据分析经验者优先其他要求： 全日制本科以上学历，计算机相关专业；

工作职责：
1.     负责构建Spark/HDFS大数据处理架构
2.     基于Spark框架大数据架构的设计、开发和维护
3.     根据相关需求使用SparkStreaming/Storm、SparkSQL进行数据处理、查询和统计
任职资格：
1.     2年（含）以上对于Hadoop、Hive、Impala, Hbase、Spark、Sqoop有实际的编码能力和海量数据的自动化分析处理项目经验
2.     熟悉主流分布式处理框架，基于Hadoop的数据挖掘、大数据组件开发和封装
3.     精通Java语言开发经验，特别是数据库和多线程开发，熟悉常见的Java开发框架及开发能力
4.     有银行项目经验者优先，有数据仓库项目经验者优先


岗位职责：
1、拥有良好的沟通能力，能够根据业务需求分析系统要点及系统开发点；
2、具备项目开发相关工作技能,并及时发现设计工作中的问题,提出解决问题的途径；
3、根据业务需求，进行技术编码，调试，单元测试，能够解决核心技术问题；
4、参与技术需求的调研，技术可行性分析，系统架构的设计、优化；
5、按照需求进行设计开发，解决开发中所遇到的技术难题；
6、完成模块详细设计与开发；
7.负责项目小组的CodeReview
 
岗位要求：
1. 3年以上java开发经验，2年以上大数据开发经验
2.了解jvm的GC机制，有实际GC优化经验
3.深入了解线程安全，锁机制，java并发包使用
4.熟练使用netty通信
5.有阅读源码能力
6.熟练hbase、storm编程API、存储模型等
7.有hbase、storm源码修改经验优先
8.有hbase优化经验优先


职位描述：
1. 智能硬件领域大数据的分析/处理，包括海量数据的存储、计算和检索 
2. 基于分布式平台（storm/Spark/flink）的业务数据分析和逻辑job的开发 
3. 开发数据统计系统，各类统计程序报表（ETL、BI） 
4. 支撑各业务线数据的处理需求 
5. 数据分析 
岗位要求 ： 
1. 计算机、数学或统计学相关专业本科以上学历；3年以上数据的开发相关经验，特别是(1) 离线领域hadoop的ETL开发经验 或者 (2)实时计算领域包括storm、spark、flink等的开发经验 其中之一经验者； 
2. 在整体实时计算的开发、数据建模、全网数据优化、数据挖掘等任一领域有深厚技术积累者优先； 
3. 有较强的sql书写功底，有sql优化经验，熟悉mysql/hive/drill等数据库相关者优先； 
4. 熟悉unix或者linux，具备优秀的编程能力，熟练掌握java或者scala开发，有storm、spark、flink等等语言中的一种或几种经验者优先； 
5. 熟悉数据挖掘等算法相关技术者优先； 
6. 对数据敏感、对技术敏感，有研究的意识和直觉者更佳； 
7. 有良好的团队合作意识，沟通表达能力和综合协调能力。

一经录用，公司将提供有竞争力的薪酬和良好的个人发展空间，员工福利包括：
1、五天工作制，周末双休；
2、公司为每位员工缴纳五险一金；
3、公司提供午餐补助；
4、每天为大家提供丰盛的下午茶；
5、半年或一年一次团队旅游；
6、法定节日及法定假期；
7、传统节日福利礼品或奖金；
8、培训（完善的部门培训）；
9、骨干员工分配股权；
10、绩效奖励及年终奖金；
11、各种经常性的团队建设活动、企业文化活动。

负责业务相关数据指标的抽取、转换、加载，数据维护相关工作；
数据质量控制和元数据整合相关工作；
分析业务需求、数据建模以及数据仓库应用产品的设计、开发；
制定数据质量维护制度、流程，数据质量例行检查；

任职要求：
有大型数据仓库或数据挖掘项目实施经验，精通数据仓库方法论和ETL架构，理解元数据管理；
至少熟悉MySQL、Oracle其中一种数据库，有动手操作能力；
熟悉Linux平台，掌握Shell、Python至少一种脚本；
熟悉SQL/MapReduce/Spark/Storm等任何一种大数据计算工具的编程
熟悉大数据调度系统的架构设计和开发实现
了解常用算法，有推荐系统/知识图谱/反欺诈等任何一种实际的算法工程应用的研发经验
熟悉Python，熟悉scipy/numpy/scikit-learn/matplotlib等模块的应用
熟悉数据可视化的基本方法，有数据可视化的开发经验
对数据敏感，具有良好的逻辑分析；
喜欢创业氛围、责任心强、良好的对外沟通和团队协作能力
能接受短期出差

岗位职责：
1、基于Spark、hadoop等构建数据分析平台，进行设计、开发分布式计算业务；
2、关注业界大数据动态和发展方向，并能够独立研究；
3、辅助管理Spark、hadoop集群运行，稳定提供平台服务；
4、完成与工作相关的技术文档编写工作。

任职资格：
1、本科及以上学历，3年以上编程经验，熟悉Spark、hadoop研发、熟悉大数据集群的搭建、管理及优化；
2、熟悉hdfs/hbase/hive/spark/mapreduce/pig/mahout/impala，有丰富的分布式编程经验；
3、熟悉java研发，有实际编程经验；
4、熟练使用sql；
5、熟练掌握linux操作系统，熟悉shell等脚本编程；
6、有海量数据的分析能力和处理经验、对数据分析和数据挖掘有浓厚兴趣者优先考虑；
7、熟悉Lambda架构者优先考虑

职位描述：
问：我们凭什么吸引你？？？
答：大数据行业·发展前景好·福利待遇优·全员持股计划
我们真的很棒！欢迎投递简历
 
【你需要做的事情】
1、负责公司大数据处理框架设计及算法研发； 2、Hadoop数据平台建设、开发、测试、部署和优化； 3、编写及维护技术开发相关文档； 4、负责大数据平台技术推广和培训。

【你要具备的技能】
1、五年以上Hadoop相关经验； 2、精通java开发，熟悉Linux系统； 3、熟练Hadoop、Yarn、HBase、Hive、Storm、Spark、Pig、Impala等Hadoop系产品和工具，有实际应用经验； 4、熟练分布式计算、MapReduce、流式计算等计算模型； 5、掌握集群的安装和部署，有集群运维和优化经验者优先 ； 6、热爱大数据工作，充满求知欲与好奇心，有较强的责任心及团队意识；善于分析和解决问题。

 
【Our Team】
我们的小伙伴们是一支有多年互联网IT技术与广告优化经验的专家技术团队，曾服务于百度、新浪、网易等各大互联网广告公司，并且结合 RTB广告的特点，创造出具有行业独特性、领先性的计算广告优化服务体系。
 
【你将得到】
员工福利——免费水果零食饮料无限量供应；节日礼物；生日聚会；每年设有年度长途旅行、季度出游、不定期outing；
薪酬保障——行业高薪，全面激励；绩效导向，体现差异；年底双薪、年终奖金、股权激励等；
培训发展——员工享有内部培训、外部培训、岗位辅导、研讨交流会等多种培训和发展机会；
康乐计划——设有员工俱乐部，每周组织羽毛球、篮球、足球等活动，定期健康体检；
社会公益——设有“优雅关爱行动基金”，不定期组织社会公益活动。

工作职责：1 、运用机器学习相关技术，对海量数据进行处理和分析，挖掘相关信息，建立模型，分析关键因素，优化地图相关产品的效果； 2 、跟进数据挖掘，机器学习相关技术的业界发展，并合理的运用到实际产品中； 3、 建立完善的线上线下流程和架构，迭代改进，不断提升系统性能； 4、 基于数据，协同PM，对产品进行优化和创新，提升用户体验。 任职资格：1、具备数学、计算机科学或相关专业领域大学本科及以上学历； 2、扎实的数据结构、模型和算法设计与分析能力； 3、熟练使用scala/java/python 中的一种或几种；4､ 熟悉hadoop/spark环境，具有相关开发经历，并能灵活运用spark mlib库进行算法设计；5、熟悉Linux/Unix 环境开发经验； 6、有相关工作经验优先。 

1.本科及以上学历，计算机相关专业者优先，2年以上数据分析相关工作经验； 2.对工作有富有热情，工作责任心强； 3.熟悉Hadoop，r,python，shell java c++等语言，熟悉常用数据分析方法；4..对数据有敏感、熟悉数据挖掘算法包括常用的分类、聚类、关联、推荐算法等；5.有互联网、金融或者航司等相关工作经历优先。

岗位职责：
1、结合公司大数据分析平台的规划，搭建以hadoop技术体系为核心的集群环境；
2、结合业务的实际数据情况，设计、开发基于hdfs/hbase/hive的数据查询分析；
3、辅助运维人员管理Hadoop集群环境，不断提高系统运行效率；
4、大规模日志分析、统计和建模。
岗位要求：
1、硕士及以上学历，计算机、软件、电子通信等相关专业；
2、精通java语言，熟悉JVM运行原理；
3、熟悉hadoop框架，熟练应用map-reduce，拥有海量数据分布式系统的开发经验优先；
4、熟悉Java、Shell，可以熟练使用Linux操作系统，了解Linux集群技术者优先；
5、了解数据挖掘技术，对数据结构、算法有所理解；
6、熟悉shell, python 或 R语言加分。

福利待遇：
1、免费员工公寓（提供热水器、免费wifi等）、员工餐厅供应三餐；
2、五险一金齐全，社保体系完善；
3、处于业界较高水平的薪资待遇，每年1-2次的薪资晋升；
4、篮球场、羽毛球场、台球室、乒乓球室等休闲设施场所供应；
5、定期健康检查、贴心的生日礼物、节日礼物；
6、五天工作制，带薪假期（年假、病假、婚假、产假）；
7、花园式的工作环境，宽敞明亮的办公环境。
发展平台：
1、国家大力支持的朝阳行业，博士后工作站，蓝鸽科研院，重视技术发展，培训、交流机会多；
2、新员工参加培训，一对一导师制，表现优秀可以进入公司战略人才培养计划；
3、公司大力启用优秀人才，两年带项目不是梦；
4、开发人员往“技术专家”和“高层管理”双线发展，公司百分之八十的技术高管和管理人才都是从内部选拔提升。


岗位职责： 
1、负责大数据平台搭建，数据仓库建模，及相关运维工作； 
2、利用大数据相关技术实现对数据的分析、挖掘、处理、及数据可视化等相关工作； 
3、维护大数据平台并能解决相关问题, 保障平台正常运行； 
5、学习和研究新技术以满足系统需求。 
6、其他部分开发任务。
 
任职资格： 
1、本科及以上学历，计算机、通信、统计、数学等相关专业； 
2、有hadoop集群运维经验优先；  
3、对互联网产品有见解，关注前沿技术，有较强的学习能力、分析能力和动手能力； 
4、熟悉Linux操作系统及ORACLE、MySQL、Postgre等数据库，了解SQL优化，熟悉ER模型和相关数据建模技术，能够熟练使用Java或Python、SHELL； 
5、熟悉Hadoop的体系架构和运行原理，有大数据处理方面经验；
6、具有大型数据仓库和ETL开发、HIVE、Kylin、Cloudera开发经验优先 
7、个性乐观开朗，沟通能力强，具备良好的团队协作精神，能利用自身技术能力提升团队整体研发效率。

工作年限：2年以上
职位描述：
1、负责hadoop/spark平台技术引进和推广，并能结合用户需求快速落地推广； 
2、负责大数据分析需求设计和开发，包括数据集市、实时分析、数据展示等的开发，并交付生产，确保输出成果； 
3、负责项目成果在公司内的推广应用、培训，以及对外对内合作交流，不断提升公司的技术和应用能力。

招聘要求：
1、计算机科学、应用数学、物理学等相关专业，本科以上学历； 
2、具有2年以上BI/报表相关工作经验，熟练掌握hadoop hive开发，有一定调优经验；
3、能熟练使用sqoop等作为etl工具，有tableau/qlikview开发经验； 
4、有良好的口头和书面表达能力； 
5、良好的结构化问题解决能力。

岗位职责:
1.制定数据平台的发展方向与前期规划；
2.负责大数据产品市场调研、产品设计；
3.负责大数据产品沟通、资源协调，推动产品上线；
4.时刻关注产品相关信息，落实日常维护和功能改进，提高产品的用户体验 。

岗位要求:
1.大专以上学历，3年以上工作经历；
2.具备移动客户端或Web端产品设计和管理经验，熟悉移动互联网产品和服务； 
3.具备优秀的需求分析和产品规划能力，独立的业务分析、数据分析、竞争分析能力和见解； 
4.良好的沟通协调能力，逻辑能力以及团队合作精神、执行能力强，乐意接受有挑战的工作；  
5.及时掌握行业最新动态，关注行业、业务发展趋势，关注创新性产品理念，并对关键点有独立见解； 
6.有物流领域背景或者大数据产品经验者优先。

一、岗位职责：1、拥有良好的沟通能力，能够根据业务需求分析系统要点及系统开发点；2、具备项目开发相关工作技能,并及时发现设计工作中的问题,提出解决问题的途径；3、根据业务需求，进行技术编码，调试，单元测试，能够解决核心技术问题；4、参与技术需求的调研，技术可行性分析，系统架构的设计、优化；5、有带领4-5人团队的项目开发的经验，按照需求进行设计开发，解决开发中所遇到的技术难题；6、完成模块详细设计与开发；7、指导其他开发工程师的学习和工作；8、参与爬虫核心算法的策略优化研究，提升网页抓取的效率和质量。
二、岗位要求：
1、大学本科以上学历，扎实的微机原理、网络、算法和数据结构基础。对于HTTP、HTTPS、TCP/IP协议原理非常熟悉。2、扎实的core Java基础。Java io、NIO、多线程、JVM、集合、Exception等概念清楚、应用熟练。3、至少两年以上Java web开发经验，servlet、springMVC、spring、myibatis、JavaScript、Jqery、HTML开发和调试技能熟练，基本原理清楚。Rest风格编程技能熟练。4、热爱技术，爱岗敬业，执行力强。乐于学习、钻研和分享，不辞劳苦。5、熟练掌握Hadoop、HDFS、map/reduce、Hive、Hbase、kafka的工作原理和编程、部署，而且有至少一年以上生产经验。6、熟练掌握ElasticSearch、spark（spark streaming等）、storm、impala、flink等优先，对于动态增量更新索引有深入研究或者有生产经验者优先，有ELK生产经验者优先，有大数据BI经验（不是Oracle经验）者优先，有用户画像、自动征信系统经验者优先，有mahout经验者优先。

主要职责：
- 基于采集数据提炼、分析、归纳用户属性、行为等信息，输出分析报告； 
- 处理用户海量数据，挖掘用户行为特征，为运营、风控和产品提供参考依据； 
- 针对具体业务问题，研究影响用户的潜在因素，进行数据分析验证并提出改善举措； 
- 参与各业务部门的重点项目，负责从数据的角度给出决策建议； 
- 参与实现业务所需的应用系统开发

职位要求：
- 2至3年java开发经验，具备扎实的程序设计基本功和学习能力
- 熟练使用Spark、MapReduce以及相关组件，对源代码或系统优化有一定研究者优先； 
- 熟练掌握scala/python其中一种语言； 
- 有2年以上的数据挖掘或者互联金融用户行为分析相关工作经验优先； 
- 有较强的人际沟通、协调能力，具备与技术人员沟通数据需求的能力； 
- 有海量数据分析经验者优先；统计学、概率学、计算机信息管理等相关专业研究生以上学历优先考虑； 
- 具备很强的软件开发能力和背景，能根据业务数据要求提供解决方案。 

岗位职责：
1. 负责数据的ETL的工作；
2. 负责数据分析工具平台的设计和研发；
3. 让数据平台为公司的商业决策提供有效的支持。
 
任职要求：
1. 对大数据处理和数据分析挖掘有浓厚的兴趣；四年及以上相关工作经验；
2. 精通MySQL,能够用SQL解决复杂问题；熟悉ETL的方法；
3. 精通Hadoop、Hive；熟悉Java/Scala/Python、Linux；
4. 了解Spark、Storm、ELK；
5. 良好的沟通能力、团队精神和服务意识；
6. 良好的逻辑思维能力，能够从海量数据中发现有价值的规律；
7. 对数据敏感，能够发现关键数据、发现关键问题。


参与超大规模数据快速查询系统的架构设计和开发；
大规模数据挖掘和机器学习算法的实现和维护；
在线和离线海量数据分析平台的开发；
研究大数据前沿技术，提升系统的运维效率；
实现大数据基础架构平台（Hadoop/Spark/MPP DB）的自动部署和维护。

任职要求：

具有5年以上大数据开发经验，至少熟悉一种编程语言（Python/Java/Scala）；
熟悉Hadoop等分布式系统开发，数据仓库技术；
熟悉HDFS/HBase/Hive/MapReduce，掌握Mapreduce程序开发；
熟悉分布式系统概念、架构，有大规模分布式系统设计、实现、部署等经验；
有较强的书面与口头沟通表达能力，独立分析、解决问题的能力，良好的英文读写能力良好。 

加分项：

对安全体系结构有一定了解，有身份认证和权限管理开发经验；
有分布式计算和搜索引擎(如Elasticsearch/Solr/Lucene等)开发经验者；
熟悉报表工具，ETL工具和数据同步工具；
熟悉编译原理，具备良好的数据结构和算法功底；
熟悉SQL语言，了解存储过程和函数；
熟悉JDBC/ODBC标准。


岗位描述：
1、负责交通服务相关产品的设计与开发
2、能够根据业务以及产品运营的需求变化，整理相配套的技术解决方案；
3、基于Storm，Spark实施数据采集、分析，算法设计等相关工作。
 
岗位要求：
1、3年以上Java开发经验，扎实的Java编程基础，本科及以上学历
2、精通Storm、Kafka、HBase、Spark、Hive等大数据领域实时与离线技术，有海量数据处理的项目经验；
3、研究过相关开源项目源码者优先
4、有个性化推荐系统开发经验者优先；
5、有数据挖掘、机器学习，优化理论研发实践经验者优先
6、具有良好的沟通能力、组织能力及团队协作精神，有较强的分析和解决问题的能力；

岗位职责：
1、负责AppStore数据收集平台的建设，保证从几千个节点收集来的数据的实时性和一致性；
2、负责分布式数据处理平台的建设，保证离线计算、实时计算系统的性能和稳定性；
3、理解数据分析和挖掘的应用场景，对数据进行合理的建模；
4、理解各产品线的业务，提炼为数据产品的需求，完善数据产品，以数据推动业务发展。
 
任职资格：
1、掌握java, python, scala等高级语言一种以上；
2、熟悉SQL语句，熟悉主流关系型数据库MS SQL Server、Oracle、MySQL其中一种；
3、熟悉大数据平台生态如hadoop, spark, storm, hive, elasticsearch, kafka, flume者优先；
4、有数据统计、机器学习基础者优先

职位描述1. 负责公司大数据平台分布式数据收集系统的架构、设计和开发工作2. 负责分布式数据收集系统的性能监控和持续优化;3. 跟踪分布式系统事务处理、分布式消息队列、实时传输协议等相关技术领域的发展趋势，并主动发起改良计划。任职要求1. 优秀的代码能力，熟练掌握C/C++/GO中至少一门语言；2. 具有解决高并发问题的实战经验和分布式系统的研发经验；3. 熟练掌握HTTP,TCP/IP等网络传输协议的工作原理，并有相关协议的调优经验;4. 了解Nginx HTTP/STREAM框架工作原理的优先；5. 熟练掌握RabbitMQ/NSQ/RocketMQ/Disque/Kafka至少一种分布式消息队列的工作原理的优先；6. 有优良的Trouble Shooting能力，能解决各种性能瓶颈（比如IO、CPU、Memory等）优先。

岗位职责：
1、负责大数据体系的搭建及数据仓库的建设及维护；
2、负责数据仓库模型的设计及大数据开发工作；
3、负责实时计算等流处理平台的建设及维护；
4、结合公司产品和业务发展，研究相关的大数据前沿技术并应用。
岗位要求：
1、熟悉Hadoop等相关大数据技术，如Hive,HBase,Spark等；
2、熟悉kafka、storm/(或spark streaming）等相关流处理技术；
3、熟练掌握HQL、MR编程技能；
4、三年以上数据仓库或大数据平台开发经验；
5、本科以上学历。

岗位职责：
1、负责和参与公司大数据平台的技术栈设计、选型和相关开发；
2、负责和参与公司数据产品的规划、设计和研发；
3、参与大数据平台的部署运维，保障其服务的可靠性和稳定性；
4、研究大数据前沿技术，持续优化大数据分析平台相关技术栈。
 
任职要求：
1、具备扎实的开发能力，至少3年以上java/c/c++/python开发经验，java优先；
2、精通大数据平台技术，3年以上hadoop或spark生态相关工作经验；
3、熟悉aws大数据技术栈EMR、kinesis、athena、redshift等更佳；
4、精通数据分析挖掘技术，熟悉机器学习和人工智能技术更佳；
5、掌握数据库开发技术，了解常用nosql数据库的使用及其分布式集群技术原理；
6、了解云计算技术，熟悉公有云平台；
7、具备沟通及表达能力、独立分析及解决问题的能力；

1、参与基于Hadoop/Spark平台生态圈的分布式数据平台开发；
2、参与基于ElasticSearch/Solr的全文搜索引擎开发；
3、参与大数据项目方案设计，技术售前，技术售后工作，研发管理，研发大数据平台，管理团队
任职要求：
1)有Hadoop相关组件（Spark, Spark Streaming, MR, Flume, Kafka, Kudu, HBase, Hive )使用经验，有快速定位并解决开发中相关开源组件的问题，有性能优化经验者优先。
2）熟练使用Scala，Java语言，可针对大数据组件进行相关开发，能够用最适合的工具解决最合适的问题。
3）有Linux系统使用经验，熟悉Shell脚本编写则更佳。
4）有ElasticSearch，Redis， Neo4J等使用经验更佳。
5） 有机器学习，数据挖掘相关领域经验更佳。
6）有责任心，有快速学习的能力，愿意加入最棒的大数据团队，做最棒的产品
员工福利：年底双薪、带薪年假、弹性工作、员工活动、交通补贴、五险一金等

岗位职责【大数据平台方向】
1、负责大数据平台的开发，维护，数据管理。
2、应业务部门要求，提供相关的分析支撑。
岗位职责【大数据应用开发方向】
1、负责市场业务数据需求分析及开发
2、负责市场业务数据分析系统设计、开发
3、主导市场各阶段数据的整理
4、配合业务，进行数据挖掘相关程序开发 

任职要求：
1、计算机相关专业本科或以上学历，1年以上工作经验 ；
2、熟悉关系型数据库，熟悉SQL语言，有spark、hadoop、
Elastic Search 、列式数据库开发经验优先；
3、熟悉Linux、UNIX等操作系统及开发环境；
4、精通至少一门主流开发语言，有Python、Ruby开发经验优先；
5、喜欢分析数据，对数字有敏感性，工作条理性强，逻辑清晰；
6、工作认真、细致、坚持不懈、态度严谨，善沟通及团队合作。 

360、小米、百度等顶级互联网公司联合投资，顶级大数据公司

你将负责
1   设计和开发数美大数据处理系统基础框架和业务组件
2   主导数美大数据平台的设计与开发，解决海量数据面临的挑战；
3   提供充分的系统底层组件，提升整个系统的通用性、性能、可扩展性

我们希望你
1   计算机或相关专业本科（或以上）学历
2   熟练掌握Java或Scala语言和常用数据结构与算法
3   熟悉Hadoop/ Spark/ Storm等框架的机制，具备在Hadoop/ Spark/ Storm上开发软件系统的经验
4   熟练掌握Linux、网络等计算机基础知识，熟练掌握至少一门脚本语言
5、对新兴技术有好奇心，有利用技术解决实际问题的热情，开源社区积极参与者优先
 

数美领先的大数据技术、产品与服务提供商
我们正在经历一个IT到DT的变革时代。大数据已经渗透到各个环节，各个角落。
这个世界，就是掩藏在表象之下，被数据所揭示的世界！
数美依托积累的海量数据、科技前沿技术， 极致的工匠精神和对数据的深度理解，提供领先的大数据产品与服务。 
我们正在寻找不平凡的你，和我们一起“发现数据之美”
欢迎投递简历


【关于数美】www.ishumei.com
      数美由百度、小米、360等顶尖互联网公司联合投资的大数据公司，致力于利用人工智能技术和海量数据解决金融、互联网等领域广泛存在的欺诈问题，先后推出了信贷反欺诈、内容反欺诈、行为反欺诈等系列产品，      
     目前已服务数百家客户，覆盖直播、金融、支付、社交、电商、游戏、O2O等行业。其中包括中信银行、360、小米、58同城、爱奇艺、酷狗、用钱宝、点融、挖财、闪银、熊猫TV、花椒、唱吧等知名企业，并与腾讯云、金山云、七牛云等云服务提供商展开深度合作。
    数美的创始人唐会军在搜索、安全、语音识别等大数据领域拥有十余年研发经验，曾历任百度系统技术负责人、360高级技术总监等职位。创始团队均来自百度、360、小米、宜信、FICO等知名互联网公司，数美核心团队是国内最早一批从事大数据平台与应用研发的团队，曾负责过的大数据平台规模居全球前十。国际顶尖反欺诈技术，拥有十余项专利，同时在安全，反作弊、推荐，广告，语音识别等领域有着丰富的大数据成功应用经验。
           www.ishumei.com

职位描述：
主要职责：
- 基于采集数据提炼、分析、归纳用户属性、行为等信息，输出分析报告； 
- 处理用户海量数据，挖掘用户行为特征，为运营、风控和产品提供参考依据； 
- 针对具体业务问题，研究影响用户的潜在因素，进行数据分析验证并提出改善举措； 
- 参与各业务部门的重点项目，负责从数据的角度给出决策建议； 
- 参与实现业务所需的应用系统开发

职位要求：
- 2至3年java开发经验，具备扎实的程序设计基本功和学习能力
- 熟练使用Spark、MapReduce以及相关组件，对源代码或系统优化有一定研究者优先； 
- 熟练掌握scala/python其中一种语言； 
- 有2年以上的数据挖掘或者互联金融用户行为分析相关工作经验优先； 
- 有较强的人际沟通、协调能力，具备与技术人员沟通数据需求的能力； 
- 有海量数据分析经验者优先；统计学、概率学、计算机信息管理等相关专业研究生以上学历优先考虑； 
- 具备很强的软件开发能力和背景，能根据业务数据要求提供解决方案。 

职位描述：
1. 负责项目中数据处理工作(数据采集、清洗、汇总、集成等),保证数据的准确性和稳定性；2. 负责协助完成应用系统中数据上下层衔接处理工作；3. 对用户数据进行分析和挖掘，提供决策支持；4. 大数据数据产品策划，对数据库信息的深度挖掘，充分体现数据的商业价值职位要求。

岗位要求：
1. 精通java或php至少一门编程语言，两种都熟悉优先；2. 精通shell脚本编程，至少熟悉Python或perl等一门语言;3. 熟悉HTTP协议;4. 熟悉Hadoop/Hive/Hbase/Spark/Storm等分布式计算环境进行海量数据分析与计算经验者优先;5. 做过数据仓库,对数据治理、数据标准及元数据有很好理念及实施经验的优先;6. 良好的沟通能力和团队精神,具备创新意识；7. 以结果为导向,具有强烈的责任心、钻研精神和良好的团队沟通能力。

岗位职责：
1、负责大数据平台的整体架构设计和开发。
2、负责大数据产品API的设计和开发。
3、参与广告数据实时流计算的设计和开发。
4、负责大数据领域数据整合产品的研发。

任职要求：
1、计算机、应用数学等相关专业本科及以上学历，3~5年以上大数据处理平台的架构设计和经验。
2、熟悉算法设计/数据结构，熟悉JAVA语言编程，并有实际产品或项目开发经验。
3、熟悉并使用过一种或多种离线数据处理工具，包括但不限于：Hoodap Hive Hbase spark 。
4、掌握实时流计算技术，有Spark Streaming 开发经验者优先。
5、有hadoop相关的实际开发及运维经验。
6、思路敏捷清晰，再学习能力强，团队意识高。

【岗位职责】
1、参与设计客户要求的大数据/数据挖掘系统，并撰写相关文档；
2、负责核心代码的编写，并对产品开发质量进行把关；
3、负责大数据/数据挖掘系统环境的维护以及调优；
4、跟踪大数据技术领域趋势并能结合实际应用到业务中；
5、攻克大用户量、高并发等不同技术场景下的挑战。
 
【基础要求】
1、计算机、数学、统计学等相关专业，大学本科及以上学历；
2、至少三年相关工作经验；
3、踏实敬业、热爱编程，喜欢钻研新技术；
4、具有团队意识，乐于分享互助，能与团队成员进行高效沟通；

【技术要求】
1、熟练掌握大数据/机器学习方法及相关算法，对数据结构、算法有深刻理解；
2、具有实际的大数据、数据挖掘、BI项目的架构设计及开发经验
3、精通java开发，熟悉Hadoop/MapReduce、HBase、Hive等系统开发；
4、熟悉关系型数据库、半结构化数据存储理论，具有实践经验；
5、熟悉Linux开发环境；
6、有一定的数学建模和分布系统功底或获得过相关竞赛奖项者优先。

【福利待遇】
1、工作时间：朝九晚六，双休；
2、法定福利：五险一金+法定节假日+加班补贴；
3、公司福利：股权激励+项目提成+节日福利+活动聚餐。

应聘者请先进入本公司官网进行相应了解后再投递简历，感谢配合！

只要您水平够高，能力够强，薪资可再商洽，我们欢迎您的加入。
优秀的技术团队，广阔的发展平台，融洽的工作氛围都在等着您！

1、负责公司数据处理工作(数据采集、清洗、汇总、集成等),保证数据的准确性和稳定性；
2、负责协助完成应用系统中数据上下层衔接处理工作；
3、对用户数据进行分析和挖掘，提供决策支持；
4、大数据数据产品策划，对数据库信息的深度挖掘，充分体现数据的商业价值职位要求；

任职资格
1、 扎实的编程能力，熟悉算法和数据结构，熟悉计算机的基础理论。
2、 熟练使用 Java，熟悉Shell   、Python、 R、Scala 等一种以上语言
3、 熟悉大数据处理相关技术，包括但不限于 Hadoop、Hive 、Hbase、   Impala、Spark ，Kafaka、 Flume、Sqoop 、Storm、 Redis等。
4、 熟悉推荐系统和数据挖掘算法者优先。
5、 有房地产相关项目开发经验优先
6、 学历要求：本科或以上，计算机软件或相关专业毕业。3年以上大数据基础平台开发或大数据分析从业经历。
   


岗位职责：
1、负责数据仓库和大数据处理模块的架构设计和开发；
2、负责基于Spark技术的海量数据的处理、分析、统计、挖掘工作；
3、基于Spark框架的数据仓库的设计，开发，维护；
4、根据需求使用Spark Streaming和Spark SQL进行数据处理、查询、统计等工作。

任职资格：
1、本科及以上学历，计算机相关专业，3-5年以上该领域产品研究和开发的工作经验；
2、熟悉Spark相关技术，至少有1年的Spark开发经验；
3、熟悉Scala语言，对Scala原理、底层技术有深入研究者优先；
4、熟悉Spark Streaming和Spark SQL；
5、有优良的Trouble Shooting能力；
6、有过海量数据系统开发经验者优先；
7、在开源社群活跃并有积极贡献者优先。
8、对新技术钻研有强烈兴趣，有良好的学习能力和强烈的进取心, 有创新精神, 有良好的团队沟通和管理能力。

岗位职责：
1.基于海量数据的数据仓库建设、数据应用开发； 
2.分布式平台应用开发（Hadoop/Hive/Hbase）； 
3.开发数据统计系统，各类统计程序报表 ；
4.支撑各业务线数据需求。

任职要求：
1.具有丰富的数据仓库开发经验，有2年以上互联网或移动互联网并基于Hadoop/Storm/HIVE/Hbase等应用开发经验，对分布式计算、数据仓库理论有深刻理解 ；
2.熟练掌握linux常规命令与工具 ；
3.对Hadoop、Hive、Storm等源码有研究优先 ；
4.精通JAVA、MapReduce、Python，有并发应用或者分布式应用软件开发经验优先 ；
5.精通shell编程，sql编程、awk脚本语言等； 
6.良好的系统分析、架构设计能力； 
7.对数据敏感、对新技术敏感，有数据挖掘技能者优先 ；
8.了解无线端技术、有ios/android下开发经验者优先；
9.对商业和业务逻辑敏感，具备良好的分析、组织、沟通能力和团队精神。

岗位职责：
1、负责大数据项目需求分析、架构设计及技术实现，并编制形成技术方案；
2、负责大数据平台基础环境的搭建；
3、负责大数据核心技术的攻关和系统优化，协助解决开发过程中的技术难题； 
4、参与大数据技术标准、规范等制定；
5、完成领导交代的其他工作。
任职要求
1、具有5年以上的软件项目开发经验，参与过大中型项目规划与实施；
2、精通WebService和J2EE等架构，熟悉Java、UML和XML等技术；
3、熟练使用关系型数据库、ETL、数据分析建模等工具； 
4、熟悉分布式系统的架构，有分布式系统架构设计的经验；
5、熟悉hive、pig、python、shell等脚本语言；
6、具有良好的团队意识和协作精神，有较强的沟通能力和书面语言能力；
7、互联网公司大数据平台设计人员优先。

岗位职责：
结合公司数据分析平台的规划，搭建以 Spark 技术体系为核心的集群环境； 结合业务的实际数据情况，设计、开发基于 Spark 的数据查询分析；
负责Hadoop/Spark组件功能和性能优化设计和实施落地工作； 大规模数据分析、统计和建模，为公司战略提供数据支持； 辅助运维人员管理集群环境，不断提高系统运行效率。

任职要求：
本科及以上学历，三年以上大数据开发工作经验； 精通Java、Scala语言开发，精通 Python 者优先；
熟悉 Mysql、Kafka
熟悉Hadoop生态圈，深度了解Hadoop/Spark/HBase 组件实现原理，具备二年以上Hadoop/Spark调优经验
熟悉数据仓库原理；

职位内容：

1. 参与数据分析平台的系统分析与设计，并负责平台核心模块的设计与研发。
2. 优化和维护大数据平台系统，确保高可用性和稳定性。
3. 调研服务化治理方案的开源框架，定制研发公司自有的微服务平台。
4. 关注大数据类技术方向，进行持续跟踪和学习以及技术攻关工作。

职位要求：

1. 计算机相关专业，3年以上项目开发经验，2年以上大数据或数据挖掘项目经验
2. 具备良好的Java开发技能，熟练使用Java各种开源项目库（Spring、Guava、Apache Commons）等。有Scala开发经验者优先。
3. 熟悉Linux系统，能够在Linux环境中熟练地部署、配置和开发大型复杂的平台软件,至少熟悉一门脚本语言(shell或python)。
4. 对大数据基础架构和平台有全面和深刻的理解。熟悉以下大数据技术和系统之一优先：Hadoop Ecosystem（如HDFS, Hbase, MapReduce/YARN, Hive等）、Spark、Storm Elasticsearch。
5. 熟悉分布式存储和非结构化数据相关NoSQL或NewSQL等数据库技术，例如 Hbase、 mongodb、Redis等，理解其原理和工作模式。
6. 了解分布式服务框架，对微服务架构和服务化治理有深入研究。熟悉DUBBO框架者优先。
7. 具有很强的团队意识、沟通能力和独立解决问题的能力，学习能力和主动性强，具有钻研精神，充满激情，乐于接受挑战

岗位职责：
基于Hadoop，Spark进行大数据分布式处理
能根据要求进行相关数据处理开发工作能进行部分数据算法研究工作
任职要求：
熟悉Linux开发环境；至少熟练掌握Python、Java、Scala 之一
英语良好，能正常阅读英语技术文档
良好的统计学知识
熟悉Hadoop，熟练掌握MapReduce程序编写
听从职位安排，能流畅沟通
拥有基本的机器学习算法功底

工作职责：
1. 负责业务相关数据指标的计算和挖掘； 
2. 负责数据建模以及数据仓库应用产品的设计和开发；
3. 负责数据仓库ETL流程的优化及解决ETL相关技术问题。
4. 负责响应业务方提出的各种数据需求
5. 负责数据仓库的持续建设
工作要求：
1、本科及以上学历，计算机相关专业
2、2年以上企业级数据仓库开发经验
3、熟悉数据仓库理论，具备复杂业务需求梳理能力
4、熟练SQL开发，精通Mysql等关系型数据库中的一种或几种
5、熟练掌握Hadoop及MapReduce应用开发，熟练掌握HBase、Hive、Storm、spark等大数据开发工具中一种或几种
6、熟悉Linux系统，具备shell、python等脚本开发能力者优先
7、学习能力强，喜欢研究开源新技术，有团队观念，具备独立解决问题的能力

加分项：
1、有物流供应链业务背景优先
2、有从0搭建企业级数据仓库经验的优先
3、有优秀的业务建模经验的优先

岗位职责：
1.负责基于 Hadoop/Spark/ES 生态的系统研发；
2.负责公司大数据的处理、建模、分析、挖掘及存储；
3.处理海量数据离线计算、在线计算相关的开发工作；
4.负责 Hadoop/Spark 集群调优；
岗位要求：
1.本科以上学历，从事大数据开发工作二年以上；
2.具备扎实的计算机理论基础，对数据结构及算法有较强的功底；
3.熟悉Java/Scala，熟悉JVM，具备优秀的系统问题追查和性能调节优化能力，熟悉常见的面向对象设计模式，具备优秀的系统构架设计能力；
4.熟悉Hadoop，hive，HBase，Kafka，ES等开发技术，熟练掌握Hadoop、hive/HBase的数据开发应用；
5.熟练掌握LINUX常规命令与工具；
6.具备大规模云集群性能调整优化经验者优先。

职位描述：
岗位职责：1、搭建基于Hadoop/Spark/Shark的大数据平台，负责数据架构设计及前端数据应用开发工作；2、完成各种面向业务目标的从数据模型、数据分布、数据传输、数据存储等方面进行大数据系统架构的设计和数据架构；3、数据性能分析与克服;4、新技术的研究与导入。


任职要求：1、具有4年以上互联网或移动互联网并基于Hadoop/Hbase等应用开发经验，对分布式计算理论有深刻理解；2、精通JAVA、熟练掌握MapReduce原理、对Hadoop、Hbase、Hive等主流云计算、大数据相关软件有充分的了解，研读过源代码者优先，并且有实践经验，能解决应用中的复杂问题；3、熟悉BI工具及方法论，有大数据分析与数据仓库设计及开发经验；4、熟悉linux/UNIX Shell、熟悉(Perl/python/shell)任意一种脚本语言；5、熟悉kafka等消息框架，了解flume等日志搜集系统；6、熟悉Storm等流计算框架或其他开源实时计算框架；7、熟悉Spark、SparkSQL、SparkStreaming等框架并能实际使用8、个性开朗，对技术钻研好学、逻辑思维能力强，沟通能力优秀，有团队合作精神。

职位描述：
1、构建分布式大数据服务平台，参与和构建公司包括海量数据存储、离线/实时计算、实时查询，大数据系统运维等系统
2、服务各种业务需求，服务日益增长的业务和数据量
3、深入源码内核改进优化开源项目，解决各种hadoop、spark、hbase疑难问题，参与到开源社区建设和代码贡献
岗位要求：
1、计算机或相关专业本科以上学历（3年以上工作经验）
2、精通C++/Java/Scala程序开发(至少一种)，熟悉Linux/Unix开发环境
3、熟悉常用开源分布式系统，精通Hadoop/Hive/Spark/Storm/Flink/HBase之一源代码
4、有大规模分布式系统开发、维护经验，有故障处理能力，源码级开发能力
5、具有良好的沟通协作能力，具有较强的分享精神
6、对Kudu、Kylin、Impala、ElasticSearch，github等系统有深入使用和底层研究者加分

职责：
1，负责数据库、数据处理、数据存储相关逻辑开发；
2，负责大数据特征工程与统计学逻辑的开发；
3，负责数据处理与分析工具的开发；
4，负责数据产品与服务化的逻辑开发；
要求：
1，本科或以上学历；
2，熟练掌握至少一门编程语言：C++／Java／Python，熟练掌握Linux日常操作；
3，正常的逻辑思维与沟通理解能力；
4，能够独立完成模块功能开发，具备良好的代码风格，能够独立完成单元测试与程序部署；
5，精通数据结构与程序算法者优先，对数据挖掘、机器学习、统计学算法原理有所了解者优先；
6，一般互联网文化素质要求；

【岗位职责】

1、针对业务需求，负责开发可扩展的、分布式的大数据系统；

2、面向业务目标，从数据模型、数据分布、数据传输、数据存储等方面进行大数据系统的开发；

3、研究前沿的数据分析建模，数据挖掘及机器学习算法，探索具有数据分析、数据挖掘能力的创新型产品。

【岗位要求】

1、至少3年以上hadoop，hive，spark开发经验；

2、精通Hadoop生态系统及相关组件，拥有Apache Hadoop实施经验；

3、精通Spark计算框架的实时采集和流处理；

4、精通Java、scala编程；

5、熟悉整个大数据的处理流程，包括数据的管理，数据的分析挖掘，服务器扩展；

6、优秀的客户服务意识，客户管理意识；思想意识开阔；

7、逻辑思维能力强，具备优秀的文档编写和良好的沟通与表达能力；

8、具有较强的沟通协调、团队合作和抗压能力。

岗位职责：
1、通过日志数据进行用户行为数据的分析挖掘 ；
工作职责： 
-对日志数据以及其他业务线数据进行收集存储；
-开发处理ETL的流程，离线的数据仓库开发，实现自动化hive建表并导入数据；
-实时数据分析功能的开发 
-开展用户行为分析相关的离线计算工作，协助架构师构建用户数据模型、建立DMP平台。
-大数据平台的构建和运维，Hadoop、hive、Storm、spark等。 

职位要求： 
1.机器学习、信息检索、统计学等相关专业学习过，有过相关实习、工作经历者优先 
2.拥有较强的相关英文论文阅读能力和表达能力 
3.具有较好的数据分析，抽象理解能力 
4.思维敏捷，良好的逻辑分析能力、良好的沟通及组织能力 
5.熟悉Java或者Python等程序设计语言;
6.有过日志分析处理，统计挖掘，广告DMP平台经验的优先
7.熟悉hadoop/hbase/spark/storm/hive中的一种或者多种；
8.有aws使用经验、参与过开源社区开发者优先。

我们能提供给你：
PB级的数据处理需求；
MAU过KW的出海app的数据分析；
日数亿次的广告请求的业务场景；
相信这些都是你技术能力提升的熔炉，经历这样场景的锤炼，能帮你未来的职业生涯打开上升通道！

我们希望你：
沟通理解力强，能够准确理解产品线数据需求；
数据敏感，能够从繁杂的数据中识别出异动的变化；
求是认真，不放过任何数据不一致问题，对数据稳定准确有执着的追求。

优秀候选人，上述薪酬没有限制。

工作职责：
1)  参与Hadoop大数据平台的设计与开发，解决海量数据面临的挑战；
2)  管理、优化并维护Hadoop集群，保证集群规模持续、稳定；
3)  负责Hadoop/Spark的功能扩展和性能优化，解决并实现业务需求；
4）协助建立数据模型，对数据挖掘脚本进行优化；
5）协助完成ETL开发工作。

职位要求：
1)  1-3年Hadoop/Spark工作经验，本科或以上学历，计算机相关专业；
2)  精通JAVA语言，熟悉Linux开发环境，具有实际系统开发经验；
3)  熟悉/Hive/Hbase/Spark/flume/storm/sqoop,具有实际开发经验；
4) 具备Java/Scala等开发经验；
5)  具有很强的学习能力、钻研精神、较强的沟通能力以及团队精神。

岗位职责：
1、基于Hadoop各种开发工具和框架实施数据采集、分析；
2、配合机器学习工程师对数据进行清洗、预处理；
3、负责基于hadoop集群，spark集群编写分布式算法实现；
二、任职要求
1、3年以上工作经验，本科计算机及相关专业学历；
2、基础扎实，熟悉数据结构和算法； 
3、熟悉Java、Scala、Python语言，较强的独立开发能力，具备良好的代码风格；
4、具备MapReduce、Hive、Spark、Redis等NoSql平台开发能力；
5、良好的数据敏感能力，敏锐而富有耐心。与数据打交道而乐此不疲；
6、优秀的沟通能力，有创新精神，乐于接受挑战，能承受工作压力。

【职位描述】
1.能够独立进行大数据服务器端项目架构；
2.能参与产品的设计讨论环节；
3.负责产品的数据分析、数据功能的开发；
4.学习最新的技术，整理文档并分享；
5.完成领导临时交办的其他工作。
 
【任职要求】
1.本科及以上学历，计算机相关专业毕业；
2.精通python或者Java语言， 3年以上软件开发经验及2个以上项目开发经验，熟悉hive、mapreduce、scala者优先；
3.熟悉大数据框架Hadoop、Spark，熟悉Storm、Kafka者优先，具有1年以上大数据开发经验；
4.了解云计算，具有开发经验者优先；
5.具备钻研精神和团队合作精神，积极的工作态度和较强的责任心，良好的沟通和学习能力，能承担一定的工作压力；

岗位职责：
1.参与公司应用开发平台的开发；2.为公司项目组提供技术支持；3.负责大数据ETL流程设计及开发。
岗位要求：
1.本科及以上学历，计算机相关专业，具有2年及以上Java Web开发经验，1年及以上大数据开发经验；2.精通Java、JAVA EE、Maven、Zookeeper、Hadoop、Hive、HBase、Spark等语言，熟悉数据模型设计、ETL设计。3.具有丰富的数据仓库系统的开发实施经验，良好的编程习惯和文档编写习惯优先；4.从事过大规模Hadoop集群经验、Cube多维建模、OLAP开发经验优先；5.有较强的学习能力，对技术有钻研精神，并有较高的热情，热衷于新技术学习和实践；6.良好的团队合作精神，对工作有热情，能够承受住压力。
 

工作职责：
大数据可视化系统的设计和开发工作；
离线和实时计算处理程序的研发工作；
岗位要求：
熟悉基本的数据结构和算法；
了解并行和分布式计算的基本原理了解Hadoop,Spark,Storm等常用的分布式计算框架；
熟悉MySQL, MongoDB, ElasticSearch等数据存储和计算平台；
熟悉Linux开发环境，熟悉Bash脚本语言；
熟练掌握Java或Python等至少一种以上的编程语言；
计算机相关专业本科以上学历；
有数据挖掘或者机器学习经验者优先。

岗位职责：
1.负责基于Spark/Storm进行离线处理和流处理；
2.负责基于Spark/MLib进行模型开发；
3.负责Spark/Hadoop等大数据平台的运维工作；
4.负责不同数据源的ETL工具开发和运维。
 
任职要求：
1.本科或以上学历，计算机相关专业，具备扎实数学基础，专注搞大数据3年以上或以上工作经验；
2.具备有以下经验1种或者多种最佳：有storm或者spark streaming实时数据处理经验；有用spark处理hbase海量数据经验；有hbase作为业务（而不是数仓）数据库，上亿记录，支持sql查询/插入，毫秒级响应；熟悉阿里ODPS数据导入/导出，PAI机器学习；
3.精通Hbase或Cassandra等列式数据库；
4.具备较强的责任心，创新意识，富有创业激情，认同公司的企业文化，能接受持续交付的工作环境。

岗位职责:
1.负责数据分析整理。
2.负责相关数据报表的开发。
3.参与产品的调研。
4.编写相关技术文档。

岗位要求:
1.熟悉java,python。
2.熟悉linux开发环境，掌握shell编程。
3.掌握sql数据分析。
4.对数据分析感兴趣。

职位描述：
岗位职责：1、搭建基于Hadoop/Spark/Shark的大数据平台，负责数据架构设计及前端数据应用开发工作；2、完成各种面向业务目标的从数据模型、数据分布、数据传输、数据存储等方面进行大数据系统架构的设计和数据架构；3、数据性能分析与克服;4、新技术的研究与导入。


任职要求：1、具有4年以上互联网或移动互联网并基于Hadoop/Hbase等应用开发经验，对分布式计算理论有深刻理解；2、精通JAVA、熟练掌握MapReduce原理、对Hadoop、Hbase、Hive等主流云计算、大数据相关软件有充分的了解，研读过源代码者优先，并且有实践经验，能解决应用中的复杂问题；3、熟悉BI工具及方法论，有大数据分析与数据仓库设计及开发经验；4、熟悉linux/UNIX Shell、熟悉(Perl/python/shell)任意一种脚本语言；5、熟悉kafka等消息框架，了解flume等日志搜集系统；6、熟悉Storm等流计算框架或其他开源实时计算框架；7、熟悉Spark、SparkSQL、SparkStreaming等框架并能实际使用8、个性开朗，对技术钻研好学、逻辑思维能力强，沟通能力优秀，有团队合作精神。


工作地址
深圳 - 福田区 - 香蜜湖 - 香蜜湖中投国际商务大厦A栋3-5层

(一) 岗位职责
1. 负责数据采集产品设计和开发;
2. 负责数据仓库建模、数据预处理子系统的设计和开发;
3. 负责数据挖掘功能设计和开发。
 
(二) 岗位要求　
1. 数学、计算机、统计分析等相关专业，本科及以上学历；
2. 有扎实的计算机理论基础, 对数据结构及算法有较强的功底，熟悉离散优化、constraint programming;
3. 具有良好的java编程基础；
4. 对分布式系统原理有较深的理解，理解数据库相关理论;
5. 具有快速学习与良好的团队协作能力；
6. 具有相关岗位工作经验者优先。

岗位职责：
1、结合公司大数据分析平台的规划，搭建以hadoop技术体系为核心的集群环境；
2、结合业务的实际数据情况，设计、开发基于hdfs/hbase/hive的数据查询分析；
3、辅助运维人员管理Hadoop集群环境，不断提高系统运行效率；
4、大规模日志分析、统计和建模。
岗位要求：
1、硕士及以上学历，计算机、软件等相关专业；
2、精通java语言，熟悉JVM运行原理；
3、熟悉hadoop框架，熟练应用map-reduce，拥有海量数据分布式系统的开发经验优先；
4、熟悉Java、Shell，可以熟练使用Linux操作系统，了解Linux集群技术者优先；
5、了解数据挖掘技术，对数据结构、算法有所理解；
6、熟悉shell, python 或 R语言加分。

职责描述：
负责数据分析、加工、清理、处理程序的开发 
负责数据相关平台的搭建、开发、维护、优化
分布式平台应用开发（Hadoop/Spark/Hive/Hbase）
开发数据统计系统，各类统计程序报表。

技能描述
2年以上Java或Python开发工作经验，JAVA基础扎实；
熟悉常见在线与离线大数据系统, 如Hive, HBase, ES, Kafka等的工作原理与开发调优; 具有MapReduce开发经验，有实际大数据项目经验
熟练掌握Oracle、MySql等主流数据库上的开发
对数据有敏锐度, 掌握常见数据分析方法, 如概率统计, 回归分析, 相关性分析等;
具有良好的沟通能力、组织能力及团队协作精神，有较强的分析和解决问题的能力.

岗位职责：
1、负责大数据平台的开发和维护，支撑业务的高速发展
2、完善数据仓库建设，开发实时、离线数据服务
3、响应业务部门日常数据需求，参与ETL开发
 
任职要求：
1、具有主流大数据工具/平台实际项目经验，如Hadoop/Hive/HBase/Spark/Kafka等，并熟悉所使用工具的技术原理、主要特点
2、有大型数据仓库项目实施经验，熟悉数据仓库方法论和ETL架构，理解元数据管理
3、熟悉Linux平台，熟练掌握 SQL/MapReduce，以及ETL过程设计和开发
4、扎实的 JAVA 开发功底，理解IO、多线程、集合、并发包，对 JVM 原理有一定的了解
5、有大容量数据处理及分布式计算开发经验
 
 

岗位职责：
1.负责构建数据仓库（设计、开发、维护），大数据处理架构；
2.负责基于cloudera的Hadoop、Spark、Kudu、Impala技术的海量数据自动化分析处理和统计工作。
3.分布式平台应用开发（Hadoop/CDH）； 
4.开发数据统计系统，各类统计程序报表 ； 
5.支撑各业务线数据需求。

岗位要求：
1. 有海量数据分析和统计相关经验；
2. 对hadoop生态、实时计算框架非常熟悉，具备集群搭建、维护、监控能力；
3. 熟悉Flume、Kafka、Storm、Spark、Hive、Kudu、Impala等大数据技术, 至少精通其中三项以上；
4. 熟练掌握scala/Java语言，Spark、Spark streaming编程.
5. 有大数据平台的数据流监控经验优先。
6. 至少实践过1个大数据平台建设项目，平台数据量不小于10T；

符合以下条件者优先
1. 有基于cloudera Hadoop/Storm/Hive/Hbase等分布式系统的大数据应用开发经验
2. 对开源分布式系统cloudera源码有研究
3. 有处理海量数据的经验
4. 有数据分析、数据挖掘经验

工作职责：
1、负责公司业务离线数据的分析研发工作，参与核心系统架构设计和实现2、根据不同的业务需求，灵活快速地完成具有挑战性的项目。3、具备需求分析，以及较强的逻辑分析和独立解决问题能力；职位要求：1、计算机相关专业，本科及以上学历2、2年以上大数据实际项目开发经验，3年左右及以上工作经验；3、熟悉haoop系统（yarn,HDFS,Hive,HBase,sqoop）的原理及使用，有一定的运维调优经验；4、有SparkSQL，SparkStreaming 实际使用经验，并能在较复杂的场景中使用5、有大批量数据离线分析的实际项目经验；6、熟悉Elasticsearch的安装，维护及使用（加分）；7、精通java语言，熟悉Spring、Struts、Hibernate等开源框架（加分）

岗位职责
1、数据平台建设2、HADOOP、HBASE、SPARK等集群维护3、基于SPARK等大数据平台进行系统开发
任职条件
1、大专及以上学历五年及以上java、scala开发经验，面向对象的设计方法，语言、框架不限2、熟练掌握Hadoop、Hbase、Spark（Sql、MLLIB、Streaming）、Hive等大数据技术，并由相关经验3、对数字敏感，对数据建模、存取、处理、可视化等相关技术有很强的学习热情4、有算法开发经验、数据建模经验者优先5、熟悉mysql数据库，并具有一定的SQL功底；6、具备良好的沟通能力，工作积极认真，具有创业精神。

职位描述：
1.负责大数据平台的维护、调优以及搭建；
2.负责数据的清洗、转换处理和分析及统计；
3.不断预研新的大数据开源技术。
 
职位要求：
1.计算机、软件工程、大数据、云计算或数学等相关专业本科及以上学历，有两年及以上Hadoop实际开发经验；
2.熟练掌握Java、Scala或Python中至少一种语言；
3.熟悉Hadoop大数据生态圈，熟练使用HDFS、MapReduce、Hive、Hbase等；有Spark开发经验者优先；
4.熟练Linux操作命令，能编写常用Shell脚本；
5.熟练掌握MYSQL、DB2等关系型数据库及常用SQL；
6.熟悉机器学习算法，搜索引擎技术，或分布式计算技术，有相关经验者优先；
7.对大数据技术有钻研热情，具备高度的责任心及团结协作精神，善于沟通交流。

1、参与行业大数据平台的架构设计及开发；
2、承担行业大数据平台及行业数据应用的开发，并对工程质量质量负责；
3、参与行业大数据平台技术培训、技术方案编制；
4、参与大数据平台的实施、维护。
岗位要求：
1、熟练掌握JAVA开发；
2、熟悉Hadoop，深入理解MapReduce、Hive、Hbase、HDFS相关原理及高级特性，具有数据处理开发经验；
3、熟悉华为、星环等大数据平台，熟悉Hadoop集群部署、开发和维护管理经验，熟悉Kafka、Spark等开源大数据处理软件；
4、数据ETL经验、数据分析经验；
5、人品优良、团队意识好、踏实好学。



岗位职责: 
1、参与数据挖掘、数据建模、数据画像等平台相关的产品规划、设计、优化。
2、参与业务专题分析，深入研究用户行为，定期提供各产品、运营数据分析解读，提供决策指导
3、挖掘业务数据，寻找数据价值点，联合BI等公司数据分析资源在业务中实现数据价值落地。
 
任职要求: 
1、计算机或相关专业，本科及以上学历，3年以上工作经验；
2、熟悉Hadoop、HBASE、Hive、Spark等分布式计算平台，有大数据应用系统开发经验者优先； 
3、熟悉JAVA，熟悉linux，至少熟练使用Shell、Python、Perl等脚本语言之一；
4、精通SQL，有较好的SQL性能调优经验，最好有hadoop,hive,hbase开发经验。
5、熟悉BI开发流程，参与过大型数据仓库类项目；
6、熟电子商务相关业务流程，具有业务分析及建模能力； 
7、良好的逻辑分析能力、分析问题和解决问题的能力，对数据敏感，良好的沟通能力； 
8、工作认真、负责、仔细，有良好的团队合作精神，良好的分析能力、沟通技巧。

作为大数据开发工程师，在掌众团队您会负责：
- 基于采集数据提炼、分析、归纳用户属性、行为等信息，输出分析报告；
- 处理用户海量数据，挖掘用户行为特征，为运营、风控和产品提供参考依据；
- 针对具体业务问题，研究影响用户的潜在因素，进行数据分析验证并提出改善举措；
我们希望您：
- 2至3年java开发经验，具备扎实的程序设计基本功和学习能力
- 熟练使用Spark、MapReduce以及相关组件，对源代码或系统优化有一定研究者优先；
- 熟练掌握scala/python其中一种语言；
- 有2年以上的数据挖掘或者互联金融用户行为分析相关工作经验优先；
- 有海量数据分析经验者优先；统计学、概率学、计算机信息管理等相关专业研究生以上学历优先考虑；
plus：有互联网电商、互联网金融、互联网营销的开发经验。
我们的团队：
原始创业团队来源北航博士系，开发团队来自Bat、互金等行业资深专家领衔组建，聚合了互联网大数据技术和风控等业界专家；
氛围：精英团队、全栈文化、定期技术培训、专属个人成长计划；
掌众公司怎么样？
掌众金融以用户的资金需求为出发点，通过数据与风控服务连接用户与资金，以小额分散为基本原则，以风控机器人为技术驱动，通过互联网、大数据技术帮助“信用空白”用户建立信用档案。旗下消费金融现金贷产品“闪电借款”于2014年上线，两年间快速积累近300万注册用户，累计交易额突破35亿，累计交易笔数超过160万笔
欢迎您加入掌众，和我们一起用技术改变金融！


大数据开发工程师
1、大学本科及以上学历，两年以上工作经验；
2、熟练掌握oracle pl/sql基本语法，熟悉hadoop,熟练掌握hive、spark等,了解hive脚本优化方法；
3、良好的逻辑思维能力、团队合作精神与沟通能力；
4、了解java或者shell；
5、海量数据处理经验优先；

岗位职责1、负责大数据平台相关的开发工作；2、负责建立和维护大数据平台技术标准规范，指导开发人员编写代码，编写相关技术文档；

任职要求1、具有本科、三年以上编程经验，至少一年以上大数据项目开发经验；2、精通Java、Python等至少一门编程语言；精通Oracle或MySQL数据库技术；3、熟悉HDFS、HBase、Hive、MapReduce、Storm、Spark等技术，有相关开发经验；4、熟悉ActiveMQ、Kafka、Redis、Memcache等相关技术一种以上；5、熟悉Sqoop、Flume、Spider、ElasticSearch、Solr等相关技术一种以上；6、具备良好的学习能力和沟通协作能力，具有积极的工作态度和高效的执行力；

（1）搭建金融大数据平台，负责数据平台概要设计、以及核心流程开发工作；
（2）基于大数据平台以及现有的框架设计开发符合公司实际应用的大数据ETL系统；
（3）负责大数据平台的性能调优，系统结构优化相关工作;（4）新技术的研究与导入；
（5）带领并指导下级工程师完成相关开发任务。
（6）负责团队技术培训相关工作。
任职要求：
（1）精通JAVA语言，3-7年后台应用系统开发经验，对JAVA语言高级特性有深入的了解。
（2）熟悉Hadoop Ecos相关框架，并且至少有两个实际项目经验。
（3）熟悉JAVA程序性能调优相关工具，并有实际的性能调优经验。
（4）熟悉ETL、消息队列工作原理，并有实际的应用经验
（5）具有大规模高并发相关系统的开发实践经验。
（6）熟悉并了解的常用JAVA框架和类库。
（7）熟悉常用的设计模式。
（8）熟悉Linux操作系统以及相关编程优先。

岗位要求：
1. 熟练使用hadoop,spark,spark streaming, kafka等大数据组件，理解基本原理；
2. 非常熟练至少一门编程语言，c++/java优先；
3. 理解多线程/同步/死锁基本原理，理解分布式基本原理；
4. 沟通能力强，有主动担当精神。 
岗位职责：
1. 参与大数据平台基础架构研发。

岗位职责:
1、大数据产品的数据清洗、转换相关开发；
2、相关数据分析结果报表生成脚本开发及调整；
3、linux平台下，后台系统的运行维护与流程处理。

岗位要求：
1、本科以上学历，计算机、统计、数学及相关专业，2年以上linux系统环境下工作经验；
2、具有以下一种或几种脚本语言能力：Shell、Python及awk、perl等脚本；
3、学习能力强，具有快速掌握新工具的能力，良好的英语阅读能力和文档习惯；
4、有责任心，工作积极主动，勤恳踏实，能承担一定的工作压力，具备良好的沟通能力和团队合作精神；
5、有学习了解ELK、solr等搜索技术，具有以下一种或几种软件：hadoop,  storm,  spark,  hbase,  hive，flume,  kafka等大数据技术或平台经验者优先。

工作职责：
1、根据业务需求，进行数据采集及计算；
2、参与通用实时计算框架、用户画像、爬虫、挖掘等架构设计
3、负责数据开发相关业务设计和开发工作。 

任职要求：
1.有用户画像、日志分析、用户行为分析、数据挖掘项目经验优先；
2.掌握hadoop集群的搭建和配置；
3.熟悉基于hadoop的集群和伪分布；
4.掌握hadoop,spark生态圈对大数据的进行分析处理；
5.熟练掌握java， scala， shell等开发语言；
6.熟练使用mysql,oracle等数据库技术，掌握Java基础，并熟悉JavaEE;
7.熟悉linux开发环境，熟悉centos以及shell编程；
8.三年以上的工作经验，热爱大数据开发，具有探索精神，技术上追求极致，善于沟通，喜欢挑战与学习;

工作职责：
1: 负责Hadoop平台MapReduce、Hive、HBase、spark和/或jstorm等应用开发。
2: 负责大数据平台日志收集，数据抽取、清洗、转换和建模的开发。
 
任职要求：
 
1: 大学本科及以上学历，计算机或相关专业；
2: 了解数据仓库开发流程，熟悉数据仓库(DW)/商业智能(BI)的数据框架；   
3: 年以上大数据工作经验，熟练掌握Python/Java至少一种编程语言，熟悉java者优先；
4: 熟悉Mysql/Oracle等至少一种关系型数据库，熟悉SQL开发；
5: 熟悉HDFS、HBase、Hive、MapReduce、Impala、Oozie、Sqoop、Kettle等相关技术/工具，具备大数据分析项目经验；
6: 熟悉Linux系统，能实际编写Shell脚本；
7: 有数据仓库开发、海量数据处理经验者优先考虑；

岗位职责:职位描述：大数据底层架构设计和实施；对移动设备数据和社交数据进行挖掘分析和建模；逐步构建基于用户行为、喜好的标签系统，并应用于相关的个性化系统和业务分析中；负责数据管理平台的核心技术实现与优化；负责大数据在广告领域的创新应用，持续推动业务线的商业效果改进；
任职资格:岗位要求： 本科及以上，计算机、软件工程、统计学、数据挖掘、机器学习等相关专业。2年及以上大数据流程架构经验，熟悉Hbase/Hive/Hadoop/Spark或等主流分布式开发平台，有高性能集群设计和开发经验。精通Linux，熟练掌握Python/C/Shell/Java，熟练掌握SQL数据库语言 HiveSQL/Mysql/Sqlserver。有数据挖掘算法实施经验，熟练掌握大规模数据挖掘、机器学习。对有广告营销大数据算法/开发经验者优先，有大型数据项目经验优先，有用户行为分析、用户建模、业务建模经验者优先。具有良好的逻辑分析能力、沟通能力和协调能力。 积极的工作态度，勤奋上进，有责任心。

必备要求：
良好的自我驱动力和职业素养，工作积极主动、结果导向
平均每家公司就职时间2年以上，频繁跳槽者勿扰
岗位职责：
1. 负责大数据平台的搭建、开发、维护、优化；
2. 负责数据分析、加工、清理、处理程序的开发；
3. 参与公司BI平台的建设、维护、优化、升级；
4. 配合数据挖掘工作进行相关程序开发。
任职要求：
1. 重点本科或以上学历，计算机、数学、通信等相关专业；
2. 有海量数据处理和并行计算开发经验者，熟悉 Hadoop生态，有实际大数据项目经验；
3. 扎实的统计学和数据挖掘基础知识，扎实的数据结构及算法功底，优秀的工程实现能力；
4. 熟悉分类、聚类、回归、图计算等机器学习算法，熟练掌握主流数据库如 PostgreSQL/MySQL；
5. 精通设计模式、设计原则、面向对象编程开发，精通可扩展分布式编程经验；
6. 优秀的分析问题解决问题能力、学习能力、团队合作意识；
 
加分项：
1. 有成熟的 BI、推荐系统、算法调优经验
2. 有海量大数据开发经验
3. 有 Hadoop/Spark/HBase/Druid/Kafka/Storm/Lucene/Elasticsearch 深入源代码分析经验
4. 熟悉机器学习、数据挖掘、分布式计算

岗位描述：
1、负责数据平台的开发和优化、基于；大数据平台完成各类统计和开发；
2、负责数据库监控，优化大数据计算性能；
3、解决大数据相关的疑难技术问题；

任职要求：
1、有事记得产品或项目开发经验；
2、精通SQL、熟悉java、scala、python；
3、开发过大数据应用，对数据挖掘和各类人工智能算法有基本的了解；
4、具备hadoop、spark大数据开源工具的使用。
工作地址

工作职责：
深度参与大数据技术及平台的设计、开发、测试，研究用户模型，为用户提供个性化的服务。可以对客户需求进行全面分析和深入理解，挖掘产品潜在价值，提供业界最具有竞争力的解决方案和最具价值的服务。你将负责：
1、研发面向大数据分析处理平台，研究数据挖掘算法技术与应用、深度学习探索，
2、研究用户模型框架、生成、维护、应用等核心算法，解决个性化评测、服务等问题，以及个性化推荐方法。
3、对分布式与并行计算技术及涉及业务有较深刻理解，对分布式系统及集群资源管理、调度有研究经验，有并行化软件设计与开发经验；
4、对数据挖掘、机器学习有研究或项目经验，熟悉分布式系统原理和技术，有研究或项目经验。

任职要求：
1. 本科或研究生在读学生，计算机相关专业，有大数据开发经验优先
2. 有良好的一门语言（Java或python）开发经验、有较强的Linux操作能力，有Shell等脚本编写经验
3. 有较强的计算机网络基础知识背景，深入理解TCP/IP协议
4. 对商用或开源的数据库的使用，例如MySQL、mongodb等有一定了解，熟悉SQL语言，有相关开发项目经历者优先。
5. 掌握Hadoop、Hive、Zookeeper、flume、Kafka、流计算、Spark使用、数据挖掘中的一种或几种的大数据技术者优先
6. 对大数据技术、网络流量、网络运维管理有钻研热情，善于学习

工作职责：-负责数据中心平台化中各个子系统的开发工作-负责大数据基础技术的调研和选型升级-结合需求设计高扩展性、高性能、安全、稳定、可靠的技术系统任职资格：- 本科或以上计算机相关专业学历- 有大数据经验，熟悉主流的大数据产品和数据分析技术并具有一定的相关项目经验，熟悉Hadoop/Hive/Hbase/Spark/Storm/Kafka/Yarn/Sqoop/Flume中的5项以上- 熟悉Java及web应用开发，了解分布式、多线程及高性能的设计与编码及性能调优，- 熟悉使用MySQL数据库，了解SQL优化方法- 熟悉Linux日常工作环境，熟悉掌握常用命令和调优监控手段- 至少会使用一种脚本语言，包括但不局限于Shell、Ruby、Groovy、Python，能够在日常工作中使用脚本简化工作 - 有很强的分析问题和解决问题的能力，有强烈的责任心和质量意识

加入享骑  共享成长

职业诱惑:
行业好，公司发展前景好，工作有意义，成长空间大

你将为享骑创造的价值：
1、参与大数据项目开发
2、结合享骑电单车产品，提出大数据解决方案及落地实施
3、参与大数据开发团队方案讨论/技术分享
4、负责大数据性能优化

享骑  希望你：
1、 三年以上hadoop项目开发经验
2、 Hadoop大数据，熟练掌握hadoop，MapReduce应用开发，精通Spark、Hbase、Hive、Pig、MapReduce、kafka、图数据库等大数据开发工具者优先
3、 精通SQL开发，掌握MySQl、Oracle等关系型数据库中的一种
4、 精通java开发
5、 学习能力强，有兴趣研究新技术，有团队观念，具备独立解决问题的能力
6、有物联网大数据研究者优先
7、具备良好的团队合作精神
8、具备良好的沟通理解和表达能力，工作踏实、积极上进

【岗位职责】
1.基于大数据技术，对视频、用户、市场、运营等数据的进行统计分析、挖掘、预测
2.参与数据采集、大数据存储、高性能离线/实时计算平台的研发与维护
3.参与大数据产品的设计和开发

【任职资格】
1.有扎实的Java/scala/python基本功，理解OO思想
2.熟练使用linux，熟悉shell编程与常用命令
3.熟悉常用的大数据相关知识体系与技术栈如：Hadoop、Hive、Storm、Spark、HBase、ZooKeeper、Kafka、Flume等，有实战经历优先
4.熟悉常用数据挖掘算法者优先
5.对coding有极高的热诚，并具有geek精神
6.如有个人的技术blog或者个人主页，github关注过某项开源项目并能深刻理解其原理、或参与、提交过issue/bug会更好

岗位职责：
1.负责大数据平台的建立、维护；
2.参与基于大数据平台建立相关的数据整合清洗、数据应用的设计和开发等。
3.参与跨部门协作，提升数据质量、稳定性和性能；
4.负责处理推荐系统相关数据流和数据整合。

任职要求：
1.统本以上学历，计算机相关专业，3年及以上大数据相关开发经验；
2.熟练Java开发，了解 Spark, HBase, hadoop、Kafka，flume等相关技术和原理；
3.必备一定的沟通、协调能力和抗压能力，良好的自我学习驱动；
4.加分项：熟悉Python、Scala等其中一种编程语言，可用python做数据分析；熟悉统计学原理或机器学习等理论。

岗位职责：
1、完成企业数据管控相关工作；
2、完成日常数据分析查询需求;
3、基础数据及需求开发。

任职要求：
1、有数据仓库、集市建模经验；
2、熟悉sql编程，能够完成日常数据分析、问题定位排查工作；
3、有数据管控（数据标准、数据质量、元数据、数据安全）其中至少一个项目经验；
4、强烈的责任意识，有进取心，有较强的学习能力；
4、有hadoop平台经验优先；
5、有金融或互联网从业经验者优先；
6、较强的沟通协调能力。

招聘初级岗位，岗位需求:

学历全日制统招本科2014年毕业及以前毕业的
有金融项目相关经验，需要一定需求分析能力
有大数据相关技术优势
不符合以上条件不要投递，谢谢！


岗位职责：1、收集业务数据，进行处理和分析；2、对多种数据源进行深度诊断性组合分析、挖掘和建模，提交有效的分析报告； 3、 从数据分析中发现市场新动向和不同客户应用场景，提供决策支持；任职资格的具体描述：1、计算机、统计、数学、信息技术专业，熟悉大型数据库,java,hadoop等技术；2、三年以上数据分析师，有海量数据处理经验，处理的数据规模在TB级别以上； 3、有数据模型建立和运营经验、数据化运营经验、数据类产品类规划经验； 4、熟悉数据采集、统计分析、数据仓库、数据挖掘、数据可视化、推荐系统等相关领域知识与算法；5、 需要对其在统计数据处理中的关键技术要有毕竟清晰的了解和认识。6、能独立编写商业数据分析报告，及时发现和分析隐含的变化和问题,并给建议；

岗位职责：
1、负责业务的数据收集、建模、统计与可视化，全方位支撑线上产品和线下业务迭代扩张；
2、构建数据的监测与分析平台，帮助业务人员快速、及时发现问题并找到原因；
3、进行数据应用开发，从海量数据中挖掘用户偏好、关联信息，完成用户端的精准推送。
任职要求：
1、至少2年大数据工作经验，熟练掌握Java/Python至少一种编程语言；
2、熟悉hadoop，Storm，Kafka等开源平台、具备分布式数据存储与计算平台搭建/应用开发/运维的相关实践经验；
3、熟练掌握SQL，理解 Hive/Mysql 基本原理和调优策略；
4、具备良好的业务理解能力，对数字敏感，有较强逻辑分析能力；
5、使用过阿里云数加、流计算、日志服务等相关数据产品优先考虑。

岗位职责:
参与京东商城Y事业部收益管理与供应链运筹优化项目中大数据方面的开发工作：
1.      负责数据分析、加工、清理、处理程序的开发
2.      从事海量数据分析、挖掘相关工作
3.      负责数据相关平台的搭建、开发、维护、优化 
任职条件: 
1.      计算机相关专业，本科及以上学历，5年以上Java开发工作经验，学习能力突出；
2.      熟悉hadoop生态系统内常见项目的使用（hdfs、hive、hbase、spark、zookeeper,yarn等），具有MapReduce开发经验，有实际大数据项目经验优先
3.      熟练掌握Oracle、MySql等主流数据库
4.      精通JAVA，熟悉基于J2EE的WEB架构设计，熟悉Web开发流程，有丰富的Web MVC（Struts、Spring，Hibernate等）开发经验；
5.      熟悉Linux/Unix系统环境下的操作；熟悉Tomcat等应用服务器的配置和优化；
6.      具有良好的沟通能力、组织能力及团队协作精神，有较强的分析和解决问题的能力；
加分项：
1. 有海量大数据开发经验
2. 有Hadoop、Spark、HBase深入源代码分析经验
3. 熟悉机器学习、数据挖掘、分布式计算
4. 基础能力+学习能力特别优秀者

岗位职责：
1.负责360企业安全大数据安全产品研发
2.参与大数据平台的设计与开发、利用大数据解决安全问题


任职要求：
1. 精通Python/Java语言, 熟悉IO机制、网络通讯、多线程等基础知识框架，熟悉缓存、消息队列、索引查询等机制；
2. 至少有一种关系数据库(Oracle、MySQL、MSSQL、SQLite)的使用经验，精通SQL语句，能查找SQL语句性能问题并进行调优，了解NoSQL(MongoDB, ElasticSearch)
3. 熟悉Hadoop、Hbase、Storm、Zookeeper、Spark等开源分布式系统，并对多个分布式系统有应用经验；
4. 有较好的沟通交流能力,善于主动思考和行动,乐于解决具有挑战性的问题；
5. 对技术有浓厚的兴趣
具备以下经验者优先
1. 有大型互联网工作经验，实际的大数据处理经验
2. 具备大数据相关工具进行海量日志分析的能力，对告警事件有理解、分析、判断和优化能力
3. 接触过安全类大数据产品，对常用的机器学习算法在安全场景下的应用有一定的了解

岗位职责：
 1、对海量用户行为数据进行离线、实时处理；
2、参与大数据的架构设计、开发、部署、自动化运维和数据分析等工作；
3、利用大数据相关的新技术，提升系统性能；
岗位要求：
1、本科及以上学历，2年以上工作经验； 2、熟练使用C++/Java/Python等语言进行开发;
3、熟练掌握 Linux 操作系统的配置，管理及优化；
4、熟悉主流分布式处理框架——Hadoop、HBase、hive等，掌握MapReduce、Storm或者Spark编程（至少其中一项）。

任职要求：

1.计算机、数学等相关专业本科以上学历，2年以上相关工作经验；
2.精通Hadoop体系结构、对Hadoop生态圈有较全面了解；
3.熟悉大数据开发框架，精通HDFS/HBase/Hive/Storm/Spark/Spark Streaming/Kafka/flume等相关技术；有多个或多年大数据项目的实施经验；
4.能够使用Python、Scala中至少一门语言进行数据处理；
5.熟悉Linux系统以及Shell脚本语言；
6.具有一定的数据库架构设计能力，能够撰写规范的技术文档；
7.掌握常用的设计模式和架构模式，能够熟练使用建模工具进行系統设计；
8.具备良好的自学能力、沟通能力、独立解决问题的能力，有责任心及团队合作精神
9.数据挖掘经验者优先。

岗位职责：
1.负责大数据平台搭建及数据仓库建模；
2.利用分布式计算集群实现对数据的分析、挖掘、处理、生成报表等；
3.维护分布式计算集群并能解决相关问题, 保障系统正常运行。

岗位要求：
1.熟悉主流分布式处理框架，如spark,hadoop；
2.具备大型数据仓库架构设计、模型设计和性能调优等相关经验；
3.有搜索及推荐系统实现经验者优先；
4.有BI产品、数据可视化产品开发经验者优先；
5.精通Python开发；
6.统招全日制本科及以上学历，计算机专业毕业，一年以上互联网相关工作经验。

工作职责：
1、对互联网产品有浓厚的兴趣，最好有旅游领域背景；
2、参与数据挖掘、数据建模、数据画像等平台相关的产品规划、设计、优化。
3、接口公司BI部门，参与业务专题分析，深入研究用户行为，定期提供各产品、运营数据分析解读，提供决策指导
4、挖掘业务数据，寻找数据价值点，联合BI等公司数据分析资源在业务中实现数据价值落地；

任职资格：
1、本科及以上学历，计算机、数学、统计学等相关专业，3年以上相关工作经历；其中承担数据分析类相关工作至少2年；
2、熟练使用数据分析和挖掘的2种以上工具，可熟练用sql语言进行数据处理；
3、具有1年及以上互联网大数据应用的工作或项目经验；最好有基于互联网用户数据对用户画像、用户经营分析、用户行为分析、精准营销等大数据应用有实践经验；
4、综合素质好，有较强的沟通协调能力、学习能及推动能力、善于执行和监控，有较强的组织和责任意识，性格开朗，善于合作，团队意识强；沟通、逻辑思维能力比较强.

工作职责：1、负责Hadoop生态圈相关组件的运维工作；2、负责目前大数据集群的部署、配置变更、配置调优；3、负责大数据集群的硬件资源和性能监控、性能调优 ;4、优化大数据集群监控、故障处理 ;5、负责自动化运维及服务虚拟化推进；任职资格：1、三年以上系统运维或开发经验2、熟悉Linux操作系统，精通Shell脚本 3、熟练部署、维护、优化Nginx/tomcat ;4、熟悉集群，负载均衡，HA、虚拟化等技术5、熟悉zabbix/ganglia/监控管理工具 , 有相关开发经验优先 ;6、熟悉salt/puppet/chef/ansible等自动化运维工具，有相关开发经验优先7、熟悉Hadoop/HBase等大数据系统，有大数据平台运维或开发经验者优先 ;8、熟悉IDC工作流程优先 ;9、熟悉java、python者优先；10、对虚拟化或docker有研究者优先 ;11、有良好的沟通能力、理解能力和团队合作精神，12、具有较强的学习能力、逻辑分析、问题排查能力13、做事认真细致，具有强烈的责任心和安全意识 ;14、为人正直进取，具备良好的职业素养，能承受较大工作压力；15、能24小时响应业务需求

【岗位职责】
1、研究大数据项目分析方法和大数据系统解决方案；
2、负责公司教育产品的机器翻译、机器学习、智能化识别等课题的研究和开发；

【岗位要求】
1、硕士及以上学历，计算机、软件、通信、模式识别等相关专业；
2、熟悉机器学习、人工智能等常用算法、具有数据挖掘等相关知识；
3、有较好的机器学习和模式分类等相关方面的理论基础和实践经验；
4、积极主动，有良好的沟通能力、团队协作精神和钻研精神。

福利
1.免费员工公寓（提供热水器、免费wifi等）
2.员工餐厅供应三餐；
3.五险一金齐全，社保体系完善；
4.处于业界较高水平的薪资待遇，每年1-2次的薪资晋升；
5.篮球场、羽毛球场、台球室、乒乓球室等休闲设施场所供应；
6.定期健康检查、贴心的生日礼物、节日礼物；
7.五天工作制，带薪假期（年假、病假、婚假、产假）；
8.花园式的工作环境，宽敞明亮的办公环境。

发展平台
1.国家大力支持的朝阳行业，博士后工作站，蓝鸽科研院，重视技术发展，培训、交流机会多；
2.新员工参加一个月的培训，一对一导师制，表现优秀可以进入公司战略人才培养计划；
3.公司大力启用优秀人才，两年带项目不是梦；
4.开发人员往“技术专家”和“高层管理”双线发展，公司百分之八十的技术高管和管理人才都是从内部选拔提升。


1、本科及以上学历，1年以上工作经验，来自互联网、金融等还有各种数据分析行业优先；
2、熟悉主流数据库oracle、sql server，mysql，mongodb等数据库中至少一种，有hadoop开发经验；
3、具有数据仓库和数据平台项目工作经验；
4、态度端正，工作积极主动，有责任心，耐心，并具有很强的团队合作意识。

岗位描述： 1. 深入理解公司业务数据， 管理公司数据资产，提升数据的易用性2. 对现有数据分析平台（Hadoop/Spark）进行功能维护、性能优化和系统升级3. 及时响应数据统计分析需求，并根据数据分析结果提出业务策略建议  4. 结合业务特点，探索并建立分析主题，对数据进行深度分析和挖掘岗位要求： 1. 本科或以上学历，计算机、统计、数学等相关专业毕业， 有互联网相关数据研发工作经历2. 熟练使用Linux，能够熟练使用各种脚本工具 
3. 熟悉Hadoop/Mapreduce、Spark等分布式计算框架，有实践经验者优先
4. 有数据挖掘、推荐系统、机器学习经验，熟悉相关算法，工具和语言者优先
5. 充分的数据敏感度，能从海量数据表现中提炼核心结果，及时分析数据中隐含的变化和问题
6. 优秀的分析问题和解决问题的能力，能够把合理的思路成功应用于实践 
7. 表达能力强，具备优秀的快速学习能力、沟通协调能力及团队精神
8. 有较强的责任心和学习积极性

1. 数据产品设计及研发
2. 海量数据建模、数据分析
3. 数据分析平台建设和优化，包括但不限于ad-hoc查询，多维数据分析，高效实时数据
4. 大数据基础架构的建设及维护，包括但不限于调度系统、元数据管理、数据监控、流式平台等
5. 解决和优化ETL人员开发过程中遇到的计算平台优化、数据处理技术、基础工具使用等技术问题
 
任职要求：
1. 熟悉php开发框架，熟悉mysql，有1年以上的开发经验；
2. 熟悉MapReduce原理，Hive SQL，熟悉常用脚本语言如java、python等；
3. 熟悉决策树、聚类、逻辑回归，关联分析、SVM，贝叶斯等数据挖掘算法 ；
4. 对数据挖掘、算法策略有浓厚兴趣，善于学习新知识，乐于挑战新高度 ；
5. 学习能力强，强烈的责任心,具有较强的沟通能力及团队合作精神，细致耐心、积极主动
6. 有较强的产品理解，能从技术角度推动产品优化
7. 有3年以上数据挖掘/机器学习/广告系统/推荐算法/自然语言处理相关工作经验优先    
8. 有大型互联网公司大数据平台及数据开发经验者优先

岗位职责：  
1. 负责构建公司大数据处理软件堆栈, 形成统一和高效的大数据处理体系 
任职要求
1.计算机本科以上学历, 3年以上数据系统、开发工作经验
2.深透的计算机基础，熟悉操作系统，编译器，数据库等的底层原理和机制
3.精通流行分布式系统的应用模式及开发：Hadoop、Hive、Impala等。
4.有flume/scribe ,kafka,storm,spark 开发和使用经验者优先
5.精通Java 、Python，兼顾代码的性能和健壮

岗位职责：
-致力于打造一套完整的大数据生产和研发平台，包括但不限于,
-基于Hadoop生态技术的存储和计算集群建设（Hadoop/Hive/Hbase/Spark等）
-工作流系统、数据质量检查和数据安全方案、ETL工具的建设
-元数据字典，Adhoc工具等研发平台的设计和实现
-参与数据建模、数据产品的设计，促进模型和产品的优化和创新
 
任职要求
-熟悉Hadoop生态技术（Hadoop/MapReduce/Hive/HBase/Spark等）
-熟练掌握Java/PHP/Python至少一种，并了解至少一种对应的常用框架
-了解多线程以及并发技术，熟悉网络编程
-有海量数据/日志处理和分析经验者优先
-扎实的计算机基础，熟悉常用的数据结构和算法
-熟悉Linux系统环境，熟悉Shell/Python/Perl等至少一种脚本语言

作职责
1. 开发、维护并扩展我们的大数据分析平台
2. 辅助其他数据研究人员建立弹性、可扩展数据管道
3. 根据业务需求，研发最新的大数据分析技术与工具
 
岗位要求：
1. 计算机或其他工程类专业本科及以上学历。
2. 熟悉机器学习中的常见监督学习(supervised learning)方法及其应用：人工神经网络(artificial neural network)，逻辑回归(logistic regression)，支持向量机(support vector machine)，决策树(decision tree)等。
3. 熟练掌握一种或多种编程语言：Java，C++等
4. 熟悉一种或多种建模语言：Python，Matlab，R等
5. 熟悉关系型或非关系型数据库操作： MS SQL Server, MySQL, MongoDB等。 
6. 熟悉linux平台下的基本操作及编程。
7. 有很强的沟通能力与团队合作精神。
8. 英文读写流利。
符合以下一项或多项条件者优先考虑：
1. 对金融征信有数据处理经验
2. 有处理大数据或平行计算经验

职位要求1、计算机或相关专业本科及以上学历；2、熟悉大数据开源架构，常用算法。参与过单天日志数据量TB级别项目。3、熟练使用大数据从收集、清洗、分析、展示等全流程相关工具，如kafka、hdfs、hbase、yarn、sarpk 、spark sql 、elk等。4、对数据分析结果进行可视化设计，直观简洁地展示分析结果。5、对数据敏感，能快速学习业务并能理解数据分析需求。6、为人务实上进、具备较强的团队合作意识、善于表达沟通。岗位主要职责：1、负责公司cdn等产品海量的访问日志、带宽、质量等数据的分析处理、展示工作。2、具备1-2年大数据相关工作经验3、熟练掌握Java、scala、python起码任意一种开发语言；4、熟悉Hadoop、Hive、Spark、Elasticsearch等大数据技术，具有相关使用和开发经验；5、对大数据技术有浓厚兴趣，有较强的逻辑思维能力，能够在压力环境下工作。

岗位职责：
1、大数据处理平台设计、环境搭建和研发；
2、Hadoop大数据生态圈组件整合、调优。
3、开发ETL过程，Hive数据仓库设计，Hbase数据库设计。
4、大数据平台应用接口开发。
任职要求：
1、熟悉Hadoop/Flume/Sqoop/Hive/Spark/HDFS/HBase/Mahout/YARN等相关技术；
2、熟悉MySQL、PostgreSQL等常用关系数据库使用。
3、熟悉Linux常用命令。
4、精通JAVA语言开发，熟悉JVM调优优先。
5、能够熟练搭建Hadoop集群环境，熟悉HDFS机制、MapReduce流程优先。
6、熟悉分布式系统概念、分布式算法实现优先。
7、熟悉MongoDB、Redis者优先。
8、熟悉SpringMVC、Mybatis、Hibernate优先。
9、较强的沟通能力、善于学习新知识、优秀的分析问题、解决问题能力，具有较好的逻辑思维。

工作职责：
1. 参与公司数据仓库架构设计与研发，建设PB级的公共数据平台和服务系统，实现高质量数据的互通与共享；2. 参与公司数据产品与应用的数据研发，发觉数据商业价值，打造极致体验的数据产品；3. 助力数据化运营业务，构建丰富多样的BI应用。
任职要求
1. 具有丰富的数据开发经验，对数据处理、数据建模、数据分析等有深刻认识和实战经验； 2. 熟练掌握Hive，灵活运用SQL实现海量数据加工处理; 3. 有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验着优先，重点考察Hdfs、Mapreduce、Hive、Flume； 4. 掌握实时流计算技术，有Spark Streaming 开发经验者优先;5. 至少掌握python、java、php其中一门开发语言；6. 积极乐观、诚信、有责任心，具备强烈的进取心、求知欲及团队合作精神；
7. 本科及以上学历，一年以上同岗位工作经验，相同项目开发经验优先。

1.熟悉Hadoop的体系架构和运行原理
2.熟悉ORACLE等关系数据库的设计和开发
3.熟悉Hadoop、spark、Storm、Flume、Kafka、Hive、ZooKeeper、Mahou等技术


岗位职责：

1、在酷家乐工程效能组从事后台软件的开发工作，你将有机会参与到高并发、高可用的大规模分布式系统的开发；
2、每天处理海量数据的大数据分析系统的开发；
3、日理万“机”的管控系统的开发。


任职资格：

1、有扎实的编程功底，至少熟悉C/C++, Java, Python, C#中的一种；
2、熟悉常用数据结构和算法；
3、了解分布式系统、负载均衡、系统容灾、高可用等知识。
PS：你将接触到最优秀的架构设计及艰深的技术栈。

职位描述：
1、构建分布式大数据服务平台，参与和构建公司包括海量数据存储、离线/实时计算、实时查询，大数据系统运维等系统
2、服务各种业务需求，服务日益增长的业务和数据量
3、深入源码内核改进优化开源项目，解决各种hadoop、spark、hbase疑难问题，参与到开源社区建设和代码贡献
岗位要求：
1、计算机或相关专业本科以上学历（3年以上工作经验）
2、精通C++/Java/Scala程序开发(至少一种)，熟悉Linux/Unix开发环境
3、熟悉常用开源分布式系统，精通Hadoop/Hive/Spark/Storm/Flink/HBase之一源代码
4、有大规模分布式系统开发、维护经验，有故障处理能力，源码级开发能力
5、具有良好的沟通协作能力，具有较强的分享精神
6、对Kudu、Kylin、Impala、ElasticSearch，github等系统有深入使用和底层研究者加分

工作职责：
1、负责公司的大数据处理框架的研发设计工作；
2、负责公司产品研发过程中的数据库设计文档的撰写；
3、参与小组的产品设计讨论，共同讨论和设计产品。

任职要求：
1、3年以上工作经验，熟悉Hadoop以及Hadoop生态圈上的各种应用的几种，如Hbase、Hive，或者分布式数据库Impala等；
2、熟悉JAVA/Scala编程语言，熟悉面向对象和设计模式，熟悉Linux平台，可以编写代码编程使用Hadoop和基于Hadoop开发大数据处理系统；
3、拥有实际的Hadoop的项目经验；
4、熟悉软件开发流程和配置库的使用，拥有软件开发流程中的代码规范意识、配置管理规范意识、文档撰写规范意识和团队合作沟通交流意识。

岗位职责：    
1.参与亿玛实时计算平台的迭代，解决各种线上问题，逐步完善系统，提升系统的吞吐率，保证高可靠性。    
2.推进实时计算平台在产品落地，提升自动化水平，提升用户体验。    
3.能够独立完成一个实时分析系统的设计，并主导代码实现，测试及上线。    
任职要求:    
1. 对数据结构及算法有一定的了解，动手能力强    
2. 掌握实时计算技术体系包括数据采集、消息队列 Kafka、计算引擎 Storm/Flink    
3. 对实时计算所涉及的事务、容错、可靠性有深入理解    
4. 精通 java，了解 JVM ，熟悉 linux 平台，掌握 shell 的日常使用，掌握 clojure 的加分。    
5. 熟悉 Hadoop 生态圈：掌握 MapReduce、Hive    
6. 熟悉 ElasticSearch 及其生态圈    
7. 对大数据技术充满热情，有流式计算开源项目 Kafka、Storm 有源码级研究的更优。    
8. 具有大型实时计算系统构建者，大数据引用经验者优先。    




岗位职责：
网络爬虫的维护与研发；
整合不同数据源（ETL），为数据分析挖掘提供规整的数据；
基于hbase、presto数据仓库的构建与维护；
从事hadoop、spark、storm等分布式大数据平台的设计与开发；
根据业务需求，提出最优的技术解决方案；
与公司各条业务线沟通协调，充分合作，发挥数据在业务产品中的作用；
 
 
任职要求：
本科及以上学历，计算机、统计学等相关专业，3年以上软件开发经验或一年以上大数据经验；
熟悉linux环境，能够熟练使用shell、python等脚本语言；
熟悉git版本控制、拥有docker实战经验；
至少精通java/python/scala编程语言一种；
熟悉Hadoop、Storm、Flume、Kafka、Presto、Mahout等，有实际集群搭建和调优经验；
精通Spark技术，熟悉Spark相关算法并有实践经验，熟悉神经网络等机器学习算法；
有大规模分布式系统管理、资源调度等经验，熟悉YARN、Mesos、ZooKeeper等。
具备数据库系统基本理论知识，熟悉mysql、mongodb。精通Hbase或Cassandre等列式数据库；
有较强的团队协作和沟通能力、学习能力以及独立解决问题能力，有强烈的责任心和良好的编程习惯；
有爬虫、搜索引擎、数据挖掘/分析、数据仓库等经验者优先；




我们可以提供：
1、挑战性的工作机会和良好的个人发展晋升空间。
2、舒适的办公环境、良好的团队合作氛围和自由的技术发挥平台，充分重视员工的自我价值实现。
3、五险一金、员工福利、每周羽毛球、拓展等各类活动、集体旅游......
4、绩效奖励及超弹性的调薪福利结构。
5、五天工作制，周末双休。
  
  鹏元数据-匠心独造，请加入我们吧，共同构建全球领先的大数据信用风险评价技术平台!

职位描述:- 金服数据平台的设计和研发、数据分布式处理、实时计算等- 完善数据监控、数据地图、数据质量、数据周期、数据安全、BI等模块的系统集成和开发，构建灵活好用的数据管理平台- 与数据仓库团队、产品经理、算法团队一起创建高效、可伸缩的数据产品和服务岗位要求:- 本科及以上计算机、统计学、数据库、机器学习等相关专业，5年以上数据相关工作- 熟悉当前主流的开源数据平台和工具以及数据云服务，如：Hadoop、HBase、Spark等，并具有Hands-On能力；- 对业务数据模型、数据仓库、数据分等大数据系统的架构有清晰的思路和落地执行的方案，对数据服务、数据产品的模式有清晰的理解；- 熟悉Java语言体系相关技术和网站、网络应用开发，熟悉JVM基本原理；- 熟悉MVC开发架构，对Spring、MyBatis等开源框架应用经验丰富；- 对Linux开发和运行环境非常熟悉；熟练使用Tomcat、Jetty等Web服务器，熟悉Dubbo、Thrift等RPC框架；- 熟悉HTML、CSS、XML、JSON等技术，熟练掌握JS/JQuery, AJAX等前端技术者优先，欢迎Javaweb全栈工程师；- 对数据库原理、数据存储原理、常用数据分析算法深刻的理解，并善于分析业务数据并将算法和数据平台技术应用与实际业务产品；- 善于制订团队目标和敏捷开发的迭代节奏；- 无障碍阅读英文资料，并不断跟踪和实践前瞻性技术。

岗位职责:1.参与公司HADOOP大数据平台建设；2.参与公司爬虫体系平台建设；3.参与公司客户统一交互（接触）平台建设。
任职资格:1.本科及以上学历；2.精通java，两年以上java相关开发经验 ，有scala语言开发经验优先； 3.熟悉linux开发环境，了解网络、性能等相关命令；4.有分布式运算相关开发经验，有mapreduce、storm、spark 等相关开发经验，有开源代码贡献优先；5.能快速学习，实际动手能力强，勤奋肯干，有责任心。

岗位职责：
1、负责公司的大数据处理框架的研发设计工作，利用大数据工程技术处理海量业务，用户行为日志；
2、 参与公司的数据产品研发，大数据平台应用及规划，支撑业务需求增长；
3、调研新技术在业务中的可行性，参与数据基础架构规划和数据治理规范制定，并实施推广；
4、 跟踪并分析公司产品相关数据，为产品创新、产品设计及产品优化提供数据支持依据。
任职要求：
1、 熟悉hadoop及hadoop生态圈中的常用组件，如Hive、Zookeeper、Flume、Kafka、Storm、Spark、Yarn、Impala等，搜索引擎等大数据框架；
2、 掌握实时流计算技术，有实际大数据项目开发经验；
3、用过Kafka/Flume/ELK等常见的一种或多种数据收集处理技术；
4、 熟练使用一种数据库开发技术：Oracle、Postgres、MySQL等，能运用SQL实现数据加工处理；
5、精通Java编程，至少熟练使用一种脚本语言，Shell、Python等；
6、良好的学习能力和阅读习惯；
7、对技术，事务有浓厚的好奇心。

1、2年以上工作经验全日制统招本科（经验优秀可放宽至大专），来自互联网、金融等还有各种数据分析行业优先；
2、熟悉主流数据库Hadoop，shark，oracle、sql  server，MySQL，mongodb等数据库中至少一种； （必须有Hadoop方面的经验）
3、具有数据仓库ETL测试经验优先；
4、熟悉大数据/BI开发流程；
5、态度端正，工作积极主动，有责任心，耐心，并具有很强的团队合作意识。

岗位职责:
1.负责基于Spark/Hadoop技术的海量数据的处理、分析、统计、挖掘工作；
2.基于Spark/Hadoop框架的数据仓库的设计，开发，维护；
3.根据需求使用Spark Streaming和Spark SQL进行数据处理、查询、统计等工作。
任职要求:
1.计算机相关专业本科以上学历，两年以上技术相关工作经验；
2.熟悉Spark，了解Hadoop相关技术；
3.熟悉java, Scala开发；
5.熟悉Apache Flume、Kafka 优先；
6.熟悉Zookeeper、HBase等优先；
7.有过海量数据系统开发经验者优先。



岗位职责:
-深入研究支撑大数据业务相关技术，持续优化服务架构
-深度参与数据处理和存储的业务系统的设计与实施
-分布式存储计算框架的bug修正、二次开发及性能优化
-大数据技术前瞻性研究与实现
-大数据相关产品调研、优化和功能开发

任职资格:
- 本科或以上学历，计算机相关专业，有操作系统、数据库等专业知识基础
- 良好的系统分析、代码编写能力
- 需要有较强的学习能力和思考问题能力，责任心强，有良好的沟通适应能力
- 熟悉Java，熟悉IO、多线程、RPC等基础技术
- 实践并较熟悉一个以上大数据计算框架（Hadoop、Spark、Storm、Flink等）
- 实践并较熟悉一个以上大数据数据库或查询引擎（HBase、Hive、Cassandra、ElasticSearch等）


加分项：
- 有大数据或高性能项目的源码阅读和修改经验
- 有参与过自研大数据或高性能项目
- 有开源社区代码贡献经验
- 有技术负责过较大数据规模的项目经验
- 有非常强的自我驱动和学习能力，自信能弥补一定程度的经验不足

岗位职责及工作内容：
1. 负责数据平台的多信息源数据分析和挖掘；
2. 根据业务需求整合优化大数据架构，并协助业务部门设计和改善流程；
3. 理解数据挖掘算法并将其用于实际的应用场景中。

任职资格：
1、熟悉HDFS/HBase/Hive/MapReduce/Storm/Spark等相关技术；
2、了解机器学习、数据挖掘的基本算法；
3、熟练掌握一种或多种编程语言：Java，C++，Python等；
4、熟悉linux平台下的基本操作及编程；
5、有较强的学习和沟通能力，良好的团队协作精神，极强的责任心，有钻研精神，有带团队经验或意向为佳；
6、计算机相关专业本科及以上学历。

1、负责大数据基础架构平台（Hadoop/Spark/MPP DB）的自动部署；
2、负责线上数据平台的运维，保障服务的稳定性和可用性；
3、参与超大规模数据快速查询系统的架构设计和开发；
4、研究大数据前沿技术，改进现有系统的服务和运维架构，提升系统的运维效率。
任职要求：
1. 熟悉linux shell及SQL语言
2. 了解Hadoop等分布式技术，数据仓库技术；
3. 熟悉数据仓库数据流监控、故障自动化定位及运维；
4. 强烈的责任心与求知欲，愿意学习新技术并能快速应用；
5. 有较强的书面与口头沟通表达能力，独立分析、解决问题的能力；
6、做事认真负责，自学能力较强。
7.能够接收出差

加分项：
1.有开发经验者优先；
2.了解docker、mesos等技术的使用者优先；
3.熟悉mr,hbase,hive,spark,flumn使用者优先。

【项目介绍】
为公司全线业务提供通用的平台技术和产品支持，在满足产品快速迭代、规模迅速扩张的要求下，实现高质量，高扩展性的服务。负责项目包括且不限于搜狗支付中心、搜狗账号中心、还有各种创新项目的孵化。在这里，你将与搜狗各业务线负责人直接过招，与各领域技术大牛亲切合作，还有机会亲手打造属于自己的创新项目。
【岗位职责】

负责公司全产品线的数据统计，支付平台和账号系统的大数据处理和数据挖掘，
基于公司级海量数据和行业竞品数据做智能化分析，为产品和商业提供有价值的数据参考和决策
基于海量的用户反馈数据和人工智能技术，做智能化的处理和决策

【任职条件】
1. 硕士及以上学历2. 具有三年以上算法研究经验；3. 熟悉主流的深度学习算法和框架4. 熟练掌握一门开发语言5. 有机器学习，自然语言处理，人工智能项目实际工作经验优先

岗位职责：1. 负责大数据平台建设与维护2. 负责报表，搜索，推荐，多维分析等数据相关系统的开发工作3.负责数据提取工作
任职要求：1. 深刻理解大数据处理(流计算、分布式计算、分布式文件系统、分布式存储等)相关技术和实现方法，有架构和设计实践经验；2. 有互联网产品BI开发经验，有网站数据、用户数据、电商、点击流、精准营销等相关经验优先；3. 熟悉Hadoop/Hbase/hive等，掌握MapReduce, Storm或者Spark编程,，熟悉数据挖掘策略与算法。4. 熟悉数据模型建模，以及常用ETL工具；5. 具备Java/C++/Python等开发经验。6. 良好的逻辑思维能力，熟悉业务抽象和数据模型设计，具有很强的分析问题和解决问题的能力，对解决具有挑战性问题充满激情；

职位描述：1.负责基于Spark的并行计算平台的开发与优化工作。2.负责流式计算平台开发结合业务的应用、处理实时数据、实时应用场景的开发;3.负责设计，开发，优化数据接入、数据存储、数据计算服务框架；4.负责优化分布式框架，解决大并发下的各种问题.5.有过数学建模经验，有较强的数据分析能力；

任职要求：1.二年以上相关工作经验，本科或以上学历，计算机相关专业；2.具备扎实的Java语言基础，熟练使用Linux操作系统，熟悉Shell编程；3.熟悉并行计算或者分布式计算，熟练掌握RDD编程及Spark框架；4.有Spark、Hadoop等数据平台的开发和使用经验;5.对性能调优，算法效率和分布式计算的资源管理策略有较深的理解；6.熟悉ZooKeeper/kafka/Hadoop/HBase/Flume等平台者优先；7.了解Scala语言，熟悉redis、mysql等缓存及数据库服务；
8.熟悉Spring、Spring MVC、ibatis,SparkStreaming或Storm熟悉其中一种或多种框架者优先；

岗位职责：1、负责海量分析挖掘平台分析功能系统设计；2、负责根据业务场景，产品需求抽取、分析处理。3、负责撰写相关文档；

任职要求：1、计算机及相关专业本科以上学历，2年以上大数据相关工作经验；2、熟悉Hadoop/spark等开源系统, 有相关系统设计经验；熟悉scala或java语言编程；3、擅长基于Spark/Spark streaming/impala/hive环境的大数据分析处理；4、良好的团队合作能力，勤奋好学。5、有大数据分析处理经验优先考虑。

岗位职责：
1.负责大数据平台的建立、维护；
2.参与基于大数据平台建立相关的数据整合清洗、数据应用的设计和开发等。
3.参与跨部门协作，提升数据质量、稳定性和性能；
4.负责处理推荐系统相关数据流和数据整合。

任职要求：
1.统招二本及以上学历，计算机相关专业，2年及以上大数据相关开发经验；
2.熟练Java开发，了解 Spark, HBase, hadoop、Kafka，flume等相关技术和原理；
3.必备一定的沟通、协调能力和抗压能力，良好的自我学习驱动；
4.加分项：熟悉Python、Scala等其中一种编程语言，可用python做数据分析；熟悉统计学原理或机器学习等理论。

职位描述：
1.基于Hive， Spark，Hadoop的计算架构，进行大数据开发工作；
2.在分布式集群上进行Hive和Spark数据开发；
3.能够定位数据计算任务的瓶颈并进行性能优化；
4.能够针对具体的业务场景，实现一些机器学习运算。

职位要求：
1.计算机相关本科及以上学历，有强烈的责任心和团队合作精神、具备良好的沟通能力以及快速学习的能力，有独立项目开发经验，优秀应届毕业生可酌情考虑；
2.熟悉数据库、数据仓库建模方法论，熟悉数据建模；
3.精通SQL语言，至少熟练掌握以下一种大数据开发技能，Hive开发，MR开发，Spark开发；
4.有ETL性能调优经验者优先；
5.熟练掌握MR、Spark编程模式，有数据计算性能调优经验；
6.有数据仓库部门从业经验者优先。

岗位职责:1.编写hive sql，udf，mr满足日常ETL任务2.负责数据提取以及用户画像，用户标签开发。3.负责数据产品，数据平台等开发。
任职资格:1.全日制本科以上学历，3年以上相关工作经验2.有hadoop，hive应用于开发经验，能够熟练编写mr程序和hive sql和udf，能够熟练编写较为复杂的hive sql语句3.熟悉一种或多种语言：java，python，shell，scala4.熟悉使用至少一种的nosql数据库，如：redis，hbase等5.熟悉至少一种调度工具，如：oozie，kettle等6.熟悉大数据技术，如：hadoop，hbase，hive，spark，flume，kafka等7.熟悉前端开发。8.有linux系统操作经验，能够在linux系统下进行工作9.具备优秀的编程能力和良好的编程习惯。10.对技术有激情，能够快速接受和掌握新技术，有良好的团队合作能力。

岗位职责:1. 开发天天果园基于大数据平台的报表；  2. 运维以Hadoop、Hive和Spark为基础的天天果园大数据平台  3. 辅助设计基于大数据技术的数据产品架构，并参与实现  4. 辅导实习生及初级开发人员  5. 领导布置的其他任务
任职资格:1.学历专业要求：计算机及相关专业，全日制本科毕业，研究生优先  2.工作年限/行业要求：3年及以上互联网及软件行业  3.硬性技能要求：能熟练使用Hadoop、Hive和Spark等大数据软件；能熟练使用SQL类语言，包括但不限于HiveQL，SparkSQL，MySQL-SQL等；能熟练使用Java/Scala/Python编程语言的一种；能熟练使用基于Linux的脚本进行编程；熟悉常用的ETL过程及工具，有Kettle经验者优先；熟悉Linux操作系统及其常用命令；  4.软性能力要求：具有乐观向上的心态，较好的沟通表达能力，良好的团队合作精神，持续学习的心态和能力  5.其他要求：

岗位职责：
1. 依据业务模型，负责大数据计算平台的架构设计，以及核心功能的开发，满足实时、离线计算的需求；
2. 负责产品实时计算平台的设计和开发，为实时监控、实时运营数据分析、个性化推荐提供数据支持。
任职要求：
1. 本科以上学历，扎实的计算机专业基础，有3年以上大数据平台开发经验，1年以上的大数据计算/存储设计经验；
2. 精通一种或几种以下语言，Python/Java/Scala；
3. 熟练掌握Hadoop、Spark、Storm、HBase的原理特性以及适用场景，精通Spark实时计算开发，并具备大规模数据集的实际开发经验；
4. 有大规模数据计算平台的架构设计经验（日处理数据量不低于2TB），且精通大规模数据集的存储方案设计；
5. 具备用户问题的定位及解决能力，善于归纳总结，对数据敏感；
6. 思维活跃、敢于担当、乐于沟通，具有良好的团队合作精神，积极主动，能承受一定的工作压力。

岗位职责：
1、参与公司数据产品与应用的研发 ;2、负责数据加工、清理、处理程序的开发;3、负责数据相关平台的维护和优化;任职要求：1、计算机相关专业本科学历以上；2、3年以上相关大数据工作经验；3、 熟悉Linux系统常规shell处理命令；4、熟悉Hadoop生态相关技术，熟悉MapReduce、Hive、Hbase，Spark等；6、熟悉Python，爬虫技术等优先考虑；

注：提供食宿；若不住宿，上下班提供班车（现阶段线路为公司至2号线虹桥火车站，其他线路积极开发中）。
岗位职责：
1、负责大数据平台的搭建；2、负责各种业务数据的采集和存储；3、负责实现数据统计和分析需求的实现和图形化展。岗位要求:1、计算机相关专业,3-5年工作，物流快递行业优先；
2、熟悉数据仓库的ETL的开发和数据建模；3、精通Hadoop/Spark平台的配置和搭建,具有基础运维经验优先；4、精通MapReduce原理；5、熟悉Java, Hbase/Hive, Linux Shell编程；6、熟悉Flume配置,具有Kafka经验优先；7、具有数据可视化经验优先。


一、工作职责
1、基于Hadoop各种开发工具和框架实施数据采集、分析；
2、配合机器学习工程师对数据进行清洗、预处理；
3、负责基于hadoop集群，spark集群编写分布式算法实现；

二、任职要求
1、2年以上工作经验，本科计算机及相关专业学历；
2、基础扎实，熟悉数据结构和算法； 
3、熟悉Java、Scala、Python语言，较强的独立开发能力，具备良好的代码风格；
4、具备MapReduce、Hive、Spark、Redis等NoSql平台开发能力；
5、良好的数据敏感能力，敏锐而富有耐心。与数据打交道而乐此不疲；
6、优秀的沟通能力，有创新精神，乐于接受挑战，能承受工作压力。

1、从事数据仓库领域至少2年以上，熟悉数据仓库模型设计与数据处理技术 
2、掌握至少一种数据库开发技术：Oracle、Teradata、DB2、Mysql等，灵活运用SQL实现海量数据ETL加工处理 
3、熟悉Linux系统常规shell处理命令，灵活运用shell做的文本处理和系统操作 
4、有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验着优先，重点考察Hdfs、Mapreduce、Hive、Hbase 、spark
5、熟练掌握一门或多门编程语言，并有大型项目建设经验者优先，重点考察Java、Python、Perl 

工作职责：
1. 参与数据系统的架构设计和开发；2. 负责离线计算产品设计、研发；3. 跟踪并解决用户使用离线计算产品过程中的问题；4. 跟踪技术社区发展动态；5. 研究大数据前沿技术，提升系统运维效率。任职资格：1. 掌握c++javapythonnodejsScala等任意一门开发语言；2. 熟悉Hadoop，了解hdfsyarnhivehbase等工作原理；3. 了解Hadoop应用场景；4. 有hdfsyarnhivehbasespark等集群配置、参数调优、性能优化经验；5. 有集群问题定位、处理、版本升级等经验。6. 有Hadoop相关Commit优先

1、为公司提供大数据存储、分析、计算支持；
2、研究业界最新的大数据技术，负责大数据系统的设计与开发。
任职要求：
1、五年以上工作经验，至少2年基于大数据的工作经验，本科以上学历；
2、熟悉分布式存储或NoSQL数据库技术；
3、精通java或scala语言，具有面向对象编程思想，对底层实现有一定研究；
4、精通spark编程，具有实际大型分布式集群项目开发经验；
5、熟悉Hadoop生态环境，熟悉hadoop相关技术，如flume、Kafka、Hdfs、storm、hive、hbase等；
6、熟悉Linux操作系统，熟悉shell、python编程；
7、了解视频推荐类相关算法，有相关工作经验，具备优秀的团队意识和沟通能力，学习能力和主动性强。


【岗位职责】

1、针对业务需求，负责开发可扩展的、分布式的大数据系统；

2、面向业务目标，从数据模型、数据分布、数据传输、数据存储等方面进行大数据系统的开发；

3、研究前沿的数据分析建模，数据挖掘及机器学习算法，探索具有数据分析、数据挖掘能力的创新型产品。

【岗位要求】

1、至少3年以上hadoop，hive，spark开发经验；

2、精通Hadoop生态系统及相关组件，拥有Apache Hadoop实施经验；

3、精通Spark计算框架的实时采集和流处理；

4、精通Java、scala编程；

5、熟悉整个大数据的处理流程，包括数据的管理，数据的分析挖掘，服务器扩展；

6、优秀的客户服务意识，客户管理意识；思想意识开阔；

7、逻辑思维能力强，具备优秀的文档编写和良好的沟通与表达能力；

8、具有较强的沟通协调、团队合作和抗压能力。

岗位职责：
1.负责大数据相关Saas产品设计和开发，参与需求分析，系统分析及详细设计；
2.负责实时计算系统核心模块的架构设计&amp;开发。
 
岗位要求：
1.本科以上学历，计算机相关专业；
2.两年以上 Java 开发经验，JAVA基础扎实，熟悉io、多线程、集合等基础知识，对JVM原理有一定的了解；
3.熟悉Hadoop、Spark、HBase、ES等大数据系统；
4.熟悉大型分布式系统设计与开发，熟悉各种web缓存、消息队列技术原理。在实际项目中使用过redis、kafka；
5.密切关注大数据相关技术的发展趋势,有Hadoop/Kafka/Zookeeper/Spark/Elasticsearch等相关技术研究或开发经验者优先。

1. 大数据平台开发；
2. 大数据平台部署、实施；
3. 大数据平台运行性能、可用性、扩展性等监控与优化。

任职要求：
1、本科以上学历，有2年以上 Hadoop/Hive/Hbase/spark 生产环境工作经验，有 spark sql或spark streaming开发经验，有Cloudera的CM使用经验；
2、熟悉 Hadoop/Hive/Hbase 原理及运维、调优方法，阅读和修改过源代码者优先；
3、熟悉Kerberos安全认证系统，实施过集群权限管理, 资源隔离方面的方案规划或二次开发工作；
4、熟悉主流的云计算、大数据产品（hadoop、spark、flume等）和数据分析技术（机器学习)并具有相关项目经验。

岗位职责：
1、负责大数据平台的设计和开发
2、负责海量数据的处理、分析、挖掘
3、负责高并发、大存储的数据系统，实时计算处理系统的研发 
任职要求：
1、精通Map Reduce / Spark编程，或者具有其他并行计算的实践经验
2、熟悉Mysql/Redis 等常用SQL和NoSQL数据库
3、熟悉 Kafka等消息中间件
4、精通数据结构和算法

 具有以下条件者优先：
1、一年以上大数据处理，大规模的数据分析和算法实践  2、一年以上hadoop 相关项目实际研发经验，比如/hive/hbase/hdfs/spark/oozie/zookeeper/mahout等
3、有数据挖掘经验者或机器学习算法熟练者
4、有丰富的大数据集群部署和维护管理经验

岗位职责
1、负责大数据处理平台应用的开发工作；
2、利用Hadoop yarn/Storm/Spark进行开发、存储、分布式计算应用的代码实现；
3、优化Hadoop yarn/Storm/Spark 参数，实现系统调优，满足行业应用的实时大数据处理需求；
4、学习新技术，提高整个平台的计算能力和效率。
 
任职要求
1、2年以上Hadoop/Storm/Spark开发经验，对分布式、并行计算理论有深刻理解；
2、精通java/scala/python任一语言；
3、对Hadoop/Storm/Spark源码有研究，有大数据平台开发工作经验者优先；
4、有很好的技术敏感性，良好的学习能力和吃苦耐劳能力；
5、具有较好的沟通协调能力、团队合作能力、文档编写能力；
6、工作地点：贵州省贵阳市。

职位描述:- 构建业务指标体系，建立和完善常规报表，定期监测业务数据并提供相关数据支持 - 根据业务部门需求，充分利用现有数据资源，进行数据提取、整理和挖掘- 研发数据查询和平台，方便输出各类业务数据，供业务部门使用职位要求:  - 熟悉常用数据分析算法和工具  - 有大数据系统使用和开发经验，包括但不限于Hadoop/Spark/Hive/Hbase等  - 具有很强的开发和动手能力，熟悉一种以上编程语言，如Python，Java等  - 具有优秀的数据建模和沟通能力，能把应用问题转化为数据问题，能把数据分析的结果转化为应用语言  - 具有较强的数据分析能力和数据敏感度，能够把握数据和分析对象的关系与重要性，善于从海量数据中总结规律  - 具有2年以上数据仓库建模和ETL架构设计，或大数据存储/计算架构经验  - 具有本科及以上学历优先条件:  - 对互联网产品有足够的兴趣，活跃的使用者  - 有互联网日志采集/大数据处理/数据可视化经验优先

岗位职责：
1、负责业务的数据收集、建模、统计与可视化，全方位支撑线上产品和线下业务迭代扩张；
2、构建数据的监测与分析平台，帮助业务人员快速、及时发现问题并找到原因；
3、进行数据应用开发，从海量数据中挖掘用户偏好、关联信息，完成用户端的精准推送。

任职要求：
1、本科及以上学历，计算机相关专业；
2、至少1年大数据工作经验，熟练掌握Java/Python/PHP至少一种编程语言；
2、熟悉hadoop，Storm，Kafka等开源平台、具备分布式数据存储与计算平台搭建/应用开发/运维的相关实践经验；
3、熟练掌握SQL，理解 Hive/Mysql 基本原理和调优策略；
4、具备优秀的业务理解能力，对数字敏感，有较强逻辑分析能力；

任职要求：
1.大学本科以上学历，计算机、软件相关专业优先；
2.熟悉MySQL，对MySQL的较大量数据存储、优化有丰富的经验；
3. 一年以上基于hadoop、hive、spark等分布式计算环境进行大数据处理经验优先；
4. 熟练使用Linux，熟悉一种以上脚本语言（Shell、Perl、Python等）；
5.对常见的数据分析模型有一定的了解，有海量数据分析项目经验、数据挖掘项目经验尤佳；
6.优秀的解决问题、抗压能力，具有较强的数据分析能力
7.有较强的抗压能力；
岗位职责：
1、负责公司大数据平台的规划和建设；
2、负责制定数据建模、数据处理、数据运维和数据安全等架构规范并落地实施；
3、设计并实现数据仓库、数据挖掘、BI、机器学习等数据系统建设、开发；
4、利用统计机器学习、深度学习算法改进数据系统的智能；
5、主导并身体力行整个技术团队的DevOps建设和实践；
6、 辅导团队，提升公司整体数据研发能力

岗位职责：1、负责操作系统运维；2、负责CDH平台以及各类大数据组件(Hadoop、Hbase、Solr、Hive、Impala、Spark、ZK)安装调试支持；3、负责大数据平台的性能优化和故障处理；4、负责大数据平台的日常操作、运维。任职资格：1、掌握 Linux系统基本命令，熟练使用 RHEL、CentOS 等Linux操作系统；2、掌握Shell脚本编程；3、掌握CDH的安装、部署和优化；4、具有较好的故障排查和解决问题的能力，能快速分析系统相关的故障原因和解决方法；5、有大数据平台安装经验者、尤其是在Kerberos认证环境下的优先；6、有Mysql/MariaDB DBA的经验优先；7、熟悉Ansible、Nginx优先。技能关键字：Cloudera、CDH、Elasticsearch、Kylin,、Ansible薪资福利： 1、有竞争力的薪金+各种补贴+年终奖金，有挑战性的工作内容，持续的高质量培训计划，良好的晋升空间；该岗位为持股岗！ 2、公司福利：只有你想不到，没有我们做不到！ ① 相信你是同我们一起奋力向前的人，不需要我们的监管，SO弹性的工作制； ② 相信你是一个顾家的人，如果回家过年假期不够，没关系，我们有探亲假； ③ 如果你想远途旅游，想去放松，当然可以！我们每年一次说走就走的旅游，还不会占用你周末的宝贵时光； ④ 如果你周末不知道做什么，我们可以帮你安排~放松的团建活动让你不再孤单； ⑤ 如果你任性，觉得世界好大，想去看看，没问题，我们的年假绝对让你想去看哪都成； ⑥ 有没有午餐补贴？当然！那通讯补贴呢？我只想说，童鞋，你从此买手机再也不用割肾了； ⑦ 元旦，春节，劳动节，端午节，中秋节，国庆节......中国传统的节日，我们会用传统的方式庆祝，节日福利发不停； ⑧ 情人节，青年节，儿童节，万圣节，圣诞节......我们也不会放过！ ⑨ 员工游艺室，活动区，咖啡吧.....我们全部都有！ 福利多多说不完，你还犹豫什么？

岗位职责：
1、业务数据仓库架构设计、建模和ETL开发，构建可扩展的数据仓库和分析解决方案；
2、为前端展示提供数据支持，为业务人员提供数据查询； 
3、大数据仓库日常管理、跑批、维护、监控。
任职要求：
1、2年以上大数据仓库项目开发经验、熟悉主流的大数据架构；
2、具有hadoop集群运维经验，熟悉Hadoop, Spark，Flume、Hive、Impala和HBase等主要工具的使用及安装配置管理；
3、熟悉Hadoop集群所需要的硬件配置。能够完成对Hadoop集群进行相应的监控、维护和性能调优；
4、熟悉hbase、hive等大数据分布式数据存储，熟悉sqoop、flume、azkaban等大数据ETL调度工具；
5、熟悉主流的消息队列中间(主流MQ、Kafka等)；
6、具有较好的故障排查和解决问题的能力，能快速分析系统相关的故障原因和解决方法；
7、有OLAP应用开发经验优先，如Kylin；
8、有大数据系统架构设计、数据分析挖掘经验者优先；
9、责任心强、思路清晰、学习力强。

        职位职责：
1、负责今日头条海量用户行为数据的处理，在分布式计算平台基础上建立高效、实时的数据 pipeline； 
2、负责推荐系统、广告系统的数据分析，发现模式与规律，为实验解释、系统改进提供数据支持； 
3、负责 Hadoop，Spark 等大数据基础设施和平台的改进，解决大规模生产环境集群可用性和性能优化问题。

职位要求：
1、2018年毕业生，本科及以上学历，计算机相关专业，每周可实习4天以上，持续3个月以上；
2、热爱计算机科学和互联网技术，优秀的编码能力，乐于快速学习和尝试新技术、新工具；
3、对数据敏感，掌握量化分析方法，善于从数据中发现问题，提出假设并使用数据进行验证；
4、对至少一项分布式计算平台有使用经验，例如 Hadoop，Spark，Hive，Storm，Kafka 等；
5、有参与开源项目对社区有贡献的经历，有互联网公司实习经历，有大数据处理或用户行为数据分析经验者优先。
        
职位描述：
1、负责和参与公司大数据基础架构平台的运维，保障数据平台服务的稳定性和可用性；
2、负责和参与自动化运维系统及平台的建设；
3、负责优化部门运维流程提升运维效率。

任职条件：
1、一年以上大数据平台运维经验；
2、掌握 Hadoop, Hive/Impala, Spark, Yarn, Kafka, Flume 等组件的安装、配置、使用和优化；熟悉源码者优先；熟悉 CDH 者优先；
3、掌握 Linux 操作系统的配置，管理及优化，能够独立排查及解决操作系统层的各类问题；
4、精通 Python, Shell，能够开发运维自动化组件和工具；
5、熟悉 MYSQL，熟练掌握 SQL；
6、工作认真负责，有较强的钻研学习能力和分析解决实际问题的能力。

工作职责：
1.负责大数据平台等产品的架构、研发和持续优化；  
2.和业务团队深入合作，解决在业务发展中遇到的产品和平台架构问题；具备一定的前瞻性；  
3.具体领域包括但不限于推荐算法开发、分布式存储、大规模分布式计算、实时计算、跨平台资源调度、大规模分布式算法平台等； 
4.负责搭建效果监控平台，数据质量监控平台，数据中心建设，算法模型平台化建设； 
5.基于Hadoop生态圈进行扩展研发，构建统一的Data Infrastructure；
任职要求：
1、熟悉Java或scala开发，具有3年及以上Java开发经验，熟悉linux操作；
2、具有3年以上大数据或分布式数据仓库系统开发经验；
3、熟悉storm, spark, hadoop, hbase, akka等框架；
4、有较强的学习能力，对技术有钻研精神，并有较高的热情，热衷于新技术学习和实践；
5、优秀的团队合作精神，对工作有热情，能够承受住压力。

岗位职责：
    1、大数据分析平台算子研发；
    2、大数据分析平台算子和分析模型测试方案撰写、测试数据集构建；
    3、能够对外支撑大数据分析平台相关项目，后续能支撑大数据分析业务；
    4、编写大数据分析平台产品安装手册、用户手册等相关文档；
    5、对公司项目或产品进行客户现场测试

任职要求：
    1、熟悉shell脚本、熟悉maven；
    2、熟悉大数据相关技术：Hadoop、spark等；
    3、了解Scala、java编程；
    4、良好的沟通能力和缜密的思维逻辑。同时有计算机和数学专业背景优先；

【职位描述】
1.负责公司大数据平台和大数据核心产品研发；
2.负责公司业务数据的分析挖掘、预测；
3.参与公司大数据平台应用及规划，支撑业务需求增长。

【职位要求】
1.大专及以上学历，至少3年以上开发经验，精通主流框架，对数据结构和数据统计分析算法有较为深刻理解；
2.拥有海量数据处理和并行计算开发3年以上经验，熟悉Hadoop，Storm，Spark，HBase等分布式系统，有开发相关功能的优先，掌握Hadoop，Spark集群维护相关知识；
3.用过Kafka/Flume/ELK等常见的一种或多种数据收集处理技术；
4.熟悉一种或多种内存数据库开发，Redis/Memcache/MongoDB等；
5.熟练使用一种或多种数据库，Oracle/Mysql/Postgres等，有一定数据建模能力；
6.具备良好的软件工程研发素质，具备极限编程或者敏捷开发经验者优先；
7.良好的逻辑思维能力，能够从海量数据中发现有价值的规律，对数据敏感，能够发现关键数据、发现关键问题；
8.良好的沟通能力、团队精神和服务意识。

岗位职责：
工作职责：
1.海量内外部结构化和非结构化数据收集、分析方法和大数据解决方案的研究；
2.针对需求提供大数据分析技术解决方案；
3.参与大数据平台项目开发，包括架构设计、编程开发等工作；
4.根据业务需要，跟踪大数据技术领域趋势并能结合实际业务应用提出优化解决方案； 
5.实时数据分析系统，流式计算系统的设计和开发。
任职要求：
1.985/211院校统招本科以上学历；     
2.从事本岗位相关技术工作满5年，从事互联网/金融行业工作满3年   
3.企业公认的技术权威，掌握企业核心技术秘密，有较强的技术指导力； 4.洞悉行业技术发展方向，了解国内外主要竞争对手的产品、技术发展策略，有较强的技术能力；     
5.对专业理论知识有深刻的理解，熟悉相关专业知识，在技术研究或产品开发实践中积累了丰富的经验，有较强的知识创新力；     
6.有两个以上国内著名互联网/金融公司的大数据平台建设经验，精通Hadoop/hive/Spark/NoSQL/Storm/kafka等相关大数据技术；    
7.多结构数据采集、处理和存储管理技术；大型分布式数据处理架构及性能优化；    
8.工作认真负责，良好的团队合作能力，良好的沟通表达能力。     

职位工作内容：
1. 参与大数据平台的设计与开发，解决海量数据面临的挑战；
2. 管理、优化并维护Hadoop、Spark等集群，保证集群规模持续、稳定；
3. 负责HDFS/Hive/HBase的功能、性能和扩展，解决并实现业务需求；
4. 协助组内同学建立数据模型，对数据进行挖掘、优化及统计。
 职位技术要求：
1. 本科生及以上学历，2年及以上互联网系统或者其他企业应用系统开发相关经验；
2. 熟悉Hadoop/HBase/Spark/Storm/Hive，熟悉数据挖掘策略与算法；
3. 具备Java开发经验，Java编程基础扎实，熟练使用springMVC、Mybatis框架；
4. 熟悉关系型数据库mysql或者oracle；
5. 熟悉常用大数据中间件，有Zookeeper、Kafka、Elasticsearch等开发经验者优先；
6. 数据控，善于发现问题、解决问题,具备良好的分析和解决问题的能力，具备一定的钻研精神和持续学习的意愿，强烈的责任感和团队感，对负有挑战性的工作充满热情。

加入我们以后：
五险一金（必须标配）
补充医疗保险（商业保险、达不到医保额度的也可以报销啦！）
生日蛋糕+礼物（大家一起陪你过生日！）
带薪年假（你有我有全都有！）
团建活动（每月各种吃喝玩乐！）
节日红包（哇咔咔，拿到不要太开心哦！）
年度旅游（今年初去的日本、韩国、厦门，各种嗨~）
员工宿舍（每天步行上班，不挤地铁~）
员工1+1(给父母的一点点孝心）
弹性工作（晚点来也OK）
更多的福利不断增加中……

关于我们：
现在支付（www.iPaynow.cn）是一家致力于支付创新的高科技上市公司，“简单、勇敢、温暖”是我们团队的工作主旨。主要成员由前招行、前谷歌等银行与IT公司资深人士组成，致力于移动支付创新及综合支付解决方案，是新一代移动支付开发、应用及内容服务提供商。
我们是一个年轻化的团队，从80后霸道总裁到90后帅气小鲜肉，无论是工作氛围还是创意思想！我们是个小而精的团队，每个团队成员都是可以独当一面的角色，团队有左手开发、右手维护，打代码打机齐飞的程序猿；有以处女座精神挑战像素的射鸡湿；有敲的了代码的前端萌妹子；也有热衷行业动态与八卦的产品精鹰。每个员工都有很大的发展空间，无论是纵向发展还是横向发展，无论是团队整体还是自己本身，你的未来拥有无限的可能。 更重要的是，只要合理、只要有想法、只要你能够做到，就给你舞台！

职位描述：
1、构建分布式大数据服务平台，参与和构建公司包括海量数据存储、离线/实时计算、实时查询，大数据系统运维等系统2、服务各种业务需求，服务日益增长的业务和数据量3、深入源码内核改进优化开源项目，解决各种hadoop、spark、hbase疑难问题，参与到开源社区建设和代码贡献
岗位要求：1、计算机或相关专业本科以上学历（3年以上工作经验）2、精通C++/Java/Scala程序开发(至少一种)，熟悉Linux/Unix开发环境3、熟悉常用开源分布式系统，精通Hadoop/Hive/Spark/Storm/Flink/HBase之一源代码4、有大规模分布式系统开发、维护经验，有故障处理能力，源码级开发能力5、具有良好的沟通协作能力，具有较强的分享精神6、对Kudu、Kylin、Impala、ElasticSearch，github等系统有深入使用和底层研究者加分

 
CIBN微视听，一家底气十足的互联网公司，合作方包括腾讯、PPTV、搜狐、嗒嗒巴士、一条、二更、途牛、飞碟说、毒蛇电影、同道大叔、美人妆等。蓬生麻中,不扶自直！
 
我们可以提供：
1、年终长达12天的春节休假；国家规定7天的假期，我们给你额外延长5天，让你回家能够过得好年；
2、年度旅游；每年组织2次集体旅游，上半年一次，下半年一次；
3、免费零食，让你饿了就吃；
4、各大大小小节日及生日活动及福利发放；
5、考勤；迟到？我们没有这个概念+弹性上班+加班有饭吃
 
岗位职责：
1. 负责公司Hadoop大数据基础平台的设计和开发工作；
2. 负责数据仓库平台的设计和开发工作；
3. 使用Hadoop/Spark平台进行分析内部及外部的数据，配合业务团队进行定量和定性分析，把数据转化成为业务增值的信息；
4. 参与技术团队探索、评估新的技术和解决方案。
 
职位描述：1、计算机及相关专业本科以上学历，三年以上同岗位工作经验；2、熟悉Hadoop，hbase，hive，mongodb等相关环境；3、擅长基于Hadoop，Spark，Shark等环境的大数据分析处理；4、参与过大数据项目的架构和设计的优先考虑；5、有Android App用户行为数据统计项目经验者优先。


岗位职责：1.负责公司大数据业务集群的运维工作（Hadoop/Hbase/Hive/Spark/Storm/Kafka/Flume等）确保高可用；
2.负责集群容量规划、扩容及性能优化；3.设计实现大规模分布式集群的运维、监控和管理平台；4.参与业务架构设计，在设计阶段给出可运维性改进建议；5.深入研究大数据业务相关运维技术，持续优化集群服务架构，探索新的大数据运维技及发展方向。任职要求：1.至少掌握java/python/shell中的一种语言。2.熟悉Hadoop/Hbase/Hive/Spark/Storm/Kafka/Flume等开源项目优先；3.熟悉Linux操作系统的配置、管理及优化，能够独立排查及解决操作系统层面的问题；4.掌握puppet、kerberos应用的优先；5.良好的客户服务意识，强烈的责任心和使命感，执行力强，富有团队合作精神；6.对大数据方向运维有很高的热情和兴趣，能主动学习了解相关知识。

岗位职责
加入我们一起建设专业的金融大数据处理平台，通过结合使用各种传统和新兴的数据处理技术，为内外部客户提供稳定，及时，准确的基础/衍生数据及服务。在这里你需要根据数据量和数据特点，选择和设计合适的技术方案，实现稳定高效的数据处理流水线，并和团队分享你的心得，指导新人成长。
任职条件
必需技能： 1. 扎实的计算机基础知识，熟悉常见的数据结构与算法，操作系统以及数据库基础知识。 2. 熟练掌握以下至少一门编程语言：Java/Scala/Python，熟悉常见的大数据技术，如Hadoop/Spark/Kafka等。 3. 良好的问题分析和解决能力，有学习新技术的热情。 加分项： 1. 有一定的金融投资领域基础知识，有过金融数据处理背景尤佳。 2. 有BI方向的背景或工作经验，熟悉各种数据库/NoSQL/数据仓库的特点。 3. 了解docker容器化以及容器编排相关知识。

技能要求：
1、本科以上学历，计算机相关专业。
2、5年的Linux 经验。
3、3年Hadoop生态系统相关经验，掌握hive、impala、hbase等应用组件。
4、深入理解Hadoop设计原理，集群连通性，安全和影响大规模系统性能的因素。
5、深刻理解自动化工具（Puppet, chef)。
6、熟练至少一种技术：Python，Perl，ruby或Bash。
7、能够用Chef, Puppet, shell创建自动化。
8、良好的合作和沟通能力，能跨团队合作。

岗位职责：
1.将负责或参与TB/PB级商业、产业数据的采集、ETL处理、元数据管理、多层仓库组织等数据平台建设和开发工作；
2.根据业务需求，制定系统的整体技术框架、业务框架；
3.搭建和部署hadoop集群，保证集群规模持续、稳定；
4.利用大数据平台实现对数据的分析和处理。
任职资格：
1.计算机或相关专业本科以上学历,3年以上开发工作经验；
2.两年以上Hadoop的应用开发经验，至少一个企业及数据仓库项目开发经验或大数据处理项目经验；
3.SQL基础扎实，有较好的SQL性能调优经验，理解Hive/Mysql 基本原理和调优策略；
4.能深入了解hadoop集群及其周边常用模块(如HDFS/Hive/HBase/YARN/Storm/Zookeeper/Flume/Kafka/RabbitMQ)；
5.熟悉Python、shell中的一种；
6.具备良好的分析和解决问题的能力，具备一定的钻研精神和持续学习的意愿，强烈的责任感和团队感，对负有挑战性的工作充满热情。

工作职责：                        1. 根据项目大数据处理业务需求，制定大数据处理平台技术架构                        2、搭建和维护大数据集群，保证集群规模持续、稳定地扩容，高效平稳运行                                        3、制定大数据处理平台维护、优化、安全及高可用方案4、编写核心代码                                                                                任职资格的具体描述：                                                1、5年工作经验以上，有丰富项目开发经验，精通java等主流编程语言。                        2、熟悉hadoop、Hbase、Spark工作原理，2年以上实战经验，熟悉分布式计算实施过程中的各种问题。 3、熟悉Zookeeper、Storm、Redis、Kafka、mysql、mongoDB、Tomcat等，有丰富的运维经验者优先。                4、熟悉Linux/Unix系统，熟悉python脚本语言。                        5、具有较强的沟通能力，工作协作能力，学习能力，执行力，组织能力。                                         6、工作态度积极主动、细致、有全局观，有一定的抗压能力，善于与他人合作，良好的团队合作意识。

1.技术研究：大数据风控、机器学习、区块链等技术在风险业务领域的应用。
项目/产品研发落地；
2.从事风险团队相关技术研究及研发落地方面的工作，涉及到大数据、深度学习、R语言、区块链等方向，要求自主学习能力强，有以上方面的学习/项目经历最佳。
工作地址

【岗位要求】
根据业务发展战略和构架，进行数据整体架构规划、设计和构建，技术改进和性能优化；构造最优的数据库模式，负责设计、评估及审核，主导开发和实施。
负责数据存储的分布式架构设计；制定和维护数据架构的规范及其标准，以及概念模型的定义和数据标准的定义（包括词汇、术语、主题域），以及建立数据管理流程；
负责数据架构的治理，规范数据存储；负责构建多数据源数据的整合、构建多数据源历史库；
负责公司数据交换平台、各主题域的搭建和流程穿越设计；
支持各业务应用和BI应用的建设；

【技能要求】
1、有三年以上数据平台项目开发、设计和实施经验；熟悉至少一种数据库建模工具，能独立进行数据库规划与设计；
2、熟练掌握Oracle、Mysql、Informatica等数据库的开发与维护经验，至少精通一种数据库软件；熟悉Nosql的数据存储产品，熟悉不同类型和数据库的底层运行原理和优缺点；熟练掌握至少一种内存数据库，如Redis/MongoDB等；
3、熟悉分布式数据库设计和建设方案，海量数据库分库分表策略以及高并发OLTP系统的设计和维护 ；
4、熟悉大数据开发框架，如Hadoop、Hive、HBase、Strom、Kafka等大数据主流工具和技术，熟悉常用分析、统计和建模方法，并能使用部分工具进行开发工作；
5、有效好的业务分析能力，具有业务设计经验；
6、有以下工作经验者优先：具备海量数据高性能分析及处理的成熟经验；有推荐系统/自然语言分析/机器学习/用户行为分析项目工作经验；在大型企业负责数据规划或者BI业务模型&amp;主数据经验；

岗位职责：
1.   从系统应用的角度，利用数据挖掘/统计学习的理论和方法解决实际问题；
2.   负责各业务系统数据到数据仓库的ETL工作。
任职要求：
1.   全日制大学本科（含）以上学历，具有CET-4(425分以上)或同等英语证书 ；
2.   2年以上工作经验，1年以上数据处理相关项目经验，至少有Spark/Hive/MapReduce/Mahout/Kylin之一相关实际开发经验；
3.   至少掌握Java/Scala/Python三种语言之一；
4.   熟练掌握SQL，了解常用的ETL SQL优化技巧；
5.   了解常用数据挖掘算法，如分类、聚类、决策树、神经网络等； 
6.   对J2EE开发熟悉者优先；
7.   有hadoop平台相关经验者优先。
务实、逻辑思维缜密、工作细致有耐心； 有良好的分析和解决问题的能力，勇于面对挑战性问题； 具有良好的学习能力、沟通能力和团队合作精神。

 1、有大数据Hadoop经验，对底层架构熟悉、熟悉编写mapreduce2、精通habase，有复杂是rowkey设计经验，并对二级所以(索引)有一定的了解3、对kafka、storm熟悉，精通对数据流的处理4、对新技术有专研精神，善于技术攻关 

职位描述：
1、负责hadoop/spark平台技术引进和推广，并能结合用户需求快速落地推广； 
2、负责大数据分析需求设计和开发，包括数据集市、实时分析、数据展示等的开发，并交付生产，确保输出成果； 
3、负责项目成果在公司内的推广应用、培训，以及对外对内合作交流，不断提升公司的技术和应用能力。

招聘要求：
1、具有2年以上BI/报表相关工作经验，熟练掌握hadoop hive开发，有一定调优经验；
2、能熟练使用sqoop等作为etl工具，有tableau/qlikview开发经验； 
3、有良好的口头和书面表达能力； 
4、良好的结构化问题解决能力;
5、本科毕业有两年以上相关工作经验或大专毕业有三年以上相关工作经验（需要提供可查验的教育部学历电子注册表）

任职要求：

本科及以上学历，学习能力强
熟悉Hadoop、Sparks、Storm系列技术，具备独自搭建大数据开发环境的能力；
有良好的Java开发基础，具备开发小规模程序的能力；
熟悉大数据系统性能监控和性能优化方面方面的知识；    

岗位职责：

大数据能力平台的建设
数据价值深入挖掘分析；    


岗位描述：

1、 构建、设计及优化大数据平台数据管理及平台性能（Hadoop、Flink等分布式平台），解决海量数据不断遇到的挑战，解决业务要求
2、 对接德国项目组，消化德国人工智能中心的相关技术；

任职要求：

1、 计算机、数学、统计学等相关专业，本科以上学历，有较好的英文阅读能力；
2、 精通Java，有大型项目经验优先；
3、 了解HDFS、MR原理，精通MapReduce java开发或者Hadoop Streaming开发；
4、 熟悉Linux环境，熟悉Linux shell/python/perl任一脚本语言；
5、 熟悉Hive、Pig、HBase、redis等开源项目，了解HBase原理；
6、 对分布式开源项目及大数据有较高的兴趣；
7、 具有良好的自我管理能力和沟通能力及快速学习能力，工作积极主动；
8、 性格开朗，善于交流，思路清晰，逻辑明确，有较强分析与解决问题能力，具有团队合作精神和责任心；
9、 拥有良好的代码习惯，要求结构清晰，命名规范，逻辑性强，代码冗余率低；乐观向上，有较好的学习能力，良好的团队合作能力，善于沟通，独立解决问题。

为什么选择我们？

•喜欢创意？来！我们是一个秉承着高效、协作、尊重创意的精英团队。
•需要保障？来！我们有五险+商业医疗保险，给你足够的关怀！
•喜欢美食？来！下午茶、零食吃不停！还有美味又营养的免费工作餐等着你！        
•喜欢旅游？来！周末双休+5天带薪年假，世界那么大带你去看看！
•喜欢瑜伽？来！内部瑜伽和净化呼吸课程培训，让你健康又气质！
•喜欢和谐？来！亦师亦友亦如亲的团队氛围及人性化管理，开心工作每一天！
•喜欢便利？来！坐拥软件园二期优势地段—公交总站旁，去哪都方便！
五天八小时工作制，高端大气上档次的办公环境，
法定节假日，过节费，年底双薪等福利，多的你意想不到！
我们所做的一切都是为了推动移动互联网时代信息交互模式的变革。
如果你也期待改变，
期待和一群志趣相投的人去完成一件很酷的事。
欢迎你加入我们！
 

工作职责：
1.    负责宜信大数据平台的建设、开发、维护工作
2.    平台业务技术支持
3.    技术攻坚，解决平台中遇到的技术难题，涉及源码层次的bug修复或者二次开发
4.    新技术调研和应用，包括大数据相关开源技术、机器学习框架等
 
要求：
1.    3年以上Hadoop及大数据生态圈实践经验，如Kafka/HBase/Impala/YARN/Spark等
2.    深入了解分布式系统、大数据平台等高可用高弹性架构
3.    有数据仓库项目经验，了解数据仓库相关理论知识；
4.    精通Java和面向对象编程，或有python、scala开发经验
5.    熟悉Linux系统，具备shell、python等脚本开发能力
6.    强烈的责任心和自我驱动意识，具备独立解决问题的能力
7.    良好的团队合作精神和沟通能力
8     学习能力强，喜欢研究新技术，对大数据领域有兴趣

加分项:
1.    有CDH版本使用经验
2.    对HDFS，Yarn，Hbase，Hive，Spark，Impala，oozie相关组件的性能优化和补丁跟踪等有实际经验
3.    学习hadoop生态圈源码或对开源社区有过贡献
4.    有tensorflow或其他机器学习经验者

岗位职责: 
1.负责数据仓库ETL数据处理；
2. 参与Hadoop的大数据分析平台建设与开发； 
3.负责数据质量跟踪与开发； 
4.参与数据中心的规划和管理工作。
 
 
任职要求： 
1.本科或以上学历，计算机或数学相关专业，1年以上的大数据开发经验；
2.熟练使用SQL/HQL,熟悉postgresql、Mysql、Sql Server 等主流数据库，对SQL语句相当熟练，能利用SQL语句实现各类较复杂的业务处理经验者优先；
3.熟练使用大数据相关框架或组件，如：Hadoop Hive/Flume/Sqoop/Hbase/Spark/Storm等； 
3.熟练使用Linux/Unix操作系统，熟悉常用的Shell/Python/Perl工具，熟悉常用linux命令，会在linux下安装部署各类环境需要的软件，会利用shell编写和开发自动化安装部署脚本； 
4.有java编程经验者优先，有数据仓库、BI系统项目开发，kettle或其他数据ETL工具使用使用经验者优先； 
5.良好的沟通能力和团队精神，具备逻辑思维能力强，态度认真积极，责任心强，具备快速学习能力。

福利待遇：
1、实行大小周，弹性工作，平行管理，气氛活跃；
2、假期福利：除法定的节假日之外，还可享有年假，婚假，丧假，生育假；
3、社保与公积金：公司依法为员工缴纳社会保险和住房公积金；
4、提供免费茶点，寿星有神秘的生日礼物，公司提供团队建设费用；
5、公司提供丰富的员工活动，除运动、唱K、聚餐等外，还可根据员工建议酌情组织；

岗位职责：
负责数据业务需求分析、建模计算以及交付运营
任职要求：
1、2年以上大数据平台应用和业务开发经验，对业务有深刻的理解
2、精通SQL，精通Oracle、MySQL等关系数据库应用，熟练掌握大数据分析技术的使用（Hadoop、Hive、HBase、Spark、Sqoop等）
3、有丰富的Java、HiveSQL、Scala、Python等语言的开发经验，精通MR、Spark计算模型
4、深刻理解数据建模方法，精通不同数据管理介质上的建模方法，理解范式和反范式的应用场景
5、心态开放，对数据业务运营充满浓厚兴趣，并具备较强的抗压能力
6、有金融业务背景者优先、有大数据平台运维经验者优先

工作职责：
• 负责数据平台的采集、传输、计算、分析、存储、挖掘；
工作要求：
• 计算机相关专业，3年及以上相关工作经验,有扎实的计算机理论基础；深入理解MapReduce，并有相关编程经验；
• 熟练使用Storm、Spark以及相关组件，对源代码有一定研究者优先；
• 熟悉HDFS、Hbase；
• 有云计算领域经验者优先；
• 具备良好的学习能力、分析解决问题能力；
• 具有良好的团队合作能力；

岗位职责：
1、业务数据数据挖掘和智能数据展现；
2、各业务数据的采集、清洗、整合，数据仓库的建设；
3、基于大数据分析平台的产品开发和维护，完成各业务的离线/实时计算；
 
任职要求：
1、熟练使用Linux，良好的编程基础， 熟悉SQL，java, python 。
2、熟悉常用机器学习算法（如 svm, k-means，HMM），了解算法内在原理
3、了解大数据生态圈，熟悉Hadoop、Hive、Hbase、Spark、Storm 等分布式开源项目优先。
4、对有数据可视化、人物画像，个性化推荐，CTR,搜索有相关工作经验优先
5、具有较好的沟通能力和团队合作精神。

岗位职责：
1、负责基于大数据分析平台的开发、优化、维护；
2、负责数据接入、数据清洗、业务主题建模等工作；
3、参与大数据分析平台的建设。

任职要求：
1、本科及以上学历，计算机相关专业，3年及以上相关开发经验；
2、JAVA基础扎实，熟悉网络、多线程、数据结构及算法等基础知识，对JVM原理有一定的了解；
3、至少熟悉一种分布式计算框架：Hadoop、Spark、Storm，了解使用Hive、Pig优先；
4、熟悉Linux系统环境、MySQL数据库，具备一定的SQL语句编写和优化能力；
5、能够熟练地阅读英文技术资料，具备良好的学习能力、分析解决问题能力；
6、1年以上大数据开发、分析相关项目经验，互联网行业从业者优先；

岗位职责：
1.负责大数据平台搭建及数据仓库建模；
2.利用分布式计算集群实现对数据的分析、挖掘、处理、生成报表等；
3.维护分布式计算集群并能解决相关问题, 保障系统正常运行。
 
任职要求：
1.熟悉主流分布式处理框架，如hire,hadoop；
2.具备大型数据仓库架构设计、模型设计和性能调优等相关经验；
3.有搜索及推荐系统实现经验者优先；
4.有BI产品、数据可视化产品开发经验者优先；
5.精通Python开发；
6.全日制统招本科或以上学历，计算机专业毕业，一年以上互联网相关工作经验。

职责：

负责实时大数据处理系统研发。

要求：

至少2年Hadoop/Spark开发经验；
大学计算机或电子专业学士或以上学位。


岗位职责1、 负责数据产品需求分析、数据建模，主导完成相关设计及编码；2、 完善现有数据产品，优化现有产品数据体系；3、 深入理解业务需求，能从数据角度推动业务发展，开发相应数据产品及工具岗位要求1. 计算机、数据等相关专业本科以上学历，工作2年以上； 2. 熟悉数据仓库和数据集市的框架结构，具备数据仓库与数据集市的架构设计能力； 3. 精通SQL，熟悉Oracle、MySQL等关系型数据库；4. 熟悉HiveSQL/MapReduce/Spark等数据开发技术；5. 有一定的Java/python开发能力，熟悉linux/Shell；6. 在数据统计、机器学习上有一定基础的优先；7. 沟通与交流能力强，业务理解能力强，具有一定的业务建模能力。

职位描述

参与公司大数据平台建设
数据分析平台后端核心系统研发
通用的数据挖掘平台研发
配合产品经理深入理解客户需求


任职要求

分布式系统或大数据分析平台两年开发经验及以上
深入理解大数据分析模型及平台架构
对用户画像、机器学习等技术了解，有过实际经验者更佳
精通java或c/c++编程，熟悉golang者更佳
了解大数据处理开源系统，对spark、hbase、cassandra等熟悉者更佳
有过知名互联网公司工作经历者优选
富有探索精神，乐观积极，勇于接受挑战
全日制大学本科及以上学历


=====Ablecloud简介=====

AbleCloud（智云奇点）是国内首家智能硬件PaaS云平台，面向IoT企业/开发者提供可定制云端功能开发，海量硬件数据存储与分析等基础设施，加速硬件实现联网智能化。
AbleCloud拥有业界最优秀的技术团队，由来自百度，阿里，小米，微软，腾讯的十多位核心架构师组成豪华云计算梦之队（团队平均值为百度T6,阿里P7,腾讯T3.1）。团队从1000多家企业中脱颖而出入选微软加速器第七期并完成A轮2500万融资。
万物联网的时代，AbleCloud已经准备好了最专业稳定的基础设施。『云端服务一体化开发引擎』，业内独创一体化开发引擎架构，自动解决底层连接、存储、分布式集群部署、弹性扩容、安全等难题，让开发者直接基于AbleCloud平台开发出硬件需要的任何云端服务；『大数据分析引擎』提供海量数据分析平台，可以支持T级别以上数据的实时分析，提供简单易用的数据收集方案；『IoT功能组件及方案超市』，提供丰富的IoT功能组件及方案，开发者可直接使用，无需“重复造轮子”。我们的合作平台包括了微信，阿里云，京东JD，联想，海尔等。 


=====创始团队：我们期待与更多优秀的人一同前行=====
CEO李海磊：前百度大数据平台高级架构师,微软Bing架构师，小米开放云平台负责人，在智能硬件云平台和大数据方面有丰富的经验。
Co-founder孙志东:前百度基础架构部架构师,阿里巴巴核心系统部架构师，分布式系统设计和大数据存储领域技术专家。
Co-founder孙文现:前百度高级产品运营经理，2006年加入百度，曾担任百度质量部技术委员会主席，领导百度联盟，网盟推广系统，曾带领过超过50人的团队，具有丰富的商业产品研发，拓展和运营经验。
Co-founder陈鹏：前百度架构师，2008 年加入百度， 在基础架构部从事分布式系统研发。主导百度分布式消息队列、百度 IDC 带宽调度管理系统、公有云计费 /IAM 系统、大数据分析平台等研发。在分布式系统、大数据分析及 hadoop、 hbase 等开源系统方面经验丰富。 
Co-founder崔潇扬：天津大学，毕业后加入大唐移动从事通信技术的研发。是国内首批参与4G通信协议的制定和研发人员，拥有多件通信技术专利。曾担任大唐移动的产品经理，带领团队推出了国内首家通过GCF认证的4G手机一致性测试仪表，目前应用于多个认证组织和运营商的手机入网入库测试当中。

岗位职责：
1、负责公司大数据处理处理和分析平台的架构和开发；2、为项目组提供大数据分析手段支撑；3、配合产品同事进行相关产品研发；4、配合部门内普及大数据处理知识和技能。5、对技术敏感，能够快速接受新技术知识，有较强的自学能力。
任职要求：

1、2年以上Java开发相关工作经验，熟悉Java核心技术,熟悉linux能够编写shell或其它语言脚本，有分布式高并发经验者优先；2、熟悉常用的数据库如oralce、mysql等关系型数据库，熟悉常用nosql数据库redis、memcache等，有分布式缓存、分布式存储技术经验者优先；3、熟悉大数据基础架构，对流式系统、并行计算、实时流计算等技术有较深的理解；4、熟悉Hadoop、Hive、Hbase、Storm、Spark、kafka等技术和架构；5、责任心强，具有良好的团队合作精神，学习能力强；6、熟悉文本挖掘算法和推荐算法者优先。

岗位要求：
1、具有3年以上大数据开发经验；
2、参与大数据架构的搭建、开发和维护；参与基于云架构项目的开发、维护工作；
3、熟悉主流大数据平台的安装，部署，运维，有hadoop，spark，hbase，kafka经验者优先。

岗位职责:
1、参与公司大数据项目的设计和开发工作；
2、负责平台的整体数据架构设计，完成从业务模型到数据模型的设计工作 ；
3、基于数据分析出得到的有价值信息，能够独立或协助项目经理形成系统性的解决方案；
4、对于数据分析和数据挖掘技术有较全面深入的理解，能够对客户或团队成员形成知识转移。

岗位要求:
1、3年以上工作经验；
2、熟练使用Spring，SpringMVC技术，熟悉Springboot，Springcloud等技术，对微服务有深刻的理解；
3、熟悉Hadoop/Spark生态系统组件（ZooKeeper/Hbase/SparkSQL/MLib等）的使用；
4、有统计学知识，擅长常用的统计方法如：熟悉决策树、聚类、逻辑回归、关联分析、SVM、贝叶斯等数据挖掘法，有海量数据库挖掘项目经验；
5、认同DevOps文化， 理解Docker技术，有Mesos/DCOS实践经验优先。

加分项：
1、有基本的英文听说读写能力；
2、了解Scrum of Scrums, Kanban等敏捷理念，有实践经验优先；
3、有B2C、B2B2C、O2O、B2B等电商行业经验者优先。

职责:1、负责物联网OneNET大数据平台相关软件的开发，维护，优化等工作；
要求:1、2年以上java开发经验2、熟悉Java语言和面向对象设计开发，熟悉多线程程序开发，对多线程技术、异步、并发有较深入理解；3、熟悉主流Web应用相关的框架，对至少两个主流框架有深入理解；4、对设计模式、软件工程等有较深入的理解；5、熟悉sql语法，常用关系型数据库及至少一种nosql数据的使用；6、熟悉linux常用命令，能够编写简单的shell或者python脚本。7、熟悉hadoop、spark、hive、hbase、storm等开源大数据框架使用者优先。8、211院校毕业者优先。

岗位职责：
1、 大数据开发与分析
2、 任务调度与监控
3、 HQL编写与优化
4、数据核对
任职要求：
1、本科及以上学历，2年以上相关工作经验；
2、熟练掌握hive\spark,了解hive脚本优化方法；
3、Oracle，PL\SQL基本语法，了解JAVA或者shell；
4、有海量数据处理经验优先；

岗位职责：
1.负责大数据基础集群及相关技术的运维保障工作。 2.负责大数据平台的整体架构，包括但不限于业务监控，容量规划，故障处理，持续优化等。 3.了解产品及研发的业务需求，完善平台相关功能。
任职要求：
1.计算机或相关专业本科以上学历 2.2年以上中等规模（及以上）大数据集群运维相关经验 3.熟悉Hadoop相关技术，包括但不限于HDFS、Yarn、Hbase、Hive、Storm、Spark/Spark Stream等 4.深入理解linux系统，熟悉shell/python/go等一种脚本语言 5.能深入理解Hadoop相关组件的原理，有源码阅读能力者优先

工作职责：
- 负责公司大数据平台、分析工具及应用的研发
- 负责机器学习和统计分析算法的设计和工程实现
- 关注学术界和产业界的前沿研究
- 用自动化智能化的方法解决大规模系统及复杂系统运维中的问题
职责要求：
- 对操作系统、网络协议、数据库系统、性能优化有深入理解
- 参与过分布式高性能服务的设计开发过程，有大规模分布式系统的实践经验
- 具有数据挖掘和机器学习等相关领域的工作经验
- 擅长找到目前系统的瓶颈，改进相关架构，提高系统性能
符合以下条件优先：
- 在 Github 上有开源项目
- 在 StackOverflow/知乎 上有良好声誉
- 对金融工程及相关专业有深入理解

工作内容：
负责大数据平台的相关开发工作。

职位要求：
1.精通Hadoop大数据平台框架，精通Hadoop原理，熟悉Hadoop架构设计及开发，包括HDFS、Hbase、Pig、Hive、Storm、Spark、Presto等开发; 2.熟悉数据库的开发，熟悉Mysql、Oracle等数据库; 3.精通Java、Python语言程序开发，熟悉Linux常用命令; 4.熟悉Kafka、RocketMQ等常用消息队列; 5.使用过ElasticSearch、Kylin、Druid、Pinot具有实时OLAP框架，对源代码有一定研究者优先; 6.具备良好的学习能力、分析解决问题能力; 7.较好的沟通表达能力，逻辑思维清晰，抗压能力强，良好的团队合作精神; 

岗位职责： 1、负责企业级大数据平台的设计和功能开发 2、负责云端大数据产品的开发 3、跟踪大数据技术的发展趋势，进行产品相关技术的预研 4、进行大数据技术培训以及相关项目交付

任职要求：
1、计算机、应用数学等相关专业本科及以上学历，3~5年以上大数据处理平台的架构设计和经验。 2、有扎实的Java基础(熟悉io、多线程、集合等基础框架，熟悉分布式、缓存、消息、搜索等机制）。 3、熟悉一些行业大数据应用场景，有数据仓库、BI、数据挖掘等方面的工作经验。 4、熟悉shell、python、scala编程，并有实际产品或项目开发经验。 5、熟悉并使用过一种或多种离线数据处理工具，包括但不限于：Hoodap Hive Hbase spark 。 6、熟悉流式处理系统的技术和原理；熟悉并且使用过流式运算系统，包括但不限于：SPARK  STORM/JSTORM。 7、有hadoop相关的实际开发及运维经验。 8、具备一定的算法能力，了解常用一些算法工具，包括但不限于：K-means聚类、LDA、神经网络、欧式距离、SVM、过/欠拟合、DL。 9、具备项目管理能力，具备带领数据研发技术团队的经验。

工作职责：
1: 负责Hadoop平台MapReduce、Hive、HBase、spark和/或jstorm等应用开发。
2: 负责大数据平台日志收集，数据抽取、清洗、转换和建模的开发。
 
任职要求：
 
1: 大学本科及以上学历，计算机或相关专业；
2: 了解数据仓库开发流程，熟悉数据仓库(DW)/商业智能(BI)的数据框架；   
3: 年以上大数据工作经验，熟练掌握Python/Java至少一种编程语言，熟悉java者优先；
4: 熟悉Mysql/Oracle等至少一种关系型数据库，熟悉SQL开发；
5: 熟悉HDFS、HBase、Hive、MapReduce、Impala、Oozie、Sqoop、Kettle等相关技术/工具，具备大数据分析项目经验；
6: 熟悉Linux系统，能实际编写Shell脚本；
7: 有数据仓库开发、海量数据处理经验者优先考虑；

岗位职责:1. 负责大规模海量数据的清洗、过滤、入库、特征提取、分析和挖掘工作；2. 负责Hadoop/Spark集群生产环境搭建，性能调优和日常维护；3. 负责数仓设计，数据建模，SQL 存储过程开发和测试，及SQL查询的性能调优。任职资格:1、计算机相关专业本科学历； 
2、有2年以上大数据开发处理经验，编程能力强。3、熟练掌握Hadoop/Spark平台开发技能
4、熟练掌握java和python5、熟悉第三方ETL工具，例如kettle
注：本岗位接受实习生

岗位职责

负责数据仓库和大数据处理模块的架构设计和开发；
负责基于Spark技术的分布式计算框架开发、处理、分析、统计、挖掘工作；
基于Spark框架的数据仓库的设计，开发，维护；
根据需求使用Spark Streaming和Spark SQL等相关技术的海量数据的处理、分析、统计、挖掘工作。


任职要求

熟悉Spark相关技术，至少有1年的Spark开发经验；
熟悉Scala/Java语言，对Scala/Java原理、底层技术有深入研究者优先；
熟悉Spark Streaming和Spark SQL；
有优良的Trouble Shooting能力；
有过海量数据系统开发经验者优先；
在开源社群活跃并有积极贡献者优先；


岗位职责
1、负责公司大数据分析处理平台基础研发工作；
2、基于Hadoop/Spark生态体系、技术、开源研究；
3、针对公司大数据业务进行数据分析、挖掘软件的开发；
4、将公司现有业务移植到大数据平台。
 
岗位要求
1、统招本科及以上学历，计算机相关专业，3年及以上相关岗位经验；
2、精通J2EE体系结构，精通Java相关技术如JSP、Servlet、Struts、EJB，JDBC，JMS，Spring、WebService；
3、熟悉Hadoop整个生态环境体系，对HDFS、MapReduce、Zookeper、Hbase、Hive、Flume、Ambari、Sqoop等Hadoop技术框架/工具有一定研究，有实际使用Hadoop开发过应用程序；
4、熟悉Spark相关技术，能通过spark提供的Scala, Java，Python API及交互式Shell来进行海量数据的处理、分析、统计、挖掘工作；
5、熟悉Spark Streaming和Spark SQL，了解SQL Server BI解决方案，对IS、AS、RS、存储过程等技术有一定的了解。

岗位职责：
1.负责公司大数据通用服务集群相关组件的支撑保障（包括如：Hadoop/Hbase/Hive/Yarn/Spark/Storm/Kafka/Elasticsearch等）
2.负责集群容量规划、扩容及性能调节优化；
3.参与业务架构设计，在设计阶段给出可运维性及可扩展性方面的改进建议；
4.深入研究大数据业务相关运维技术，持续优化集群服务架构，调研集群资源调度技术及平台方向。
 
任职要求：
1.至少掌握java/python/shell中的一种语言。
2.熟悉Hadoop/Hbase/Hive/Storm/Spark/Kafka/Elasticsearch等开源组件项目优先；
3.熟悉Linux操作系统的配置、管理及优化，能够独立排查及解决操作系统层面的问题；
4.掌握ansible、yarn及mesos应用的优先；
5.良好的客户服务意识，强烈的责任心和使命感，执行力强，富有团队合作精神；
6.对大数据方向运维有很高的热情和兴趣，能主动学习了解相关知识；

岗位职责：
1、负责公司大数据处理处理和分析平台的架构和开发；2、为项目组提供大数据分析手段支撑；3、配合产品同事进行相关产品研发；4、配合部门内普及大数据处理知识和技能。5、对技术敏感，能够快速接受新技术知识，有较强的自学能力。
任职要求：

1、2年以上Java开发相关工作经验，熟悉Java核心技术,熟悉linux能够编写shell或其它语言脚本，有分布式高并发经验者优先；2、熟悉常用的数据库如oralce、mysql等关系型数据库，熟悉常用nosql数据库redis、memcache等，有分布式缓存、分布式存储技术经验者优先；3、熟悉大数据基础架构，对流式系统、并行计算、实时流计算等技术有较深的理解；4、熟悉Hadoop、Hive、Hbase、Storm、Spark、kafka等技术和架构；5、责任心强，具有良好的团队合作精神，学习能力强；6、熟悉文本挖掘算法和推荐算法者优先。

职责：                                 
• 按照规范及设计文档完成编码工作，并对代码质量负责；
• 编写及维护技术开发相关文档；
• 能够对自己开发的代码设计并编写单元测试及功能测试代码；
• 学习和研究新技术以满足产品的需求；
• 为产品改进、优化、效率提升设计开发产品内部工具。
 
要求：
• 计算机相关专业本科及以上；
• 软件基础理论知识扎实，具有良好的数据结构、算法功底；
• 熟悉Hadoop等分布式开发，了解Hadoop相关各种开源项目，如：Hive、Hbase等，并有实际应用，熟悉Storm、Spark者优先；
• 熟练应用Spring、Java Cache等开源框架；
• 熟悉MySQL等关系型数据库，熟悉NoSQL数据库者优先；
• 对新技术敏感，有一定独立分析，技术研究能力；
• 熟练使用Linux环境下开发者优先；
• 熟悉至少一种版本控制工具，如：SVN，熟悉分布式版本控制工具Mercurial或Git者优先；
• 有个人开源项目或参与开源项目者优先；
• 有代码洁癖和自发组织Code Review的开发者优先；
• 提供本人半年内写过的代码，不限开发语言；
 
工作态度：
• 具备良好的人际交往、语言表达和沟通能力；
• 具备高度的责任心、诚信的工作作风、优秀沟通能力及团队精神；
• 愿意接受挑战性的工作，能够高效及时完成工作；

岗位职责：
1.  负责大数据采集、存储、计算、分析等场景的通用架构设计和开发
2.  负责流式数据的实时传递、清洗、转换和计算（实时统计、分析等）的设计和开发
3.  负责大数据中间件的设计和开发
4.  负责以上各种架构平台及相关基础技术组件的稳定性保障及源码级的bugfix
任职要求：
1.  计算机相关专业，五年以上工作经验，具有大型系统的技术架构/应用架构/数据架构的的自主研发经验
2.  深入使用Java，熟悉掌握常用的Java类库及框架，如多线程、并发处理、I/O与网络通讯，Velocity、Spring、Hibernate、iBatis等，对SOA模式有较深的理解
3.  对Java虚拟机有较深了解，有运行态JVM分析及调优的实际经验，有Linux下的开发或运行环境操作经验
4.  熟悉并使用过各种大数据相关框架或组件优先，如Kafka、Storm/JStorm、Hadoop/Spark、Hive、HBase等，特别是有Spark实战经验/海量数据处理经验者优先
5.  具有良好的产品Sense，从商业需求到技术实现的映射能力，能够开发创新，以实际的分析方法去抽象分解复杂的业务需求问题
6.  具有良好的沟通、团队协作、计划和主动性思考的能力，在互联网或大数据业界有一定影响力公司的工作经验者优先

岗位职责：
1.  负责大数据采集、存储、计算、分析等场景的通用架构设计和开发
2.  负责流式数据的实时传递、清洗、转换和计算（实时统计、分析等）的设计和开发
3.  负责大数据中间件的设计和开发
4.  负责以上各种架构平台及相关基础技术组件的稳定性保障及源码级的bugfix
任职要求：
1.  计算机相关专业，五年以上工作经验，具有大型系统的技术架构/应用架构/数据架构的的自主研发经验
2.  深入使用Java，熟悉掌握常用的Java类库及框架，如多线程、并发处理、I/O与网络通讯，Velocity、Spring、Hibernate、iBatis等，对SOA模式有较深的理解
3.  对Java虚拟机有较深了解，有运行态JVM分析及调优的实际经验，有Linux下的开发或运行环境操作经验
4.  熟悉并使用过各种大数据相关框架或组件优先，如Kafka、Storm/JStorm、Hadoop/Spark、Hive、HBase等，特别是有Spark实战经验/海量数据处理经验者优先
5.  具有良好的产品Sense，从商业需求到技术实现的映射能力，能够开发创新，以实际的分析方法去抽象分解复杂的业务需求问题
6.  具有良好的沟通、团队协作、计划和主动性思考的能力，在互联网或大数据业界有一定影响力公司的工作经验者优先

1.掌握 Linux 操作系统的配置，管理及优化，能够独立排查及解决系统层的各类问题；
2.熟悉Hadoop/HBase/Hive/Spark/Kafka/Zookeeper等开源项目的安装与调试,升级扩容
3.至少精通 Perl/Python/Shell脚本语言中的一种；
4.熟悉大数据周边相关的数据库系统，mysql和 mongodb/redis等。
PS：运营过Hadoop/HBase/Hive等相关系统，有从事过海量数据分布式处理、各种分布式计算，或者分布式存储、分布式计算系统相关的工作经验的优先；

1、负责大数据平台(Hadoop,Spark)运维保障；
2、负责大数据自动化运维以及运营组件的开发工作； 
3、负责Hbase，ElasticSearch，ETL等系统的架构审核、业务监控、持续交付、应急响应、容量规划等； 
4、负责支持数据平台的平稳、有效运行，支撑公司业务的快速发展；
5、对数据平台架构有较为深入的理解，及时发现并解决故障及性能瓶颈；
任职要求：
1、熟悉分布式系统、分布式计算系统的工作机制，熟悉Hadoop生态圈相关核心技术的工作机理，有一定源码研究者优先；
2、熟悉Hadoop相关技术：Hadoop、Spark等；
3、深入理解linux系统，运维体系结构和性能优化方法；
4、熟悉Linux系统管理工作；熟悉Shell编程，能够编写脚本解决日常运维问题；
5、熟悉各种Hadoop大数据自动化运维与监控工具，并有二次开发经验；
6、持续优化集群服务架构，探索新的大数据运维技术及发展方向。
员工福利：年底双薪、带薪年假、弹性工作、员工活动、交通补贴、五险一金等

工作职责
1. 多个异构数据源的整合以及数据体系的建设；
2. 商业智能(BI)系统的建模与开发；
3. 为精准营销提供快捷灵活的数据支持；
4. 数据分析代码库的建设及优化；
5. 用户画像的构建；
 
任职要求
1. 3年以上互联网行业数据仓库，数据分析挖掘相关工作经验；
2. 熟悉数据仓库和数据建模的相关技术细节，熟悉传统关系型数据库，熟悉Hive，HBase，MapReduce等大数据处理技术；
3. 参与过完整的数据采集、数据清洗、分析和建模工作；
4. 熟悉常见机器学习或数据挖掘类的算法原理，熟悉常见的统计原理及方法；
5. 良好的沟通能力，逻辑分析能力，以及解决问题的能力；
6. 良好的团队合作精神。

岗位职责： 
1、用户行为数据仓库设计和实现； 
2、根据业务和产品情况对数据模型进行设计和优化； 
3、完成数据模型的ETL开发、实施，ETL流程优化以及相关技术问题的解决； 
4、根据业务需求的理解，开发数据，提供面向业务的数据服务； 
岗位要求： 
1、统招本科及以上学历，计算机相关专业； 
2、熟悉数据仓库建模理论，了解数据仓库数据分层架构、多维数据模型设计，有1年以上的实际工作经验； 
3、在用户行为日志采集、处理、建模方面有丰富经验； 
4、熟悉Hadoop / Spark / Hive ，熟练掌握SQL，有HIVE、Spark Sql使用经验者优先；
5、熟悉Linux开发环境，熟悉至少一种脚本语言（Python / Awk等）；
6、优秀的逻辑思维能力、业务需求分析能力和执行力，较好的沟通能力；

岗位职责：1、负责大数据产品的开发，理解业务需求，制定系统的技术方案；2、负责给产品开发、实施、运维团队提供技术保障;3、负责对系统的重用、扩展、安全、性能、伸缩性、简洁等做系统级的把握;4、对系统框架相关技术和业务进行培训，指导开发人员开发，解决系统开发、运行中出现的各种问题。任职要求1 、熟悉Kafka、Hadoop、Hive、Impala、Spark中的一种或几种技术并具备实际项目经验；2、4年以上开发经验，2年以上大数据开发经验;3、熟悉主流关系型数据库Oracle、Mysql，精通主流KV store如HBase、MongoDB、Redis等;4、熟悉Yarn，Azkaban等管理及调度技术;5、对大数据的技术发展有较深理解，有较强的学习能力，有较强的组织和责任意识，性格开朗，团队意识强，沟通、逻辑思维能力强。

岗位职责：
数据仓库、大数据分析开发
任职资格：
1、6年以上软件开发经验，计算机相关专业；
2、精通Java语言及设计模式，熟悉Spring、Mybatis等主流开源框架及原理；
3、精通MySQL，熟悉分布式数据库的设计与优化；
4、熟悉MongoDB、Redis、Memcached、Hbase等NoSql开发；
5、熟练使用Linux操作系统及shell编程，熟悉Linux开发环境部署；
6、擅长系统性能调优，具备高并发高可用性系统开发；
7、熟悉大数据相关技术，例如：ETL、Otter、Stom、MapReduce、flume、Spark、Spark Streaming、Kafka、zookeper、HDFS等；
8、热爱技术，善于总结，了解系统架构原则，良好的团队合作精神和认真负责的工作态度

1、熟练掌握Hadoop，spark，strom的环境搭建
2、大数据算法设计，数据分析

岗位职责：1、负责海量分析挖掘平台分析功能系统设计；2、负责根据业务场景，产品需求抽取、分析处理。3、负责撰写相关文档；?任职要求：1、计算机及相关专业本科以上学历，三年以上大数据相关工作经验；2、熟悉Hadoop/spark等开源系统, 有相关系统设计经验；熟悉scala或java语言编程；3、擅长基于Spark/Spark streaming/impala/hive环境的大数据分析处理；4、良好的团队合作能力，勤奋好学。

职位描述：大数据底层架构设计和实施；对移动设备数据和社交数据进行挖掘分析和建模；逐步构建基于用户行为、喜好的标签系统，并应用于相关的个性化系统和业务分析中；负责数据管理平台的核心技术实现与优化；负责大数据在广告领域的创新应用，持续推动业务线的商业效果改进； 任职资格 岗位要求： 本科及以上，计算机、软件工程、统计学、数据挖掘、机器学习等相关专业。 2年及以上大数据流程架构经验，熟悉Hbase/Hive/Hadoop/Spark或等主流分布式开发平台，有高性能集群设计和开发经验。精通Linux，熟练掌握Python/C/Shell/Java，熟练掌握SQL数据库语言 HiveSQL/Mysql/Sqlserver。有数据挖掘算法实施经验，熟练掌握大规模数据挖掘、机器学习。对有广告营销大数据算法/开发经验者优先，有大型数据项目经验优先，有用户行为分析、用户建模、业务建模经验者优先。具有良好的逻辑分析能力、沟通能力和协调能力。 积极的工作态度，勤奋上进，有责任心。

工作职责：
（1）负责大数据处理平台应用的开发工作。
（2）利用Hadoop yarn/Storm/Spark进行开发、存储、分布式计算应用的代码实现。
（3）优化Hadoop yarn/Storm/Spark 参数，实现系统调优，满足行业应用的实时大数据处理需求。
（4）学习新技术，提高整个平台的计算能力和效率。
（5）开发基于HIVE、Hbase、ES等数据处理方式的脚本程序。
 
任职资格：
（1）3年以上Hadoop/Storm/Spark开发经验，对分布式、并行计算理论有深刻理解。
（2）精通java/scala/python任一语言。
（3）对Hadoop/Storm/Spark源码有研究，有大数据平台开发工作经验者优先。
（4）有很好的技术敏感性，良好的学习能力和吃苦耐劳能力。
（5）具有较好的沟通协调能力、团队合作能力、文档编写能力。

工作职责：
1.  研究业界最新的大数据技术，负责大数据系统的设计与开发
2.  日常大数据系统运维、更新、监控、发布
3.  为公司提供大数据存储、分析、计算支持
职位要求：
1.  3年以上大型互联网产品或分布式系统开发设计经验
2、熟练Java语言，有两年以上java开发经验，对分布式有深刻理解。
3、熟悉ZooKeeper/Hadoop/Storm/Spark/HIVE/Hbase/kafka/Flume等分布式开源项目及其工作原理，并有实际开发经验。
4、熟悉常用脚本语言shell,python等。
5.  响应动手优先，目标导向，全栈技术文化优先;

岗位职责：
1.深入研究Spark、Hadoop及其他大数据处理技术；
2.执行大数据平台研发计划；
3.处理现行产品平台中的问题。
 
岗位要求：
1.1年以上Spark、Hadoop项目相关工作经验；
2.了解大数据生态环境中的多项技术：HDFS/ElasticSearch等；
3.了解脚本编程(Shell / Python / Perl其中一种）；
4.良好的文档习惯、标准化的代码编写习惯；
5.良好的需求理解能力、测试习惯、学习和总结的能力。

岗位职责：1. 基于互联网\电子商务\金融海量数据，分析买卖家用户特征，开发各类保险信用模型，识别风险；2. 建立消费者、商户信用评分、授信模型体系，支持各类保险业务场景；3． 根据不同场景和产品形态，开发信用担保保险产品政策，制定欺诈、风险控制等策略；岗位要求：1. 本科以上，计算机、统计、金融等相关专业；2年以上互联网或金融机构数据分析、挖掘工作经验。2. 精通数据分析、挖掘方法，能熟练运用SAS/SPSS，R语言等挖掘工具和技能（至少精通一种）。 3. 熟悉巴塞尔风险评估体系，熟悉金融风险控制，授信模型，贷后监控过程。4. 熟悉Linux、Oracle等大型数据库及分布式环境，能通过SQL熟练操作数据。5. 具有较好的商业Sense和逻辑推理能力，善于从商业角度解读数据，能推动数据分析结果落地。

1.掌握 Linux 操作系统的配置，管理及优化，能够独立排查及解决系统层的各类问题；
2.熟悉Hadoop/HBase/Hive/Spark/Kafka/Zookeeper等开源项目的安装与调试,升级扩容
3.至少精通 Perl/Python/Shell脚本语言中的一种；
4.熟悉大数据周边相关的数据库系统，mysql和 mongodb/redis等。
PS：运营过Hadoop/HBase/Hive等相关系统，有从事过海量数据分布式处理、各种分布式计算，或者分布式存储、分布式计算系统相关的工作经验的优先；

1）计算机相关专业本科以上学历，2年以上相关工作经验；
    2）熟练掌握Java、Python等开发语言；
    3）掌握Spark、MapReduce开发，掌握作业调优方式，有海量数据处理经验；
    4）掌握流处理框架开发，Spark Streaming、Flink、Storm；
    5）精通Hive、Spark SQL开发；
    6）熟悉主流NoSQL数据库和图数据库应用开发，如HBase、MongoDB、Rediis、Neo4j等，有过高并发读写调优经验；
    7）熟悉主流全文搜索框架开发，如Solr、ES；
    8）有大数据架构经验，能够根据需求完成大数据架构设计；
    9）熟悉Hadoop、Spark生态圈，能运用其解决问题；
    10）良好的沟通，团队合作意识，非常强的学习能力。

岗位职责：
1、负责公司大数据/Hadoop/Hive/Spark/实时计算的运维保障；
2、负责Hadoop/Hbase/Spark/Hive等系统的架构审核、业务监控、持续交付、应急响应、容量规划等；
3、跟进并处理系统事件，对系统问题及故障解决跟踪优化，负责服务状况与服务
4、梳理优化业务使用集群的流程及规范，使集群使用在资源利用、质量等方面均达到较高水平；
5、日常跟踪业界技术发展动态，并结合业务发展需要，研究引入合适的技术。
岗位要求：
1、大学本科及以上学历，计算机或者相关专业，2年以上分布式存储与计算的相关工作经验；
2、深入理解linux系统，运维体系结构，精于容量规划、架构设计、性能优化；
3、有开发经验优先，精通一门以上脚本语言(shell/perl/python等)；
4、熟悉hadoop、hive、hbase、yarn、spark、storm等之组件的原理及运维方式；
5、具备很强的故障排查能力，有很好的技术敏感度和风险识别能力；
6、良好的服务意识，善于团队协作；
7、能够承受较大的工作压力。

岗位职责：
1、主要负责企业级数据中心平台开发框架的设计、性能调优、数据流监控及日常维护；
2、直接参与或指导开发人员基于框架进行海量数据的处理、分析、挖掘；
3、负责开源大数据平台与产品和相关技术的追踪及研究； 
4、负责高并发、大存储、实时计算等技术攻关；
5、负责大数据平台及产品研发团队的组织与管理，并进行相关技术培训；
6、对前瞻创新技术进行应用型研究、技术攻关。
任职资格：
1、至少3年hadoop分布式平台工作经验，熟悉hive、hbase、pig、hdfs，map/reduce、oozie、spark等；
2、熟悉分布式系统的设计和应用，熟悉分布式、缓存、消息、负载均衡等机制和实现；
3、有Hadoop集群搭建和管理经验者优先考虑，有海量数据挖掘算法开发经验者优先考虑，兼有Oracle，MySQL，NoSQL开发经验者优先考虑；
4、对大数据充满热情善于解决问题。

岗位职责：
1、负责企业数据仓库设计和大数据项目的开发工作；
2、负责非结构化大数据处理项目的开发实施。
任职要求：
1、计算机、数学或者电子信息技术相关专业，具有3年以上大数据清洗、整合处理项目经验；
2、精通Hadoop生态技术，包括Hive、Spark、HBase、HDFS、sqoop和impala等；
3、精通Hive优化，熟悉sparkSQL使用和调优者优先；
4、有互联网、电商或相近行业工作经验者优先；
5、具有优秀的问题分析和解决能力，良好的沟通协调能力。
我们可以提供：
1、挑战性的工作机会和良好的个人发展晋升空间。
2、舒适的办公环境、良好的团队合作氛围和自由的技术发挥平台，充分重视员工的自我价值实现。
3、五险一金、员工福利、运动会、嘉年会、拓展各类活动、集体旅游......。
4、绩效奖励、股权及其它晋升、调薪福利结构。
5、五天工作制，周末双休。
鹏元之道、以诚为本、以人为本，广纳英才，期待您的加盟共创美好明天！


工作地址
深圳市福田区深南大道7008号阳光高尔夫大厦四楼

岗位要求：
（1） 计算机、数学、统计学或相关专业，本科以上学历，1年以上工作经验。
（2） 具有大数据系统开发经验，能独立完成系统的设计、开发、测试和维护。
（3） 对大数据处理、分析有浓厚兴趣，喜欢钻研，具有较强的学习能力，能独立解决问题。
（4） 工作勤奋、负责，有较强沟通能力。
职位描述：
央视市场研究（CTR）是国内最权威的媒体监测与市场研究公司，隶属于中国国际电视总公司与Kantar集团。拥有二十多年的媒介研究经验及媒体监测、人群属性、行为、价值偏好等数据积累，并与国内外若干知名互联网企业深度合作，专注于融合多屏数据，打通用户的线上线下行为，实现对用户的同源分析和360度洞察。
如果您对技术充满热情，享受解决富有挑战性问题的过程；如果您喜欢大数据，乐于学习最新的海量数据处理方法；或者，您具有扎实的统计学习功底，能从多元化的数据中发掘有价值的洞察——这里都会是您施展才能的平台。期待您与我们一起，迎接挑战，共同进步。
专业技能：
（1） 技术功底扎实，熟悉网络、数据库、分布式计算等理论，熟悉常用数据结构和算法。
（2） 熟练的英语读写能力，无障碍的阅读英文资料，撰写英文文档。
（3） 熟悉至少一种大数据计算平台，如Hadoop、Spark、Storm、Kafka等。
（4） 熟悉至少一种NoSQL数据库，如Redis、Memcached、MongoDB、HBase等。
（5） 熟悉Linux环境，熟练运用Java语言。
（6） 具有Lucene等搜索引擎实践经验者优先。
（7） 具有网络爬虫、分词系统等开发经验者优先。
（8） 熟悉统计学知识，有海量数据分析、挖掘经验者优先。

岗位职责：1、负责大数据仓库（ODS、EDW、CSL、ADM）的设计、开发、测试；2、负责各业务系统数据源业务探查、数据探查、ID调研、准确性完整性验证； 3、为前端展示提供数据支持，为业务人员提供数据查询； 4、大数据仓库日常管理、跑批、维护、监控。任职要求：1、2年以上大数据仓库项目开发经验，本科以上学历；2、熟悉hbase、hive、Phoenix等大数据分布式数据存储，熟悉sqoop、datax、azkaban等大数据ETL调度工具；3、熟悉inmon企业数据仓库（EDW）设计理论与技术、Kimball维度建模理论与技术；4、了解PowerDesigner、ERwin等建模工具，熟悉概念模型、逻辑模型、物理模型；5、熟悉P2P、互联网金融业务优先；6、熟悉Hadoop，spark生态圈优先；7、责任心强、思路清晰、学习力强。

岗位职责：
1、负责基于Spark技术的海量数据的处理、分析、统计、挖掘工作；
2、基于Spark框架的数据仓库的设计，开发，维护；
3、根据需求使用Spark Streaming和Spark SQL进行数据处理、查询、统计等工作。


岗位要求：
1、本科及以上学历，软件工程、计算机等相关专业，优秀硕士研究生优先考虑；
2、熟悉RDD/DataFrame编程，对Spark体系结构、运行机制有深入研究，熟悉源码；
3、熟悉Spark相关技术；
4、熟悉linux、shell脚本或python脚本编程；
5、熟悉Spark Streaming和Spark SQL，有过程序开发经验；
6、具有良好的Trouble Shooting能力；
7、能够用python开发数据算法，熟悉python算法库的优先；
8、具有海量数据系统开发经验，且在开源社群活跃并有积极贡献者优先考虑。

工作职责：
1、负责HBase集群的大规模、高可用和稳定性开发工作
2、负责全文搜索系统的搭建
3、解决业务需求，深度参与业务系统的设计与实施
4、持续完善监控等周边系统功能，改进和优化存储系统的设计架构
任职资格：
1、2年以上Java开发相关工作，熟悉J2EE知识体系；
2、熟悉Hadoop/HBase/Zookeeper/Spark等的运行机制和工作原理；
3、熟悉Linux/Unix平台，熟悉bash、python语言中至少一种；
4、熟悉多进程、多线程、数据库、IO、内存管理等方面编程者优先；
5、熟悉主流全文搜索框架开发，如Solr、ES；
6、熟悉主流NoSQL数据库和图数据库应用开发，如HBase、MongoDB、Rediis等，有过高并发读写调优经验；

岗位职责:1、负责大数据计算和存储平台的设计和搭建工作;2、组织实现内部和外部对大数据服务的需求;3、新技术的研究与导入;4、带领并指导下级工程师完成相关开发任务;5、负责团队技术培训相关工作.
任职资格:1、精通JAVA语言，对JAVA语言高级特性有深入的了解;2、对Map/Reduce原理有深入研究，熟悉Hadoop、Hive、Hbase、Spark、Storm等大数据开源项目，具有多个以上大数据平台项目实施经验;3、熟悉业界大数据建模方法及新的建模方法的发展;4、本科及以上学历，5年以上大数据业务工作经验，有互联网公司大数据工作经验的优先，有海外工作经验的优先，硕士以上更高学位者优先;5、了解大数据平台建设过程中的挑战与问题，有系统化解决问题的成功案例;6、有很好的向上沟通能力，跨部门沟通推动协作能力，很强的团队合作精神;7、熟悉Linux操作系统以及相关编程优先.工作地点：深圳最后入职公司为：北京国金开科科技有限公司 北京国金开科科技有限公司（简称：国金开科）成立于2017年1月。公司由原厦门国际金融技术有限公司（X-Fintech）科技部独立，成为瀚徳金控集团旗下子公司。国金开科注册资本1000万元人民币，由厦门国际金融技术有限公司和北京开科唯识技术有限公司共同出资成立。国金开科专注于资产证券化信息系统的建设，包括资产证券化的新闻资讯、数据库系统、全流程管理和分析、量化模型系统。国金开科将应用大数据、人工智能和区块链等多种最新技术为资产证券化的数据、估值、分析提供大数据环境下的智能信息服务，我们的愿景是成为中国资产证券化行业一流的信息提供商。


岗位职责：
1、设计和开发第四范式大数据处理系统基础框架和业务组件；
2、提供充分的系统底层组件，提升整个系统的通用性、性能、可扩展性；
任职资格：
1、计算机相关专业本科（或以上）学历；
2、熟练掌握Java或Scala语言和常用数据结构与算法；
3、熟悉Hadoop/ Spark/ Storm等框架的机制，具备在Hadoop/ Spark/Storm上开发软件系统的经验；
4、熟练掌握Linux、网络等计算机基础知识，熟练掌握至少一门脚本语言；
5、对计算机系统有一定的认识，对软硬件协同有理解，具备较强的动手能力、故障诊断能力；
6、对新兴技术有好奇心，有利用技术解决实际问题的热情，开源社区积极参与者优先。

职责：• 按照规范及设计文档完成编码工作，并对代码质量负责；• 编写及维护技术开发相关文档；• 能够对自己开发的代码设计并编写单元测试及功能测试代码；• 学习和研究新技术以满足产品的需求；• 为产品改进、优化、效率提升设计开发产品内部工具。
要求：• 计算机相关专业本科及以上；• 软件基础理论知识扎实，具有良好的数据结构、算法功底；• 熟悉Hadoop等分布式开发，了解Hadoop相关各种开源项目，如：Hive、Hbase等，并有实际应用，熟悉Storm、Spark者优先；• 熟练应用Spring、Java Cache等开源框架；• 熟悉MySQL等关系型数据库，熟悉NoSQL数据库者优先；• 对新技术敏感，有一定独立分析，技术研究能力；• 熟练使用Linux环境下开发者优先；• 熟悉至少一种版本控制工具，如：SVN，熟悉分布式版本控制工具Mercurial或Git者优先；• 有个人开源项目或参与开源项目者优先；• 有代码洁癖和自发组织Code Review的开发者优先；• 提供本人半年内写过的代码，不限开发语言；
工作态度：• 具备良好的人际交往、语言表达和沟通能力；• 具备高度的责任心、诚信的工作作风、优秀沟通能力及团队精神；• 愿意接受挑战性的工作，能够高效及时完成工作

职位描述：1、构建分布式大数据服务平台，参与和构建公司包括海量数据存储、离线/实时计算、实时查询，大数据系统运维等系统2、服务各种业务需求，服务日益增长的业务和数据量3、深入源码内核改进优化开源项目，解决各种hadoop、spark、hbase疑难问题，参与到开源社区建设和代码贡献
岗位要求：1、计算机或相关专业本科以上学历（3年以上工作经验）2、精通C++/Java/Scala程序开发(至少一种)，熟悉Linux/Unix开发环境3、熟悉常用开源分布式系统，精通Hadoop/Hive/Spark/Storm/Flink/HBase之一源代码4、有大规模分布式系统开发、维护经验，有故障处理能力，源码级开发能力5、具有良好的沟通协作能力，具有较强的分享精神6、对Kudu、Kylin、Impala、ElasticSearch，github等系统有深入使用和底层研究者加分

岗位职责
1、负责公司的各类数据处理任务,熟悉数据的抽取（extract），转换（transform），加载（load）等流程，有数据仓库的使用和架构经验。
2、负责配合算法团队，一起开发相应的大数据分析平台。
任职要求
1、计算机或相关专业本科以上学历,3年以上相关工作经验。
2、熟悉Linux平台上的开发环境，熟悉常用脚本语言。
3、精通Java/Scala。
4、至少掌握一种计算框架Hadoop/Spark/Flink等。
5、至少掌握一种分布式存储技术HBase/Cassandra等。
6、至少掌握一种大数据ETL工具Hive/Spark等。
7、善于学习新的知识，对解决具有挑战性问题充满激情。
有Hadoop, Spark使用经验优先

岗位职责：负责数据仓库的搭建
负责大数据平台的开发
负责金融数据的采集、清洗、规约等工作
负责统计报表等数据统计、数据展现的工作
负责用户投资分析、借贷人审核等数据挖掘、机器学习的工作
职位需求：具有3年以上据仓库经验熟练掌握MapReduce应用开发精通Hive、HBase等大数据开发工具熟悉mysql数据库操作精通Java语言、熟悉Shell熟悉Linux操作
了解web项目优先、有数据挖掘与机器学习的经验优先

岗位职责：
1.负责数据清洗、加工、分类等开发工作，并能完成数据分析师对数据提取的需求。
2.负责从数据中挖掘出有价值的数据，把这些数据录入到数据中心，支持应用端资料分析与预测。

岗位要求：
1.熟悉常用的数据挖掘算法
2.熟练在Hadoop，spark等框架上进行数据处理工作
3.熟悉使用Scala，R语言等数据分析语言


加入鼎捷，您可以获得优厚的薪资福利待遇和完善的培训发展体系 
----固定的基本薪资、岗位技能/管理津贴、年终奖、绩效奖金、年度调薪
----法定年假、福利年假、法定节假日、带薪病假
----五险一金、商业保险（补充医疗险、意外伤害险）
----午餐补贴、通讯补贴、自备机补贴、出差补贴
----生日礼金、节假日福利、婚丧喜庆福利、定期体检
----健全完善的培训体系（新人训、专业训、部门内训、新人带教制度等）
----宽广的晋升发展平台                                                                                                                                              更多鼎捷相关：http://www.digiwin.com.cn/yqh/Simple_dem/index.html
注意：应聘者需承诺提供的相关材料真实、合法，不存在虚假成分；如有虚假材料，视为不符合该岗位的录用条件。

职位描述：
负责数据产品的架构设计和研发；
根据业务需求，制定系统的整体技术框架、业务框架和系统架构；
和团队成员一起完成大数据智能分析工作的流程、规范和方法建立；
对系统框架相关技术和业务进行培训，指导开发人员开发，解决系统开发、运行中出现的各种问题；
职位要求：
对各种架构模型有深入理解，了解模型的优缺点；
Java基础扎实，熟练使用Shell、Python、R等语言；
掌握数据仓库(DW)/ 商业智能(BI)/ 数据统计理论，并灵活的应用；
精通SQL，有较好的SQL性能调优经验，理解Greenplum/Mysql 基本原理和调优策略；
算法基础扎实，熟悉常见的数据结构，了解分布式算法和分布式系统；
熟悉常见的开源分布式计算/存储相关技术，包括但不限于YARN，MapReduce，Impala，Spark，Kafka等；
有互联网产品BI开发经验，有网站数据、用户数据、电商、点击流、精准营销等相关经验；

职责：
负责滴滴各种后台业务系统(API数据接入）的设计、开发、维护
职位要求：
1、熟练掌握java、python，PHP等语言，熟悉golang将是很大的加分项，我们未来的开发将以golang为主；本科以上学历，一线互联网公司背景，3年以上开发经验
2、有丰富的工作经验，能够独立主导要求对自己做的项目有自己深入的理解，并能持续的关注和优化自己做的项目，研究过优秀开源软件的源码并有心得者优先； 
3、精通 MySQL 应用开发，熟悉数据库原理和常用性能优化技术，以及 NoSQL原理、使用场景以及限制； 
4、熟悉常用的互联网技术，包括但不限于RPC、MQ、缓存技术、调用策略等； 
5、参与过大型复杂分布式互联网系统的设计、架构者优先； 
6、有较强的逻辑思维能力，善于分析、归纳、解决问题；
 

岗位职责：
1、参与大数据平台的设计与开发，解决海量数据面临的挑战；
2、管理、优化并维护Hadoop、Spark等集群，保证集群规模持续、稳定；
3、负责HDFS/hive/HBase的功能、性能和扩展，解决并实现业务需求；
4、协助团队成员建立数据模型，对数据进行挖掘、优化及统计。

任职要求：
1、本科生及以上学历，2年及以上互联网系统或者其他企业应用系统开发相关经验；
2、具备Java开发经验，Java编程基础扎实，熟练使用struts2、spring、ibatis或hibernate等框架；
3、有分布式系统开发经验；
3、熟悉Hadoop/HBase/Spark/Storm/Hive，熟悉数据挖掘策略与算法者优先；
4、数据控，善于发现问题、解决问题,具备良好的分析和解决问题的能力，具备一定的钻研精神和持续学习的意愿，强烈的责任感和团队感，对负有挑战性的工作充满热情。

工作职责：1、 参与公司数据仓库架构设计与研发，建设PB级的公共数据平台和服务系统，实现高质量数据的互通与共享。同时针对各业务场景探索大数据解决方案2、 参与公司数据产品与应用的数据研发，发觉数据商业价值，打造极致体验的数据产品3、 助力数据化运营业务，构建丰富多样的BI应用。任职资格：1、 计算机或相关专业本科及以上学历 ，从事数据仓库领域至少2年以上。2、 具有丰富的数据开发经验，对数据处理、数据建模、数据分析等有深刻认识和实战经验  3、 掌握至少一种数据库开发技术：Oracle、Teradata、DB2、Mysql等，灵活运用SQL实现海量数据加工处理   4、 有从事分布式数据存储与计算平台应用开发经验，熟悉Hadoop生态相关技术并有相关实践经验着优先，重点考察Hdfs、Mapreduce、Hive、Hbase 5、 掌握实时流计算技术，有storm开发经验者优先6、 积极乐观、诚信、有责任心；具备强烈的进取心、求知欲及团队合作精神

任职要求：
1. 拥有计算机、数学相关方向硕士学位，3年以上工作经验；
2. 熟悉Linux操作系统及MySQL数据库，了解SQL优化，熟练使用Java、Python、SHELL；
3. 精通Hadoop生态圈相关技术，如HDFS、Flume、MapReduce或Spark等；
4. 熟悉kafka, logstash等数据仓库中间件；
5. 具有海量数据处理、优化经验，至少1个以上大型大数据成熟项目的经验；
6. 逻辑清晰，快速的学习能力及良好的沟通能力；

工作职责：
1．参与部门大数据平台的设计、建设与维护工作；
2．负责大数据的采集、处理、分析、挖掘，为运营决策提供支持；
3．深度挖掘业务数据，通过用户行为分析、关联分析，指导产品、开发和市场运营工作，并实现有价值的商业预测等；
4．负责应用平台中报表相关功能的规划与设计，各业务线日志采集、清洗、整合等工作；
5．利用BI工具整合、分析、展示数据，撰写数据统计报告；

岗位职责：
1、根据需求完成海量数据的处理任务；
2、能够对关联数据进行并行挖掘；
3、开发高并发、实时的流处理作业；
4、对Hadoop、Spak进行深度定制二次开发；
5、对数据应用进行架构设计；
6、运用开源大数据软件解决问题。

岗位要求：
1、计算机相关专业本科以上学历；
2、至少熟练掌握Java、Python、Scala中的两种语言；
3、掌握Spark、MapReduce开发，掌握作业调优方式，有海量数据处理经验；
4、掌握流处理框架开发，Spark Streaming、Flink、Storm；
5、精通Hive、Spark SQL开发；
6、熟悉主流NoSQL数据库和图数据库应用开发，如HBase、MongoDB、Redis等，有过高并发读写调优经验；
7、熟悉主流全文搜索框架开发，如Solr、Elasticsearch；
8、有大数据架构经验，能够根据需求完成大数据架构设计；
9、熟悉Hadoop、Spark生态圈，能运用其解决问题；
10、良好的沟通，团队合作意识，非常强的学习能力。


工作职责：
1. 参与大数据处理系统或应用的设计、开发、维护；
2. 参与或主导内部大数据相关项目建设，参与架构讨论并推进技术演进&amp;优化。
 
任职要求：
1、  本科及以上学历，统计、数学、计算机等相关专业；
2、  具备1年以上数据分析、数据建模工作经验，构建过挖掘模型；
3、精通Java编程，具备扎实的数据结构与算法功底；
4、熟悉Spark或Hadoop生态圈技术，有丰富的RDD/MapReduce开发经验；
5、熟悉MySQL、Oracle或NoSQL数据库技术；熟悉ETL者优先；
6、有Linux下的开发经验，熟练掌握python、C++或JAVA之一；
7、有互联网分布式大数据挖掘、分析、数据仓库开发实施经验者优先。


岗位职责：
1、大数据平台的运维、调优
2、提升系统稳定性
3、大数据相关的运维自动化工作
4、新技术调研
岗位要求：
1、熟悉常见linux系统，有丰富的故障排查、性能调优经验
2、精通大数据生态圈相关技术(hadoop、spark、hbase、hive、kafka、storm)等，有丰富的故障处理和运维经验
3、熟悉大数据平台的监控以及调优
4、熟悉ELK，有相关运维、调优经验
5、熟悉prestodb架构，有相关经验者优先
6、精通至少一种常用脚本语言(shell、python等)，熟悉java者优先
7、有独立分析问题和解决问题的能力

岗位职责：  
    设计、开发玩吧项目数据仓库与BI平台
    通过开发工具来支持分析师的复杂数据需求
岗位要求：
    熟练掌握分布式大数据框架和相关技术
    精通Python/Java/Scala语言，具备从零开始建立数据仓库的能力
    熟练掌握MySQL等传统数据库
    3年以上大数据项目经验
    熟练使用linux环境


工作职责：1. 服务器端后台算法系统的开发， 重构与维护。2. 后端数据处理、数据分析系统优化。任职资格：1. 3年以上互联网公司开发经验，从事过大型系统的架构与研发工作。2. 熟练使用C++PythonJava语言，熟悉各种开源类库的使用与开发.3. 熟悉机器学习系统架构，有机器学习系统开发经验者优先。4. 对并行系统流程熟悉，熟悉MySQL与Hive SQL优化，有HiveSparkHBase等开发经验者优先。5. 较强的学习、分析问题的能力，良好的团队合作意识与跨部门沟通的能力。6. 开源社区贡献代码者优先。

岗位职责：
1.负责大存储和实时流的Hadoop/spark大数据平台运维，监控和优化工作；
2.保证Hadoop/spark平台各核心服务运行的稳定、高效；
3.对Hadoop/spark平台运维不断优化，提升数据产品的质量和响应速度；
4.开发各种Hadoop大数据自动化运维与监控工具；
5.研究大数据前沿技术，改进现有系统的服务和运维架构，提升系统可靠性和可运维性。
岗位要求：
1.有apache hadoop、cdh搭建和运维经验，能够独立搭建相关环境；
2.2年以上Hadoop大数据平台实际生产环境经验；熟悉Apache spark资源管理、调度和性能调优；熟悉Spark，Kafka，HDFS，Hive，Hbase，MapReduce，Yarn，Flume，Mesos，ZooKeeper中的2个以上组件；
3.理解Spark和MapReduce的原理，能够根据日志分析程序运行出现错误的原因，并对程序运行的参数进行优化，给予业务开发人员建议和支持；
4.熟悉分布式系统、分布式计算系统的工作机制，熟悉Hadoop生态圈相关核心技术的工作机理；有一定源码研究者优先；
5.熟悉Linux系统管理工作；熟悉Shell编程，能够编写脚本解决日常问题，包括自动化的工作流设计；
6.熟悉Scala或者Python编程者优先。

岗位职责：
1.负责大数据平台的开发需求
2.与业务部门需求的沟通协调等；
3.团队人员进行大数据项目的落地开发等；
4.与外部公司数据接口、交互等的开发、沟通等；

任职要求：
1.熟悉大数据生态圈；
2.熟练使用hadoop、spark、storm、hive、python等；
3.掌握Linux基本操作 ；
4.熟悉SQL、JAVA等；
4.具有大数据项目经验项目经验尤佳。

岗位职责：
1、负责DSP业务各模块数据分析工作，能够从数据中发掘商业价值；2、人群画像、统一用户识别、关键指标统计、可视化展示及深入分析；3、采用统计分析/数学建模/数据挖掘等方法，提供有价值的商业数据、模型、算法支持。4、对海量数据进行分析，分析数据之间的相互作用关系和联系，发现潜在规律，为优化产品的设计和业务方向提供决策支持；5、指导团队成员根据不同业务需求、业务场景构建业务模型， 负责与业务部门沟通、寻找业务突破点，提出解决方案；6、跟踪大数据应用市场动向，市场竞争对手分析，及时调整市场策略，创新产品应用    任职要求：1、本科及以上学历，3年以上互联网行业数据统计与分析经验；2、3年以上互联网行业工作经验，负责设计过数据分析、数据挖掘、数据可视化、在线数据相关产品经验，至少一年以上移动端领域数据分析工作经验；3、精通使用Excel/SPSS/SAS分析数据，有多年撰写商业数据分析报告经验；4、熟悉 Storm/Spark或其他类似实时计算系统，熟悉编写Map Reduce和Hive SQL统计和分析数据；5、有Adx/DSP/SSP/DMP等程序化购买业务工作经验者优先考虑；6、对业务系统的日志数据的实时分析、监控有实际工作经验，对数据敏感，有较强的学习能力以及快速解决问题的能力；

工作职责：
1、输入法基础数据系统建设；
2、配合各业务给予数据支持，对产品和运营数据总结和优化； 
3、处理用户海量数据，提取、分析、归纳用户属性，行为等信息，完成分析结果； 
4、发现并指出数据异常情况，分析数据合理性； 
任职要求：
1、3年以上互联网行业研发经验，有使用hadoop/hive/spark分析海量数据的能力； 
2、在数据挖掘等领域算法有实际经验；
3、有良好的沟通能力，具备出色的规划、执行力，强烈的责任感，以及优秀的学习能力。

工作职责：
大数据底层架构设计和实施；
对移动设备数据和社交数据进行挖掘分析和建模；
逐步构建基于用户行为、喜好的标签系统，并应用于相关的个性化系统和业务分析中；
负责数据管理平台的核心技术实现与优化；
负责大数据在广告领域的创新应用，持续推动业务线的商业效果改进； 任职资格:

岗位要求：
本科及以上，计算机、软件工程、统计学、数据挖掘、机器学习等相关专业。
2年及以上大数据流程架构经验，熟悉Hbase/Hive/Hadoop/Spark或等主流分布式开发平台，有高性能集群设计和开发经验。
精通Linux，熟练掌握Python/C/Shell/Java，熟练掌握SQL数据库语言 HiveSQL/Mysql/Sqlserver。
有数据挖掘算法实施经验，熟练掌握大规模数据挖掘、机器学习。
对有广告营销大数据算法/开发经验者优先，有大型数据项目经验优先，有用户行为分析、用户建模、业务建模经验者优先。
具有良好的逻辑分析能力、沟通能力和协调能力。
积极的工作态度，勤奋上进，有责任心。
 


职责：
1.负责大数据平台建设与维护
2.负责报表，搜索，推荐，多维分析等数据相关系统的开发工作
3.负责数据提取工作

要求：
1. 深刻理解大数据处理(流计算、分布式计算、分布式文件系统、分布式存储等)相关技术和实现方法，有架构和设计实践经验；
2. 有互联网产品BI开发经验，有网站数据、用户数据、电商、点击流、精准营销等相关经验优先；
3. 熟悉Hadoop/Hbase/hive等，掌握MapReduce, Storm或者Spark编程,，熟悉数据挖掘策略与算法。
4. 熟悉数据模型建模，以及常用ETL工具；
5. 具备Java/C++/Python等开发经验；
6. 良好的逻辑思维能力，熟悉业务抽象和数据模型设计，具有很强的分析问题和解决问题的能力，对解决具有挑战性问题充满激情。

岗位职责说明：
1、构建数据采集、提取平台。
2、采集数据、汇总数据 、提供数据分析结果。 
3、负责公司大数据平台框架的设计和优化，数据分析结果可视化展示。
4、负责公司大数据平台核心模块的开发、编程任务；
任职资格说明：
1、有3年及以上Java项目开发经验，1年及以上Hadoop使用经验。
2、熟悉J2EE技术体系，精通Struts、Spring、Hibernate等技术。
3、良好的Java代码编程能力，了解PHP、Groovy等脚本语言、熟悉linux平台者优先。
4、熟悉Hadoop、HBase等相关大数据系统的应用和开发者优先。
5、具有应用分析和数据挖掘者经验优先。
6、本科及以上学历。

工作职责：
1.根据对产品业务的理解梳理数据需求，建立相关业务模型，负责业务的数据需求和报表开发;
2.搭建数据化运营平台与数据中心，以数据驱动渲染业务发展，提升业务运营效率 
3.具体领域包括但不限于分布式存储、大规模分布式计算、实时计算、跨平台资源调度、大规模分布式算法平台等；

任职要求：
1.有Hadoop、Hive、HBase、Spark、Storm等技术体系的实际项目经验
2.有数据仓库、BI系统实施经验者优先
3.有扎实的算法基础，熟悉常见的数据结构，了解分布式算法和分布式系统
4.对数据敏感，有较强的逻辑分析能力，对(大)数据处理和分析技术有强烈热情；
5.有良好的沟通表达能力和团队合作精神，热衷技术，乐于寻求挑战和突破自我。
斗米介绍2015年11月，“斗米兼职”正式从 58 赶集分拆独立（原品牌赶集职有和58职达），由赵世勇担任 CEO。“斗米兼职” 是一个连接 B 端和 C 端的第三方兼职平台。A轮 4000万美金（2015年11月）------58赶集集团、高榕资本（为领投放）、蓝湖资本B轮4000万美金（2016年10月）--------高瓴资本、腾讯、百度和新希望集团、高同资本和蓝湖资本跟投斗米平台目前月活用户远超千万，平台在线交易月流水上亿元，累计服务企业商户数量超50万；月访问用户超2000万。目前全国30多家城市分站，公司规模1000+人数。


岗位职责：
1、和产品经理一起讨论需求，并对需求进行分析、设计和开发工作；
2、核心代码编写、指导和培训工程师；
3、担任某个系统的负责人，如果你有好的想法，可以尽情在你负责的系统里进行实现；
4、前瞻性的考虑业务需求、系统现状以及问题，对系统的发展进行规划并推进实施。
岗位要求：
1、JAVA基础扎实，理解io、多线程、集合等基础框架，对JVM原理有一定的了解；
2、四年以上使用JAVA开发的经验，对于你用过的开源框架，能了解到它的原理和机制；对Spring,ibatis,struts等开源框架熟悉；
3、熟悉分布式系统的设计和应用，熟悉分布式、缓存、消息等机制；能对分布式常用技术进行合理应用，解决问题；
4、掌握多线程及高性能的设计与编码及性能调优；有高并发应用开发经验；
5、掌握Linux 操作系统和大型数据库（Oracle、MySql）；对sql优化有丰富的经验；
6、良好的沟通技能，团队合作能力，勤奋好学；
7、对互联网或J2EE应用开发的最新潮流有关注，喜欢去看及尝试最新的技术。

任职要求：
1. 熟悉大数据开源产品的架构和技术细节，具Spark(Streaming/MLlib)、Hadoop、Hive、YARN/Mesos、Flume、Kafka平台的项目开发经验，平台运营维护经验；
2. 有扎实的Java基础，Java多线程、并发以及网络通信有深厚的经验；首先scala优先考虑；
3. 有较强的实现能力及学习能力，拥有实际的Hadoop的项目经验;
4. 工作认真，负责，良好的团队合作精神和解决问题分析能力。钻研技术克服困难，勇于挑战；
5. 熟悉Linux/Unix操作系统，熟悉脚本编程(Shell/Python/Perl其中一种）。
工作内容：1. 负责海量数据的自动化分析处理和统计工作；
2. 数据仓库的设计，开发，维护；
3. 根据相关需求进行数据处理、查询，统计等工作。


工作职责：
1.负责滴滴研究院语音团队训练数据自动化生成、管理，帮助提高模型训练的迭代效率；
2.利用技术实现业务的原始数据自动化获取、清洗、整理、分类入库供算法团队调取使用


任职资格：
1.熟练掌握：mysql、hdfshivehbase 、nosql数据库使用；
2.熟练掌握：shell、python脚本，通过脚本语言编写程序进行数据清洗、分类、入库；
3.具有1年以上数据清洗、数据挖掘方向的脚本开发经验；
4.熟练使用linux操作系统，具有服务端（c++javaphp）开放经验者优先；
4.具备分析、解决问题的能力，能够承受工作中的压力；
5.具备良好的人际沟通能力和团队协作能力。


岗位职责：
1.负责大数据平台的开发需求 2.与业务部门需求的沟通协调等； 3.团队人员进行大数据项目的落地开发等； 4.与外部公司数据接口、交互等的开发、沟通等；

任职要求：
1.熟悉大数据生态圈； 2.熟练使用hadoop、spark、storm、hive、python等； 3.掌握Linux基本操作 ； 4.熟悉SQL、JAVA等； 4.具有大数据项目经验项目经验尤佳。

岗位职责
1、根据需求完成海量数据的处理任务；
2、能够对关联数据进行并行图挖掘；
3、开发高并发、实时的流处理作业；
4、对Hadoop、Spak进行深度定制二次开发；
5、对数据应用进行架构设计；
6、运用开源大数据软件解决问题。

任职资格
1、计算机相关专业硕士以上学历；
2、至少熟练掌握Java、Python、Scala中的两种语言；
3、掌握Spark、MapReduce开发，掌握作业调优方式，有海量数据处理经验；
4、掌握流处理框架开发，Spark Streaming、Flink、Storm；
5、精通Hive、Spark SQL开发；
6、熟悉主流NoSQL数据库和图数据库应用开发，如HBase、MongoDB、Rediis、Neo4j等，有过高并发读写调优经验；
7、熟悉主流全文搜索框架开发，如Solr、ES；
8、有大数据架构经验，能够根据需求完成大数据架构设计；
9、熟悉Hadoop、Spark生态圈，能运用其解决问题；
10、良好的沟通，团队合作意识，非常强的学习能力。

1、大学本科及以上学历，两年以上工作经验；
2、熟练掌握oracle pl/sql基本语法，熟悉hadoop,熟练掌握hive、spark等,了解hive脚本优化方法；
3、良好的逻辑思维能力、团队合作精神与沟通能力；
4、了解java或者shell；
5、海量数据处理经验优先；

工作职责：
1. 服务器端后台算法系统的开发， 重构与维护。
2. 后端数据处理、数据分析系统优化。
 
岗位要求：
1. 3年以上互联网公司开发经验，从事过大型系统的架构与研发工作。
2. 熟练使用C++/Python/Java语言，熟悉各种开源类库的使用与开发.
3. 熟悉机器学习系统架构，有机器学习系统开发经验者优先。
4. 对并行系统流程熟悉，熟悉MySQL与Hive SQL优化，有Hive/Spark/HBase等开发经验者优先。
5. 较强的学习、分析问题的能力，良好的团队合作意识与跨部门沟通的能力。
6. 开源社区贡献代码者优先。

职位描述：
1.负责和参与公司大数据基础架构平台的运维，保障数据平台服务的稳定性和可用性；
2.负责和参与自动化运维系统及平台的建设；
3.负责优化运维流程提升运维效率；
4.处理各类异常和故障，确保系统平台的稳定运行。

职位要求：
1.一年以上大数据平台运维经验；
2.掌握Hadoop, Hbase, Hive/Impala, Spark, Yarn, Kafka, Flume等组件的安装、配置、使用和优化；熟悉 CDH 者优先；
3.掌握Linux 操作系统的配置，管理及优化，能够独立排查及解决操作系统层的各类问题；
4.熟悉大数据开发流程，对数据安全控制有一定的经验；
5.精通Python, Shell，能够开发运维自动化组件和工具；
6.工作认真负责，有较强的钻研学习能力和分析解决实际问题的能力。

工作职责:
-对海量数据做采集、存储、管理、查询、分析、挖掘、建模等处理，对内提供大数据平台。
-探索大数据可视化的展现方式,帮助用户更加直观深入地了解数据的内容
职责要求:
-B站商业产品数据平台核心系统的研发工作,包括架构,存储,计算高性能服务
-熟练使用C++、Java、Python等至少一种编程语言
-编程基础扎实，熟悉常用算法和数据结构，熟悉分布式系统原理
-有较强的学习和动手能力，有责任心，具备良好的沟通和协同工作能力
-计算机、工程、数据统计分析相关专业，本科及以上学历
具有如下条件之一优先考虑
-具备分布式相关项目经验，分布式系统、分布式存储、分布式计算、高性能并行计算、分布式cache、分布式数据仓库合作开发项目经验或基本技能，例如Hadoop、MapReduce、Storm、Spark等
-熟悉数据库的架构、扩展特点，能够熟练进行SQL优化、集群部署、数据同步等工作
-具备数据分析、数据挖掘、机器学习、人工智能相关经验或基本技能，例如ETL技术，OLAP技术，推荐和个性化/预测/分类/聚类/关联分析等
-具备在互联网企业从事大规模数据处理实习经验

1）3年以上工作经验2）有数据仓库经验，熟悉ETL,BI相关工具的是和二次开发3）有Java开发服务器端开发经验4）有大数据相关生态软件如hadoop, hive, hbase等经验优先5）可接受出差到客户现场（重庆）工作6）有电力行业项目背景优先7）乐于学习、善于沟通，责任心强
职位描述1）负责项目进度及质量2）带领团队成员进行项目实施3）培养指导团队成员工作4）配合公司其他部门工作
待遇1）月薪15k-20k,出差补助120元/工作日2）五险一金

工作职责：1、参与公司核心机器学习算法设计与开发，成果将应用于滴滴各产品线，提供智能出行解决方案2、构建高效率的算法平台，优化产品各环节的乘客体验任职资格：1、计算机相关专业硕士及以上学历2、有数据挖掘，机器学习，最优化理论等相关基础， 熟悉基本算法3、编程基础扎实，熟悉算法数据结构，有超过三年以上C++或Python开发经验4、有机器学习、数据挖掘等相关项目实际经验者优先5、有大数据相关系统，了解hadoop原理，如map-reduce、spark、mpi等经验者优先6、踏实勤奋，自我驱动

职位描述：
1、能够在教学总监的指导下独立研发符合市场需求的课程体系 
2、按照课程体系、教学大纲高质量完成日常网络授课或线下授课
3、积极参与部门内训，保持技术先进性，学习能力强，对新技术敏感且保持强烈兴趣 
4 、配合教学总监完成相关的教学资料（实训大纲、教学 PPT 、教学用书、教学案例等）的研发工作

职位要求：
1. 本科及以上学历，计算机相关专业。
2. 3年以上大数据领域开发经验，熟悉Hadoop/Spark/HBase/Amazon S3等大数据系统，有大数据平台或开发经验者优先。
3. 熟悉Linux操作系统，熟悉Java，熟练使用Shell/Perl/Python/Ruby中至少一种语言。
4. 具有较强的学习能力、逻辑分析能力、问题排查能力。
5. 具有较强的工作主动性，工作认真、负责、细致、敬业。
6. 有钻研新技术的热情和能力，善于交流和表达，富有团队精神，具有一定的管理组织能力。
7. 面对挫折时保持情绪的稳定，在比较艰苦的情况下或巨大的压力下坚持工作。
8、有过培训课程授课经验（专兼职），能按要求自行制作课件者优先考虑。
9、接受外地出差。

岗位职责：
1、搭建并维护管理Hadoop&amp;spark集群，优化底层数据架构；
2、负责Hadoop平台上的MapReduce、Hive、HBase、Mahout应用维护、管理；
3、负责指导其他软件工程师基于Hadoop的MapReduce、Hive、HBase、mahout应用开发；
4、承接部门上各种技术工作。

岗位要求：
1、计算机及相关专业，本科以上学历，4年以上工作经验（至少2年以上数据分析经验），参与过较完整的数据采集、清洗、抽取、分析和建模工作；
2、精通Java，3年以上Java开发经验，对Java系统开发熟练（spring，mybatis等），对数据结构、算法有深刻的理解；
3、熟悉Hadoop、spark、mahout，深入理解Map/Reduce、Hive相关原理及高级特性，具有丰富的海量数据处理开发经验，熟悉YARN；
4、有10台以上的Hadoop集群部署、开发和维护管理经验；
5、熟悉常见的开源大数据处理软件（MongoDB、Storm、Kafka、Sqoop等）；
6、热爱开发，有极强的责任心和良好的沟通能力，有较强的学习能力和快速解决问题的能力，具备优化和不断改善产品的激情。


我们可以提供：
1、挑战性的工作机会和良好的个人发展晋升空间。
2、舒适的办公环境、良好的团队合作氛围和自由的技术发挥平台，充分重视员工的自我价值实现。
3、五险一金、员工福利、运动会、嘉年会、拓展各类活动、集体旅游......
4、绩效奖励及其它晋升、调薪福利结构。
5、五天工作制，周末双休。
 
鹏元之道、以诚为本、以人为本，广纳英才，期待您的加盟共创美好明天！

岗位职责：
1.   从系统应用的角度，利用数据挖掘/统计学习的理论和方法解决实际问题；
2.   数据挖掘相关算法的研究和改进，挖掘数据价值，为业务应用系统提供数据支持； 
3.   负责各业务系统数据到数据仓库的ETL工作；
4.   对开发团队进行技术指导和培训。
任职要求：
1.   全日制大学本科（含）以上学历，具有CET-4(425分以上)或同等英语证书 ；
2.   3年以上工作经验，2年以上数据处理相关项目经验，至少有Spark/ /MapReduce/Mahout/Kylin之一相关实际开发经验；
3.   至少掌握Java/Scala/Python三种语言之一；
4.   熟练掌握SQL，了解常用的ETL SQL优化技巧；
5.   熟悉常用数据挖掘算法，如分类、聚类、决策树、神经网络等； 
6.   对J2EE开发熟悉者优先；
7.   有hadoop平台相关经验者优先。
8.   务实、逻辑思维缜密、工作细致有耐心；-具有良好的分析和解决问题的能力，勇于面对挑战性问题； 具有良好的学习能力、沟通能力和团队合作精神。

        工作职责：
1、 计算机相关专业硕士及以上学历
2、 有数据挖掘，机器学习，最优化理论等相关基础， 熟悉基本算法
3、 编程基础扎实，熟悉算法数据结构，有超过三年以上C++或Python开发经验
4、 有机器学习、数据挖掘等相关项目实际经验者优先
5、 有大数据相关系统，如map-reduce、spark、mpi等经验者优先
6、 踏实勤奋，自我驱动


任职资格：
1、 参与公司核心机器学习算法设计与开发，成果将应用于滴滴各产品线，提供智能出行解决方案
2、 构建高效率的算法平台，优化产品各环节的乘客体验


岗位职责：
1、搭建分布式的海量数据处理平台，提取关键特征，建立数据模型，提升数据质量；
2、搭建运营数据平台，建立数据分析/数据挖掘模型，指导产品日常运营；
3、分析海量用户的行为数据，搭建个性化的数据推荐系统，优化产品效果。
任职资格：
1、本科及以上学历，计算机、统计和应用数学等相关专业；
2、5年以上大规模数据分析、挖掘相关工作经验；
3、熟悉Linux/Unix平台上的开发环境；
4、熟悉聚类、分类、回归等机器学习算法；
5、对常见的核心算法理解透彻，有实际建模经验者或者熟悉智能业务者优先；
6、具有Hadoop/Spark等大数据分析工具相关使用经验；
7、熟悉至少一种脚本语言（Shell，Python等），能独立完成相关的数据分析、挖掘工作；
8、了解数理统计、数据分析及挖掘，熟知常用算法，有数据仓库和建模理论基础或实际经验；
9、具有良好的数据敏感度，能从海量数据提炼核心结果；
10、具备高度的责任心，对数据分析及挖掘有浓厚兴趣；
11、具备良好的沟通交流能力和文字语言表达能力，较好的逻辑分析能力。
12、有相关管理经验可应聘部门经理

岗位职责: 
参与京东商城Y事业部收益管理与供应链运筹优化项目中大数据方面的开发工作：
1.负责数据分析、加工、清理、处理程序的开发
2.从事海量数据分析、挖掘相关工作
3.负责数据相关平台的搭建、开发、维护、优化 
任职条件:  
1.计算机相关专业，本科及以上学历，5年以上Java开发工作经验，学习能力突出；
2.熟悉hadoop生态系统内常见项目的使用（hdfs、hive、hbase、spark、zookeeper,yarn等），具有MapReduce开发经验，有实际大数据项目经验优先
3.熟练掌握Oracle、MySql等主流数据库
4.精通JAVA，熟悉基于J2EE的WEB架构设计，熟悉Web开发流程，有丰富的Web MVC（Struts、Spring，Hibernate等）开发经验；
5.熟悉Linux/Unix系统环境下的操作；熟悉Tomcat等应用服务器的配置和优化；
6.具有良好的沟通能力、组织能力及团队协作精神，有较强的分析和解决问题的能力；
加分项： 
1. 有海量大数据开发经验
2. 有Hadoop、Spark、HBase深入源代码分析经验
3. 熟悉机器学习、数据挖掘、分布式计算
4. 基础能力+学习能力特别优秀者

岗位职责：
1.负责大数据平台的产品开发；
2.完成各个模块单元的代码开发与测试；
3.维护平台的运行，迭代并改进产品；
4.持续关注新的技术，学习并利用新兴技术。

任职要求：
1.专业不限
2.1年以上的大数据产品开发与运维经验
3.熟悉主流的大数据产品和数据分析技术并具有相关项目经验
4.掌握对Hadoop/spark体系，并能够针对开发；
5.熟悉数据仓库相关技术，了解基本的数据挖掘原理
6.良好的沟通与表达能力，思路清晰，能够及时的发现问题，并解决问题
7.独立思考的能力，团队合作的精神，积极学习的态度。

从事基于hadoop、storm，spark的数据处理工作，利用java完成数据的分析、汇总和挖掘。基于hive、hbase、kylin实现数据仓库的搭建和离线、在线分析。


职位描述
1,掌握Linux操作系统的配置,管理及优化,能够独立排查及解决操作系统的各类问题；
2,熟悉Hadoop家族相关软件,负责对其进行安装,调试,维护,升级,包括但不限于:HDFS,HBase,Zookeeper,Kafka,Spark,Storm,Hive;
3,熟悉Elastic家族相关软件,负责对齐进行安装,调试,维护,升级,包括但不限于:ElasticSearch,Kibana,Logstash;
4,熟悉数据处理平台相关软件:Redis,mysql,Mongodb;
5,精通至少一种开发语言:Shell/Python/Golang/Java等;
6,在Hadoop/Elastic相关方面有至少1年以上开发或运维经验;
7,计算机相关专业本科以上学历;

职位描述：
1、负责和参与公司大数据基础架构平台的运维，保障数据平台服务的稳定性和可用性；
2、负责和参与自动化运维系统及平台的建设；
3、负责优化运维流程提升运维效率；
4、处理各类异常和故障，确保系统平台的稳定运行。
职位要求：
1、掌握 Linux 操作系统的配置、管理及优化，能够独立排查及解决系统层的各类问题；
2、熟悉Hadoop/HBase/Hive/Spark/Kafka/elasticsearch/flume/Zookeeper等开源项目的安装与调试、升级扩容；
3、至少精通 Perl/Python/Shell脚本语言中的一种；
4、熟悉大数据周边相关的数据库系统，mysql和 mongodb/redis等；
5、运营过Hadoop/HBase/Hive等相关系统，有从事过海量数据分布式处理、各种分布式计算及系统、分布式存储相关的工作经验的优先。

职位描述：

负责大数据部门的数据采集与爬取、解析处理、入库及备份等数据日常工作；
负责分析新的数据需求, 完成数据处理的设计(文档)和实现；
负责数据质量的监控, 根据实际情况设计方案并实现数据质量的提高；
负责数据处理程序设计框架改善, 数据处理性能优化, 系统数据处理的能力提高；
负责和数据架构师协同工作, 完成架构升级更新；
负责参与和带领项目小组完成不同时期项目任务, 达成项目目标；

职位要求：

本科及以上学历, 计算机软件及相关专业；
五年以上工作经验, 三年以上大数据处理相关工作经验；
熟练掌握Java编程, 熟悉/了解shell/python；
熟悉数据库原理, 对数据处理和数据质量有较深认识, 有NoSQL数据库数据处理和数据处理性能优化经验；
熟悉Linux系统及基本操作, 了解AWS相关技术；
熟悉HTTP/HTTPS等网络通信协议, 有网络爬虫相关经验者优先考虑；
有责任心, 学习能力强, 工作积极主动, 思路清晰，擅长沟通；
有团队合作精神有良好的英文沟通能力者，优先考虑。


福利待遇： 
在PatSnap智慧芽，收获的绝不仅仅是一份工作，我们有的都想说给你听： 
1 、 扁平化的几乎不可见的管理：没有上下等级之分，你的想法都会有人重视，可以率性地为自己代言。老板深受美国平等、开放文化影响，所以在这里没有任何拘束，希望跟他待久了能早日像他一样完成逆袭之路。 
2 、 全面贴心福利：在五险一金的基础上，我们增加了商业保险；我们相信身体是革命的本钱所以有年度体检；还有努力就有回报的年终奖；带薪年假、弹性工作制让你多点时间陪陪家人。每年生日的时候会有美女为你送上惊喜和祝福。当你在公司工作满4年开始我们还会每月给你父母支付1000元的工资。 
3 、 总有适合你的狂欢：无论是运动达人们的篮球社、羽毛球社，还是文艺范的吉他社，这里的业余生活不孤单；各种团建活动，或饕餮大餐或来一次说走就走的旅游：看看大海闻闻花香；圣诞狂欢年末盛宴必须邀你赴我们的青春之约。 
4 、 综合提升的培训场：免费量身打造的内外培训，助力你的职业成长之路，即使在这里的宴席散去，依然希望你在哪里都值得骄傲。 
5 、 可视化前景：从2007年创立智慧芽以来，老板立志于在2017年能带领大家到纳斯达克敲钟，如今我们已从2人团队发展为250团队，全球营业额在2014年已达到五千万人民币，每年都是翻番增长。


岗位职责：
1、负责hadoop业务平台日常运营、故障处理等运维工作。
2、负责相关业务的运营数据分析、运营质量分析等运营工作。
3、负责相关业务的运营优化，制定相关运营规划
岗位要求： 
1、大专以上学历，计算机软件或相关专业；
2、3年以上Linux、unix操作系统运维经验；
3、能够胜任7*24小时故障响应及处理；
4、具备linux下编程经验，擅长shell编程者优先；
5、有互联网运营经验者优先；
6、具备良好的沟通技巧和团队合作精神。

1.大专以上学历，计算机或相关专业；2.至少2年以上服务端工作经验；3.熟悉LINUX/UNIX系统 ,至少熟悉以下一种shell,perl,python4.熟悉常用关系型数据库，至少熟悉以下一种NoSQL数据库：HBase/Redis/MongoDB；5.良好的沟通，表达能力，具有团队合作精神，责任心强。6.有过使用Hadoop、Hbase、storm、spark、kafka经验的优先；7.拥有海量数据处理经验优先； 

岗位职责：
1.根据给定算法开发切合用户实际应用场景的数据存储和数据处理程序；
2.实际的调试和优化。
任职要求：
1.有扎实的编程功底、数学功底；
2.熟悉hadoop,hive,spark等大数据生态圈；
3.熟悉网络通讯tcp/ip协议族；
4.有良好的数学基础，理解统计分析模型如主成份分析、聚类分析，对数据挖掘及机器学习相关算法有一定地了解，同时具有相关算法的应用经验；
5.良好的学习能力和沟通能力。

主要职责：
负责和参与公司大数据基础架构平台的运维，保障数据平台服务的稳定性和可用性；
负责和参与超大规模数据存储与计算任务的精细化管理系统的设计，选型和开发；
负责和参与大数据基础架构平台的监控、资源管理、数据流管理；
负责和参与自动化运维系统及平台的建设；
负责和参与基于数据分析的可预测的云平台弹性扩展解决方案。

职位要求：
三年以上计算机软件开发工作经验 ；
掌握Linux操作系统的配置，管理及优化，能够独立排查及解决操作系统层的各类问题；
掌握Hadoop, Kafka, Zookeeper, Hbase, Spark的安装与调试；
至少精通Python, Perl, Ruby, Bash脚本语言中的一种；
有良好的系统性能优化及故障排除能力；
熟悉Puppet, Chef, Ansible等配置管理工具；
熟悉大数据周边相关的数据库系统，关系型数据库和NoSQL。

工作职责：
1、利用MapReduce、Spark、Pig等Hadoop生态技术，构建多维基础数据支撑平台，利用实际数据，解决业务运营过程中的问题，驱动运营决策； 2、利用大数据技术，实现数据分析师设计的挖掘模型，进行分布式算法的研究，以及个性化推荐系统的构建。

任职要求：
1、熟悉Hadoop生态，有Hadoop相关开发经验者优先 ；2、熟悉Scala语法，有Spark相关开发经验者优先 ；3、具有数据挖掘、海量数据处理等相关项目经验者优先 ；4、具备良好的逻辑思维能力，对数据敏感，能够发现关键数据、抓住核心问题 ；5、较强的沟通能力和表达能力，具备良好的团队合作精神和主动沟通意识。

工作年限：2年以上
职位描述：
1、负责hadoop/spark平台技术引进和推广，并能结合用户需求快速落地推广； 
2、负责大数据分析需求设计和开发，包括数据集市、实时分析、数据展示等的开发，并交付生产，确保输出成果； 
3、负责项目成果在公司内的推广应用、培训，以及对外对内合作交流，不断提升公司的技术和应用能力。

招聘要求：
1、计算机科学、应用数学、物理学等相关专业，本科以上学历； 
2、具有2年以上BI/报表相关工作经验，熟练掌握hadoop hive开发，有一定调优经验；
3、能熟练使用sqoop等作为etl工具，有tableau/qlikview开发经验； 
4、有良好的口头和书面表达能力； 
5、良好的结构化问题解决能力。
 
注：以上岗位要求国家统招学历，本科及以上学历需要有学位证书。

岗位职责: 1. 应用机器学习、文本挖掘等技术，对海量学习用户数据进行挖掘，发现学习规则，潜在关系，指导业务发展； 2. Hadoop、Spark环境的搭建、维护及优化； 3. 构建通用的分布式环境下算法平台，包括矩阵计算、变量构造、算法封装，快速支持算法应用； 4. 对海量数据的分析处理和数据仓库的设计开发； 5. 通过海量学习数据实现用户画像、知识图谱、智能推荐、个性化学习； 6. 和业务部门密切配合寻求数据层面的商业价值并组织建设相应的数据标签。  任职要求: 1. 数学、统计、计算机等相关专业本科及以上学历； 2. 2年以上Hadoop开发经验，熟悉Hadoop平台及其相关组件如Hbase、Hive等，熟悉Map/Reduce编程框架； 3. 熟悉Redis，Memcached，Hbase等NOSQL的设计和开发；4. 有linux下的开发和工作经验，精通Python、R、MATLAB、SAS等任意一中或者多种数据编程语言； 5. 熟悉常见的数据挖掘或机器学习算法及相关开发经验； 6. 具备良好的英文资料阅读能力，能够查阅相关文献和专利； 7. 优秀的分析和解决问题的能力，对挑战性问题充满激情； 8. 具备良好的团队合作精神，较强的沟通能力，能承受一定的工作压力。
 

工作职责：
1、负责数据平台的多信息源数据采集、传输、存储、计算、分析和挖掘；
2、管理、优化并维护Hadoop、Spark等集群，保证集群规模持续、稳定；

任职要求：
1、计算机相关专业本科及以上，3年及以上互联网系统或者其他企业应用系统开发相关经验；
2、深入理解Hadoop/HBase/HDFS／Kafka／Sqoop／Zookeeper，并有相关编程经验；
3、有数据统计分析、推荐系统、数据挖掘经验者，有MLLib／mahout使用经验的优先；


多到眼花缭乱的福利：
1、薪资对标BAT，根据面试结果评级而定；
2、人手一台mac，配大屏双显示器；
3、早午餐每月650元补贴；晚餐统一标配，30元起；
4、交通补贴每月200元；
5、年假每年15天，春节假15天；
6、每年妥妥出国游，15年马来西亚，16年泰国，至于明年去哪，来了你就知道了；
7、季度郊区游，想去哪打声招呼；
8、每月团队建设费用，吃喝玩乐你说了算；
9、公司团队来自百度、腾讯、京东、人人、美丽说等一线互联网公司；
10、每年2次加薪机会，只要你努力，就有可能；

岗位职责：
1.负责大数据平台中实时计算和分布式并行计算的程序开发，以及开源技术组件的二次开发
2.负责大数据分析需求设计和开发,参与数据、工具平台相关的功能接口、完成业务功能
3.处理用户海量数据，挖掘用户行为特征，为运营、风控和产品提供参考依据

任职要求：
1.3年以上java开发经验，具备扎实的程序设计基本功和学习能力,掌握scala/python其中一种语言
2.掌握hadoop相关技术框架，熟练用MR进行复杂的数据处理与分析
3.熟悉zookeeper、hive、hbase、spark、ElasticSearch等分布式运算存储框架
4.熟悉Flume，Kafka，Storm、spark streaming等框架的整合，能够熟练整合并进行实时流处理开发
5.数据敏感，逻辑清晰、严谨，理解数据发现价值，数据驱动业务,了解数据仓库；
6.有2年以上的数据挖掘或者互联金融用户行为分析相关工作经验优先


工作职责：1. 负责GPUX86ARM平台上深度学习和数学库的开发和优化；2. 负责语音产品在嵌入式平台（armdsp）的移植加速工作；3. 负责机器学习计算集群和语音相关算法研发；任职资格：1. 本科以上学历，3年以上相关工作经验；2. 精通Intel x86体系结构相关的软件性能优化；3. 熟悉ARMGPU的数学函数库性能优化优先；4. 有高性能计算集群开发经验者优先

岗位描述：
-负责垂直领域的定向爬虫引擎开发及优化工作
-实现数据抓取分析系统的架构设计及核心算法
-负责数据抓取及数据清洗工作
岗位要求：
-热爱技术专研，对爬取技术，探索未知领域有浓厚兴趣
-熟悉HTML，熟悉HTTP协议，熟悉正则表达式网页解析
-熟悉分布式存储的原理，掌握一种或多种分布式存储系统的使用
-熟练掌握Python、Java/Scala、C/C++、PHP、Golang、Javascript中任意一门语言，掌握多门语言者优先
-优先项：对数据敏感，有数据建模、分析和挖掘相关经验优先
-优先项：有node.js开发经验者优先

岗位职责：

负责建设、维护、优化基于Hadoop生态技术的大数据集群和计算框架；
通过提供平台化的计算框架，支撑海量数据分析、数据挖掘、机器学习工作；
负责数据服务平台架构的系统设计和调优；
关注开源技术动态，预研和评测最新的大数据平台和云平台技术，推动集群技术架构持续更新；
协助子公司或者租户设计数据平台架构。    

任职资格：

具有8年以上BI与数据平台项目经验，3年以上数据平台设计与管理经验，具有TB级数据规模的大型项目架构设计经验
精通数据仓库实施方法论、深入了解数据仓库体系、产品体系架构；
具备良好的沟通表达能力，具备良好的团队合作精神和执行能力；
热衷于产品研发和技术创新， 具有很强的学习力并有强烈的责任意识和开放的心态；
有丰富的Hadoop生态相关实施和优化经验（Hadoop/MapReduce/Hive/ HBase/Spark/Storm/Kafka等）；
熟悉 NoSQL数据库、内存数据库 以及搜索引擎，如ElasticSearch（ES）等；
熟悉Oracle/DB2、MySQL等数据库，具有丰富的数据库设计能力，能独立分析需求并设计高并发分布式数据库者优先。


岗位职责:岗位职责：（1）使用 python或C 语言对系统后台业务逻辑进行开发以及维护（2）负责海量用户数据处理平台建设；（3）负责大规模并行机器学习算法研发应用工作；（4）深入信息流推荐业务做数据分析和优化。岗位要求：（1）扎实的数据结构和算法功底，编码强悍；（2）熟悉 Linux 开发环境，熟悉C++，Python；（3）熟悉redis，能使用redis来进行通信和缓存 （4）熟悉DB2，oracle,postgresql等关系型数据库（5）有自然语言处理、机器学习知识背景，有实践经验更佳；（6）有深度学习开发经验（有 RNN/LSTM 模型训练经验优先），熟悉常用深度学习框架（Theano、Tensorflow、Keras 等）（7）有海量数据处理和并行计算开发经验者优先，如 Hadoop、Storm、Spark等；（8）有良好的分析问题和解决问题的能力，对大数据工作充满热情；（9）本科及以上学历，硕士优先，有开源项目开发经验者优先。

工作职责：1、深入研究hadoop、hbase、hive、kafka、storm集群运维相关技术，持续优化服务架构2、负责构建可支撑大规模分布式集群的运维平台、监控报警系统、集群自动部署系统等等3、基于分布式系统集群性能改进、权限管理、功能扩展、故障分析4、负责服务器的安装、调试、维护及更新等工作，保证服务器的稳定运行
任职要求：1、计算机相关专业本科及以上学历，有3年以上运维相关经验2、具有大型应用平台运维经验，有过运维自动化项目经验者优先3. 熟悉Python、shell语言,并且能够熟练使用Python、Shell进行脚本编写4、熟悉hadoop、hbase、hive、kafka、storm中至少一种系统并具备管理，配置，运维经验5、具有很高的分析、解决问题的能力和应变能力，良好的沟通能力6、对Linux/Unix系统有深入的理解，有过具体的系统优化经验

岗位职责：
1、负责大数据团队建设；
2、负责大数据平台系统的稳定；
3、负责大数据项目开发和维护；
4、负责软件系统的功能模块设计及相关过程文档的编写；
5、参与研究大数据技术应用解决方案等；
6、应用模块、WEB、接口开发，编写相关文档；
7、完成DB/REDIS/接口设计文档；
8、完成上级领导交办的其他各项事宜；
任职要求：
1、精通Java/J2EE编程，熟练使用Eclipse/Git/MVN等开发工具，有2年以上开发经验； 2、有良好的代码书写、注释和单元测试习惯； 3、熟练使用oracle数据库，有redis，rabbitMQ，spring，zookeeper等经验者优先； 4、熟悉Linux操作系统，掌握常用的Linux命令，熟悉脚本编程Shell/Python优先；
5、熟练掌握hadoop、hbase、hive、oozie、sqoop等； 6、负责平台数据提取、数据挖掘及数据分析，具有良好的商业敏感度和优秀的数据分析技能，能够解决复杂的商业问题； 7、主动好学，具备良好的沟通合作技巧，较强的责任心及团队合作精神，并有一定领导经验；
8、熟练掌握数据结构，操作系统，数据库原理等。

岗位职责：
1、 参与公司核心机器学习算法设计与开发，成果将应用于滴滴各产品线，提供智能出行解决方案
2、 构建高效率的算法平台，优化产品各环节的乘客体验
岗位要求：
1、 计算机相关专业硕士及以上学历
2、 有数据挖掘，机器学习，最优化理论等相关基础， 熟悉基本算法
3、 编程基础扎实，熟悉算法数据结构，有超过三年以上C++或Python开发经验
4、 有机器学习、数据挖掘等相关项目实际经验者优先
5、 有大数据相关系统，如map-reduce、spark、mpi等经验者优先
6、 踏实勤奋，自我驱动
 

1、负责大数据平台的后端架构和核心代码开发；
2、负责服务器端开发，高并发系统开发；
3、带领3~5人的团队完成独立子系统开发、维护；
4、能够指导新人完成日常工作；
   
任职要求：
1、熟练掌握基础算法
2、精通java基础(IO, 集合框架, 多线程, 网络)
3、熟练掌握java常用的设计模式
4、有类似Neo4j图库的使用经验
5、熟悉linux, 能写脚本完成重复性工作
6、了解搜索引擎基本用法、自然语言处理等
7、有hadoop、spark等分布式开发经验优先

工作职责：
1、负责公司的大数据处理框架的研发设计工作；
2、负责公司产品研发过程中的数据库设计文档的撰写；
3、参与小组的产品设计讨论，共同讨论和设计产品。

任职要求：
1、精通Hadoop以及Hadoop生态圈上的各种应用的几种，如Hbase、Hive，或者分布式数据库Impala等；
2、精通JAVA编程语言，精通面试对象和设计模式，熟悉Linux平台，可以编写代码编程使用Hadoop和基于Hadoop开发大数据处理系统；
3、拥有实际的Hadoop的项目经验；
4、熟悉软件开发流程和配置库的使用，拥有软件开发流程中的代码规范意识、配置管理规范意识、文档撰写规范意识和团队合作沟通交流意识。

我们需要您：
1，参与集团智能大数据平台的架构设计和开发
2，基于业务需求和应用场景，设计和实现集团大数据相关产品
3，为集团视频及其他业务线提供数据支持和服务
您需要：
1，本科或以上学历，计算机专业，3年以上大数据项目开发经验。
2，熟练java,python开发，熟悉常用框架
3，熟练mysql以及数据库设计，熟悉mongo,redis等nosql数据库，熟悉数据仓库基础理论
4，具有Hadoop/Spark开发与应用经验，熟悉hbase、hive、YARN、Storm、zookeeper、kafka等大数据相关工具，并有处理TB级以上数据的项目经验
5，具有独立完成从方案选型设计到原型系统开发实现的能力
6，有较强的沟通表达能力，善于学习，能迅速理解产品需求；有较强的责任心和事业心，能够自我驱动.



工作职责：    
-基于分布式组件定制、研发高稳定、高可靠、高易用的云端大数据产品    
-负责大数据产品服务端设计与研发    
-大数据产品的服务端性能优化及平台组件优化    

职位要求：    
-良好的计算机基础，3年以上工作经验，熟悉java开发    
-熟悉常用算法和数据结构、网络编程、多线程编程技术    
-有大规模分布式系统的设计和工程实现以及集群建设经验    
-至少熟悉Elasticsearch/Cassandra/Spark/Storm/Kafka一种分布式组件并有相关项目经验    
-熟悉spring/tomcat/nginx/netty    
-有大型互联网服务的设计和开发经验者优先    
-开源社区活跃者优先    
-良好的团队合作精神，较强的沟通能力    

1.掌握 Linux 操作系统的配置，管理及优化，能够独立排查及解决系统层的各类问题；
2.熟悉Hadoop/HBase/Hive/Spark/Kafka/Zookeeper等开源项目的安装与调试,升级扩容
3.至少精通 Perl/Python/Shell脚本语言中的一种；
4.熟悉大数据周边相关的数据库系统，mysql和 mongodb/redis等。
PS：运营过Hadoop/HBase/Hive等相关系统，有从事过海量数据分布式处理、各种分布式计算，或者分布式存储、分布式计算系统相关的工作经验的优先；

工作职责：
      1. 负责公司大数据平台的运维，保障平台服务的稳定性和可用性
      2. 处理各类异常和故障，确保平台的稳定运行
      3. 参与公司大数据平台应用及规划，支撑业务需求增长
 
岗位要求：
      1. 大学本科及以上学历，计算机或者相关专业；
      2. 精通Linux操作系统，能够独立排查及解决操作系统层的各类问题；精通一门以上脚本语言(shell / perl / python等)
      3. 一年以上大数据平台运维经验 。掌握Hadoop, Hbase, Hive/Impala, Spark, Yarn, Kafka, Flume等组件的安装、配置、使用和优化；熟悉 CDH 者优先；
      4. 工作中胆大心细，具有强烈的责任心与主动性，对所负责工作有owner意识；具备良好的沟通、学习能力及团队合作精神，能承担一定工作压力，有较强的独立分析和解决问题的能力。
      5. 具有集群运维经验，以及大负载下的容量评估、问题定位、架构优化等能力优先；有分布式系统（计算/存储）开发经验优先。

岗位职责：
负责浏览器用户画像数据挖掘工作，主要工作内容包括用户标签体系建设、用户分群、多业务画像融合、画像迁移等。
负责海量用户数据的管理，为数据分析、挖掘等提供强有力的支撑
负责浏览器画像数据相关系统（数据流系统和在线应用系统）的开发，建立数据灰度、ABTest能力。

岗位要求：
硕士及以上学历，机器学习、自然语言处理、数据挖掘或相关专业；
3年以上的工作经验，熟悉数理统计、数据分析、数据挖掘，熟知常用的推荐算法；
熟悉C++ &amp; Spark &amp; Python开发，对数据结构和算法设计有较为深刻的理解；
熟悉大规模数据挖掘、机器学习、自然语言处理、分布式计算中的一项或多项技术，并具有实际工作经验；
有较强的技术选型及规划能力、较好的沟通能力、积极主动，愿意接受挑战；
具有海量数据处理、并行计算、推荐系统或大数据方向相关背景和工作经验优先。

岗位职责：
1. 参与数据收集与存储；
2. 对数据进行特征值提取与分析；
3. 支撑大数据处理过程中所产生的性能瓶颈；
4. 依据可视化需要按照维度条件对行为数据进行二次汇聚处理；
5. 具备一定的沟通、协调能力和抗压能力。

任职要求：
1 3年以上的互联网领域研发经验，Java和Python两种开发语言任意会一种；
2. 熟悉基于Linux操作系统的研发流程，对主流开源技术有着高度的研究热情；
3. 利用Hadoop或Spark架设过集群，并基于两者做过实际研发，研读过他们的底层原理性代码优先；
4. 熟悉Redis、Hive、MongoDB、Dubbo、Druid、Solr、Storm等互联网热点技术，研读过这些开源技术的代码优先；
5. 熟悉并使用过MySQL、DB2、Oracle、SQL Server等任意两种以上的数据库，熟悉并掌握SVN、Git、Maven等相关主流管控工具；
6. 熟悉使用科大讯飞、百度等相关公司API，如科大讯飞的语音处理、百度的语音处理、视频处理等；
7. 对Github中主流的Java、Python开源技术框架应用比较熟悉并有实战。

岗位职责： 
1、对大规模在线终端实时的数据收集、存储、计算。 
2、在无线数据服务、数据价值挖掘的技术实现； 
3、根据公司产品和无线业务发展特点，研究无线应用相关的大数据产品和技术发展方向。
4、.针对新人、普通开发人员进行有效辅导，帮助其快速成长

岗位要求： 
1、5年以上从事软件开发工作经验，2年以上大数据系统分析、设计和实施经验； 
2、拥有2年以上Hadoop开发设计和实施经验，对Hadoop相关的技术和组件（HDFS，MR，Hase，Hive，Spark，Storm等）有全面深入了解，能够熟练安装、配置、部署和优化大型Hadoop集群系统。 
3. 熟悉整个大数据的完整处理流程，包括数据的采集、清洗、预处理、存储、计算。
4、工作责任心强，具备良好的团队合作精神，良好的沟通及协作能力。 

岗位职责：
1、参与公司大数据平台架构、技术发展战略规划及产品体系规划；
2、参与公司大数据平台的核心代码开发，技术路线研究工作；
3、负责公司核心集群搭建，保证其高可用和稳定性；
4、跟进了解开源社区Hadoop的功能，及时了解新的技术架构和功能特性，有针对性地应用于公司大数据业务。
任职要求：
 1、正规院校计算机、数学相关专业本科及以上学历；
 2、2年及以上大数据平台、分布式应用开发经验；
 3、精通java，具备Hadoop/Hbase/Storm/Hive/Zookeeper/Spark等集群搭建、优化经验；
 4、具备MR、hive UDF、实时计算等实际开发经验；
 5、具备搜索引擎、电子商务平台、云计算平台、个性化推荐引擎开发经验者优先；
6、强烈的主动性与工作责任心，对所负责工作有owner意识，并能自我驱动不断成长。

岗位职责：
1、负责公司的大数据处理框架的研发设计工作；
2、负责公司产品研发过程中的数据库设计文档的撰写；
3、参与小组的产品设计讨论，共同讨论和设计产品。
任职要求：
1、精通Hadoop以及Hadoop生态圈上的各种应用的几种，如Hbase、Hive，或者分布式数据库Impala等；
2、精通JAVA编程语言，精通面向对象和设计模式，熟悉Linux平台，可以编写代码编程使用Hadoop和基于Hadoop开发大数据处理系统；
3、拥有实际的Hadoop的项目经验；
4、熟悉软件开发流程和配置库的使用，拥有软件开发流程中的代码规范意识、配置管理规范意识、文档撰写规范意识和团队合作沟通交流意识。

【项目介绍】国内第二大互联网产品，输入法行业的绝对领先者。我们一方面不断优化用户表达和获取信息路径上的体验；另一方面持续探索未来用户在输入形式上的各种可能性，继续引领移动互联时代的输入方式；追求极致，致力于给用户提供更炫酷、便捷的输入体验，让输入玩出新花样，欢迎加入这个团队，与我们创造更多可能。

【特别提示 】搜狗欢迎专情的你，最多投递两个职位，请谨慎投递
【岗位职责】1.负责支持搜狗手机输入法的数据统计和分析工作，通过数据提升产品品质；2.理解数据的产品应用场景逻辑，通过统计方法和通用分布式框架工具语言如hadoop，不断加强数据服务质量；3.负责数据清洗、转换、建模等工作,对海量用户行为数据进行离线和实时处理；4.参与数据、工具平台相关的功能接口、数据接口开发，完成业务功能；

任职条件
1. 计算机、统计相关专业，大学本科以上， 具有独立支持产品数据分析的工程经验；2. 精通数据结构和基础算法，精通Linux平台下Java编程；3. 灵活运用Linux下各种文本处理方法，如Python、awk、shell；4. 擅长逻辑分析，对数据敏感，具备较强的数据抽象能力，有超强责任心和工作热情；

部门概述
搜狗公司是中国互联网领先的搜索，客户端和移动产品及服务提供商。截至2013年9月底，搜狗公司总用户数达4.5亿，在用户规模上，搜狗已成为中国第三大互联网公司。
搜狗是一家用创新保持增长的技术性公司，同时具备"搜索"和"客户端"的全技术能力。搜狗公司非常重视技术型人才，目前，搜狗正式员工人数超过2,100人，其中技术员工比例超过82%。而且研究生及博士以上学历所占比例也达到了41.9%；截至目前，搜狗持有的技术专利居行业第三。搜狗一直以"让网民表达和获取信息更简单"为使命，在拥有深厚技术底蕴的同时，不断追求产品创新，已成为快速发展的中国互联网领先企业。

1.负责平台及相关产品新需求数据库设计、开发及维护工作；
2.负责核心业务系统的设计、开发工作，并确保按期完成与线上稳定性；
3.根据业务需要，对新技术的调研，及于第三方接口的接入工作；
4.完善和优化现有JAVA开发平台框架，编写核心开发框架程序。
5.设计及优化API，为更多计算业务提供支持
6.负责日常同产品、运营、测试等相关部门，平台业务沟通协调工作；
7.负责代码review，从产品发展和技术角度对产品提出优化方案。
8.负责研发代码的自测。

【薪酬福利】
16薪+免费下午茶  + 入职配备爱疯手机 + 每月话费套餐+ 每年一次加薪机会，年薪平均涨幅20%以上 + 个人私家车上班享有车补1000元/月 +差异化购买公积金政策（未来购房还可以享有更低贷款利率）+员工互助金政策（员工意外伤害保障）

【岗位职责】
1、负责公司数据服务类产品的规划、需求分析和产品设计；2、产品全生命周期跟进，协调各种资源保证产品顺利发展；3、关注房地产大数据应用相关方向的前沿研究，并将相关成果快速产品化、商品化,将创新推向用户；4、完成其他领导安排的任务。【岗位要求】
1、基本要求：本科，2年以上产品设计，能够独产承担产品规划工作；2、工作经验：最好有互联网数据产品从策划到上线运营的经验；有大数据处理相关经验以及良好的逻辑表达和抗压能力尤佳；
3、知识结构：具备C端产品的知识；
4、加分项：对大数据应用有所了解


【看产品】  家家顺房产网www.jjshome.com定位于“E2E模式”全国性人居生活服务平台，为用户提供从线上找房到线下交易全链条服务；以房产交易为入口，切入金融、社区生活服务等领域，致力于为用户提供高效、便捷的生活服务体验。  
集团网址：http://home.jjshome.com

工作地点：福田八卦岭八卦路
交通便利：1、距9号地铁红岭北站和7号地铁八卦岭站步行5分钟
      2、公交枢纽：泥岗村、八卦路

岗位职责：
1、负责基于Spark技术的海量数据的处理、分析、统计、挖掘工作；
2、基于Spark框架的数据仓库的设计，开发，维护；
3、根据需求使用Spark Streaming和Spark SQL进行数据处理、查询、统计等工作。

岗位要求：
1、本科及以上学历，软件工程、计算机等相关专业；
2、熟悉RDD/DataFrame编程，对Spark体系结构、运行机制有深入研究，熟悉源码；
3、熟悉Spark相关技术；
4、熟悉linux、shell脚本或python脚本编程；
5、熟悉Spark Streaming和Spark SQL，有过程序开发经验；
6、具有良好的Trouble Shooting能力；
7、能够用python开发数据算法，熟悉python算法库的优先；
8、具有海量数据系统开发经验，且在开源社群活跃并有积极贡献者优先考虑。



任职要求：

1.精通python／java编码，并能熟练使用python。
2.具有3年以上大型系统编码经验（Linux），熟悉常用设计模式。
3.熟悉大数据处理业务。
4.熟悉mysql/mangoDB等常用数据库，并了解分布式数据库与分布式文件系统。
5.具有扎实过硬的后台开发能力。
6.熟悉hadoop平台。

福利：
1.为员工提供完善的福利（六险一金、节日礼物、员工年假、优秀员工奖励（旅游、现金、金币等）
2.员工生日会、户外拓展、活动经费、年度体检、欢乐下午茶、公司/部门活动、足球、羽毛球活动等）
3.可根据员工具体情况实行工作时间弹性制安排
4.同时提供多样化的基础技能培训和专业拓展培训，通过系统的企业培训制度助力每位员工的个人成长与职业发展

参与机构客户新一代数据仓库的建模、数据整合和后期业务代码优化等工作：
1. 数据仓库项目前期业务的梳理，协助建模工程师建模。
2. 新一代数据仓库平台（如Greenplum\Hadoop）的搭建、扩容、调整和代码优化以及后期巡检。
3. 使用主流ETL工具实现整个数据整合过程，包括数据的抽取、转换、装载。

岗位要求:
1. 计算机或相关专业本科及以上学历，两年以上工作经验。 
2. 熟悉PostGreSQL\Oracle\Teardata等传统数据库中的一种；对数据治理、数据清洗等有深刻认识和实战经验，有数据建模、数据分析经验者优先。
3. 熟悉SQL，有一定的SQL性能优化经验，能够根据业务逻辑熟练的编写函数或存储过程。
4.掌握脚本语言Shell/Python/Perl之一，有java基础者优先。
5. 熟悉新一代大数据技术平台Greenplum\Hadoop之一者优先。
6.业务理解力强，对数据、新技术敏感，对云计算、大数据技术充满热情。
7.积极乐观、诚信、有责任心；具备强烈的进取心、求知欲及团队合作精神。

工作内容
1、理解系统的业务需求，主导重大项目的架构设计和核心模块设计；
2、负责大数据相关数据架构规划、数据建模、数据库设计以及大数据产品研发工作，并为应用开发团队提供技术支持、模型分析；
3、识别关键能力与角色，构建集成交付流程并指导大数据系统集成交付团队的组建；
4、主导技术难题攻关，保证项目按期高质量交付；
5、负责核心功能的架构与代码模板编写，开发与维护系统公用核心模块；
6、进行系统技术平台的选型和评估新技术的可行性；
7、识别出技术方向、产品组件、技术培训等需求，并组织实施；
8、根据业界最佳实践、项目实施经验等优化系统集成交付流程与方法论；
9、组织并负责大数据相关方案评审；
10、为开发人员提供技术指导及帮助；
职位要求
1、6年以上行业软件设计开发经验，具有丰富的行业解决方案经验；
2、熟悉云计算开发框架，Hadoop、Hive、HBase、Storm、Kafka等大数据主流工具和技术，有海量数据或海量并发的大型项目架构设计经验；
3、扎实的Java（或.NET、PHP）和数据库技术基础，精通Web应用相关技术，熟悉分布式、多线程、异步处理、消息处理、搜索等中间件产品和工作机制；
4、丰富的软件开发经验，深入理解各种框架工作原理，有框架开发/定制开发经验者优先考虑；
5、具有出色的抽象设计能力，思路清晰，善于思考，能独立分析和解决问题。
6、熟悉行业标准，如：TMF eTOM, ITIL，TMF SID等，并有实践经验；
7、技术视野开阔，学习能力好。
8、性格开朗，系统思维能力好，善于沟通，具备良好的项目管理能力。

工作职责：
负责数据平台功展现、应用层面设计开发工作。
岗位要求：
1、拥有大数据平台开发经验；
2、能够搭建hadoop/spark集群环境；
3、熟悉Hadoop\Hbase\Spark\Storm\Hive等相关数据平台；
4、有JAVA开发经验，有python或scala开发经验者优先考虑；
5、熟悉常见的关系型数据库，mysql/Oracle/SqlServer，有BI开发经验者优先考虑；
6、熟练使用linux，熟悉Linux api人员优先考虑。


熟悉Java，熟悉Scala、Python其中之一；
熟悉IO机制、网络通讯、多线程等基础知识框架，熟悉缓存、消息队列、索引查询等机制；
熟悉Spark SQL、Streaming等；
熟悉Hadoop、Storm等，对其中1个或多个分布式系统有应用经验；
熟悉HBase、Redis等；
保持大数据行业相关技术持续学习的热情，了解行业最新技术动态；
熟悉MPI、TBB、CUDA等高性能计算者优先；
具有良好的沟通能力和协调能力，优秀的学习能力，具备良好的团队精神，能承受工作压力，富有进取心 

工作职责：
1、现有大数据平台（离线、实时）的持续开发、规划升级和性能调优；
2、帮助业务方合理、正确使用平台计算和存储资源，快速响应其提出的相关业务需求；
3、深入理解公司公司业务特点，规划如何利用大数据为公司新零售战略赋能；
4、利用自身优势，不断为团队注入新活力，帮助新人成长，进一步提升团队战斗力；
5、数据建模与分析，搭建海量、分布式、大规模机器学习平台；
岗位要求：
1、五年以上大数据相关工作经验，扎实的数据挖掘、机器学习和统计学相关理论知识；
2、精通Hadoop相关技术，包括但不限于HDFS/YARN/Hive/Spark/Impala/Kudu/Kafka/HBase等；
3、熟悉分布式相关算法和理论，具有大规模分布式系统架构经验和实现案例；
4、有TensorFlow/Theano/Keras/Caffe/Torch等深度学习工具经验优先；
5、有饱满的工作热情，良好的团队协作意识，时刻对新技术保持好奇心，紧跟技术发展前沿，对开源社区有所贡献者优先；

职位描述：
1、参与超大规模数据快速查询系统的架构设计和开发；
2、大规模数据挖掘和机器学习算法的实现和维护；
3、在线和离线海量数据分析平台的开发；
4、研究大数据前沿技术，提升系统的运维效率；
5、实现大数据基础架构平台（Hadoop/Spark/MPP DB）的系统设计、脚本开发、维护等工作

任职要求：
1、5年以上开发经验，3年以上大数据开发经验，至少熟悉一种编程语言（Python/Java/Scala）；
2、能够独立搭建企业级大数据的环境、包括hadoop、hive、spark和yarn等开源框架;熟悉分布式系统概念、架构，有大规模分布式系统设计、实现、部署等经验
3、熟悉HDFS/HBase/Hive/SPARK/MapReduce，掌握SPARK （STREAMING）/Mapreduce程序开发；
4、熟悉hadoop平台下的数据ETL；
5、强烈的责任心与求知欲，开源社区的活跃贡献者优先；
6、有较强的书面与口头沟通表达能力，独立分析、解决问题的能力
7、有团队合作意识，做事积极主动，善于沟通表达协作
8、能适应出差
9、电信行业或者通信领域项目背景者优先

学历：本科及以上
专业：计算机或相关专业
年限：四年以上Java大数据开发经验
经验：
1、有较强的责任心并具有一定的抗压能力，具备良好的团队合作精神，较强的沟通协调能力；
2、善于学习，对业务有浓厚的兴趣，能够快速理解业务，能够独立与业务人员进行有效沟通；
3、熟悉Java/Scala程序开发(至少一种)，熟悉Linux/Unix开发环境，具有扎实的j2se基础，注重代码规范、代码执行效率，善用设计模式；
4、熟悉常用开源分布式系统，Hadoop/Hive/Spark/Yarn，熟练掌握主流Spark框架，熟悉主流NoSQL数据库；
5、熟悉Hadoop、流式计算、任务协同管理、YARN资源管理、多线程并发及通讯编程；
6、熟悉数据仓库原理，熟悉SQL语言。
7、熟悉机器学习常用相关开源框架，如Mahout、MLlib、Trident等优先；


职位描述：
1.掌握 Linux 操作系统的配置，管理及优化，能够独立排查及解决系统层的各类问题；
2.熟悉Hadoop/HBase/Hive/Spark/Kafka/Zookeeper等开源项目的安装与调试,升级扩容
3.至少精通 Perl/Python/Shell脚本语言中的一种；
4.熟悉大数据周边相关的数据库系统，mysql和 mongodb/redis等。
PS：运营过Hadoop/HBase/Hive等相关系统，有从事过海量数据分布式处理、各种分布式计算，或者分布式存储、分布式计算系统相关的工作经验的优先；

主要职责：

负责大数据平台的架构审核、业务监控、持续交付、应急响应、容量规划等；
为线上服务高效稳定运行负责，支撑业务和数据量的快速扩张；
深入理解大数据平台架构，发现并解决重大故障及性能瓶颈，打造一流的大数据平台；
具有持续创新和优化能力，提升产品整体质量，改善用户体验，控制系统成本。

职位要求：

负责全公司HADOOP集群的规划、管理工作并保证集群的高可靠；
深度优化HADOOP平台MR作业/计算框架/存储技术，提升集群吞吐并降低成本；
了解Hadoop、Hbase、Kafka、Hive、Spark等组件的工作原理，并有2年以上Hadoop生态系统运维经验；
熟悉HADOOP生态，并能对平台CPU/MEM/IO/网络/调度中一个或多个方面的性能调优；
熟练掌握shell/php/python/perl中的任意一门语言，能够快速理解JAVA代码；
强烈责任感、 缜密的逻辑思维能力，善于用数据说话，具备良好的项目管理及执行能力；
本科以上学历，有至少2年以上互联网公司的从业经验。

具备如下实际项目经验者优先考虑：

有大型互联网公司HADOOP开发、测试、运维、应用工作经验者，熟悉源码尤佳；
熟悉HADOOP业界动态，技术极客尤佳。


岗位职责：
1.负责大数据采集、存储、计算、分析等场景的通用架构设计和开发；
2.负责流式数据的实时传递、清洗、转换和计算（实时统计、分析等）的设计和开发；
3.负责大数据中间件的设计和开发；
4.负责以上各种架构平台及相关基础技术组件的稳定性保障及源码级的bugfix。

任职要求：
1.计算机相关专业，1年以上工作经验，具有大型系统的技术架构/应用架构/数据架构的的自主研发经验；
2.使用Java，熟悉掌握常用的Java类库及框架，如多线程、并发处理、I/O与网络通讯，Velocity、Spring、Hibernate、iBatis等，对SOA模式有较深的理解；
3.对Java虚拟机有了解，有运行态JVM分析及调优的实际经验，有Linux下的开发或运行环境操作经验；
4.熟悉并使用过各种大数据相关框架或组件优先，如Kafka、Storm/JStorm、Hadoop/Spark、Hive、HBase等，特别是有Spark实战经验/海量数据处理经验者优先；
5.具有良好的产品Sense，从商业需求到技术实现的映射能力，能够开发创新，以实际的分析方法去抽象分解复杂的业务需求问题；
6.具有良好的沟通、团队协作、计划和主动性思考的能力，在互联网或大数据业界有一定影响力公司的工作经验者优先。

岗位职责：
1、专注于公司各产品线产生的海量数据，如何在分布式文件系统上高效、经济的存储；
2、与具体产品对接，通过分布式任务，对数据进行各维度的加工。
任职资格：
1、懂得如何分层、分步骤地表达复杂观点；
2、您需要有计算机、软件等相关专业的本科以上学历。三年以上的研发工作经历（在校生/毕业生除外)；
3、至少具备下述四个方向（之一）的研究与工程经历：机器学习、个性化推荐、自然语言处理、模式识别；
4、熟练使用下述一种语言：Python、C/C++、C#。能熟练使用数据库进行开发Mysql，SQL Server，Oracle等；
5、大数据分析与研发经历者优先。熟悉Hadoop、NoSQL数据库、GFS系统者优先；
6、熟悉linux操作系统，熟悉python，shell脚本语言中一种；
7、热爱技术，对技术有不懈的追求，喜欢研究开源代码。

附注：
1、有数据分析经验（如误差分析、线性回归、参数估计等）的候选者优先考虑；
2、有WLAN建设经验；
3、熟悉Linux的安装、使用、配置，掌握LINUX系统的优先考虑。

岗位职责：
1、亲身参与业界领先的云计算、大数据平台和应用软件产品的开发，打造世界一流的云计算大数据产品线；
2、充分发挥自己专业技能，高质量、高效率的完成产品各阶段的设计和开发任务；
3、利用业界最新的技术和工具，不断优化云和大数据系统的性能和承载能力，攻克技术难关。
岗位要求：
1、具备良好的学习能力，有钻研精神，热爱互联网行业；
2、具备良好的编码能力，具有规范化，标准化的代码编写习惯；
3、对云计算、大数据、互联网的新技术、新知识、新工具有敏锐的洞察力和执着的热爱；
4、具备良好的技术文档输出能力；
5、性格开朗，积极进取，善于沟通，抗压力强，工作细致有责任心，有合作共赢的团队意识。


岗位职责:1.参与公司业务数据源整合、数据流水线、数据仓库／集市的建设。
任职资格:1.具有很强的自我驱动力，对技术有热情。且具有很强的学习能力，能快速掌握新的技术。2.基础知识（数据结构与算法、多线程、数据库、网络等）扎实。 熟悉Java开发，会Scala更佳。3.有2年以上Hadop生态圈技术相关的工作经验。4.熟悉Kafka、HBase、Impala、Spark、Kylin这些框架／平台／引擎当中的两个以上。有数据仓库方面经验的优先。

职位描述：
1、负责业务相关数据指标的抽取、转换、加载，数据维护相关工作；
2、数据质量控制和元数据整合相关工作；
3、分析业务需求、数据建模以及数据仓库应用产品的设计、开发；
4、制定数据质量维护制度、流程，数据质量例行检查；
任职要求：
1、有大型数据仓库或数据挖掘项目实施经验，精通数据仓库方法论和ETL架构，理解元数据管理；
2、至少熟悉MySQL、Oracle其中一种数据库，有动手操作能力；
3、熟悉Linux平台，掌握Shell、Python至少一种脚本；
4、熟悉SQL/MapReduce/Spark/Storm等任何一种大数据计算工具的编程
5、熟悉大数据调度系统的架构设计和开发实现
6、了解常用算法，有推荐系统/知识图谱/反欺诈等任何一种实际的算法工程应用的研发经验
7、熟悉Python，熟悉scipy/numpy/scikit-learn/matplotlib等模块的应用
8、熟悉数据可视化的基本方法，有数据可视化的开发经验
8、对数据敏感，具有良好的逻辑分析；
9、喜欢创业氛围、责任心强、良好的对外沟通和团队协作能力

任职要求：
1.本科及以上学历，计算机等相关专业毕业；
2.对hadoop、hive、hbase、MapReduce、Storm、spark、redis一种或者几种有一定的理解，并能够独立安装部署系统，能独立分析解决集群的运行故障；
3.熟练使用java语言，两年以上Java开发工作经验，熟悉Jvm运行机制及内存管理者优先；
4.熟悉Linux操作系统，对shell有一定了解
5.对数据结构和算法设计有较为深刻的理解，有自然语言处 理、搜索引擎、文本分类等算法经验者优先。
岗位职责：
1、负责大数据产品线的设计和开发工作； 2、参与需求分析和市场分析等工作，参与项目的售前技术支持等。


岗位职责：1、参与大数据分析平台的规划和建设；2、协助相关业务数据服务接口的制定；；3、负责大数据处理分析平台的服务框架的设计与开发。任职要求：1、计算机相关专业本科以上学历；2、熟练应用 python、java、scala 等任意一门语言；3、熟练使用hadoop,hbase,spark等系统框架完成数据处理；4、了解 mysql，redis，mongodb 数据库的常规使用；5、有计算广告、推荐系统或搜索引擎领域工作经验者优先；6、有网络编程经验，精通 TCP／IP 协议，了解系统网络、负责过线上服务，或互联网公司背景。

岗位职责：
1.  负责携程大数据系统平台开发与管理
2.  负责大数据开发和查询平台建设，包括数据传输，调度，主数据，质量中心以及报表和Adhoc查询系统等
3.  助力携程数据化运营业务，构建丰富多样的大数据应用
 
岗位要求：
1.  良好的java编程能力，熟悉java开发工具和调试工具
2.  熟悉Spring MVC，Hibernate / Mybatis，Bootstrap，AngularJS2等Web开发的前后端框架和技术，有实际项目的经验
3.  熟悉linux系统，熟练使用shell/python/perl 脚本处理工具
4.  熟悉hadoop / hive / spark / Storm等开源大数据系统的原理和使用
5.  有良好的产品思维，能够根据用户需要设计简单，易用的产品
6.  有良好的逻辑思维及解决问题的能力

岗位职责：
1、参与海量数据收集处理、分析，分布式系统框架、大数据基础架构等的设计、架构和开发工作。
2、搭建高可用高扩展高性能的大数据处理系统、开发和维护大数据相关基础设施。
3、负责统计、数据分析等相关各类算法的计算框架及架构的设计和工程实现。
任职要求：

1、全日制本科及以上学历，计算机相关专业。
2、有扎实的java基础和算法基础，编程思维开放活跃。
3、熟悉Linux，并至少掌握shell、Scala、Python等其中一门开发语言。
4、5年及以上java开发经验，3年及以上Hadoop开发与应用经验，大并发的分布式系统开发设计经验。
5、熟悉Hadoop、MapReduce、Storm、Spark、Pig、Sqoop、HBase、Hive、ElasticSearch等主流大数据技术的原理及技术，并有相关的源码阅读经验。
6、熟悉日志收集处理涉及的各种主流组件，如：Kafka、Flume、Scribe等。
7、对数据敏感，善于发现数据中的潜在规律，有大数据分析、架构设计、深度学习者优先。
8、工作有计划性，责任心和执行能力强，具备高度的责任心和团队精神。
9、具有良好的语言表达和文档撰写能力，能够熟练阅读英文文档和论文，可以快速学习和掌握新的方法和技术。



薪酬福利：1、 工作时间：5天7.5小时工作制（周末双休）2、 各类假期：带薪年假（入职转正即可享受）、带薪病假、婚假、产假、国家法定假期，一样都不能少；3、完善的福利：五险一金+额外高额商业综合医疗保险（员工本人及配偶子女均可享受）；
4、薪酬待遇：有竞争力的薪酬福利待遇体系，丰厚的年终奖金等着你来拿；5、公司活动：不定期举办各类员工活动，月度生日会、节日活动、每周花样文体活动等着你来参加；
6、工作环境：地铁上盖物业，交通便捷。7、完善的培训发展体系：各种入职培训、各类专业培训、管理类培训、外部培训，以及完善的员工职业发展通道；
8、各种福利包：新婚贺礼、生育贺礼、节日大礼包、生日礼品、老板红包，各种暖心大礼包不停发；
9、吃货福利：新人欢迎餐、每周花样下午茶（蛋糕、甜点、水果、饮料）等。

1、 具有BI系统开发经验2、精通SQL的计算与调优，并具有严密的逻辑分析能力3、熟悉主流的Hadoop处理技术，有Hive、Spark SQL的项目开发经验（至少半年）4、熟悉Linux操作系统操作，具有Shell、Python（非必需）程序开发经验5、具有较强的文档撰写能力。

岗位职责:1.广告投放引擎系统架构设计及开发； 2.支撑平台的研发；3.新技术的预研和应用。
任职资格:1.基础扎实,熟练掌握JAVA语言; 有互联网公司工作经验，有1-2年hadoop等相关大数据工具开发经验；2.熟悉TCP/IP、HTTP等网络协议，有大访问量高压力程序开发经验；3.熟练掌握常用数据结构和算法，并能灵活运用；4.能承担较大工作压力，有较强独立分析，解决问题的能力；5.逻辑思维清晰，良好的文字和语言沟通表达能力，有良好的团队合作精神。

工作职责：
1、负责渠道系统个险风险项目数据挖掘开发工作
2、负责渠道系统常规需求大数据应用开发工作
3、负责制定项目计划并能够按计划完成任务
4、负责系统架构设计和优化，以及性能调优
5、提升团队大数据应用开发能力，评估大数据应用使用场景
应聘要求：
学位、专业：
计算机相关专业本科及以上学历
工作经验：
3年以上hadoop的应用开发经验，至少一个企业级数据仓库项目开发经验或者大数据处理项目经验
专业技能：
良好的编程习惯和开发能力，精通Java等开发语言
基本能力：
熟悉常用开源分布式系统，Hadoop/Hive/Spark/Yarn，精通源代码尤佳
其他：
3年以上mysql, oracle等数据库经验，具备优秀的SQL编写和调优能力
 
有意者请将个人简历、学历、学位及身份证正反面扫描件，近期生活彩照，一并发送到以下邮箱。
 


职位描述：
1、带领本地项目团队准时、优质、高效地完成产品交付与BUG修改工作；
2、项目整体管理，包括项目进度、质量、成本、风险等全过程管理；
3、组织参与方案讨论和需求调研、产品设计等工作；
4、负责本地各项目客户的对接与沟通协调工作；
5、本岗位涉及省内地市驻点支撑；
任职要求：
1、有3年以上java/J2EE软件项目开发经验，2年以上项目经理或核心研发工作经验，5人以上团队开发经验；
2、熟悉大数据相关技术原理，具备一定的研发能力，对hadoop，java，python等语言有一定了解和开发能力；
3、具备较强的沟通协调能力、执行能力和抗压能力，思维清晰，有良好的职业道德及团队合作精神；
4、具备技术方案的编写和宣讲能力，具有较强的抗压能力和学习能力；
5、在可扩展、高性能，高并发，高稳定性系统设计、开发和调优方面有实际经验；
6、具有海量数据处理、数据挖掘、数据分析相关项目的工作经验者优先；

工作职责：
1.  负责构建数据仓库（设计、开发、维护），大数据处理架构；
2.  负责基于阿里云数加、Hadoop、Spark等技术的海量数据自动化分析处理和统计工作。
 
职位要求：
1.  有海量数据分析和统计相关经验；
2.  精通Hadoop、Hive、Hbase、MapReduce等常见大数据框架，有三年以上的大数据经验；
3.  精通Scala，有自动化脚本编写经验；
4.  有较强的动手能力及学习能力，熟悉Java、Python；
5.  有数据可视化相关经验或推荐系统相关经验的优先；
6.  熟悉Linux操作系统，熟悉脚本编程(Shell、Python其中一种）；
7.  具备良好的团队合作及较强的沟通能力，对解决挑战型问题充满激情。

工作内容：
1、从事部门大数据相关的平台实施、运维、培训等工作。               2、完成对事业部各智慧城市IOC项目的支援和建设。                   3、大数据支撑平台相关产品的开发、测试。

任职资格：
1、必备知识：本科学历，计算机或者相关专业。对Linux SQL基础有很强的掌握。  
2、 计算机技术：熟悉hadoop体系架构，熟悉 hbase、hive、zookeeper等工作原理；熟练掌握Hive，并有相当优化经验，理解 Hbase 体系架构，并有相当开发经验；熟练Java编程语言，深入理解面向对象编程思想；熟悉某种关系型数据库（oracle、Mysql）；.熟练掌握linux/UNIX shell 、熟悉(Perl/python/shell)任意一种脚本语言；
3、工作经验：至少3年以上工作经验，1-3年大数据经验。至少1年以上真实的Hadoop平台使用经验，必须有hadoop集群搭建实际经验；
4、 个人素质要求：目光长远、态度诚恳、岗位有稳定性，能够长期培养、具备很强的自学能力、承压能力强、接受出差支援项目等工作。对coding有浓厚的兴趣并有明确职业规划，优秀的学习能力和团队沟通协作能力，对新技术有浓厚兴趣并有钻研精神。

岗位职责：
1.参与公司大数据产品的架构设计，负责大数据清洗、存储、处理、分析等场景的架构设计和开发
2.参与平台级通用大数据中间件的评审和开发，基于公司大数据平台进行应用逻辑开发，并对具体业务场景下复杂海量数据应用的各项性能进行优化
3.培养并带领初级工程师，进行技术设计、代码编写的指导和评审

任职要求：
五年或以上工作经验，两年以上大数据相关工作经验，熟悉Hadoop生态，具有大型系统的架构设计经验。
- 精通Java/Scala中的一种或多种语言，熟练掌握多线程、并发处理、I/O与网络通讯相关原理及类库，熟练掌握多种设计模式。
1.精通Hadoop大数据平台框架，精通HDFS系统原理，熟悉Spark、Hive、HBase、Impala、Storm等组件的应用设计及开发，能够独立完成Hadoop环境的搭建及管理。
2.对Java虚拟机有较深了解，**有运行态JVM分析及调优经验者优先**。
- 熟悉关系型数据库（SQL Server\Oracle\Mysql\Postgresql），可熟练编写SQL语句及存储过程，了解SQL性能调优。**有NoSQL（Redis、MongoDB）经验者优先**。
- 有良好的编码习惯和测试意识，能遵循开发流程、文档规范和编码规范，能独立学习技术并解决问题，对新技术有钻研精神**有长期维护的技术博客者优先**。
- 有良好的职业素养和沟通交流能力，具有优秀的团队意识和合作精神**有小团队管理经验者优先

我们是处于快速发展期的行业独角兽，A轮融资2.04亿创行业之最，目前正在扩充核心技术和产品团队，急需最高端的瓜子仁和我们一起勇攀高峰，创造奇迹。这里有最顶尖的技术团队、最好的个人发展平台以及给力高薪，足够优秀的公司需要足够优秀的你，期待你的加入。
职位描述：
岗位职责：
1.负责hadoop平台上的数据处理；
2.使用spark、mapreduce进行数据处理
任职要求：
1.熟悉Hadoop、HBase、Hive、Spark、Mapreduce
2.对数据结构、算法有深刻理解
3.精通Java、Python
4.熟悉linux开发环境
5.熟悉hadoop、hbase、spark的源码的优先
6.对新技术充满激情，认真负责、有良好的沟通和学习能力
7.计算机或数学相关专业本科及以上学历

职位描述：
1. 数据平台的研发和服务接入
2. 分布式平台应用开发（Hadoop/Hbase/Hive/Spark）
3. 负责公司内部自研大数据平台的运维管理工作。
4. 处理各类异常和故障，确保系统平台的稳定运行。
5. 深入理解系统平台，为其持续优化提供建设性意见。

职位要求：
1.扎实的计算机系统和算法基础知识；良好的英文阅读能力
2.扎实的Java语言基础，熟悉Spring等开源框架
3.熟悉Hadoop、Hive、HBase并有丰富的Map/Reduce程序开发经验
4.熟悉MySQL等关系型数据库
5.熟悉大容量、高性能的数据库系统的应用开发，对各种开源的软件有深入的了解
6.熟悉企业应用设计模式、面向对象的分析和设计技术，包括设计模式、UML建模等
7.责任心强，具备良好的团队合作精神
8.有Spark/Scala开发经验者优先
9.对Hadoop、Hive、HBase等源码有研究者优先

奇虎360 IT架构中心系统部直招

职责：
1. 负责几万台服务器规模的大数据平台Storm/Kafka/Druid等运维及优化工作

2. 研究业界最新的大数据技术，负责大数据运维工具、系统的设计与开发

3. 支撑360安全、搜索、广告、推荐、智能硬件等大数据业务

要求：

1. 一到三年工作经验，熟悉Linux操作系统，熟练使用各种常用命令

2. 良好的Shell/Perl/Python/PHP至少一种脚本编程能力

3. 有Storm/Kafka/Druid等大数据平台运维经验优先

4. 能阅读Java代码者加分

5. 良好的团队合作及沟通能力，较强的责任心

工作地址

- 酒仙桥路6号院2号楼360大厦

岗位职责：1、大数据底层架构，设计数据产品的底层架构和实施；2、对运营日志数据进行分析挖掘；3、与技术部门进行数据段对接；4、对数据进行建模分析，并且进行产品化设计；岗位要求：1、本科及以上， 211优先，专业 computer science，software engineer,Electrical Engineering, Statistics, Math, 等等；2、扎实的Java语言基础，3年以上Java后台开发经验；3、熟悉数据仓库原理，熟悉SQL语言，良好的SQL功底，较强的数据库设计能力，对数据库优化有实践经验者优先考虑；4、熟悉大数据技术包括hadoop，hive，hbase，yarn, Zookeeper,精通分布式数据处理, 具有 hadoop 、hive 、hbase 等数据库存储设计和调优经验；5、熟悉Linux操作系统，可以熟练使用常用的Linux命令完成日常工作；6、 有MemoryCache，Redis，elasticsearch，Solr使用经验者优先；7、有能力从报表数据中分析用户行为、挖掘用户需求并提出建议；

职位要求： 1.熟练掌握Hive，熟练在hive平台下进行代码开发，支持金融业务需求; 2.熟悉在hive平台下进行调优; 3.能解决hadoop平台下的故障、性能等问题; 4. 有过海量数据系统开发 经验者优先; 5.掌握Linux操作系统,并具备shell编程能力; 6.有Spark SQL、Hbase、Python编程经验优先; 
任职资格 1.在hive环境下有较强的撰写SQL能力; 2.至少一年HIVE数据开发项目经历，有较强的开发调优能力; 3.了解LINUX脚本编程; 4.对数据敏感，有较强的逻辑分析能力，对(大)数据处理和分析技术有强烈热情; 5.有互联网金融项目经历者优先 

职位描述
1.参与公司大数据平台设计与工程实现
2.满足公司不同业务线的数据分析需求
 
任职要求
1.重点大学计算机相关专业本科及以上学历, 良好的计算机、统计学基础知识
2.熟悉Linux开发环境
3.熟练掌握Java、Python之一
4.熟悉Java并发编程、对分布式应用开发、Java内存模型、JVM故障排查有一定接触
5.熟悉Hadoop、hive、kafka、flume、hbase、spark、storm中的至少一个
6.熟悉主流关系型和非关系型数据库，擅长sql脚本或者具有数据可视化的前端开发经验
7.英语良好，能正常阅读英语技术文档

职位描述：大数据底层架构设计和实施；对移动设备数据和社交数据进行挖掘分析和建模；逐步构建基于用户行为、喜好的标签系统，并应用于相关的个性化系统和业务分析中；负责数据管理平台的核心技术实现与优化；负责大数据在广告领域的创新应用，持续推动业务线的商业效果改进； 任职资格 岗位要求： 本科及以上，计算机、软件工程、统计学、数据挖掘、机器学习等相关专业。 2年及以上大数据流程架构经验，熟悉Hbase/Hive/Hadoop/Spark或等主流分布式开发平台，有高性能集群设计和开发经验。精通Linux，熟练掌握Python/C/Shell/Java，熟练掌握SQL数据库语言 HiveSQL/Mysql/Sqlserver。有数据挖掘算法实施经验，熟练掌握大规模数据挖掘、机器学习。对有广告营销大数据算法/开发经验者优先，有大型数据项目经验优先，有用户行为分析、用户建模、业务建模经验者优先。具有良好的逻辑分析能力、沟通能力和协调能力。 积极的工作态度，勤奋上进，有责任心。


职位诱惑：
国内硅谷文化
职位描述：

岗位职责：
 
1、负责和参与公司大数据基础架构平台的运维，保障数据平台服务的稳定性和可用性；
 
2、负责和参与超大规模数据存储与计算任务的精细化管理系统的设计，选型和开发；
 
3、负责和参与大数据基础架构平台的监控、资源管理、数据流管理；
任职要求：
 
1、掌握 Linux 操作系统的配置，管理及优化，能够独立排查及解决操作系统层的各类问题；
 
2、掌握 Hadoop、Kafka、Zookeeper、Hbase、Spark 的安装与调试；
 
3、掌握Java语言，至少精通 Python、Perl、Ruby、Bash 脚本语言中的一种；
 
4、有良好的系统性能优化及故障排除能力；
 
5、熟悉大数据周边相关的数据库系统，关系型数据库和 NoSQL

岗位职责：1、负责产品后台的大数据平台开发与维护工作，包括：2、基于Hadoop/Spark的计算平台框架的搭建和维护，保障计算平台的稳定可靠；3、数据源的梳理、ETL过程的开发、数据流转和存储框架的开发和维护；4、数据分析平台的支持，完成数据的离线、实时的统计和分析；任职要求：1、熟悉 Linux 操作系统，有良好的编程能力，以及较强的动手和学习能力；2、至少熟悉 Java, Python、Scala等其中一种编程语言，Scala优先考虑；3、熟悉常见的机器学习算法（SVM）和深度学习算法（CNN、RNN、DNN）更佳；4、有从事分布式数据存储与计算平台应用开发经验，熟悉 Spark, HBase, Kafka等相关技术和原理；5、熟悉软件开发过程，有良好的代码和文档编写习惯；6、有良好的逻辑思维和表达能力，善于学习，独立思考能力强；7、本科以上学历，要求工作态度认真，有责任感，有良好的团队精神和抗压能力；8、1年以上大数据平台开发工作经验。

岗位职责：
1、负责数据业务编码（报表相关）；
2、负责任务调度脚本编写；
3、负责新技术的预研；
4、负责研发平台环境的运维相关工作；
5、参与数据引擎数据研发工作，探索和挖掘数据的商业价值；
6、参与数据产品的研发工作，包括数据探索、ETL、数据研发、数据服务化、数据API研发；
7、对数据平台维护及管理。

任职资格：
1.熟练掌握 java、scala 或其他编程语言，并有大型项目实施经验；
2.精通至少一种数据库开发技术：mysql、Oracle、等，精通 SQL 与性能优化；
3.熟练掌握 Linux 系统常规命令，能灵活运用 shell 完成日常工作；
4.掌握分布式数据处理技术，HDFS、mapreduce、Spark、ES、Hive 、 Hbase、Kylin等，有从事分布式数据存储与计算平台应用开发经验者优先；
5.掌握实时流计算技术，有 Spark 相关开发经验者优先；
6.掌握数据仓库技术与 ETL 研发技术者优先，包括数据模型建设、ETL 技术、元数据管理、数据开发与测试技术、数据质量管理等；
7.掌握搜索、广告、推荐、知识图谱等相关大数据计算、挖掘、分析平台技术优先；
8.良好的沟通能力及自我驱动力、性格积极乐观，态度踏实诚信，富有团队合作精神。

岗位职责：
1、负责处理日常网上问题；2、按照客户业务进行定制开发；3、引导客户在大数据平台业务开发；4、跟踪并研究新技术并能应用于产品。

任职要求：
1、两年以上开发经验；2、熟悉使用hadoop/mr/spark/mpp3、熟悉java/python语言4、至少熟悉两种（贝叶斯，决策树，逻辑回归，K最近邻，向量机算法等）机器学习算法5、具备良好的编码能力，具有规范化，标准化的代码编写习惯；6、具备良好的技术文档输出能力；7、性格开朗，积极进取，善于沟通，抗压能力强，工作细致有责任心。

岗位职责：1.负责公司大数据业务集群的运维工作（Hadoop/Hbase/Hive/Presto/Yarn/Spark/Storm/Kafka/Elasticsearch/Flume等）确保高可用2.负责集群容量规划、扩容及性能优化；3.设计实现大规模分布式集群的运维、监控和管理平台；4.参与业务架构设计，在设计阶段给出可运维性改进建议；5.深入研究大数据业务相关运维技术，持续优化集群服务架构，探索新的大数据运维技及发展方向。任职要求：1.至少掌握java/python/shell中的一种语言。2.熟悉Hadoop/Hbase/Hive/Storm/Spark/Kafka/Elasticsearch/Flume等开源项目优先；3.熟悉Linux操作系统的配置、管理及优化，能够独立排查及解决操作系统层面的问题；4.掌握puppet、kerberos应用的优先；5.良好的客户服务意识，强烈的责任心和使命感，执行力强，富有团队合作精神；6.对大数据方向运维有很高的热情和兴趣，能主动学习了解相关知识；

加入我们一起建设专业的金融大数据处理平台，通过结合使用各种传统和新兴的数据处理技术，为内外部客户提供稳定，及时，准确的基础/衍生数据及服务。在这里你需要根据数据量和数据特点，选择和设计合适的技术方案，实现稳定高效的数据处理流水线，并和团队分享你的心得，指导新人成长。

岗位任职要求:       
必需技能：
1. 扎实的计算机基础知识，熟悉常见的数据结构与算法，操作系统以及数据库基础知识。
2. 熟练掌握以下至少一门编程语言：Java/Scala/Python，熟悉常见的大数据技术，如Hadoop/Spark/Kafka等。
3. 良好的问题分析和解决能力，有学习新技术的热情。
 
加分项：
1. 有一定的金融投资领域基础知识，有过金融数据处理背景尤佳。
2. 有BI方向的背景或工作经验，熟悉各种数据库/NoSQL/数据仓库的特点。
3. 了解docker容器化以及容器编排相关知识。

岗位职责：
1. 负责大数据项目分析方法和大数据解决方案的研究；
2. 针对需求提供大数据分析技术解决方案；
3. 参与大数据项目开发，包括架构设计、编程开发等工作；
4. 根据业务需要，跟踪大数据技术领域趋势并能结合实际业务应用。
任职要求：
1、精通Hadoop以及Hadoop生态圈上的各种应用的几种，如Hbase、Hive，或者分布式数据库Impala等；
2、精通JAVA编程语言，精通面试对象和设计模式，熟悉Linux平台，可以编写代码编程使用Hadoop和基于Haddop开发大数据处理系统；
3、拥有实际的Hadoop的项目经验；
4、具有Storm，Spark，Elasticsearch等一种或多种技术者优先；
5、具有良好的团队沟通和协作能力；

工作职责
1、根据业务和产品情况对数据模型和逻辑进行规划、设计和实现，并参与数据模型优化；
2、完成数据模型的ETL实施，ETL流程优化以及相关技术问题的解决；
3、负责业务需求的需求理解、数据开发，提供面向业务的数据服务；
4、建设数据仓库架构的子系统，包括不限于：ETL调度系统、元数据管理、数据质量监控、高效数据同步、流式数据采集、多维数据分析引擎等；
5、参与相关数据分析、评估监控的工具平台的研发，负责数据模型设计、ETL开发等工作。
岗位要求
1、统招本科及以上学历，计算机相关专业；
2、熟悉数据仓库建模理论，了解数据仓库数据分层架构、多维数据模型设计，有1年以上的实际工作经验；
3、在用户行为日志采集、海量数据处理、数据建模、业务理解方面有丰富经验；
4、熟悉Hadoop / Spark streaming / Hive / Hbase / Impala，有一定的Hql/Sql性能调优经验， 对Hadoop、Hive源码有研究更佳；
5、熟悉Linux开发环境，熟练掌握至少一种编程语言（Java / Python / SHELL / Scala）；
6、优秀的逻辑思维能力和业务需求分析能力，较好的沟通交流能力，善于主动思考和行动；
7、有数据仓库架构的开发经验者优先，例如元数据管理、OLAP引擎、数据同步等；
8、有数据分析工具平台的开发经验者优先；
9、具有良好的学习能力、时间和流程意识、沟通协作能力。

岗位职责：                        
                                          
1、负责公司内部大数据处理平台设计及开发；                        
2、设计和实现灵活可扩展、稳定、高并发的存储系统和计算模型；                        
3、生成系统的trouble-shooting，设计和实现必要的机制和工具保障生产系统整体运行。                        
                                                  
任职资格：                        
1、本科及以上学历，计算机相关专业，有强烈的求知欲和进取心；                        
2、熟悉使用Java/C/C++/Python等开发语言，并可以开发高效可靠的代码；                        
3、熟悉Linux开发环境，良好的系统编程、数据结构、算法基础、系统设计能力；                        
4、熟悉常用的开源分布式计算/存储相关技术。                        
如YARN,Spark,Shark,Storm,Zookeeper,HDFS,Hbase,Hive,Redis,Flume,Kafka,Sqoop,Drill,Presto等。                        
5、有Spark stream， Storm等流式计算引擎开发经验者为佳；                        
6、有生产环境数据Pipeline开发经验者为佳。 
 

工作职责： 1.优化调整大数据平台的整体架构 2.大数据平台基础架构设计 3.负责大数据平台数据中心的基础设施的建设落地 4.研究新的技术并运用于大数据平台，提高平台的运行效率 任职要求： 1.5年以上互联网从业经验，至少2年大数据架构师相关经验 2.有分布式系统分析及架构设计经验，有大型计算集群的基础设施开发维护经验 3.熟悉Hadoop/Spark/Storm，有管理或优化大型分布式集群经验 4.熟悉openstack，docker，mesos，kubernetes等云计算技术 5.熟悉高性能，高可用，高拓展系统架构设计 6.精通Java，Scala，Go，python，Erlang等编程语言 7.熟悉linux系统，有内核调优经验优先

岗位职责：
1、负责公司的大数据处理框架的研发设计工作；2、负责公司产品研发过程中的数据存储结构设计文档的撰写；3、参与小组的产品设计讨论，共同讨论和设计产品；4、负责公司产品的大数据平台问题排查和性能优化等相关工作。 

任职要求：
1、1年以上工作经验。
2、熟悉Linux操作系统，能够编写基本的Shell脚本或者熟悉Python编程语言。
3、熟悉HDFS、Hbase，熟悉spark计算框架，会编写基本的spark离线任务。
4、了解Hadoop生态圈组件，熟悉Impala、Hive等。
5、有责任心，具有团队合作精神，具备良好的学习能力。

岗位职责：1. 根据项目大数据处理业务需求，设计大数据处理方案，实现相关功能。 2、搭建和维护大数据集群，保证集群规模持续、稳定、高效平稳运行。 3、制定大数据处理平台维护、优化、安全及高可用方案。 任职资格： 1、5年工作经验，有丰富项目开发经验，精通Java等主流编程语言。 2、熟悉Hadoop、Hbase、Hive、spark等工作原理，2年以上实战经验，熟悉分布式计算实施过程中的各种问题。 3、熟悉Zookeeper、Kafka、Elasticsearch、Logstash、Mysql等，有丰富的运维经验者优先。 4、熟悉Linux/Unix系统，熟悉Shell脚本语言。5、具有较强的沟通能力，工作协作能力，学习能力，执行力和组织能力。 6、工作态度积极主动、细致、有全局观，有抗压能力，善于与他人合作，良好的团队合作意识。

职位描述：
1.负责实现数据的自动化ETL，并提升数据质量； 2.负责实现数据的分析和计算； 3.负责实现自定义的报表和统计。 任职资格：
1.熟练Java语言和常用的设计模式； 2.熟练Spring MVC、myBatis等技术框架；熟悉WebSevice/Json等网络技术； 3.至少熟悉Oracle/MySQL/PostgreSQL等关系型数据库中的一种,有良好的SQL编写能力； 4.有Hadoop大数据平台、GIS地图相关的云平台等开发经验者优先。

岗位职责：
1.负责业务数据建模与DW建设； 2.参与用户画像项目开发； 3.使用ETL/HIVE/Spark完成海量数据的存取&amp;建模，为数据分析人员提供全面、准确的基础数据； 4.满足业务方需求，提供多维度的OLAP数据，支撑业务决策；

任职要求：
1.3年及以上工作经验，有大数据开发经验； 2.熟悉Hadoop、HBase、Storm、Spark、es等相关开源项目； 3.对数据建模、存取、处理、可视化等相关技术有很强的学习热情； 4.熟悉数据库的基本知识，有使用MySQL/Hive等数据库的经验，熟悉SQL/HQL调优； 5.熟悉面向对象的程序设计，熟悉Python/Java/Shell中至少一门语言；  优先考虑:有数据仓库建设经验；

岗位描述： 
1、负责设计、实施、运维公司大数据平台； 
2、负责整体核心技术，确定技术方案和系统框架设计； 
3、能够根据不同的业务需求，灵活快速地完成具有挑战性的大数据平台项目；
4、带领团队进行大数据领域的技术难点攻关，并能指导数据平台的设计。 
岗位要求： 
1、重点大学计算机、数学、统计或相关专业本科及以上学历，2年以上相关经验； 
2、具备良好的团队合作精神，具有良好的沟通能力、解决问题能力； 
3、精通各种大数据计算框架，熟悉Spark/Hadoop/Map-Reduce/MPI分布式计算框架，特别是有Spark类实战经验/海量数据处理经验者优先； 
4、精通并深入使用Java，对虚拟机以及Linux下的开发环境有较深厚的开发经验； 
5、有相关大数据平台开发工作经验优先。

岗位职责：
1、把握复杂分布式系统的设计、开发、维护全过程，不断进行系统优化；
2、和团队一起攻克大数据量、大用户量、实时业务、高并发、高吞吐、高可靠性等各种不同技术场景下的技术挑战。
职位要求：
1、大学本科及以上学历，熟悉IO机制、网络通讯、多线程等基础知识框架，熟悉缓存、消息队列、索引查询等机制；
2、熟悉Hadoop、hbase、storm、zookeeper、Spark等开源分布式系统，对其中1个或多个分布式系统有应用经验；
3、对分布式系统内的应用开发有丰富经验，语言包括并不限于JAVA, clojure，scala，python, C等；
4、熟悉大数据量、大用户量、实时业务、高并发、高吞吐、高可靠性分布式系统的优先；
5、保持大数据行业相关技术持续学习的热情，了解行业最新技术动态，开源社区参与者和贡献者优先；
6、良好的沟通技能，团队合作能力，勤奋好学。

岗位职责：
1、参与大数据平台、产品的设计与开发（包括算法设计及实现），解决海量数据面临的各方面挑战；
2、管理、优化并维护Hadoop、Spark、MongoDB等集群，保证集群规模持续、稳定；
3、负责HDFS/hive/HBase等的功能、性能和扩展，解决并实现业务需求；
4、协助团队成员建立数据模型，对数据进行挖掘、优化及统计，确保项目的进度和质量；
5、能够在团队中完成Code Review的任务，确保相关代码的有效性和正确性，并能够通过Code Review提供相关性能以及安全的建议；
6、 能够有效地对新人或普通开发工程师进行辅导，帮助其快速成长；
7、参与通用实时计算框架、用户画像、爬虫、挖掘等架构设计。
 
任职要求：
1、计算机相关专业的本科及以上学历，3年及以上互联网系统或者其他企业应用系统开发相关经验；
2、具备Java/C/C++/Python/Scala/Shell等开发经验，具体要求：比如偏Java，则编程基础要扎实，熟练使用struts2、spring、ibatis或hibernate等框架，熟悉linux开发环境；
3、有分布式系统开发经验，至少熟悉一种关系型数据库和一种NoSQL；
4、熟悉Hadoop/HBase/Spark/Storm/Hive/MongoDB等；
5、熟悉数据挖掘策略与算法、熟悉数据仓库模型设计，具备海量数据加工处理（ETL）相关经验的优先；
6、有舆情分析/搜索/CRM系统研发相关项目经验、有用户画像、日志分析、用户行为分析、BI项目经验者优先；
7、数据控，善于发现问题、解决问题,具备良好的分析和解决问题的能力，具备一定的钻研精神和持续学习的意愿，强烈的责任感和团队感，对负有挑战性的工作充满热情。

职位描述：
1、负责大数据平台的架构制定、技术选型、设计开发，以及系统问题的解决和持续优化；
2、海量数据离线分析和实时分析系统架构的建设和维护；
3、负责大数据应用相关产品的整体架构设计，进行大数据平台上数据挖掘产品的规划及研发。
任职要求：
1、熟悉大数据开源产品的架构和技术细节，具有Spark、Hadoop、Hbase、Hive、Flume、Kafka等项目开发经验，平台运营维护经验；
2、熟练掌握至少一种编程语言（Java、Python优先）；
3、研究过Spark、Hadoop、Hbase、Hive、Flume、Kafka等源代码者优先；
4、有推荐系、搜索、广告等相关处理工作，数据挖掘经验者优先；
5、工作认真，负责，良好的团队合作精神和解决问题分析能力。钻研技术克服困难，勇于挑战。

一、职位描述
 
1、参与公司大数据产品规划；
 
2、大数据处理分析平台的设计与开发；
 
3、为其他项目组提供大数据技术指导及分析手段支持。
 
二、职位要求
 
1、熟练使用Linux操作系统，精通Java或C++语言，有两年以上实际项目开发经验；
 
2、熟悉Hadoop、Spark生态相关技术优先考虑(非硬性)；
 
3、具有ETL设计/开发工作经验者优先考虑；
 
4、熟悉Oracle或MySQL等关系数据库技术；
 
5、具有一定的技术钻研精神，对大数据领域相关技术有浓厚的兴趣；
 
6、工作主动性强，具有良好的团队意识和沟通能力。

工作内容：
1.负责公司软件产品的代码编写工作。
2.负责软件研发过程中的文档撰写。
3.参与小组的产品设计讨论，共同讨论和设计产品。

任职要求：
1.熟悉JAVA语言，编程基础扎实，对面向对象编程思想有深刻理解，熟悉数据结构和常用的编程算法。
2.熟悉JAVA平台下的其中某一种子技术：
J2SE平台和J2EE平台下的jsp开发、servlet开发、struts、spring、hibernate、jdbc、java web service、swing界面编程、JAVA核心类库编程等各种JAVA子技术。
3.熟悉常用的设计模式和常用的设计原则。
4.熟悉软件开发流程和配置库的使用，拥有软件开发流程中的代码规范意识、配置管理规范意识、文档撰写规范意识和团队合作沟通交流意识。

岗位职责：
负责TRS相关产品的开发工作
 
任职要求：
 
1.计算机及其相关专业，本科及以上学历，1年以上相关工作经验；
 
2.掌握java基础知识,掌握JAVA多线程等；
 
3.熟悉大数据相关开源技术，如Elasticsearch、MongoDB，必须有相关经验，否则请勿投递；
 
4.具有良好的学习能力、团队协作能力和沟通能力；
 
5.责任心强，善于思考，能独立分析和解决问题。

【职位描述】 
1、负责公司大数据处理平台工具研发，为公司提供公共大数据的相关服务；
2、提供业务关键数据指标及运维指标的离线or实时分析服务，为监控平台及自动化运维平台提供数据及决策支持；
3、深入研究并负责持续优化hadoop、hbase、storm、elasticsearch、spark等平台的服务运营，支持特殊需求的定制开发；
4、负责开发优化数据采集、传输、落地存储等服务。
 
【职位要求】
1、大学本科（统招）及以上学历，2年以上相关工作经验；
2、对Hadoop、HBase、Hive、Flume、Storm、kafka等开源工具中至少有1-2个有深入理解，并有一定经验；
3、至少2年的java开发经验；
4、具备对mysql、redis其中之一的开发经验；
5、学习能力强、具有良好逻辑分析能力、文档编写、语言表达能力，有强烈的责任心及团队合作精神。

岗位职责：
1.参与亿玛实时计算平台的迭代，解决各种线上问题，逐步完善系统，提升系统的吞吐率，保证高可靠性。 2.推进实时计算平台在产品落地，提升自动化水平，提升用户体验。 3.能够独立完成一个实时分析系统的设计，并主导代码实现，测试及上线。 岗位要求: 1. 三年以上相关经验，对数据结构及算法有一定的了解，动手能力强 2. 掌握实时计算技术体系包括数据采集、消息队列 Kafka、计算引擎 Storm/Flink 3. 对实时计算所涉及的事务、容错、可靠性有深入理解 4. 精通 java，了解 JVM ，熟悉 linux 平台，掌握 shell 的日常使用，掌握 clojure 的加分。 5. 熟悉 Hadoop 生态圈：掌握 MapReduce、Hive 6. 熟悉 ElasticSearch 及其生态圈 7. 对大数据技术充满热情，有流式计算开源项目 Kafka、Storm 有源码级研究的更优。 8. 具有大型实时计算系统构建者，大数据引用经验者优先。

工作职责：1. 根据业务需求，制定系统的整体技术框架、业务框架和系统架构2. 处理用户海量数据，提取、分析、归纳用户属性，行为等信息，完成分析结果3. 配合各业务给予数据支持，对产品和运营数据总结和优化4. 大数据基础架构平台的监控、资源管理、数据流管理任职要求：1. 专业要求：计算机相关2. 工作经验：Hadoop项目开发和维护经验3. 性格特征：责任心强、能承担工作压力、良好的沟通能力，具备出色的规划、执行力 4. 语言和计算机：有使用hadoop/hive/spark分析海量数据的能力、有良好的系统性能优化及故障排除能力、熟悉大数据周边相关的数据库系统，关系型数据库和 NoSQL，熟悉Linux开发环境

岗位说明：
1、负责电商平台数据相关的开发工作；
2、预研大数据领域的前沿技术，优化现有架构。
岗位要求：
1、计算机及相关专业本科以上学历；
2、熟悉Java、Jvm，熟悉网络编程、多线程等；
3、有Linux操作系统使用、开发经验，熟悉hadoop相关技术框架，比如zookeeper、hive、 hbase、spark等分布式运算存储框架；
4、熟练使用MySql、Hbase关系型及非关系型数据库的操作；
5、参与过大数据平台或分布式系统开发工作；
6、优秀的学习能力，扎实的数据结构和算法基础；
7、优秀的分析、解决问题的能力，对挑战性问题充满激情；
8、具备强烈的工作责任感，具备良好的团队精神和沟通能力。



 
岗位职责：
 
1、负责和参与公司大数据基础架构平台的运维，保障数据平台服务的稳定性和可用性；
 
2、负责和参与超大规模数据存储与计算任务的精细化管理系统的设计，选型和开发；
 
3、负责和参与大数据基础架构平台的监控、资源管理、数据流管理；
任职要求：
 
1、掌握 Linux 操作系统的配置，管理及优化，能够独立排查及解决操作系统层的各类问题；
 
2、掌握 Hadoop、Kafka、Zookeeper、Hbase、Spark 的安装与调试；
 
3、掌握Java语言，至少精通 Python、Perl、Ruby、Bash 脚本语言中的一种；
 
4、有良好的系统性能优化及故障排除能力；
 
5、熟悉大数据周边相关的数据库系统，关系型数据库和 NoSQL。

一、工作职责

1、基于Hadoop各种开发工具和框架实施数据采集、分析；

2、配合机器学习工程师对数据进行清洗、预处理；

3、负责基于hadoop集群，spark集群编写分布式算法实现；

二、任职要求

1、2年以上工作经验，本科计算机及相关专业学历；

2、基础扎实，熟悉数据结构和算法； 

3、熟悉Java、Scala、Python语言，较强的独立开发能力，具备良好的代码风格；

4、具备MapReduce、Hive、Spark、Redis等NoSql平台开发能力；

5、良好的数据敏感能力，敏锐而富有耐心。与数据打交道而乐此不疲；

6、优秀的沟通能力，有创新精神，乐于接受挑战，能承受工作压力。

岗位要求：
-985/211本科以上学历，计算机/通信相关专业，1-5年相关工作经验
-熟悉java/jvm， 丰富的java/web或服务器端开发相关经验
           -了解缓存/队列技术，熟悉mysql/nosql,有调优经验
-熟悉linux，有良好的算法和数据结构基础
-关注性能、有分布式系统或者高并发开发经验者优先
-优秀的分析和解决问题能力，良好的沟通和组织能力
 
加分项：
           -熟悉hadoop/spark/hive/hbase/kafka/storm等分布式系统，有相关实践经验
           -
 
岗位职责：
           -负责大数据平台相关核心模块的设计和开发        
           -持续性架构优化、性能调优等
 
公司地址：
北京海淀区科学院南路2号院3号楼 搜狐媒体大厦

岗位职责：
1、负责收集市场和行业信息，提供有效应对方案；
2、负责日常维护，保证平台的正常运作，结合前向需求提出优化建议；
3、负责运营规范及业务流程的制定，推动各环节运营工作的形成和相关流程的优化；
4、平台运营数据的定期统计、形成平台运营情况效果分析报告，及时更新及完善平台相关内容；
5、产品\平台运营所需资源管理及协调

任职资格：
1．对互联网及其大数据业务有极大热情，熟悉互联网的主要发展方向和概念并有敏锐的市场意识；
2．具有优秀的创造力、想象力、逻辑思维与系统分析能力，突出的文字组织能力和沟通能力，良好的数据分析能力；
3．2年以上在知名互联网公司设计或运营互联网产品，或直接负责互联网产品的运营及策划工作；
4．做事踏实，责任心强，学习能力突出，有强烈的进取心和成长愿望；
5．本科或硕士学历，专业不限，计算机或相关专业优先。
6.  有B2B平台运营经验者优先

岗位职责：
1、负责大数据平台在环境支持、部署自动化；
2、优化和完善现有工作流程及规范
3、基于高效的原则，进行自动化系统和工具的建设；
4、研究了解前沿的运维技术，并推进内部应用。
任职要求：
1、计算机相关专业，本科以上学历，3年以上相关工作经验；
2、深入理解 Linux 系统，2年以上 Linux/Unix 系统运维经验；
3、熟悉使用 Linux 下的各种常用命令，基本故障排查能力；
4、具有大数据平台部署经验的优先：ES，Cassandra，Spark，Redis，Kafka等；
5、具备脚本开发能力：如 Python, php，golang 等；
6、了解路由器、交换机、负载均衡等网络设备的相关知识；
7、具备良好的学习能力以及解决问题能力；
8、高度的责任服务意识和团队精神；
9、具有大型网站的运维经验，由参与开源项目的优先。

岗位职责
1、完成大数据平台和BI系统的开发； 
2、按照设计要求完成基于hadoop平台的编码任务；
3、负责代码的优化，保证代码质量； 
4、大数据平台所有API系统的研发工作，包括：高并发查询/计算/鉴权/频度、安全防护系统；
5、大数据平台系统的研发工作，包括：数据分布式查询/批量存储/高可用服务。

任职资格
1、精通Java语音，具有Spring、Struts、hibernate/ibatis等常用框架开发经验； 
2、有软件工程知识和质量意识； 
3、良好的团队合作精神和沟通能力，较强的责任心； 
4、三年以上Java开发经验，精通Hadoop，HBase，Hive；
5、熟悉mysql、mongo等数据库，熟悉redis/memcache；
6、数学、统计学背景、模式识别专业者优先;
7、有爬虫相关经验者优先;

岗位职责：
1、执行公司销售战略，承担经营业绩指标，拓展销售渠道（运营商和各行业大客户），完成销售目标；
2、负责公司云/大数据/行业应用产品销售，实施行业标杆客户的销售，及行业合作的达成；
3、采集分析市场信息，掌握并及时反馈市场动态，参与市场拓展计划的制定；
4、建立与维护良好的客户合作关系。

任职要求：
1、本科以上学历，2年以上通信、IT行业销售经验，移动互联网/互联网工作经验优先；
2、熟悉云平台、大数据主流产品及方案、发展趋势、行业市场情况、具有成功案例和客户资源者优先；
3、熟悉顾问式解决方案销售流程；
4、优秀的沟通协调能力，时间管理能力，判断能力，有创新精神，有积极主动的工作态度，能承受一定的工作压力。

公司福利：
【全面的薪酬福利】
五险一金+商业意外险+员工补充医疗保险+子女补充医疗保险；
福利补助（餐补、话补、交通补）；带薪年假；多项贺礼（结婚、生育、生日、节日）；多元化俱乐部（篮球、足球、爬山、瑜伽）；年度体检；合家欢；员工旅游。。。
老多了，要啥有啥！
【完善的培训体系】
培训平台学习；新员工导师制；新任管理者培训；
培训阶梯：新员工培训→春苗计划→春蕾计划→鹰才计划→雄鹰计划；
旨在为员工提供基于工作胜任与个人能力发展的多样化培训！


工作职责：
1、对数据分析业务团队提供技术支持，协助方案规划，数据产品开发；
2、设计并实现数据可视化相关产品以及相关数据系统。
3、用户行为数据挖掘和推荐系统开发。
任职要求：
1、计算机相关专业，本科学历以上，至少3年工作经验，研究生2年以上；
2、精通Spark Streaming；
3、精通Spark性能调优，打造高可伸缩的数据处理程序；
4、精通Spark监控，包括任务和系统级别；
5、熟悉数据挖掘、推荐系统基本算法，有相关经验者优先;
6、自我驱动，自主学习新的技术和分析方法，并勇于在业务上进行创新；

岗位职责：1、负责大数据接入、存储、分析、监控等系统的架构设计、开发和优化工作；2、负责Hive、Spark、HBase、Kafka等组件的性能优化工作；3、负责分布式数据仓库的主题模型设计和宽表开发工作；4、负责大数据集群的部署和维护；5、负责新技术的调研、评估和分享。

任职要求：1、统招本科及以上学历，计算机、数学等相关专业； 2、2年以上Java开发经验，有代码洁癖、熟练在Linux上工作；3、2年以上大数据或数据仓库系统开发经验；4、熟悉Hadoop、Hive、Spark、HBase等原理和特性，有调优经验，阅读过相关源码；5、有较强的学习能力和快速解决问题能力，对技术有较高的热情，愿意钻研，热衷于新技术学习和分享；6、优秀的团队合作精神。

有以下工作经验PLUS:有知名互联网公司大数据工作经验者优先；有实时计算工作经验者优先；有数据埋点工作经验者优先。

岗位职责：
1、规划、设计、部署和技术支持SequoiaDB数据库系统，并与Hadoop、Spark，以及各种大数据和BI组件对接；
2、管理并实施大数据及分布式NewSQL数据库项目；
3、为客户提供SequoiaDB、Hadoop、Spark项目相关专业服务（包括巡检、调优、诊断、咨询，以及其他技术支持工作）；
4、参与PoC测试及投标工作；
5、编写实施项目和专业服务项目验收相关文档及其他交付物；
6、研究和分享相关技术和产品；
7、管理项目实施团队.
任职要求：
1、计算机科学或相关专业，本科及以上学历；
2、3年或以上数据库运维或售后经验，能够独立诊断并解决复杂的功能及性能问题；
3、至少精通一种商业数据库，并深入理解Linux操作系统原理，能够熟练使用shell编写脚本；
4、具备Hadoop、Spark等大数据和BI相关软件使用经验者优先；
5、具备C/C++、Java、Scala语言开发能力者优先；
6、良好的英文读写能力，能够有效的阅读和学习英文技术资料；
7、具备良好的人际沟通能力和团队合作精神；
8、具备坚韧的意志和乐观的工作态度，能够承受和管理工作压力；
9、具备项目管理经验者优先。

岗位职责：
1、负责hadoop运维相关工作；
2、集群日常问题的troubleshooting；
3、完成日常升级、维护等任务。
任职条件：
1、负责cdn集群的运维，做过大规模hadoop集群优先；
2、 对hdfs,yarn,hive,spark,oozie,hbase，了解并精通至少一种；
3、对linux基础运维命令熟悉，shell,python至少精通一种，如会scala语言可优先考虑；
可以独立处理问题，有团队精神。

【工作职责】：
1、 在机器学习领域持续探索，确认公司长期的技术优势
2、 对公司的新业务算法问题进行抽象和建模，并且进行持续性的探索优化
3、 对公司已有业务进行算法层面的持续优化
4、 在机器学习基础理论对工程团队进行输出
【岗位要求】： 
1、 计算机相关专业博士学历，在机器学习，数据挖掘，统计学理论等领域有着深厚积累
2、 熟悉机器学习和数据挖掘领域前沿技术，在国际顶级会议上发表过机器学习相关的论文者优先 
3、 优秀的编程能力，熟练至少一门常用编程语言，有大数据相关系统，如Map-Reduce, Spark, MPI开发经验
4、 对前沿和有价值的研究领域保持敏感，有能力判断需要探索和钻研的方向
5、 良好的沟通能力，和良好的团队合作精神
【优先条件】： 
1、实际的计算广告算法经验
2、熟悉深度学习，至少熟悉一种常用的深度学习框架，并且有一定的调参经验
3、熟悉图算法，熟悉GraphX, GraphLab等图计算工具
4、熟悉机器学习可视化，对大规模机器学习模型的可视化做过相对深入的研究
5、熟悉常用的时间序列分析算法

工作职责： 1、负责ElasticSearch上层应用开发，偏产品前端； 3、根据产品的特性设计搜索规则，提升搜索效率； 4、对搜索算法进行优化，提高处理的准确性和性能。 技能及资质要求： 1、本科及以上学历，计算机专业背景； 2、有独立分析问题和解决问题的能力，熟悉JAVA、python； 3、精通ElasticSearch、kibana等，熟悉搜索引擎中的常用算法； 4、有ElasticSearch上层应用开发经验； 5、具有海量数据处理、高性能计算、大规模分布式系统开发等方面经验者优先； 6、有十亿级别以上搜索质量调优经验优先； 7、有Redis相关使用经验优先。

大数据开发
岗位职责： 1、负责海量数据处理分布式平台以及大数据分析系统的研发； 2、根据业务和产品情况对数据模型进行设计和开发，对数据模型进行优化； 3、负责业务需求的需求理解、数据开发，提供面向业务的数据服务； 4、应用大数据技术完成离线分析和实时数据分析工作； 5、对集群进行优化及数据处理的调优； 6、线上已有架构的运维。
任职要求： 1、计算机相关专业本科以上学历，最少5年工作经验，2年以上大数据研发经验； 2、有扎实的Java基础，熟悉spring/mybatis/redis/maven，熟悉一种以上数据库并熟练运用SQL； 3、熟悉scala、python等计算机语言尤佳； 4、具备良好的J2EE、SOA、Database、nosql等广泛的知识体系； 5、熟悉主流Web应用服务器，如Tomcat、Nginx、weblogic等； 6、熟悉Linux开发环境，了解常用工具使用，掌握limux常用命令，能使用shell脚本实现相关功能； 7、深刻理解Hadoop大数据平台架构原理，熟悉HDFS/MapReduce，能熟练运用MapReduce程序处理数据； 8、熟悉 Storm / Spark / Kafka 等实时计算技术栈，有过实际项目经验； 9、能够运用spark程序处理离线或实时数据 10、熟悉hadoop生态圈相关工具 flume/ ELK / azkaban或者Oozie 11、熟悉Hive / Pig / Hbase / ZooKeeper，对Hadoop、Hive源码有研究更佳； 12、有Hadoop集群的搭建、维护和优化经验； 13、有算法, 数据建模挖据, 机器学习方面经验尤佳，了解Kylin/nifi者尤佳； 14、热爱技术，对技术有不懈的追求，喜欢研究开源代码； 15、做事积极主动，具有高度的责任感与团队合作精神，主动学习新技术，有良好的沟通能力。

职位描述：
1、负责建设公司的大数据平台，包括数据采集、传输、存储、计算、可视化等底层能力。
2、根据业务团队的需求，规划设计上层大数据应用。
3、搭建公司的大数据团队。

任职要求：
1、计算机、数学等相关专业本科以上学历，5年以上相关工作经验。
2、精通Hadoop体系结构、对Hadoop生态圈有较全面了解。
3、精通HDFS/HBase/Hive/Storm/Spark/Spark Streaming/Kafka/flume等相关技术；有多个或多年大数据项目的实施经验。
4、熟悉分布式系统的底层工作原理。
5、有机器学习、数据挖掘经验者优先，有solr、ES使用经验者优先。

工作职责：1. 数据仓库调度系统的稳定性保障2. Hadoop大数据平台的稳定性保障3. 梳理和建立流程来管理大数据的各类系统变更4. 大数据监控和告警程序的管理职位要求：1. 3年以上运维或运维工作经验，对shell/python/perl有1-2门语言使用熟练2. 能熟练使用互联网公司的常用运维软件3. 熟悉zabbix/nagios等开源软件4. 接触过大数据相关应用者优先。包括但不限于：hadoop/zookeeper/hbase/storm/kafka/flume

岗位职责：
1.负责搭建并管理Hadoop、Storm集群，维护并优化平台上的数据存储。
2.负责Hadoop平台上的MapReduce、Hive、HBase应用的维护和管理。
3.参与基于Hadoop、Hive技术的开放平台软件项目的开发。
任职资格：
任职要求：
1、熟悉Java，3年以上Java开发经验，对数据结构、算法有深刻的理解；
2、熟悉Hadoop Hive相关原理及高级特性，3年以上Hadoop&amp;Storm集群开发经验；
3、对Hadoop&amp;Storm生态圈开源产品有深入了解者优先考虑
4、独自搭建过大数据环境者优先考虑；
5、熟悉linux系统，熟悉常用shell命令；
6、良好的沟通理解能力、团队协作意识、学习能力、执行力，并热爱技术研发工作；
7、参与过大数据相关的大型项目，并作为主要开发人员者优先、硕士及以上学历优先。

岗位职责：
1.参与设计、研发大数据处理平台；    
2.帮助平台用户快速构建基于大数据的数据产品和应用，将大数据快速转变成商业价值； 
3.从事大数据的并行计算、实时流计算的研究和开发；    
4.从事大数据数据挖掘、数据分析的研究和开发；    
5.负责大数据平台集群的审核、部署、发布、监控、维护和优化。    
6.负责大数据系统的性能分析与系统优化，不断提高系统运行效率。

任职要求：
1.熟悉Linux或Unix系统，5年以上大规模集群的运维经验，熟悉ganglia等监控和管理工具；    
2.熟悉Hadoop平台及主要子项目，有一年以上Hadoop平台mapreduce的开发经验；    
3.熟悉shell,python、java、C/C++至少一种；    
4.对Hadoop、HBase、Storm、Zookeeper、impala、spark presto之一有深入理解并在现实项目中大规模应用；
5.熟悉MongoDB、Redis、Memcache 其一，对pig,hive,spooq,flume,scribe有研发经验者优先；    
6.具备快速学习掌握新知识的能力，优秀的分析、解决问题能力，具备良好的抽象归纳能力和创新能力。

职位描述：
1.搭建分布式大数据处理平台，进行自动化ETL，提升数据质量； 2.搭建数据分析平台，建立数据分析/数据挖掘模型； 3.分析用户行为数据，搭建个性化的数据推荐系统，优化产品效果。 任职资格：
1.本科或以上学历，3年以上工作经验；
2.熟悉BI平台架构、大数据解决方案包括Hadoop、Spark、Storm、机器学习等； 3.理解大数据处理(流计算、分布式计算、分布式文件系统、分布式存储等)相关技术和实现方法； 4.熟悉MySql/Postgresql/Oracle/MongoDB/Redis等主流数据数据库； 5.精通java、scala、python的一种或多种语言； 6.具备良好的沟通交流能力和文字语言表达能力，较好的逻辑分析能力。

岗位职责：
1、负责spark大数据平台的ETL工作，
2、负责Spark的功能扩展和性能优化，解决并实现业务需求，
3、使用hive、spark进行数据处理，协助建立数据模型；
 
任职要求：
 
1、本科及以上学历。2年以上相关工作经验，精通SQL，精通Java、scala，Python其中至少一门语言，
2、熟悉数据库/数据仓库设计
3、熟悉Hive、Spark、kafka，Sqoop、hdfs，HBase
4，熟悉linux开发环境，掌握shell编程
5、对数据敏感，能够发现关键数据、抓住核心问题，有良好的沟通和学习能力。
6，具有数据挖掘、海量数据处理等相关项目经验者优先

岗位职责：
1、负责分布式数据仓库的主题模型设计和宽表开发工作；
2、负责大数据分析需求设计和开发，承担数据抽取、清洗、转化等数据处理程序开发；
3、负责BI平台数据分析、报表开发工作。

岗位要求：
1、具有3年及以上大数据开发经验；
2、熟悉Java或scala开发，熟悉linux操作；
3、熟悉Hadoop、Hive、HBase、Spark等相关技术，具有多个以上大数据平台项目实施经验；
4、具有丰富的数据仓库系统的开发实施经验，熟练设计数据模型、ETL设计、Cube多维建模、OLAP开发、报表开发等；具有良好的编程习惯和文档编写习惯；
5、有较强的学习能力，对技术有钻研精神，并有较高的热情，热衷于新技术学习和实践；

职位描述：
1、负责业务相关数据指标的抽取、转换、加载，数据维护相关工作；
2、负责对业务数据进行分析、建模，为业务部门的数据化运营提供支持；
3、依据业务需求，进行数据产品的规划和设计开发，为数据分析和运营等人员搭建友好高效的数据产品。
岗位要求:
1、5年以上工作经验，至少2年大数据工作经验；
2、能独立使用工具，完成结构化数据库与非结构化数据库数据转化；
3、了解MapReduce或Yarn工作原理，熟悉Hbase，HDFS，Storm，Kafka，DataX/Sqoop等大数据处理框架,特别是有Spark实战经验,并有实际大数据平台搭建和调优的经验；； 
4、精通Java、Python、R、PHP之中一种语言，并有大数据分析处理实际项目经验，熟练掌握linux系统和shell编程；
5、认真严谨，喜欢钻研，有责任心，良好的团队合作精神，积极上进，具备良好的学习能力
6、具有互联网金融大数据风控经验者优先

岗位职责：
1、负责公司大数据/Hadoop/Hive/Spark/实时计算的运维保障；
2、负责Hadoop/Hbase/Spark/Hive等系统的架构审核、业务监控、持续交付、应急响应、容量规划等；
3、跟进并处理系统事件，对系统问题及故障解决跟踪优化，负责服务状况与服务
4、梳理优化业务使用集群的流程及规范，使集群使用在资源利用、质量等方面均达到较高水平；
5、日常跟踪业界技术发展动态，并结合业务发展需要，研究引入合适的技术。
岗位要求：
1、大学本科及以上学历，计算机或者相关专业，2年以上分布式存储与计算的相关工作经验；
2、深入理解linux系统，运维体系结构，精于容量规划、架构设计、性能优化；
3、有开发经验优先，精通一门以上脚本语言(shell/perl/python等)；
4、熟悉hadoop、hive、hbase、yarn、spark、storm等之组件的原理及运维方式；
5、具备很强的故障排查能力，有很好的技术敏感度和风险识别能力；
6、良好的服务意识，善于团队协作；
7、能够承受较大的工作压力。

岗位职责：
1、负责数据业务编码（报表相关）；
2、负责任务调度脚本编写；
3、负责新技术的预研；
4、负责研发平台环境的运维相关工作；
5、参与数据引擎数据研发工作，探索和挖掘数据的商业价值；
6、参与数据产品的研发工作，包括数据探索、ETL、数据研发、数据服务化、数据API研发；
7、对数据平台维护及管理。

任职资格：
1.熟练掌握 java、scala或其他编程语言，并有大型项目实施经验；
2.精通至少一种数据库开发技术：mysql、Oracle、等，精通 SQL 与性能优化；
3.熟练掌握 Linux 系统常规命令，能灵活运用 shell 完成日常工作；
4.掌握分布式数据处理技术，HDFS、mapreduce、Spark、ES、Hive 、 Hbase、Kylin等，有从事分布式数据存储与计算平台应用开发经验者优先；
5.掌握实时流计算技术，有 Spark 相关开发经验者优先；
6.掌握数据仓库技术与 ETL 研发技术者优先，包括数据模型建设、ETL 技术、元数据管理、数据开发与测试技术、数据质量管理等；
7.掌握搜索、广告、推荐、知识图谱等相关大数据计算、挖掘、分析平台技术优先；
8.良好的沟通能力及自我驱动力、性格积极乐观，态度踏实诚信，富有团队合作精神。

岗位职责：
 1、 参与ODS系统或Hadoop 系统数据库相关开发,包括数据仓库的数据模型设计(ODS层设计、基础数据层设计、汇总层设计等)2、 参与ETL Mapping设计及开发工作3、 参与客户/用户画像、经营管理、产品画像、营销活动等主题域建设工作
任职要求：
1.计算机相关专业大专及以上学历2.有大型数据库(ORALCE/MSSQL SERVER等)开发经验，有Sybase IQ\HIVE\Spark SQL开发经验者优先3、有较强的SQL编程能力,熟练编写存储过程，能设计各种复杂的业务处理、统计分析语句，精通sql性能优化；3、具有数据仓库、ods、BI商务智能项目经验者优先，具有金融行业项目背景者优先；4、较好的沟通理解能力，态度踏实，积极上进

岗位职责：
1、负责物流平台实时/离线经营指标数据开发；
2、负责物流平台实时/离线报表数据开发；

岗位要求：
1、一年以上SparkStreaming或者storm开发经验；
2、了解元数据管理；具有一定数据建模经验。


岗位职责：
 
1、负责和参与公司大数据基础架构平台的运维，保障数据平台服务的稳定性和可用性；
 
2、负责和参与超大规模数据存储与计算任务的精细化管理系统的设计，选型和开发；
 
3、负责和参与大数据基础架构平台的监控、资源管理、数据流管理；
任职要求：
 
1、掌握 Linux 操作系统的配置，管理及优化，能够独立排查及解决操作系统层的各类问题；
 
2、掌握 Hadoop、Kafka、Zookeeper、Hbase、Spark 的安装与调试；
 
3、掌握Java语言，至少精通 Python、Perl、Ruby、Bash 脚本语言中的一种；
 
4、有良好的系统性能优化及故障排除能力；
 
5、熟悉大数据周边相关的数据库系统，关系型数据库和 NoSQL

工作：
1、精通阿里云大数据产品的原理、方案；
2、基于大数据产品熟练进行数仓建设和进行数据开发治理，支持项目开发；
3、大数据项目咨询，对ISV或第三方进行大数据产品的培训和指导；

要求：
1、熟悉linux操作系统；
2、熟悉MySql/SQLserver/oracle等数据库产品，有数仓经验者优先；
3、熟悉hardoop/spark者优先；
4、熟悉greenplum者优先；
5、熟悉阿里云大数据产品者优先；
6、五年以上开发经验；

1.快速了解业务，为业务决策提供数据支持，包括指标体系构建和深入的商业价值分析   2.基于用户行为数据，构建高性能，低延迟的处理流程，产出中间数据和统计指标，支撑用户行为分析和平台运营；   3.对平台内外各种运营活动包括推广、拉新等提供数据支持   4.利用统计或者机器学习算法，独立或者合作进行用户属性/偏好/行为分析，并进行特征提取、建立用户画像，包括分类和聚类，并进行预测建模等   5.协助推进大数据应用项目落地。    
1.有丰富的数据分析建模经验，能够用最快速最简单的方法得出结论，驱动业务；   2.有用户分析或者产品分析经验或者运营经验，熟悉Logistic regression、Random   Forest、人工神经网络等机器学习算法者优先；   3.熟悉 Linux/Unix平台开发环境，精通sql &amp;   python能够熟练提取数据，熟练使用excel、SPSS或R等数据分析和统计分析工具；   4.熟悉分布式系统（如Hadoop/Spark）和算法设计，熟悉常用的分类、聚类、回归、图论等基础算法；   5.有数据挖掘、推荐系统、搜索系统、机器学习或自然语言处理相关工作背景；   6.对数据有极强的敏感性，能够从调研数据和产品数据中提炼分析，挖掘产品体验存在的问题，为产品体验优化做引导。      

岗位职责：1、负责用户数据、服务器数据的收集；2、负责数据后台的搭建与数据分析；3、负责数据界面可视化展示。我们希望你：1、本科或以上学历，计算机、通信电子相关专业，两年以上工作经验，一年以上大数据工作经验；2、有较强的程序代码开发能力和架构能力，扎实的Java/c基础，熟悉linux；3、学习能力强，具有较强的沟通能力及团队合作精神，富有大胆创新精神，勇于探索、善于突破难关；4、有安卓开发经验，python脚本编写经验，web前端开发经验者优先。

岗位描述：
利用机器学习实现照片视频内容识别，内容推荐，异常检测，解决产品功能以及运营实际问题。

岗位要求：
1.熟悉常用机器学习算法，线性/逻辑回归，支持向量机，神经网络，贝叶斯，聚类等，对其原理和实现有较为深度的理解和认识
2. Scala, Python, Matlab 基础扎实，熟悉大规模系统的负载均衡、缓存、网络存储、网络安全、数据库高可用设计及性能评估机制； 
3. 清晰的逻辑分析和表达能力，热爱技术，乐于分享，对行业和技术的发展有自己的见解，在大数据领域内有深入的研究和积累者优先； 
4. 熟悉各种大数据计算框架，例如Hadoop/Map-Reduce/Spark等分布式计算框架，对于如何创新设计新的体系来支撑更大更快的机器学习算法有强烈兴趣。 
5. 熟悉深度学习框架和相关技术，如CNN，Faster-RCNN，RNN，以及相关技术与框架包括，Tensorflow，Caffe，BigDL等

加分项： 
1、具备搜索引擎或推荐系统开发经验以及其他机器学习平台的开发经验； 
2、有机器学习相关领域经验者； 
3、熟悉亚马逊和微软等的机器学习平台工程实现方案等。 

1、 计算机相关专业硕士及以上学历，在机器学习，数据挖掘，统计学理论，最优化理论等领域有着深厚积累；
2、 熟悉机器学习和数据挖掘领域前沿技术；
3、 有机器学习、数据挖掘等相关项目有实际经验；
4、 编程基础扎实，熟悉算法数据结构，有超过五年以上Java、C++或Python开发经验；
5、 有大数据相关系统，如map-reduce、Spark、mpi等经验者优先；
6、 踏实勤奋，自我驱动，善于沟通；
7、 研发迭代线上算法，确保公司产品的长期技术优势；
8、 对公司新业务算法问题进行抽象和建模，并持续优化。

岗位职责
1、负责大数据平台的数据采集、处理、存储以及挖掘分析的架构实现；
2、参与大数据实时/批处理框架的设计和开发；
3、参与大数据平台的性能优化，不断提升系统的稳定性和效率，监控体系的设计和开发；
4、协助制订数据标准规范，优化IT、数据或业务部门的数据交互标准；

岗位要求
1、3年及以上java开发经验，2年及以上数据平台相关经验；
2、熟练掌握大数据分布式处理，机器学习，实时计算中的一项或多项技术；
3、熟悉目前正在发展的大数据分布式平台前沿技术的应用，包括但不仅仅限于：hadoop、hive、hbase、storm、spark、flink、dremel等等，并具有相关开发和数据建模经验；
4、熟悉分布式存储、NoSQL或者图数据库技术（如MongoDB、Redis、Cassandra等），有实际生产项目应用经验。
5、具备优秀的团队意识，良好的沟通和逻辑思维能力，能够对业务需求进行抽象并据此进行架构设计。

岗位职责：
1. 负责万亿级空间大数据平台研发：架构设计开发、服务设计开发、性能优化和成本管理等工作；
2. 负责每日百亿级LBS数据流的处理逻辑开发、优化、自动化和品质维护等工作；
3. 负责基于GIS、统计、机器学习等技术的海量数据处理以及挖掘的研发工作；
4. 负责建立对海量用户数据的可用性、完整型和机密性的一整套维护体制。

任职条件：
1. 熟练掌握关系型数据库和SQL， 以及HBase、Mongo 等常用 KVS 的使用和开发。精通PostgreSQL者从优；
2. 熟悉 PostGIS等空间数据库，以及GDAL 等GIS工具库。有3年以上研发经验者从优；
3. 熟练掌握 Python、Bash 等脚本语言，有3年以上开发经验。熟悉大数据开发工具；
4. 精通 Linux 操作系统，理解网络和存储技术原理，有能力针对大数据处理过程进行优化；
5. 有LBS数据服务开发经验或机器学习相关工作经验者从优；
6. GIS、测绘、数据挖掘、数学或计算机等相关专业硕士及以上学历；
7. 具有良好的个人素质及团队协作能力，能承担一定压力，有很强的分析和解决问题的能力，有强烈的责任心。

职位描述：职位说明1、基于产品线产品整体云化的发展，基于Hadoop平台进行相关架构设计与产品研发；2、指导产品开发人员基于Hadoop体系架构进行具体应用与部署；3、完成相关知识的培训与指导，保障相关应用软件的合理应用，保障系统稳定高效运行；4、跟踪Hadoop技术架构及其相关分布式技术的发展并进行相关研究工作；5、培养相关Hadoop技术架构开发与应用人员，完成部门级培训文档及相关工作；6、规划产品线分布式产品的技术发展与产品演进方向。任职资格1、 精通Hadoop1.0、Hadoop2.0框架，熟悉分布式系统部署、开发、测试、维护过程与方法；2、精通Hbase、Hive、Strom、ZooKeeper、Spark等分布式开源软件，有长期实际开发和应用经验，具备系统优化与性能调优能力;3、熟练掌握HDFS文件系统的应用开发与性能优化；掌握Map/Reduce算法与原理，具备二次设计与开发能力 ;4、精通Linux/Unix环境下的Java编程，良好的技术功底与长期的开发经验，熟悉脚本编程(Shell/Perl/Python)等；5、具有良好的沟通表达能力，良好的文档编写能力，善于团队合作、指导新人。
职能类别：高级软件工程师

具有2年以上设计开发经验，熟悉编程语言Python有良好的计算机和网络基础，精通linux文件系统、内核、性能调优，TCP/IP、HTTP等协议 懂hive，熟悉sql语言，懂数据库工作细致、善于思考，有很强的问题分析和推进解决的能力 强烈的责任心与上进心能够吃苦耐劳、抗压能力强 良好的沟通和协调能力 极强的业务推动能力、勇于接受挑战

职位描述：
1、负责大数据工程项目环境和接口的开发。
2、负责大数据项目开发和基础工程算法框架建设。
3、跟进大数据新的技术，及时尝试引进并使用到项目之中。


任职要求：
1、精通java语言和Mysql语言。熟悉hadoop、hive、hbase、flume、kafka、storm、spark、thrift等工程组件，以及能够基于这些组件进行大数据项目的开发。
2、熟悉常用大数据算法框架，如MLlib、Mahout、HiveMall等是加分项。熟悉python、scala语言等也是加分项。
3、有从事过大数据工程项目工作的优先。有互联网公司工作经验优先。

岗位职责：
1、负责大数据征信产品方案讨论、技术选型、架构设计与开发；
2、负责基于大数据平台建立相关的数据整合清洗、数据应用的设计和开发；
3、负责数据平台API的设计与研发工作，高性能读写接口实现。
岗位要求：
1、计算机相关专业本科以上学历，3年以上互联网平台或大数据开发与架构经验；
2、熟练掌握java开发语言，熟练使用主流Java开源框架；
3、熟悉Linux操作系统；
4、熟悉主流NoSQL数据库，如HBase、Mongodb、Redis等；    
5、熟悉至少一种大数据处理技术，并有实际项目经验，如Hadoop， Hive，Spark，Storm等；
6、有ActiveMQ、Kafka等开源中间件使用经验可加分；    
7.  有数据仓库架构设计、开发经验可加分。
公司简介：（ http://www.ccxcredit.com.cn/） 
      中诚信征信有限公司（简称“中诚信征信”）隶属于中诚信集团。在企业征信、个人征信、商业信息服务、市场调研咨询等领域，拥有十余年的丰富经验。公司始终坚守中立、客观、公正的理念，秉持专业、诚信、严谨的操守，做市场认可的独立第三方征信机构。      中诚信征信于 2014 年 6 月，率先获得全国企业征信业务经营备案资质，并于 2015 年 1 月，成为首批获准开展个人征信业务准备工作的独立第三方征信机构。作为第一批央行获得批准开展个人征信准备工作的民间征信机构，中诚信征信在商业利益驱动以外，希望能通过市场化行为和生活化应用让更多的人更好的了解个人信用的价值，促进我国社会化信用体系建设良性发展。
我们的优势 
  底蕴：隶属于中国最大的信用管理集团--中国诚信集团。
  资质：中国第一张企业征信牌照、首批个人征信准备工作牌照。
  专业：十余年征信行业领导者，持续专注于征信技术的研发。
   客观：坚持独立第三方定位，秉持客观中立原则。
 全面：线上与线下征信相结合，涵盖标准化与定制化服务。
 创新：中国首批互联网大数据征信的践行者。
我们的福利：
我们不仅为员工提供优厚的福利保障，还致力于打造轻松、愉快的团队环境：
——按国家标准缴纳社保、公积金；
——年度14-15薪；
——扁平化管理，平易近人的领导团队；
——丰富的内、外部培训分享平台；
——每周五4点半下班，开启各类丰富有趣的团建活动；
——弹性的工作时间；
——免费的优质午餐、可口的下午茶；
——位于东二环环境优美的独立四合院，紧邻地铁5、6号线东四站。
 

1、负责网易大数据平台和网易大数据云产品研发；2、网易大数据平台是服务于网易各大互联网业务的大数据开发计算平台；3、网易大数据云产品是网易云中的大数据基础设施产品；

资格要求：
1. 两年以上平台设计和开发经验，具备优秀的编程能力和良好的开发习惯。2. 熟悉调度系统如aws datapipeline、数加、oozie、azkaban等；3. 熟悉主流大数据产品（hadoop、spark、hive等）4. 熟悉数据ETL过程5. 熟悉Linux/Unix平台上的开发环境6. 优秀的理解和沟通能力，逻辑思维清晰7. 有大数据相关系统的开发经验优先

工作职责：
1.负责业务线数据实时计算的研发工作。
2.对接业务需求，提供实时特征更新机制。
3.持续改进系统架构、保证系统高性能、高可用性和高可扩展性。
工作要求：
1.精通Java语言，熟练掌握NoSQL数据库等技术，有大规模分布式系统使用经验。
2.熟悉Storm流式计算平台，熟悉Hadoop、Hive、Spark等分布式数据处理平台。
3.熟悉常用的设计模式，注重代码质量与可维护性。
4.优秀的分析及解决问题的能力，责任心强，细心耐心。
5.有搜索、推荐、排序等策略系统经验者优先。
6.优秀的分析及解决问题的能力，责任心强，细心耐心，对美食和吃文化有热情者优先。



岗位职责： 1、Hadoop集群设计包括软硬件架构、节点配置、网络、存储和容量规划； 2、大规模Hadoop集群部署、管理和日常运维、调优； 3、基于Hadoop各种开发工具和框架实施数据采集、分析和报表。 任职要求： 1、2年以上工作经验，本科计算机及相关专业学历； 2、基础扎实，熟悉数据结构和算法, 熟悉Linux操作系统； 3、熟悉Java、Python、Shell语言，较强的独立开发能力，具备良好的代码风格； 4、具备以下1种或多种工具的开发和实施经验：Java-Mapreduce, Hive, PIG, Sqoop, Flume, HBASE, Cassandra, MangoDB, CouchDB, Spark, Shark； 5、有独立分析和解决问题的能力； 6、能够承担一定工作压力，具备创新思维、具备团队协作精神。

岗位职责:1、负责个性化推荐系统中基于Spark/storm流式处理的海量用户数据的处理、挖掘工作； 2、负责离线/实时的用户画像/视频画像基础数据构建。
任职资格:1、本科及以上学历，计算机相关专业，3年左右工作经验；2、熟悉Hadoop、Spark、storm相关技术，至少有1年的Spark/storm开发经验；3、熟悉Scala、java语言，对Scala原理、底层技术有深入研究者优先；4、有推荐系统、数据挖掘、机器学习、自然语言处理等领域的理论基础和研发经验；5、有优良的Trouble Shooting能力。

职位描述
1、负责网站、APP的数据采集需求的实现
2、根据需求对数据进行实时或离线处理
3、对数据进行挖掘分析，实现个性化推荐、用户画像等一系列功能
4、数据可视化系统的搭建
任职要求
1、本科以上学历，计算机、数学相关专业背景；
2、具备3年以上工作经验，在大数据相关领域工作一年以上；
3、熟练掌握JAVA语言；熟练使用Linux操作系统；熟悉Java script，
4、掌握Flume，Kafka，Storm，Spark，hive，Hbase，zookeeper，mapreduce，HDFS，Yarn并有过实际项目经验；了解mahout或Spark MLIB，了解Oozie。
5、做事积极主动，能够主动学习新知识，具有高度的责任感与团队合作精神
6、熟悉数据挖掘算法、数据可视化、会使用Scala、Python优先

岗位职责：
1、根据业务需求，进行大数据分析产品的规划、设计和开发；
2、负责大数据平台架构，确定技术方案，建立大数据模型。

任职要求：
1、3年以上系统开发设计经验，有实际的设计开发经历；
2、熟悉hadoop、Hive、spark等相关技术；
3、熟悉spl、java、Python等开发语言；
4、具有良好的团队协作与沟通能力，对数据敏感。

岗位职责：
1、负责研发基于NLP技术的文本结构化技术，包括但不限于分类器、情感模型、实体识别、知识图谱、推荐引擎、文本摘要、机器写作等，并应用于工业级产品中；
2、主导基础模块的维护，包括但不限于，分词模块、各类基础词库、语料库等，以及各类具体的应用扩展和改造；
3、文档编写、参与发文

职位要求：
1、对自然语言处理和机器学习算法有较深理解。
2、熟练掌握至少一门编程语言（Java、Python或其他）。
3、有2年以上的文本分析相关的代码编写经验。
4、可以有效调研并实现工作中有可能涉及到的前沿技术，熟练阅读中英文相关文献。

职位描述：
这是一个很有挑战的工作，简单来说，你需要能读懂各类Paper并实现它们（虽然90%代码并不是你写的），但是真正的挑战是在生产环境下运行它们，而不是实验室或课堂。
我们不欢迎眼高手低的伙伴，我们需要能搞定产品的人。
也就是说，你的工作，除了那些高大上的内容，还有以下让人恼火缺不可缺少的内容，甚至是主要部分：
1、数据预处理，包括收集、分析和处理各类型数据——是的，这仍然是本行当的主要工作内容；
2、协助量化研发，开发金融方面的量化投资模型和交易策略，开发相关内部工具、提供数据；
3、Paper研究，搜集和整理业内外现有的各类量化投资策略和研究成果；

具体要求：
1、物理、数学、概率统计、金融工程、计算机等与数量分析相关的学科；
2、具有良好的数理统计功底；
3、具备丰富的数学建模经验，具有很强的数据处理能力；
4、熟悉C++、C#、Python、Java编程工具和编程语言；
5、勤于动手，有毅力，并乐于钻研。


职位描述：
工作职责：
1. 负责公司产品的数据开发工作，梳理数据基本指标，建立数据模型；
2. 优化与完善数据工具，以数据为驱动力，为产品策划和运营提供决策依据及策略指导；
3. 关注大数据应用相关方向的前沿研究，并将相关数据结合产品特点，设计数据个性化产品及可视化产品；
工作要求：
1. 统招本科及以上学历，知名公司背景优先考虑。计算机、统计学、数学、物理，心理学专业优先；
2. 3年以上相关工作经验，至少1年以上数据产品经验，侧重数据挖掘、数据系统、数据产品；
3. 熟悉互联网行业，对数据具有高度敏感性，有独立的理解和判断；
4. 具有较强的逻辑思维及梳理归纳能力，能够在繁杂中找出规则与秩序，制定规范；
5. 具有高效的沟通能力、良好的项目管理能力；
6、参与公司大数据平台建设；
7、设计数据接入的处理流程，以便从不同的数据源获取数据，并开发相关程序及服务；
8、响应业务对数据的临时分析需求。
岗位要求
9、熟练使用Unix/Linux操作系统，熟悉常用的shell/python，必须不局限于某一项特定的开发技术，需要能够根据环境快速适应新技术；

*1年ETL相关工作经验，技能突出者可酌情调整；
*熟练使用至少一种ETL框架；
*具备传统数据库的开发及管理的技巧. 有mysql/PostgreSQL经验更好；
*使用mapreduce/hive/spark进行数据分析及验证的技能优先；
*有hadoop相关经验优先。


    Future Data是国内最早致力于司法业务量化分析、提供司法大数据服务的企业之一。本着专业化、精英化的发展理想，专注于司法行业的数据分析、人工智能和信息化咨询等方面的业务拓展，帮助客户提升信息系统智能化并发现数据的潜在价值。    我们的团队来自巴黎综合理工大学、法国里昂大学、北京大学、中国科学技术大学、华东政法大学，北京科技大学、浙江大学等知名院校，我们拥有IBM、Cisco、Murex、华为、知名律所、法院的工作经验。Future Data是一支朝气蓬勃的创业团队，我们致力于推动司法领域的人工智能发展。

岗位名称：大数据开发工程师

岗位描述：
1、负责数据处理相关模块开发和实施；
2、负责大数据平台的维护和管理；
3、负责大数据相关功能的开发与实施；
4、根据需求，进行功能模块的代码实现；
5、根据开发要求规范编写开发文档；

任职要求：
1、熟悉hadoop/yarn/hbase/MapReduce；
2、熟悉java语言，2年或以上java开发经验；
3、熟练使用Spring MVC，Spring等框架，熟悉常用的设计模式；
4、熟练使用MySQL等主流数据库；
5、熟悉spark/spark SQL/spark streaming任意一项技术者优先；
6、能够熟练阅读英文文档者优先；
7、有较强的学习能力和自我提升欲望；
8、能够承受一定的任务及工作压力；

1、负责渠道平台运营数据云平台的建设； 2、负责海量数据的实时计算、离线计算、存储、查询； 3、参与数据平台自助化建设。招聘要求：
1、计算机相关专业，3年及以上相关工作经验,有扎实的计算机理论基础；2、熟练Java、Python服务端编程，有良好的编码习惯； 3、深入理解MapReduce，熟练使用Storm、Hadoop、Spark，并阅读部分源码； 4、熟练使用HDFS、Hbase、Kafka、ElasticSearch； 5、深入理解全文检索引擎Lucene，有优化经验者优先； 6、具备良好的学习能力、分析解决问题能力；7、具有高度的责任心和团队合作精神。              
        

工作职责：
1、  以用户产生的海量行为日志为基础，进行个性化推荐；
2、  熟练掌握推荐算法模型，了解算法的核心内容，负责智能推荐相关算法的设计和优化；
3、  对推荐效果进行跟踪，对推荐策略持续优化。
任职要求：
1、  学历：全日制本科以上学历；
2、  专业要求：计算机、数学、统计学等相关专业；
3、  工作经验：有2年以上互联网行业智能推荐工作经验；
4、  性格特征：沟通协调能力强、抗压能力强、工作积极、责任心强；
5、  语言和计算机：英语。

职位描述：
1.参与海量数据收集处理、分析，分布式系统框架、大数据基础架构等的设计、架构和开发工
作；
2.搭建高可用高扩展高性能的大数据处理系统、开发和维护大数据相关基础设施；
3.负责统计、数据分析等相关各类算法的计算框架及架构的设计和工程实现；


职位要求：
1.全日制本科及以上学历，计算机相关专业；
2.有扎实的 java 基础和算法基础，编程思维开放活跃；
3.熟悉 Linux ，并至少掌握 shell 、 Scala 、 Python 等其中一门开发语言；
4.5 年及以上 java 开发经验， 3 年及以上 Hadoop 开发与应用经验，大并发的分布式系统开发设计
经验；
5.熟悉 Hadoop 、 MapReduce 、 Storm 、 Spark 、 Pig 、 Sqoop 、 HBase 、 Hive 、 ElasticSearch 等主流
大数据技术的原理及技术，并有相关的源码阅读经验；
6.熟悉日志收集处理涉及的各种主流组件，如： Kafka 、 Flume 、 Scribe 等；
7.对数据敏感，善于发现数据中的潜在规律，有大数据分析、架构设计、深度学习者优先；
8.工作有计划性，责任心和执行能力强，具备高度的责任心和团队精神；
9.具有良好的语言表达和文档撰写能力，能够熟练阅读英文文档和论文，可以快速学习和掌握
新的方法和技术。

工作职责：                        1、根据项目大数据处理业务需求，设计大数据处理方案，实现相关功能。                        2、搭建和维护大数据集群，保证集群规模持续、稳定、高效平稳运行。                               3、制定大数据处理平台维护、优化、安全及高可用方案。                                        任职资格：                        1、本科以上学历5年工作经验，有丰富项目开发经验，精通Java等主流编程语言。                        2、熟悉Hadoop、Hbase、Hive等工作原理，2年以上实战经验，熟悉分布式计算实施过程中的各种问题。 3、熟悉Zookeeper、Kafka、Elasticsearch、Logstash、Mysql等，有丰富的运维经验者优先。                4、熟悉Linux/Unix系统，熟悉Shell脚本语言。5、具有较强的沟通能力，工作协作能力，学习能力，执行力和组织能力。                                         6、工作态度积极主动、细致、有全局观，有一定的抗压能力，善于与他人合作，良好的团队合作意识。

岗位职责：
1. 基于Hadoop(CDH)大数据系统平台核心模块设计和实施；
2. Hadoop及相关组件Flume、Hive、Spark等功能开发和性能优化；
3. 负责内外部数据在大数据平台上的收集、存储、处理、提取等数据流项目的实施；
4. 为数据仓库、数据挖掘建模等数据应用项目提供支持；
任职资格：
1. 本科及以上学历，计算机、统计学等相关专业，2年以上相关工作经验；
2. 熟悉Linux开发环境和shell脚本；
3. 熟悉Hadoop及其相关组件开发，有实际项目经验；
加分项：
1. 具有Hadoop大数据平台监控、运维经验；
2. 具有数据仓库经验

职位描述：
1. 完成日常数据统计需求；2. 进行基础的数据整理和分析；3. 负责海量数据的处理、分析和挖掘工作；

任职要求：
1. 计算机相关专业，3年及以上相关工作经验,有扎实的计算机理论基础；2. 熟练掌握 Java 编程语言，并熟悉 Shell，Python 等一门以上脚本语言；3. 熟悉 Linux/Unix 环境；4. 有 Hadoop 框架开发经验，深入理解MapReduce、HDFS；5. 熟悉Hive、HBase、Spark者优先；6. 逻辑思维能力强，对数据敏感，有较强的学习能力和创新思维；7. 具备良好的学习能力、分析解决问题能力。

岗位职责：
1、参与大数据应用产品架构的整体规划和设计； 2、制定数据处理整个流水线的相关规范； 3、大数据应用开发过程的技术难点攻关； 4、将技术实现及业务场景联系起来，根据业务需求快速提出技术解决方案；

岗位要求：
1、全日制统招本科及以上学历，计算机、数据相关专业； 2、5年以上工作经验，不少于2年大数据架构经验、3年web系统架构经验； 3、熟悉数据仓库设计，有2年以上实际数据产品研发经验； 4、熟悉数据爬取、存储、清洗、挖掘、API服务整体技术系统架构； 5、精通Hadoop生态技术，包括Yarn、Hive、Spark、Kafka、HBase、HDFS、Sqoop、Flume、Presto、Zeppelin等； 6、熟悉实时计算框架Storm、Flink、Spark Streaming其中之一； 7、精通java编程语言、Spring框架，熟悉Scala编程语言； 8、良好的系统编程、算法基础、系统设计能力； 9、工作态度积极主动、细致、有全局观，有一定的抗压能力，善于与他人合作，良好的团队合作意识； 10、有互联网、电商行业工作经验者优先。

岗位职责：

1、承担数据采集、抽取、清洗、转化等数据处理程序开发；
2、商用平台指标数据挖掘；
3、负责公司大数据集群的构建，任务调度、监控预警，持续完善大数据平台，保证稳定性、安全性；
4、跟进了解开源社区Hadoop、Spark相关的进展，深入研究大数据业务相关运维技术，持续优化集群服务架构，探索新的大数据运维技术及发展方向 ；
5、主动学习新的技术，并为公司培养大数据相关人才。

任职要求：

1、大学专科及以上学历，具有良好的学习能力、沟通能力、团队合作能力及适应能力；
 2、熟悉inux开发平台及工具链，熟悉Linux系统的配置管理；
 3、掌握Python/Shell/Java/Scala中至少2种开发语言；
 4、具备Hadoop/Kafka/Zookeeper/Spark/Storm/Flume/Hive等框架开发使用以及集群运维经验者优先；
6、具有机器学习经验者，并熟悉相关算法；
7、云计算平台经验者优先，熟悉Docker相关技术；
6、能够承担较大的工作压力，研究系统管理相关技术，有较好的自我驱动能力和责任感。


1、我们是怎样的一个组织？
有梦想，梦想照亮前进的路；
有朝气 ，年轻是我们力量的源泉；
有品味，只做行业顶尖；
踏实进步，热爱分享。
2、我们在做什么事？
用工匠精神打造移动互联网的解决方案，
用百年育人的态度为学子提供高端的岗前实训，
以“合伙人”的方式为人才提供全面的创业扶持，
追求IT极客的终级目标！
3、你来了能做什么？
无限成长的空间，无限增长的回报

岗位职责：   1.  负责大数据采集、存储、计算、分析等场景的通用架构设计和开发   2.  负责流式数据的实时传递、清洗、转换和计算（实时统计、分析等）的设计和开发   3.  负责大数据中间件的设计和开发   4.  负责以上各种架构平台及相关基础技术组件的稳定性保障及源码级的bugfix   任职要求：   1.  计算机相关专业，三年以上工作经验，具有大型系统的技术架构/应用架构/数据架构的的自主研发经验   2.  深入使用Java，熟悉掌握常用的Java类库及框架，如多线程、并发处理、I/O与网络通讯，Velocity、Spring、Hibernate、iBatis等，对SOA模式有较深的理解   3.  对Java虚拟机有较深了解，有运行态JVM分析及调优的实际经验，有Linux下的开发或运行环境操作经验   4.  熟悉并使用过各种大数据相关框架或组件优先，如Kafka、Storm/JStorm、Hadoop/Spark、Hive、HBase等，特别是有Spark实战经验/海量数据处理经验者优先   5.  具有良好的产品Sense，从商业需求到技术实现的映射能力，能够开发创新，以实际的分析方法去抽象分解复杂的业务需求问题   6.  具有良好的沟通、团队协作、计划和主动性思考的能力，在互联网或大数据业界有一定影响力公司的工作经验者优先 

岗位职责：
1)负责环保大数据产品的开发设计。 2)参与产品及相关项目的需求讨论、制定开发计划、负责系统架构的搭建以及核心模块的详细设计、check点检查、上线计划等工作；3)带领初级工程师完成产品相关项目的核心编码。

任职要求：
1)本科或以上学历，计算机相关专业，3年以上软件开发经验；
2)熟练掌握Java开发技术，熟悉应用服务器（WebSphere、WebLogic、JBoss之一）； 
3)熟悉大型关系型数据库（如Oracle、SYBASE、MS SQL Server等），具备B/S应用系统的体系设计、关系型数据库结构设计与优秀编程开发能力；
4)熟悉和理解Java开发各层次框架，如struts、spring、hibernate等，掌握基本Web前台技术； 
5)有系统架构搭建经验，在过去的项目中担任核心开发人员；
6)热爱大数据，对于hadoop开源框架有所了解，具备良好的程序开发驾驭能力，需求分析把握能力；
7)熟悉XML、UML技术、了解开发规范和测试技术；
8)可接受适当的出差工作。

工作职责： 1.负责广告大数据平台的架构和开发 2.负责广告业务数据的统计和多维数据分析 3.数据挖掘，机器学习，推荐算法
 职位要求： 1.本科或以上，计算机软件或相关专业毕业； 2.扎实的编程能力，熟悉算法和数据结构，熟悉计算机的基础理论； 3.熟练使用Java，熟悉Shell、Python、R、Scala等一种以上语言 4.熟悉大数据处理相关技术，包括但不限于Hadoop、Hive、Hbase、Impala、Spark，Kafaka、Flume、Sqoop、Storm、Redis等 5.熟悉推荐系统和数据挖掘算法者优先； 

岗位职责：
1.负责大数据平台的建立、维护；
2.参与基于大数据平台建立相关的数据整合清洗、数据应用的设计和开发等。
3.参与跨部门协作，提升数据质量、稳定性和性能；
4.负责处理推荐系统相关数据流和数据整合。
任职要求：
1.统招二本及以上学历，计算机相关专业，2年及以上大数据相关开发经验；
2.熟练Java开发，了解 Spark, HBase, hadoop、Kafka，flume等相关技术和原理；
3.必备一定的沟通、协调能力和抗压能力，良好的自我学习驱动；
4.加分项：熟悉Python、Scala等其中一种编程语言，可用python做数据分析；熟悉统计学原理或机器学习等理论。

工作职责：
1、负责公司大数据平台建设，包括架构设计以及分析功能系统设计；
2、基于海量数据的数据仓库建设和数据统计分析，同时针对各业务场景探索大数据解决方案；
3、负责大数据分析需求设计和开发，包括数据集市搭建、实时分析、数据展示等的开发；
4、参与公司大数据处理方向的技术创新。
应聘要求：
1、本科及以上学历，计算机、统计和应用数学等相关专业；
2、三年以上大数据分析相关工作；
3、深入理解HDFS和MapReduce，熟悉scala或java语言编程；
4、熟悉Storm、Spark/spark streaming、Kafka、Hive、Hbase，并阅读过部分源码；能对程序进行故障分析、性能调优；
5、了解数据仓库概念，精通SQL，熟悉oracle等数据库，有使用一种ETL工具经验优先；
6、具备良好的学习能力、分析和解决问题能力；
7、具有高度的责任心和团队合作精神


1、有扎实的Java基础，熟练掌握IO、多线程、集合、消息处理等技术；    2、对Hadoop大数据处理体系有深入认识，有相关产品（HDFS，YARN，MapReduce，Spark，kafka，storm，sqoop，hive，hbase）项目应用研发经验；熟悉相关产品的接口API；    3、熟悉Linux/Unix开发环境；    4、熟悉分布式存储计算系统的相关理论技术，有一定Hadoop源码研究开发者优先；    5、熟悉数据挖掘、机器学习算法，有Mahout或者Spark ML数据挖掘开发经验者优先。    

岗位职责
1.负责公司Spark集群的架构设计和开发；
2.实现基于Spark框架的分布式计算框架的开发；
3.Spark技术研究和通用数据平台的性能调优；

职位要求
1.本科及以上学历要求，计算机或相关专业背景；
2.四年以上数据领域技术开发经验，其中两年以上Spark开发经验；
3.熟悉Python、Scala语言；
4.熟悉Spark Streaming和Spark SQL，对Spark原理及底层技术有深入了解；
5.良好的团队合作意识、沟通能力；
6.有过海量数据系统开发经验者优先；
7.有智能家居、物联网或一线互联网公司从业经验者优先。

岗位职责：  1、 基于大数据平台完成各类统计和开发任务。  2、 完成日常数据分析查询需求  3、 数据仓库的设计，开发，维护  任职要求：  1、 两年以上的BI相关项目经验,、熟悉数据仓库基本原理。  2、 熟练掌握java，具有hadoop或者spark的开发经验。  3、 熟悉Linux系统，能在Linux系统环境下完成开发  4、 强烈的责任意识，有进取心，有较强的学习能力，理解能力

1.参与亿玛实时计算平台的迭代，解决各种线上问题，逐步完善系统，提升系统的吞吐率，保证高可靠性。2.推进实时计算平台在产品落地，提升自动化水平，提升用户体验。3.能够独立完成一个实时分析系统的设计，并主导代码实现，测试及上线。岗位要求:1. 对数据结构及算法有一定的了解，动手能力强2. 掌握实时计算技术体系包括数据采集、消息队列 Kafka、计算引擎 Storm/Flink3. 对实时计算所涉及的事务、容错、可靠性有深入理解4. 精通 java，了解 JVM ，熟悉 linux 平台，掌握 shell 的日常使用，掌握 clojure 的加分。5. 熟悉 Hadoop 生态圈：掌握 MapReduce、Hive6. 熟悉 ElasticSearch 及其生态圈7. 对大数据技术充满热情，有流式计算开源项目 Kafka、Storm 有源码级研究的更优。8. 具有大型实时计算系统构建者，大数据引用经验者优先。

        职位职责：
1、负责头条各核心业务数据仓库的架构设计和实施，紧跟业务发展，推动规范的制定和落实
2、负责大数据产品的模型提出&amp;优化、系统设计、开发和维护，和产品、分析师等紧密合作，让数据充分发挥价值
3、针对复杂的业务场景，探索和实施新的技术方案，与业务团队一起发现、解决数据流及相关技术问题

职位要求：
1、热爱计算机科学和互联网技术，乐于快速学习和尝试新技术、新工具，良好的沟通和理解能力
2、具备强悍的编码能力，熟悉 linux 开发环境，熟悉 Python 语言优先；
3、具备在复杂业务场景中发现和解决数据&amp;业务问题的能力，不被固有方案限制，对解决有挑战性的问题充满激情
4、熟悉至少一个分布式框架，如 Hadoop/YARN、Hive、Spark、Storm、Kafka 等
5、有大数据处理、数据平台、数据仓库经验者优先
        
岗位描述：1. 海量交通领域大数据的分析/处理，包括海量数据的存储、计算和检索；2. 基于分布式平台（MR/storm/Spark/flink）的业务数据分析和逻辑job的开发；3. 开发数据统计系统。
岗位要求：1. 计算机、数学或统计学相关专业本科以上学历；3年以上数据的开发相关经验，特别是(1) 离线领域hadoop的ETL开发经验或者 (2)实时计算领域包括storm、spark、flink等的开发经验其中之一经验者；2. 有很好的海量数据开发经验，理解元数据管理。具有一定数据模型和数据架构基础；交通领域大数据工作者更佳；3. 熟悉unix或者linux，具备优秀的编程能力，熟练掌握java或者scala开发，有storm、spark、flink等等语言中的一种或几种经验者优先；4. 对数据敏感、对技术敏感，有研究的意识和直觉者更佳；5. 有良好的团队合作意识，沟通表达能力和综合协调能力。

我们在寻找并肩战斗的小伙伴，我们需要你：• 分析数据、使用数据，实现及优化推荐系统效果 • 理解用户数据分析和挖掘应用场景，抽象为数据产品需求，不断完善基础数据的建设• 负责设计，实现或改进分实时流式计算平台 (数据量: 数个TB / 天）我们希望你：技术上：• 熟悉Scala语言，对Scala原理、底层技术有深入研究者优先 • 熟练使用spark BDAS 各组件，对基于内存的计算框架有深入理解• 精通Hadoop、Hive、Storm、Spark、Hbase、zookeeper、Kafka、Flume等分布式框架• 熟悉常用开源分布式系统，Hadoop/Hive/Spark/Yarn，精通源代码尤佳 • 熟练使用spark机器学习算法包

岗位职责:1. 本科及以上学历，2年及以上互联网系统或者其他企业应用系统开发相关经验；2. 熟悉Hadoop/HBase/Spark/Storm/Hive，熟悉数据挖掘策略与算法；3.具备JAVA系统开发经验，熟悉Hadoop(MapReduce/HDFS)、Kafka、Spark、Strom、HBASE等开源大数据技术的开发与部署；4. 数据控，善于发现问题、解决问题,具备良好的分析和解决问题的能力，具备一定的钻研精神和持续学习的意愿，强烈的责任感和团队感，对负有挑战性的工作充满热情。

工作地点：北京
岗位职责：
负责公司数据中心的需求分析、方案设计、系统开发、系统测试等工作
任职资格：1. 全日制重点大学应届毕业生，计算机、软件工程等相关专业，硕士研究生及以上学历；
2. 专业基础扎实，具有良好的沟通能力、学习能力、分析判断能力，良好的职业素养与团队合作意识，创新意识强；
3. 具备良好的身体素质与较强的抗压能力；
4. 具备大数据研发经验，熟悉Hadoop/HBase/Spark/Storm/Hive；
5. 具有证券从业资格、软件工程师相关认证资格者优先；
6. 具有金融行业数据中心建设经验优先； 
7. 具有量化平台开发经验优先；

1、计算机相关专业毕业，2年以上工作经验；
2、熟练掌握oracle数据库的大体结构，了解Java或shell；
3、熟练掌握PL/SQL，熟练掌握函数、存储过程，练掌握hive、spark等,了解hive脚本优化方法；
4、会编写pl/sql脚本，从数据库中提取清单，并验证；
5、良好的沟通能力和逻辑思维能力，团体协作精神，要有责任心，

岗位职责：1.负责管理公司全平台多业务线的数据采集埋点方案并保证采集的准确性；2.参与日常运营、安全风控、推荐搜索、算法等相关大数据业务的需求沟通，并负责保证埋点、收集、ETL、DW（整套大数据方案基于阿里云ODPS）的进度满足业务需要；3.持续优化整套大数据方案（包括埋点、收集、ETL、DW）的性能、设计的合理性、效率等用来满足公司未来大数据需求。岗位要求：1.计算机相关专业本科以上学历，5年以上软件研发经验，2年以上大型软件架构和大数据经验；2.有很强的数据设计抽象能力，善于从复杂的数据问题中找到关键路径；3.熟悉Hadoop、Spark，impala、hbase、实时计算，对大数据生态圈有整体认识；4.有推荐引擎、机器学习、用户行为分析项目工作经验者优先，有负责项目和带领技术团队的经验优先；5.具有较强的团队意识与良好的沟通能力，高度的责任感，较强的学习能力以及快速解决问题的能力。

岗位职责:1. 负责公司大数据平台的设计和开发，数据仓库建模、数据预处理子系统的设计和开发；2. 负责海量数据的处理、分析、挖掘；3. 负责高并发、大存储的数据系统，实时计算处理系统的研发；4、大规模Hadoop集群部署、管理和日常运维； 任职要求：1、计算机或相关专业本科以上学历，3年以上Java语言为主的软件开发经验；2、熟悉了解Mapreduce、hbase、hive、Solr等hadoop相关组件优先3、精通JAVA技术知识，熟悉IO，多线程，异步处理，集合类等基础框架和常用中间件产品，熟悉缓存，消息，搜索等机制；4、精通Linux环境下开发部署，熟悉Shell编程；5、熟练掌握编写SQL语句以及MySQL、Oracle、DB2等任一种关系型数据库的使用

负责数据项目的研发及维护，大数据相关新技术的研究。任职条件:1.6年以上java项目研发经验。至少有2年的项目需求分析经验，有数据项目研发经验者优先。2.熟练使用Spring、Mybatis等开发框架，能熟练进行项目的前后端开发和代码评审，有系统架构设计经验者优先。3.熟练掌握Oracle数据库，有业务建模经验，能实现较复杂的查询，熟悉多维技术、有数据仓库建模经验者优先。4.熟悉HTML、CSS，熟练掌握Javascript语言，熟练使用JQuery框架。至少使用过一种前端图表框架，有数据可视化研发经验者优先。5.熟悉Linux的基本操作，有Linux运维经验者优先。6.有Hadoop、Spark或者数据相关技术实际研发经验者优先。7.有数据挖掘项目研发经验者优先。8.有团队管理经验者优先。

岗位职责：
1、负责产品后台的业务逻辑。 
2、负责招聘数据的分析工作，包括简历数据、岗位数据、企业数据等。 
3、理解产品需求，提出解决方案并实现。 
4、快速理解现有的产品解决方案，提出改进方案并实现。 
5、探索产品的新需求和实现的新方法。  

岗位要求：  
1、计算机科学相关专业硕士以上学历。 
2、熟悉至少一种关系型数据库的设计和数据操作，例如MySQL、PostgreSQL等。 
3、有至少1年的Java/Scala/Python的程序开发经验。 
4、熟悉机器学习（含深度学习）算法和自然语言处理算法。 
5、有Hadoop/Spark开发经验者优先。 
6、有Keras/TensorFlow/Theano/PyTorch开发经验者优先。
7、热爱科技创新，有极强的学习新技术的能力和自我驱动力。 
8、强大的抗压能力。
9、英语能力优秀者优先。

福利待遇：
1、¥15k-20k每月
2、优厚的年终奖
3、五险一金
4、和能力相匹配的期权
5、工作地选择权，可根据需要选择深圳办公室或香港办公室
6、学术会议资助
7、优秀人员可帮助申请深圳市孔雀计划，由于公司符合相关政策，深圳政府可补贴孔雀C到A类人才160万到300万，不用缴税哦

岗位职责：
1、负责数据分析平台的设计和开发工作；
2、负责海量数据的处理、分析和挖掘工作；
3、负责日志处理，用户行为分析，用户画像等开发工作；
4、负责实时处理系统的设计和开发工作。

任职资格：
1、本科及以上学历毕业， 3年以上工作经验，有大型互联网公司从业经验优先。
2、熟练掌握 Java/Python 语言，并熟悉 Shell 等一门以上脚本语言；
3、熟悉 Linux/Unix 环境，有 Hadoop 框架开发经验；
4、熟悉ELK，EMR等优先 ；
5、了解 Hive，Hbase，Spark，Storm 等一种以上大数据处理工具和技术；
6、逻辑思维能力强，对数据敏感，有较强的学习能力和创新思维；
7、具备良好的沟通能力和文字表达能力，有较强的团队协作能力。

岗位职责：
1.负责数据服务类和平台类数据产品的规划，需求分析和产品设计；包括多来源的数据整合、数据挖掘及API接口设计；   2.研究大数据能力平台化和开放的形态和生态，推动业务领域内的数据产品的创新和设计； 3.负责与平台开发团队一起，规划和完成需求的收集、沟通、规划、项目推进、效果验收、线上故障跟进、用户反馈与产品运营等全过程； 4.与数据分析师团队共同完成基础维度指标体系的搭建（数据需求的分析，指标、维度定义，指数输出，算法迭代等；5.负责在项目推进过程中的跨部门跨公司协调沟通工作，能够协调各资源以确保产品顺利发展。    

任职资格：
1.5年以上互联网产品或开发经验，3年以上数据行业工作经验；2．自我驱动力强，跨团队与部门的沟通能力强，有较强的团队协作意识和能力；3.深刻理解产品研发和运营流程，善于挖掘真正的用户需求，懂得产业链价值搭建，设计高度可运营的版本；思维开放、善于学习创新，较强的逻辑分析能力；4.有比较丰富的产品经验，从需求的确认、产品的原型，文档的撰写、资源的协调，产品上线后的跟进与项目管理； 5.具备数据仓库和BI系统知识与经验, 能使用数理统计方法进行数据分析；   6.具备较强的SQL实操能力, 能独立完成基础的数据探查工作，有使用Hadoop, Hive, Spark处理数据经验者优先。    

职责：1、负责公司大数据平台的开发；2、支撑日常业务数据需求，问题跟进并及时解决。

要求：1、计算机、数学等相关专业，本科以上学历； 2、熟练掌握Java/Scala语言，具有2年及以上Java/Scala开发经验，熟悉linux操作；3、具有2年以上大数据系统开发经验；4、熟悉Hadoop、Spark、Storm等相关技术，具有1个以上大数据平台项目实施经验；5、熟悉Zookeeper、Kafka等相关技术；6、有较强的学习能力，对技术有钻研精神，热衷于新技术学习和实践并乐于分享；7、优秀的团队合作精神，对工作有热情；8、有大数据实时计算工作经验者优先。
 

主要职责：
理解产品设计，负责大数据平台后端功能的实现；
在上级的领导和监督下定期完成量化的工作要求；
根据开发进度和任务分配，完成相应模块软件的设计、开发、编程任务；
进行程序单元、功能的测试，查出软件存在的缺陷并保证其质量；
进行编制项目文档和质量记录的工作；

能力要求：
1、3年以上java开发经验，基础扎实；
2、精通Spark和Hadoop生态，有大数据平台产品架构经验优先；
3、精通SpringMVC，Mybatis等开源框架；
4、熟悉mysql和NoSQL数据库；
5、熟悉使用maven、SVN、Eclipse等工具；
6、有互联网产品开发经验，熟悉大数据和云，有微服务开发经验者优先；
7、熟悉Redis，Kafka，Nginx，Dubbo等；
8、有海量数据，高并发高性能分析及处理经验优先；

岗位职责：
参与大数据平台或产品的系统架构建立，负责项目需求分析、设计开发；
主要负责Hadoop平台ETL、算法封装、环境部署等工作，操作日常作业的部署和调度；

任职要求：
熟练使用Java语言，拥有两年以上Java开发工作经验，能够在Hadoop/spark/HBase/storm之上进行开发，熟悉Jvm运行机制及内存管理者优先；
熟悉Linux开发环境，能够熟练使用shell、python等脚本；
精通Oracle、Sql server、MySQL等关系型数据库系统及PL/SQL等脚本编写；
熟练使用MapReduce、Spark、hive等大数据平台工具，能够独立安装部署系统，分析解决集群的运行故障；
有较好的独立工作能力和团队协作精神，有较好的沟通能力。
有运营商大数据平台开发经验者优先，如DPI或信令数据的解析、客户标签开发等开发经验；
有大数据可视化开发经验者优先，如熟悉e-chart等开源工具；

工作职责：
1、运用数据挖掘和机器学习方法和技术，深入挖掘和分析海量商业数据；
2、包括但不限于风控模型、用户画像、商家画像建模、文本分析和商业预测等；
3、运用数据挖掘/统计学习的理论和方法，深入挖掘和分析用户行为，建设用户画像；
4、从系统应用的角度，利用数据挖掘/统计学习的理论和方法解决实际问题。
岗位要求：
1、计算机、数学，统计学或人工智能等相关专业硕士以上学历，3-6年以上或相关工作经历；
2、精通1-2种编程语言（Python或Java），熟练掌握常用数据结构和算法,具1、备比较强的实战开发能力，能带领团队共同进步。
3、具有统计或数据挖掘背景，并对机器学习算法和理论有较深入的研究；
4、熟悉数据挖掘相关算法(决策树、SVM、聚类、逻辑回归、贝叶斯)；
5、具有良好的学习能力、时间和流程意识、沟通能力；
6、熟悉Spark或hadoop生态分布式计算框架；
7、优秀的沟通能力，有创新精神，乐于接受挑战，能承受工作压力。

职位描述：
1、合理规划产品发展与功能设计，结合行业发展趋势，制定产品策略，找到产品的发展方向，协调推动产品功能实施；
2、调研、挖掘、分析用户需求，准确抽象出产品需求，合理判断需求的优先级，并维护产品需求池；
3、使用原型、流程图、PRD等方法将需求转化成可供需求方、设计和开发使用的文档，并与各方沟通确认；
4、规划管理产品进度，推动产品的技术实现，把控产品实施质量和效率；
5、负责征信、互联网金融行业研究，业务模式探索；
6、负责对产品的整体设计，与市场、IT等各部门沟通协调，保证项目按时交付。
 
岗位要求：
1、统招本科及以上学历，4年以上互联网产品工作经验，有成功产品案例者优先，具有征信行业从业经历优先考虑；
2、具有较强的沟通能力，有团队合作精神，逻辑性强，擅长数据分析和需求调研， 具备一定的商业意识和行业知识。
3、具备良好的需求分析和产品设计能力，可以完成PRD等标准产品文档撰写；
4、熟悉互联网金融产品实现流程，及产品设计和产品开发基本流程，并能熟练进行金融产品设计和项目管理；
5、做事积极主动，沟通协调良好，逻辑思维清晰，对工作认真负责，有较强责任 心、执行力和抗压能力强。

岗位职责：1.智能物流系统后台开发
       2.区域电商平台后台开发
任职要求：1.精通Java编程，熟练应用Spring、MyBatis、Dubbo等开源框架
      2.精通使用常用服务器，前端、后端、安卓的移动端
      3.精通UML语言，有独立分析、设计和开发的能力
      4.精通Mysql、Oracle,DB2等数据库，具备Redis、Memcache等技术的实际开发经验
      5.具备良好的沟通交流、团队协作能力
      6.具备系统调优、性能调优等技能，对疑难技术问题具备较强的排查能力
      7.掌握Maven（项目管理软件），SVN、Git源码管理工具：SOA架构设计、RESTFUL接口及相关规范
      8.熟悉Linux环境及常用shell脚本
      9.熟悉异步、多线程及线程池、分布式、缓存、负载均衡、消息队列等技术的设计和应用
      10.具有分布式服务、高可靠性集群、并发编程和自动部署等经验者优先
      11.具有glassfish、jboss等应用服务器软件的实际开发经验、对大规模系统具有一定的规划能力

岗位职责：1、基于Spark、hadoop等构建数据分析平台，进行设计、开发分布式计算业务；2、关注业界大数据动态和发展方向，并能够独立研究；3、辅助管理Spark、hadoop集群运行，稳定提供平台服务；4、完成与工作相关的技术文档编写工作。5、完成上级交代的其他工作；任职资格：1、本科及以上学历，2年以上编程经验，熟悉Spark、hadoop研发、熟悉大数据集群的搭建、管理及优化；2、熟悉hdfs/hbase/hive/spark/mapreduce/pig/mahout/impala，有丰富的分布式编程经验；3、熟悉java研发，有实际编程经验；4、熟练使用sql；5、熟练掌握linux操作系统，熟悉shell等脚本编程；6、有海量数据的分析能力和处理经验、对数据分析和数据挖掘有浓厚兴趣者优先考虑；7、熟悉Lambda架构者优先考虑

岗位职责：
１、 数据采集，统计埋点的规划，建立相关的统计模型；
２、分析和挖掘业务数据找出有意义的问题，并进行验证和改进，或指导产品，算法的演进方向
３、基于大数据分析平台的产品设计、开发、测试和部署；
 
任职要求：
１、熟练使用Linux，良好的编程基础， 熟悉SQL，java, python 。
2、熟悉常用机器学习算法（如 svm, k-means，HMM），了解算法内在原理
3、有人物画像，个性化推荐，点击预测，搜索相关工作经验.
4、了解大数据生态圈，使用过Hadoop、Hive、Hbase、Spark、Storm等分布式开源项目开发.
5、具有较好的沟通能力和团队合作精神。

团队简介：大叔主管，老骥伏枥，深耕代码世界。
公司简介：杭州不可多得的低调、优质移动互联网公司，人性、平等、扁平的管理风格！我们提供：双休、带薪年假、五险一金（全额12%）、B轮公司成长机会，2017“亲宝宝”期待你的加入！

岗位职责：
1.负责公司数据仓库、大数据平台报表平台的建设；
2.负责搭建基于SAS/Hadoop的数据分析平台和大数据平台；
3.负责完成业务部门提出的各种数据分析和报表需求的开发；
4.基于对业务的理解和数据挖掘发现新的业务知识点。
  
任职要求：
1.本科及以上，计算机相关专业；
2.3～5年的大数据相关开发组织工作经验；
3.熟练掌握MySQL数据库开发技能；
4.具备大数据处理Hadoop/MapReduce及Hive、Spark、Hbase等项目经验；
5.具备独具有深厚的统计学、数学、人工智能和数据挖掘知识基础，有1年以上数据挖掘项目实践经验；
6.具备掌握至少一种统计分析和数据挖掘软件，最好精通R语言；
7.具备基于Hadoop平台的建模算法实现和优化的工作经验；
8.具备金融行业、电子商务相关行业项目经验者优先。

 职位描述:1. 负责维护公司的各种环境.2. 学习分享各种新技术, 以工作要用到的优先.3. 优秀应届生亦可任职资格:1. 喜欢技术,乐于分享. [必须]2. 良好的英语阅读能力. [必须]3. 熟悉(centos|rhel|ubuntu). [必须]4. 掌握(shell|python|ruby|perl|php|*)任意一门语言. [必须]5. 熟悉hadoop核心组件,且独立部署并维护过数量大于10个节点的hadoop集群.[必须]6. 有(github|其它开源代码|个人站点|*). [加分项]7. 熟悉网络设置和存储设备的配置和管理(cisco|huawei|emc|*). [加分项]8. 熟悉(nagios|zabbix|puppet|jenkins|gitlab|cloudstack|openstack|saltstack|docker|ceph|mariadb|markdown|aws|azure|cloudera|hortonworks|*)任意一种或多种. [加分项]

该岗位是北京分公司需要，前期需要来上海总部培训2-4周，具体看个人的基础。

岗位职责
-深入研究支撑大数据业务相关技术，持续优化服务架构-深度参与数据处理和存储的业务系统的设计与实施-分布式存储计算框架的bug修正、二次开发及性能优化-大数据技术前瞻性研究与实现-大数据相关产品调研、优化和功能开发
任职条件
- 本科或以上学历，计算机相关专业，有操作系统、数据库等专业知识基础- 良好的系统分析、代码编写能力- 需要有较强的学习能力和思考问题能力，责任心强，有良好的沟通适应能力- 熟悉Java，熟悉IO、多线程、RPC等基础技术- 实践并较熟悉一个以上大数据计算框架（Hadoop、Spark、Storm、Flink等）- 实践并较熟悉一个以上大数据数据库或查询引擎（HBase、Hive、Cassandra、ElasticSearch等）加分项：- 有大数据或高性能项目的源码阅读和修改经验- 有参与过自研大数据或高性能项目- 有开源社区代码贡献经验- 有技术负责过较大数据规模的项目经验- 有非常强的自我驱动和学习能力，自信能弥补一定程度的经验不足

岗位职责：
1.负责研发类大数据平台的规划、设计、开发和运维工作；
2.负责海量数据的实时计算、离线计算、存储、查询；
3.参与数据平台自助化建设。
任职资格：
1.本科及以上学历，计算机或相关专业；
2.有3年及以上大数据平台开发方面相关工作经验；
3.熟悉数据仓库和数据建模的相关技术细节，熟悉SQL/Hadoop/Hive/Hbase/Spark等大数据工具；
4.扎实可靠的编程能力，精通C/C++/JAVA至少一门编程语言；
5.具备良好的学习能力、沟通能力、适应能力，责任心强，能在压力下独立解决问题；
6.海量数据处理经验，或有互联网行业数据挖掘工作经验者优先。

工作概述：
1、参与大数据平台技术层面的设计、开发、布署和维护工作。2、参与跟踪大数据相关的最新技术，并能应用于平台的改进和优化。
 
任职资格：
1、本科以上学历，计算机以及相关专业。2、熟悉Java语言，具有多线程和分布式的实际开发经验，熟悉J2EE架构、SSH框架，熟悉Linux环境下的开发，熟悉SQL。3、有较丰富的实际项目开发经验；工作细心负责，思维敏捷，有钻研和创新精神；沟通顺畅；有很强的责任心、纪律性和团队协作精神。对大数据及各种新技术趋势有较大兴趣。4、熟悉关系型数据库为佳，了解Hadoop及相关生态系统技术和架构为佳。

职位要求：
1、3-5年以上JAVA WEB编程经验。
2、熟练J2EE编程开发技术（JSP、JSTL、JDBC、JavaScript等相关技术）。
3、熟练掌握Spring、Spring MVC、JPA或Hibernate等主流的开发框架。
4、熟悉主流JavaScript，掌握jquery、bootstrap等（优先）
5、能够熟练编写Shell/Perl/Python程序，了解Django框架
6、熟悉cloudear-hue的部署和使用
7、了解Docker的原理，掌握Docker等相关容器的实施
8、有以下一种数据库的开发经验：oracle、mysql、PostGreSQL
9、有能力对大规模分布式集群的CPU/内存总体情况、网络吞吐、I/O吞吐进行监控、测试、调优（优先）
10、有Linux服务器的性能调优能力，大规模服务器的运维经验（优先）
11、熟悉Hadoop/Spark，包括原理、架构、代码，具有相关研发经验，能够进行性能调优、功能扩展以及故障排除（优先）
12、有较强的团队协作和沟通能力，具备较强的技术研究能力和攻关能力，善于学习新事物。
13、工作责任心强，能承受一定的工作压力。
 
岗位职责：
1、全栈工程师，负责hadoop平台运维
2、大规模集群管理工具的开发、部署和维护
3、负责开放数据平台的研发工作

大数据应用工程师
岗位职责：
1、负责大数据平台的设计和开发；
2、负责海量社交数据的处理、分析、挖掘；
3、能灵活对应产品需求快速搭建原型并持续迭代。
 
任职要求：
1. 三年以上服务器端开发经验；
2. 熟练 Java, Scala, 追求代码质量和程序效率, 熟悉设计模式；
3. 熟练使用Linux系统,，熟悉Shell脚本语言；
4. 有数据挖掘经验，对常用机器学习算法有较为扎实的基础；
5. 有基于Redis，ElasticSearch和Neo4j数据存储的开发经验；
6. 熟悉Akka消息机制和Kafka消息中间件者优先；
7. 有爬虫平台调度系统开发经验者优先。

岗位职责：     
1. 负责建模和数据分析所需数据清洗；    
2. 负责大数据建模；    

任职资格：    
1.计算机、数学或统计等相关专业本科及以上学历；    
2.熟练掌握聚类、分类、回归、神经网络等机器学习算法和实现，对常见的核心算法和数据挖掘方法有透彻的理解和实际经验；    
3.对Hadoop、Hive、Spark、Storm等大规模数据存储运算平台有实践经验，熟练掌握SQL，熟悉数据仓库相关技术，如 ETL、报表开发；    
4.较强的编程能力，熟练掌握R、Python、C++语言,熟悉Linux开发环境；    
5.精通Caffe、MxNet、Tensorflow、Cuda-convnet、Torch等任一种深度学习开源框架者优先；    
6.有三年以上互联网公司或者海量数据处理工作经验，大数据挖掘、分析、建模经验；    

岗位职责：
1. 作为大数据平台创始成员，参与大数据平台的设计与开发，解决海量数据面临的挑战；
2. 管理、优化并维护Hadoop (Hbase)、Spark、ElasticSearch等集群，保证集群规模持续、稳定；
3. 实现大数据系统的功能、性能和扩展，解决BI、人工智能、数据挖掘等业务需求；
职位要求：
1.从事大数据开发2年及以上工作经验。
2.精通大数据平台框架(Kafka, Zookeeper, Hadoop或Spark等)，了解分布式架构设计及开发。
3.精通Java开发，能够使用Java开发服务，理解微服务，SOA，cache等
4.熟悉数据库的原理和开发 。
5.较好的沟通表达能力，逻辑思维清晰，抗压能力强，良好的团队合作精神　　
6.掌握具体缺陷管理流程（提交bug报告，追踪bug状态）。
7.能够完成大数据环境的搭建，管理，熟悉系统的调优

职位要求/Requirement:   
1. Bachelors or Master's degree in Computer Science, Management Information Systems or related field. 
2. 5+ years of experience with distributed, highly-scalable environments.
3. Programming experience in Java (preferred) or python, but we are open to other experience if you’re willing to learn the languages we use.
4. Experience with Big Data Technologies (MapReduce, Hive, Spark, Kafka, Yarn, Storm), understands the concepts and technology ecosystem around both real-time and batch processing in Hadoop.
5. We use AWS extensively, so experience with EMR and other web services will help you hit the ground running.
6. Knowledge in data mining, machine learning, natural language processing, or information retrieval is a big plus.
7. Strong knowledge of and experience with statistics is a big plus.

1. 计算机及相关专业毕业，本科或以上学历；
2. 5年以上分布式，高并发工作经验。
3. 精通Java或python（如果只有其他编程语言经验并愿意学习的也欢迎）。
4. 精通大数据技术(MapReduce, Hive, Spark, Kafka, Yarn, Storm)，理解Hadoop生态圈实时和离线批次处理的相关技术。
5. 熟悉AWS相关服务者优先，比如EMR，data pipeline等等。
6. 熟悉数据挖掘，机器学习，自然语言处理或相关技术者优先。
7. 有统计学知识者优先。

岗位职责：
1.负责公司数据仓库、大数据平台报表平台的建设；
2.负责搭建基于SAS/Hadoop的数据分析平台和大数据平台；
3.负责完成业务部门提出的各种数据分析和报表需求的开发；
4.基于对业务的理解和数据挖掘发现新的业务知识点。
   

任职要求：

1.本科及以上，计算机相关专业；
2.3～5年的大数据相关开发组织工作经验；
3.熟练掌握MySQL数据库开发技能；
4.具备大数据处理Hadoop/MapReduce及Hive、Spark、Hbase等项目经验；
5.具备独具有深厚的统计学、数学、人工智能和数据挖掘知识基础，有1年以上数据挖掘项目实践经验；
6.具备掌握至少一种统计分析和数据挖掘软件，最好精通R语言；
7.具备基于Hadoop平台的建模算法实现和优化的工作经验；
8.具备金融行业、电子商务相关行业项目经验者优先。

岗位职责：
1. 基于大数据技术实现业务数据服务的开发
2. 数据抽取转换和存储、在线和离线分布式数据分析系统设计和研发
3. 大数据平台的搭建、监控、性能调优

任职要求：
1. 精通Java 语言、以及常用的设计模式，对使用Java多线程、死锁、常用数据结构等有较深入的认识；有一定Java及Web应用开发经验，熟练使用Mysql，Oracle等至少一个关系型数据库；
2. 熟练使用Linux系统环境，完成应用部署等操作，能够使用Java语言编写Mapreduce、Spark等应用程序，以及相关的性能优化方式；
3. 熟练掌握多个大数据相关组件的使用、原理实现，可以应用的场景如Hadoop，Hbase，Zookeeper、Hive、Sqoop 、Kafka等，能够独立完成相关组件的部署和基本优化，有CDH使用经验更佳；
4. 熟悉对分布式系统的监控、运维、故障恢复，高可用配置，有较强分析处理问题能力；
5. 熟练使用Maven、SVN、Nexus 、Hudson、Git 等项目管理、持续集成、代码管理工具，能独立搭建开发项目骨架并能制定开发规范；
6. 熟练使用常用的测试框架，重视单元测试，集成测试，保证代码质量，并定期对其不合理和可优化的地方进行重构；
7. 有快速和持续学习的能力，动手能力强，有进取心、责任心强、团队合作意识强；能够适应加班及出差。

岗位职责：1 搭建实时性能高的大数据处理和展现平台，为海量数据和大规模业务系统提供基础设施。
2 搭建高性能的用户预算管理平台，为线上业务提供可靠保障。任职要求：
1 本科以上学历、计算机相关专业，互联网行业两年以上工作经验；2 对分布式系统原理，存储、队列、计算、集群管理中的一项或多项有深入的理解和认识；      3 memcache, Redis, LevelDB, RocksDB, MySQL, HBase, scribe, kafka 的一项或多项有经验者优先；   4 Hadoop/YARN, Mapreduce, spark, storm, Hive, Impala 的一项或多项有经验者优先；   
职位优势：1、准上市公司，我们将于3月份宣布上市，核心研发人员会有股票期权；公司福利：1、年薪制，一年15薪-17薪2、六险一金，社保、公积金全额缴纳；3、弹性工作制，上班时间9：00-10：00，下班时间18：00-19：00；4、自有大厦，世外桃源，景色优美，环境清新，让你远离市区的喧嚣和拥挤；5、开放式办公环境，工位和空间足够宽敞，沟通无极限；6、班车免费接送；让你远离挤公交车、地铁的窘状和无奈；7、年度健康体检，一年2次外出旅行的机会，1个月1次工作日带薪团队活动；8、不仅有美女相伴，还有 一群志同道合、对技术执着的攻城狮、程序猿与你并肩奋斗；9、核心人员公司代办工作居住证

Position Description:
1. 负责维护、优化基于Hadoop生态的集群和计算框架，为业务开发人员提供支持；
2. 提供大数据存储、计算、调度等基础服务，支撑海量数据分析、数据挖掘、机器学习等组件的维护工作。
3. 组织研究行业应用领域最新技术发展方向，主持制定技术发展战略规划，并组织实施、监督；
4. 负责提供解决Hadoop、hbase平台开发与运维问题的总体思路
5. 负责团队内公有云（Azure）维护及管理
5. 关注开源技术动态，结合业务场景，寻找最佳解决方案。
 
Position Requirements:
1. 大学本科以上学历，计算机/软件工程等相关专业；
2. 3年以上Hadoop生态相关运维经验，熟悉但不限于Hdfs/Yarn/Spark/Storm/kafka/Presto/Kylin/Hbase/Hive/ES/codis/zeppelin,并拥有持续调优能力
3. 深入了解hadoop、hbase、hive等架构并且有实践经验者优先；
4. 独立排错能力，熟练使用linux、python，熟悉TCP/IP
5. 掌握Java、python、shell中至少一门编程语言;
6. 具有较强的领导能力、敏锐的行业技术发展趋势把握能力和宏观分析判断决策能力、较强的组织管理能力、良好的人际关系协调和沟通能力；
7. 具备公有云维护管理工作经验者优先

入职条件/岗位要求：
1.完成项目开发任务。
2.参与大数据的并行计算、实时流计算工具的研究和开发。
3.参与大数据数据挖掘、数据分析工具的研究和开发。
4.参与大数据体系架构设计、平台架构设计、应用场景设计。
5.参与大数据相关科研课题，编写研究报告或技术文档。
6.完成核心模块和核心算法的开发。

能力要求：
1.大学本科及以上学历。
2.精通Java，对常用开源中间件及J2EE体系有深入理解。
3.熟悉Hadoop、HDFS，MapReduce，Spark，Impala，Hbase，Hive，Mahout，Storm，zookeeper等开源分布式系统，对其中1个或多个分布式系统有应用经验。
4.有商业级大数据系统工作经验者优先。
5.具有良好的逻辑分析能力、沟通能力和协调能力。
6.具备强烈的进取心、求知欲及团队合作精神。
7.保持大数据行业相关技术持续学习的热情，了解行业最新技术动态，开源社区参与者和贡献者优先。


岗位职责：
1、负责Hadoop大数据平台的设计与开发，解决海量数据面临的挑战，
2、负责Hadoop集群的管理、优化和维护，保证集群规模持续、稳定，
3、负责Hadoop/Spark的功能扩展和性能优化，解决并实现业务需求，
4、使用hive、spark、mapreduce进行数据处理，协助建立数据模型，对数据挖掘脚本进行优化；
 
任职要求：
1、熟悉linux开发环境，精通Java、Python其中至少一门语言，
2、对数据结构、算法有较深刻的理解，
3、熟悉Hadoop、HBase、Hive、Spark、Mapreduce、Azkaban，熟悉源码优先，
4、对新技术充满激情，认真负责，有良好的沟通和学习能力。

职位描述：
1、负责业务相关数据指标的抽取、转换、加载，数据维护相关工作；
2、负责对业务数据进行分析、建模，为业务部门的数据化运营提供支持；
3、依据业务需求，进行数据产品的规划和设计开发，为数据分析和运营等人员搭建友好高效的数据产品。
岗位要求:
1、5年以上工作经验，至少2年大数据工作经验；
2、能独立使用工具，完成结构化数据库与非结构化数据库数据转化；
3、了解MapReduce或Yarn工作原理，熟悉Hbase，HDFS，Storm，Kafka，DataX/Sqoop等大数据处理框架,特别是有Spark实战经验,并有实际大数据平台搭建和调优的经验；； 
4、精通Java、Python、R、PHP之中一种语言，并有大数据分析处理实际项目经验，熟练掌握linux系统和shell编程；
5、认真严谨，喜欢钻研，有责任心，良好的团队合作精神，积极上进，具备良好的学习能力
6、具有互联网金融大数据风控经验者优先

职责：1、负责公司大数据平台的开发；2、支撑日常业务数据需求，问题跟进并及时解决。

要求：1、计算机、数学等相关专业，本科以上学历； 2、熟练掌握Java/Scala语言，具有5年及以上Java/Scala开发经验，熟悉linux操作；3、具有2年以上大数据系统开发经验；4、熟悉Hadoop、Spark、Storm等相关技术，具有2个以上大数据平台项目实施经验；5、熟悉Zookeeper、Kafka等相关技术；6、有较强的学习能力，对技术有钻研精神，热衷于新技术学习和实践并乐于分享；7、优秀的团队合作精神，对工作有热情；8、有大数据实时计算工作经验者优先。


【岗位职责】
1、负责大数据系统的设计和开发工作；
2、负责分布式数据仓库的主题模型设计和款表开发工作；
3、支撑日常业务数据需求，负责系统优化，问题跟进并及时解决。

【任职要求】
1、本科及以上学历，计算机相关专业；
2、熟悉Java与Python开发，具有良好编程与文档编写习惯；
3、具有五年以上分布式数据库开发与服务器部署经验，熟悉hadoop与spark生态；
4、熟悉多种关联与非关系型数据库操作与调优，具有丰富的数据仓库系统相关开发经验，如：ETL设计、OLAP开发、Cube多维建模。
5、了解web服务流程，清楚spring framework配置；
6、优秀的团队合作精神，对项目积极负责。

职位描述：

lead7-8人左右的大数据平台开发团队；
负责大数据平台的架构制定、技术选型、设计开发，以及系统问题的解决和持续优化人选要求；
负责核心产品Android研发工作。


岗位要求：

本科以上学历，计算机相关专业，有扎实的计算机基础；
看重自我技术水平的提升，追求卓越，有带人经验，了解如何帮助team成员一起成长。


岗位要求：
1、主要负责构建公司级大数据平台； 
2、负责大数据运营平台的开发与维护；
3、独立研究数据挖掘模型，参与数据挖掘模型的构建、维护和评估工作；
4、根据实际业务要求，完成较深入的专项数据分析并形成分析报告；
 
任职资格：
1、计算机、统计学相关专业本科及以上学历；
2、互联网、电商行业，数据分析、数据挖掘等3年及以上工作经验者优先；
3、熟练掌握所需的开发语言、开发工具；
4、乐于数据分析、大数据挖掘；

岗位职责：
1、参与并负责大数据架构的搭建、开发和维护监控
2、熟悉统计分析/数学建模/数据挖掘等方法
3、提供有价值的商业数据、模型、算法支持
4、参与公司平台化产品的开发
任职要求：
1、5年及以上的Java开发经验，了解J2EE相关技术
2、熟悉分布式缓存、消息队列、对高并发大流量系统性能优化有一定的经验
3、熟悉Hadoop大数据平台架构，有Map/Reduce开发运维经验，具有Storm、Spark、Hbase等大数据平台经验；
4、熟悉Linux的基本操作及应用部署，了解Shell命令
5、良好的沟通与团队合作能力以及创业心态
6、了解DMP或有数据挖掘以及机器学习项目经验相关开发者优先考虑

岗位职责：
1、负责公司的大数据处理框架的研发设计工作；
2、负责公司产品研发过程中的数据库设计文档的撰写；
3、参与小组的产品设计讨论，共同讨论和设计产品。
任职资格：
1、本科学历，2年以上大数据开发经验,熟悉Hadoop,Spark等研发，熟悉大数据集群搭建，管理和优化；
2、具有数据分析,数据挖掘能力经验,有较强业务理解和分析能力；
3、熟悉数据建模，了解常用算法(如推荐算法,深度优先等)； 
4、良好沟通能力，善于团队合作。



岗位描述：
1.负责渠道平台运营数据云平台的建设；
2.负责海量数据的实时计算、离线计算、存储、查询；
3.参与数据平台自助化建设。

岗位要求：
1.计算机相关专业，3年及以上相关工作经验,有扎实的计算机理论基础；
2.熟练Java、Python服务端编程，有良好的编码习惯；
3.深入理解MapReduce，熟练使用Storm、Hadoop、Spark，并阅读部分源码；
4.熟练使用HDFS、Hbase、Kafka、ElasticSearch；
5.深入理解全文检索引擎Lucene，有优化经验者优先；
6.具备良好的学习能力、分析解决问题能力；
7.具有高度的责任心和团队合作精神。

岗位职责：1、负责区域市场的业务拓展、客户挖掘工作，承担区域销售任务；2、负责客户信息及销售信息的汇总及市场分析报告撰写、竞品分析及市场动态更新；3、负责新客户、新机会的挖掘和开发，了解、分析并评估客户的需求，进行项目运作，以及重点客户的维护管理工作。任职要求1、本科及以上学历，有三年以上的政府行业销售经验；2、熟悉IT服务、IT软件及系统集成等IT产品，了解政府行业市场、产品和产业链结构，熟悉政府行业的项目运作流程； 3、具有相关行业、区域资源及政府信息化销售经验者优先；4、具有很强的业务规划能力及市场感知力，能准确把握市场动态及方向；5、优秀的表达能力与沟通技巧、市场开拓能力、执行力、应变能力、商务谈判能力； 6、具有良好的团队协作能力； 7、能接受阶段性出差。

岗位职责：
1、负责基于大数据分析平台的开发、优化、维护；
2、负责基于业务／产品需求构建数据模型、设计算法；
3、参与大数据分析平台的建设。

职位要求：
1、本科及以上学历，计算机相关专业，5年及以上相关经验；
2、JAVA开发经验丰富，掌握网络、多线程、数据结构及算法等基础知识，熟悉JVM原理和调优；
3、熟悉Hadoop、Spark、Storm分布式计算框架，了解使用Hive、Pig、hBase、Kafka优先；
4、熟悉Linux系统环境、MySQL数据库，具备一定的SQL语句编写和优化能力；
5、能够熟练的阅读英文技术资料，具备良好的学习能力、分析解决问题能力；
6、两年以上大数据开发、分析相关项目经验，互联网行业从业者优先；

职位描述：
1、分析竞品，制定公司媒介推广策略；
2、制定并执行公司传播计划，提升品牌知名度；
3、抓住各类行业热点、事件时机，调动内部资源，策划并执行各类媒介渠道的推广，包括但不限于媒体评论、软文、专访，专题合作，峰会演讲等；
4、拓展和维护各类媒介关系，保持长期友好合作；
5、复盘媒介推广效果，优化推广策略。
应聘要求：
1、本科及以上学历，有良好的统筹、沟通能力，观察力敏锐；
2、开朗外向，思维活跃开阔，学习、创新能力强；
3、有公关媒介经验与资源，熟悉互联网行业者优先，擅长文案策划与撰写。
 

【岗位职责】(1) 利用大数据处理技术，采用统计分析/数学建模/数据挖掘等方法， 分析现有大数据资源，提供统计报表、数据可视化；(2) 参与构建各种数据分析模型，跟踪和分析运营数据，发现潜在的缺陷与机会，为运营和业务决策提供数据支撑，并推进落地。【岗位要求】(1) 本科或以上学历，计算机、数据挖掘等相关专业，相关工作经验3年以上；(2) 精通Java EE，基础扎实，对tomcat、spring，Mybatis，freemarker等主流框架，以及分布式缓存、消息、SOA架构开发有一定研究。(3) 熟悉数据库，MySQL/Postgres/Redshift,或NoSQL，并对数据库优化有一定经验；(4) 熟悉Linux系统，有脚本经验(Shell/Python/perl)优先。(5) 熟悉AWS云服务，Hadoop， Spark等大数据处理技术优先。(6) 其他-需要较强的逻辑分析、数据分析能力、问题排查能力，团队合作，工作主动，学习能力强，具备丰富想象力和创造力；

岗位职责：
1. 负责大数据平台和相关应用系统的研发工作，具备独立工作能力，能按产品需求进行系统设计和编码实现，保证系统的安全性、可扩展性和性能；
2. 对开发团队进行技术指导和培训。
任职要求：
1. 全日制大学本科（含）以上学历，具有CET-4(425分以上)或同等英语证书；
2. 5年以上JAVA开发经验，熟悉IO、网络、多线程等框架，了解如何进行JVM调优；
3. 熟悉Spring、MyBatis、SpingMVC等开源框架；
4. 熟悉Velocity模板引擎，常用JavaScript框架的日常开发与使用，熟悉linux，能够熟练使用常用命令；
5. 熟悉MySQL数据库，掌握常用的相关设计和开发知识；
6. 了解常用的系统架构设计、性能优化和高可用方案；
7. 有数据仓库、数据挖掘、数据可视化、自然语言处理、机器学习、爬虫、搜索、推荐、广告等相关项目经验者优先；
8. 有hadoop平台、高并发、分布式相关项目经验者优先；
9. 务实、逻辑思维缜密、工作细致有耐心，具有良好的分析和解决问题的能力，勇于面对挑战性问题，具有良好的学习能力、沟通能力和团队合作精神。 

职责描述：      
1、负责专有云数据库(MySQL)高可用集群运维,保障服务稳定可用    
2、负责大数据产品（ODPS、ADS）产品运维    
3、参与客户应用上云及分库分表咨询，制定数据库设计及迁移方案    
4、负责及时排除数据库故障，形成知识库，完善运维文档   
5、负责数据库开发支持，对生产环境的SQL进行审查，处理客户咨询等    
6、负责监控和优化数据库的性能,持续性地提出改进自动化运维平台建议    

技能要求：    
1、计算机科学或相关专业本科及以上学历，3年以上DBA经验； 2、熟悉Linux系统,熟练编写shell/perl/python一种或多种脚本语言；    
3、熟悉oracle运维，能独立进行RAC安装配置及故障处理，对存储有深入了解及实践；    
4、熟悉MySQL主从复制模式及实践，对MySQL/Oracle高可用架构有深入理解；    
5、熟悉Hive、Hadoop、MapReduce集群原理，有hadoop大数据平台运维经验者优先；    
6、熟悉数据库的性能优化、SQL调优，对锁和事务隔离问题有深入理解，有高并发场景的调优经验；    
7、熟悉MySQL各个开源分支及插件，深入理解InnoDB等主流MySQL引擎，有源码阅读能力尤佳；    
8、抗压能力强，有强烈的责任心，良好的沟通能力、学习能力及团队合作能力。    

岗位职责：
1、把握复杂分布式系统的设计、开发、维护全过程，不断进行系统优化；
2、和团队一起攻克大数据量、大用户量、实时业务、高并发、高吞吐、高可靠性等各种不同技术场景下的技术挑战。
职位要求：
1、硕士及以上学历，熟悉IO机制、网络通讯、多线程等基础知识框架，熟悉缓存、消息队列、索引查询等机制；
2、熟悉Hadoop、hbase、storm、zookeeper、Spark等开源分布式系统，对其中1个或多个分布式系统有应用经验；
3、对分布式系统内的应用开发有丰富经验，语言包括并不限于JAVA, clojure，scala，python, C等；
4、熟悉大数据量、大用户量、实时业务、高并发、高吞吐、高可靠性分布式系统的优先；
5、保持大数据行业相关技术持续学习的热情，了解行业最新技术动态，开源社区参与者和贡献者优先；
6、良好的沟通技能，团队合作能力，勤奋好学。

职位优势：1、准上市公司，我们将于3月份宣布上市，核心研发人员会有股票期权；公司福利：1、年薪制，一年15薪-17薪2、六险一金，社保、公积金全额缴纳；3、弹性工作制，上班时间9：00-10：00，下班时间18：00-19：00；4、自有大厦，世外桃源，景色优美，环境清新，让你远离市区的喧嚣和拥挤；5、开放式办公环境，工位和空间足够宽敞，沟通无极限；6、班车免费接送；让你远离挤公交车、地铁的窘状和无奈；7、年度健康体检，一年2次外出旅行的机会，1个月1次工作日带薪团队活动；8、不仅有美女相伴，还有 一群志同道合、对技术执着的攻城狮、程序猿与你并肩奋斗；9、核心人员公司代办工作居住证

岗位职责：
1.负责大数据实时处理系统的设计、开发、维护与优化；
2.参与大数据的架构设计、开发、部署和数据分析等工作。
岗位要求：
1.3年以上Java开发经验，具备大数据系统的架构设计和优化能力；
2.精通Storm、Spark Streaming等流式计算框架，精通Storm优先；
3.熟悉Hadoop、Hive、Kafka、ZK、Elasticsearch的工作原理，有相关平台应用开发经验；
4.熟悉Mysql、Hbase、Redis等数据存储平台；
5.具有较强的学习能力、自我管理能力、能够在压力环境下工作；
6.具有较强的文档编写能力，能够按照公司要求编写架构设计文档；
7.性格积极乐观、诚信、有较强的语言表达能力，具备强烈的进取心、求知欲及团队合作精神;
8.认同和实践DevOps文化，有坚持自动化一切和监控一切的追求。

岗位职责：
1、负责业务的数据收集、建模、统计与可视化，全方位支撑线上产品和线下业务迭代扩张；
2、构建数据的监测与分析平台，帮助业务人员快速、及时发现问题并找到原因；
任职要求：
1、至少1年大数据工作经验，熟练掌握Java/Python/PHP至少一种编程语言；
2、熟悉hadoop，Storm，Kafka等开源平台、具备分布式数据存储与计算平台搭建/应用开发/运维的相关实践经验；
3、熟练掌握SQL，理解 Hive/Mysql 基本原理和调优策略；
4、具备优秀的业务理解能力，对数字敏感，有较强逻辑分析能力；

岗位职责：

结合业务需求,设计和开发公司数据服务平台，承担数据抽取、转化等服务代码开发。
结合业务需求,分析用户行为，为产品和运营提供决策支持,以数据驱动业务发展。
结合业务需求,为风控提供数据支持服务。
结合业务需求,负责用户行为轨迹分析和标签体系建设。

任职资格：

计算机相关专业全日制本科及以上学历基本功扎实。
积极、主动的工作态度,责任心强。
参与大数据分析项目并至少一年以上工作经验。
精通Java/Scala/Python等至少一门开发语言。
熟练掌握spark/spark sql/spark streaming开发
熟悉hadoop平台部署、调优、troubleshooting、运行维护。
熟悉apache生态系统apache kylin/Zookeeper/Flume/Kafka/sqoop/hive/hbase


岗位职责  
 
* 深入理解业务，训练迭代模型，业务数据模型持续优化  * 参与业务分析、建立风控模型、或其他模型开发相关工作     
必备技能  
* 精通Hadoop2、Hive编程
* 精通Java/Python语言中一种
* 熟悉Unix/Linux 下常用命令和开发
* 精通SQL开发
* 精通分布式并发编程
* 熟悉常用机器学习算法：降维(PCA、SVD)、梯度下降、SVM、逻辑回归(Logistics Regression)、决策树(GBDT、RandomForest)、
关联规则(Apriori、FP-Growth)、聚类(K-Means)、提升(Adaboost、xgboost)、word2vec、主题模型、HMM中的大多数。。。
* 有以下技能其中一项或几项者加分：
1）熟悉Caffe、Tensorflow机器学习框架
2）熟悉Numpy、Scipy、Pandas、Matplotlib、Scikit-learn算法库使用。。。
3）熟悉大数据可视化开发，比如D3.js、Angular、EChart。。。
 
任职要求  * 扎实的计算机基础，能够自驱动技术学习
* 互联网公司2年以上数据平台算法设计开发经验
* 熟悉Hadoop生态相关技术，精通机器学习、数据挖掘等常用算法和技术* 数据敏感，逻辑清晰、严谨，能够独立分析、决策  * 对互联网金融感兴趣，愿意钻研相关领域技术、业务  * 任何对我们业务、团队有帮助的地方都是加分项，尽管展示给我们

职位描述：
1. 负责大数据框架、数据平台、数据中间件及相关产品应用的架构设计和开发；
2. 负责数据平台的建设规划，包括环境和框架的规划搭建以及核心编码实现
3. 负责流式数据的实时传递、清洗、转换和计算（实时统计、分析等）的设计和开发
4. 负责带领新人或普通开发工程师进行数据平台的开发，并帮助其快速成长
任职资格：
1. 3年以上数据研发工作经验，本科及以上学历，有完备的计算机知识体系，对网络、安全、数据库、WEB等均有一定的了解
2. 精通主流数据库技术，包括SQL类和NoSQL类
3. 能够快速学习，有良好的技术表达沟通能力
4. 熟悉并使用过各种大数据相关框架或组件，如Kafka、Storm、Hadoop、Hive、HBase等
5. 有云计算平台开发经验者，熟悉阿里数加平台，有ODPS平台使用经验者优先
6. 具有良好的沟通、团队协作，工作责任心强

岗位职责
1.负责大数据平台软件需求分析、设计；
2.参与产品需求讨论、应用产品系统架构的设计、开发；
3.负责编写相应的需求、设计与技术文档；
4.参与线上系统环境的升级、运维监控、性能调优,向系统使用者提供技术支持服务。
 
岗位要求
1.本科以上学历，3年以上大数据相关设计或研发经验；
2.熟悉分布式系统的架构，有分布式系统架构设计、大数据架构设计的经验，至少1个以上大型成熟项目的经验；
3.精通 Java、HFDS、MapReduce，并有相关的开发及优化经验；
4. 熟悉Spring、Spring Batch，Solr全文检索与推荐引擎开发；
5.熟悉MySql、SqlServer等数据库系统，有数据库编程经验、熟悉数据仓库的ETL的开发,有海量数据处理相关经验；
6.熟悉Hadoop、HBase、Hive、Spark、Storm等软件，至少精读过一个源码；
7.有电商大数据开发经验；
8.强烈的责任心，良好的沟通协调能力,较强的学习能力。

岗位职责:
1.负责滴滴业务所依赖的地图服务的设计与研发，包括检索，推荐，定位，数据等服务;
2.负责数据采集，存储，计算，分析等场景下的通用架构或框架的设计与研发;
3.负责检索业务的产品需求，提升用户搜索体验，并承担系统的维护与引擎性能优化等。
岗位要求:
1.扎实的数据结构和算法功底，思维敏捷，编码强悍;
2.熟悉C/C++，Java、Scala、Python至少两种以上;
3.掌握操作系统、设计模式、网络编程、数据库等;
4.良好的沟通能力，需求理解能力，团队合作意识;
5.有Spark、Haddoop、HBase、Storm等经验优先;
6.本科以上学历，计算机相关专业，2年以上工作经验.

参与京东商城Y事业部收益管理与供应链运筹优化项目中大数据方面的开发工作：
1.      负责数据分析、加工、清理、处理程序的开发
2.      从事海量数据分析、挖掘相关工作
3.      负责数据相关平台的搭建、开发、维护、优化  
任职条件: 
1.      计算机相关专业，本科及以上学历，5年以上Java开发工作经验，学习能力突出；
2.      熟悉hadoop生态系统内常见项目的使用（hdfs、hive、hbase、spark、zookeeper,yarn等），具有MapReduce开发经验，有实际大数据项目经验优先
3.      熟练掌握Oracle、MySql等主流数据库
4.      精通JAVA，熟悉基于J2EE的WEB架构设计，熟悉Web开发流程，有丰富的Web MVC（Struts、Spring，Hibernate等）开发经验；
5.      熟悉Linux/Unix系统环境下的操作；熟悉Tomcat等应用服务器的配置和优化；
6.      具有良好的沟通能力、组织能力及团队协作精神，有较强的分析和解决问题的能力；
加分项：
1. 有海量大数据开发经验
2. 有Hadoop、Spark、HBase深入源代码分析经验
3. 熟悉机器学习、数据挖掘、分布式计算
4. 基础能力+学习能力特别优秀者
 
福利待遇：
大平台/顶级教授讲座/全城班车/健身房/餐补

岗位职责
直播 SDK &amp; 流媒体服务器日志收集
日志数据的实时计算处理和离线计算处理
依托于质量数据做直播产品的质量运营和线路调优，能够反映七牛直播云的网络拓普质量，体现数据价值
通过机器学习能够做到实时或者预测线路质量，实现最终自动化运营的目标
任职要求
具备流式日志数据的收集知识，对于离线&amp;实时日志数据的存储和计算有一定经验
了解 Flume，Kafka，Spark&amp;Storm，Hadoop，Hive 等技术
对于数据挖掘和运营分析有一定经验
最好具备可视化 MVC 系统的开发知识，掌握 Go，Java，Python 等其中至少一门开发语言
有 CDN 调度系统的研发、调优经验者优先
了解一定 HTML，CSS，JS 等前端知识
最好具备一定机器学习的背景

岗位职责：
1、负责分布式网络爬虫系统设计，搭建系统框架，开发分布式网络爬虫系统。
2、 带领项目成员完成数据采集爬取、解析提取、清洗入库等数据生产工作。
3、研究网页特点和规律，对网页信息进行分类、抽取、数据清洗、存储结构等研发和优化工作。
4、负责领域知识的定向爬取、深度提取和挖掘。
5、对数据进行清洗、整理、去重及合并等工作。
任职资格：
1、大专以上学历，５年以上JAVA开发经验，熟悉一种开源爬虫系统实现或作为主力参与过一个完整的爬虫开发项目。
2、熟悉网页爬取原理及技术，熟悉深度抓取、动态网页抓取技术、熟悉请求伪装，模拟登陆，代理应用，爬虫和反爬技术。
3、精通正则表达式、Javascript、HTTP协议、HTML，善于从各种结构化和非结构化数据中抽取有用的信息。
4、熟悉http client、netty、ajax、htmlunit、Nutch、selenium、HtmlParser、Jsoup、XPATH等技术。
5、熟练多线程技术、网络编程技术、自然语言处理、信息检索、机器学习等相关优势经验者优先。 
6、熟悉hadoop、hbase、Zookeeper、spark、storm、Solr、hive、kafka、redis、mongodb等相关技术者优先；具有验证码破解经验者优先。

我们可以提供：
1、挑战性的工作机会和良好的个人发展晋升空间。
2、舒适的办公环境、良好的团队合作氛围和自由的技术发挥平台，充分重视员工的自我价值实现。
3、五险一金、员工福利、运动会、嘉年会、每周羽毛球、拓展等各类活动、集体旅游......
4、绩效奖励及其它晋升、调薪福利结构。
5、五天工作制，周末双休。
鹏元之道、以诚为本、以人为本，广纳英才，期待您的加盟共创美好明天！


关键词：
大数据、互联网、团队管理、Java、Spring、Struts、HTML5

岗位职责：
 1.参与大数据互联网Web产品的研发工作，为产品提供技术支持和解决方案。 2.大数据某产品的研发负责人，团队管理、客户需求沟通工作；
 任职要求：
1.三年以上的Java开发经验，熟悉Java语言,良好的编程规范； 2.熟悉Spring Struts2 Hibernate，SpringMVC等主流框架，以及常见WebService引擎 3.深度掌握JavaScript/Query等框架/HTML5 4.有良好的团队合作意识、耐心诚恳、有强烈的责任心和积极主动的工作态度，有优秀的学习能力。 5.具有大数据相关处理经验及多并发程序设计能力优先。
 
【全面的薪酬福利】
七险一金；福利补助（餐补、话补、交通补）；带薪年假；多项贺礼（结婚、生育、生日、节日）；多元化俱乐部（篮球、足球、爬山、瑜伽）。。。
老多了，要啥有啥！
 【完善的培训体系】
培训平台学习；新员工导师制；新员工培训；春苗培训；春蕾培训；管理技能培训；
旨在为员工提供基于工作胜任与个人能力发展的多样化培训！
 


职位描述：
1、做大数据专业课程建设，视频课程的研发和录制；
2、讨论教学相关项目的需求，参与案例设计，完成设计文档以及核心模块编写；
3、解决案例开发过程中的实际项目和业务问题；
4、参与新技术预研并做技术分享；
5、负责项目版本更新以及文档维护；
6、带领和培养在线班级的学生完成学习任务。

任职要求：
1、全日制本科以上学历，计算机、数学或统计学相关专业；
2、有3年以上大数据开发经验，有带过3人以上团队经验的优先；
3、有数据挖掘、数据分析、数据仓库、推荐算法等开发经验者优先；
4、有Hadoop/Hive/Impala/Spark/MPI/HBase等相关经验；
5、善于沟通，表达能力强，乐于技术分享；
6、具有较强分析问题和解决问题能力。

岗位职责：
1、围绕酷狗直播数据体系进行数据分析和开发，为可视化数据产品提供数据应用支撑； 
2、负责酷狗直播业务及流量数据统计和挖掘，完成数据模型的设计、开发及维护； 
3、面向业务需求的数据分析、开发与管理； 
4、紧跟上游数据及业务变动，洞查、分析定位并处理各种离线/实时数据问题。

任职要求：
1、计算机相关专业本科及以上学历；
2、深入了解数据仓库、数据模型相关原理及概念；
3、5年以上工作经验，2年以上基于Hadoop架构DW/BI项目实施和开发经验；
4、熟悉Hadoop、Hive、spark、presto等大数据技术，拥有基于海量数据的hql开发及调优经验；
5、熟悉Linux系统，具备shell或python脚本开发能力；
6、逻辑思维及沟通交流能力强，善于学习，能够独立分析和解决问题，具备良好的团队合作精神；
7、具备大数据开发及应用经验者优先、具备互联网APP流量、UV、PV等数据分析经验者优先。

大数据开发 

岗位职责描述： 
1、 参与ODS系统或Hadoop 系统数据库相关开发,包括数据仓库的数据模型设计(ODS层设计、基础数据层设计、汇总层设计等) 
2、 参与ETL Mapping设计及开发工作 
3、 参与客户/用户画像、经营管理、产品画像、营销活动等主题域建设工作 

技能要求： 
1.三年及以上开发经验，计算机相关专业大专及以上学历 
2.有大型数据库(ORALCE/MSSQL SERVER等)开发经验，有Sybase IQ\HIVE\Spark SQL开发经验者优先 
3、有较强的SQL编程能力,熟练编写存储过程，能设计各种复杂的业务处理、统计分析语句，精通sql性能优化； 
3、具有数据仓库、ods、BI商务智能项目经验者优先，具有金融行业项目背景者优先； 
4、较好的沟通理解能力，态度踏实，积极上进 

岗位职责：
1、负责订单/用户/支付/商品数据的自动化分析处理和统计工作；
2、数据仓库的设计开发维护；
3、统计平台的设计开发维护；
4、根据相关需求进行数据处理、查询，统计等工作；
5、创新性的预研工作。
任职要求：
1. 本科以上学历、计算机/数学/统计学等相关专业，互联网行业算法方向三年以上工作经验；
2. 熟练掌握java、c/c++语言之一，有三年以上的编程经验；
3. 熟悉Hadoop相关大数据生态圈包括但不限于：YARN/HDFS/Hive/Pig/Oozie/Spark/Druid等；
4. 熟练掌握常用的数据分析工具与机器学习packages、Libs；
5.熟悉Shell，并熟练掌握一门脚本语言包括但不限于：Python/Perl/Ruby等。
加分项：
1、BAT的靠谱主力；
2、有大型架构设计/优化/维护经历；
3、对分布式有较深的造诣；
4、能带领团队创造佳绩。

岗位职责：
1．负责产品总体技术框架的规划和设计，并负责核心功能和核心模块的代码编写。
2. 负责系统技术难关攻关，带领研发团队进行相关新技术的研究。
3. 根据需求使用Spark Streaming和Spark SQL进行数据处理、查询、统计等工作。

岗位要求：
1. 精通相关技术和框架（java\.net），对相关技术标准有深刻的理解，对软件工程标准有良好的把握。
2. 熟悉分布式、延展性、可扩展性架构设计，具备高并发、高负载环境下的系统开发及优化经验。
3. 拥有丰富的数据库系统经验（Oracle、SQLServer、Mysql、DB2）。


岗位职责：
1、以保险业务数据为基础，结合相关系统提供的数据，研发与实施数据分析预测模型，如：信用评估、风险评估、客户生命周期和客户价值、产品定价、客户行为与产品需求的模型；
2、通过数据分析，发现互联网保险机会点，配合产品团队进行保险产品的研发，制定产品策略；
3、对各保险产品运营、风控数据进行分析，完成各类分析报告、报表，帮助运营人员共同制定保险产品运营策略；
4、为业务部门的非技术人员解释数据挖掘的分析结果与发现，并为其制定市场计划提供必要的建议。

任职资格
1.5年以上软件开发经验，3年以上分布式系统开发经验；
2.参与过大数据开发项目，熟悉Hadoop MapReduce开发，精通HDFS，熟悉HDFS源码并能在源码基础上进行修改；
3.了解zookeeper，MetaQ，spark，storm等其中一种或多种相关分布式系统；
4.有扎实的Java开发基础，熟悉多线程高性能开发；
5.良好的沟通能力、逻辑分析能力，善于总结，能抓住问题的本质和重点；
6.做事认真塌实、为人诚实，工作积极主动、能适应较大的工作压力；
7.具有创新精神、团队精神及艰苦创业精神。

岗位职责：
1、负责建设公司的大数据平台，包括数据采集、传输、存储、计算、可视化等底层能力；
2、根据业务团队的需求，规划设计上层大数据应用；
3、负责软件程序的设计和代码编写；
4、能主导系统架构设计及核心代码开发，解决开发中的技术难题，确保系统性能、质量安全；

岗位要求：
1.计算机、统计学、数学、数理统计等相关专业，本科以上学历，5年以上工作经验；
2、精通Hadoop体系结构、对Hadoop生态圈有较全面了解；
3、精通HDFS/HBase/Hive/Storm/Spark/Spark Streaming/Kafka/flume 等相关技术；有多个或多年大数据项目的实施经验；
4、熟练使用Eclipse、Maven、SVN等开发工具，熟练掌握Java/Python/C/Shell，SSH、Mybatis、Memcached、Dubbo、ActiveMQ等基本技能；
5、熟练掌握SQL数据库语言 Oracle/Mysql/HiveSQL，熟练应用Linux操作系统；
6、具有结构化思维能力、快速的学习能力以及良好的沟通协作能力，积极主动，能承受一定的工作压力；
7、有数据统计相关的经验，广告平台开发经验，有大数据处理经验或愿意从事大数据分析者优先；

职位诱惑：
顶尖技术,优厚待遇,自由氛围

岗位职责：
1、利用数据挖掘、机器学习相关算法，解决产品业务需求；
2、调研新技术在数据分析领域的应用价值，以技术驱动产品。

任职要求：
1、扎实的数据结构及算法功底，优秀的工程实现能力；
2、熟悉常见的机器学习&amp;数据挖掘算法，有相关研究或项目经验；
3、熟悉Linux开发环境，熟悉Java, 熟悉python；
4、有良好的沟通能力和团队合作能力、高度的责任心和诚信的品质

职位描述
1、基于海量用户行为，开发用户画像数据挖掘模型（标签开发与标签评测）
2、对海量用户行为数据进行离线、实时处理
3、参与大数据的架构设计、开发、部署、自动化运维和数据分析等工作
4、利用大数据相关的新技术，提升系统性能。
任职资格:
1、熟练使用Java/Python等语言进行开发;
2、熟练掌握 Linux 操作系统的配置，管理及优化
3、熟悉主流分布式处理框架——Hadoop、HBase、hive等，掌握MapReduce、Storm或者Spark编程（至少其中一项）；

岗位职责  
* 深入理解业务，训练迭代模型，业务数据模型持续优化  
* 参与业务分析、建立风控模型、或其他模型开发相关工作     
必备技能  
* 精通Hadoop2、Hive编程
* 精通Java/Python语言中一种
* 熟悉Unix/Linux 下常用命令和开发
* 精通SQL开发
* 精通分布式并发编程
* 熟悉常用机器学习算法：降维(PCA、SVD)、梯度下降、SVM、逻辑回归(Logistics Regression)、决策树(GBDT、RandomForest)、关联规则(Apriori、FP-Growth)、聚类(K-Means)、提升(Adaboost、xgboost)、word2vec、主题模型、HMM中的大多数。。。
* 有以下技能其中一项或几项者加分：
1）熟悉Caffe、Tensorflow机器学习框架
2）熟悉Numpy、Scipy、Pandas、Matplotlib、Scikit-learn算法库使用。。。
3）熟悉大数据可视化开发，比如D3.js、Angular、EChart。。。
 
任职要求  * 扎实的计算机基础，能够自驱动技术学习
* 互联网公司2年以上数据平台算法设计开发经验
* 熟悉Hadoop生态相关技术，精通机器学习、数据挖掘等常用算法和技术* 数据敏感，逻辑清晰、严谨，能够独立分析、决策  * 对互联网金融感兴趣，愿意钻研相关领域技术、业务  * 任何对我们业务、团队有帮助的地方都是加分项，尽管展示给我们
 
 

岗位职责
1.负责或参与基于公司技术体系针对大数据采集及存储系统的系统规划制定方案；
2.参与大数据采集的实时性及数据一致性提出建议并进一步实施落地；
3.参与数据仓库中运行效率的优化及数据仓库系统实施过程中相关技术问题的解决。
 
任职资格
1.本科及以上学历，计算机相关专业；5年以上开发经验，2年以上设计经验
2.精通java语言，熟悉jvm核心原理 和 主流开发框架
3.精通面向对象技术,设计模式、数据库设计；
4.熟悉开源社区，有详细研究过开源框架源码的优先；
5.熟悉hadoop系统，对hdfs、hbase、hive以及map reduce框架计算有研究和实践者优先；
7.具备一定的数据库操作经验，有书写过存储过程等复杂SQL脚本的优先；
8.性格乐观，态度踏实，积极上进；适应压力性工作。

岗位职责：
1、参与中国汽车受众大数据平台的建设。
2、从多方数据源聚合、构建用户画像系统。
3、参与大数据统计分析工作。
4、根据算法或者模型设计相应代码，计算业务指标

职位要求：
1. 计算机或相关专业本科或以上学历
2. JAVA基础扎实（3年以上工作经验）
3. 熟悉下面的一种或几种，hadoop, spark, nutch, hive, hbase, pig, AWS或阿里云, nosql等。理解云计算，对源码有研究优先，熟悉MapReduce编程，有过大数据处理经验;
4. 有互联网公司经验或者对技术有热情的加分
5. 有复杂算法或者模型实现经验的加分

工作职责：1、 负责公司大数据产品的规划、进度跟踪、协调其他部门完成产品开发上线，参与产品运营和改善，确保产品达成预定业绩指标，管控风险。2、 深度了解负责领域大数据产品的架构、运行方式，制定收益水平合理并且合规的产品策略。3、 深度把握客户的需求，并结合公司现有数据产品情况，改进现有数据产品，提升转化率和收益水平，撰写需求文档。4、 对产品ROI、投诉率等主要指标进行持续跟踪，持续提升所在行业客户的满意度。5、 能够充分挖掘产品的创新点，配合市场部门持续提升公司数据产品的市场美誉度任职资格：1、 本科及以上学历，5年以上相关数据产品的产品或者运营工作经验。2、 熟悉产品设计的的流程、运营和风险管控3、 有医疗健康、旅游、家居金融、电商广告、电信运营商、互联网、数字娱乐类数据产品的产品或者运营背景者优先。4、 善于开拓大数据新业务模式，具有较强的大数据营销项目策划能力者优先。5、 擅于项目管理，能够推进项目分工合作，带动周边伙伴一起工作。6、 具备良好的沟通能力与谈判能力，性格开朗，思维清晰、逻辑思维能力强，团队合作及亲和力强；7、 有良好的客户服务意识，能够迅速准确响应客户需求

岗位职责
1.软件设计开发； 2.数据库设计开发； 3.搜索系统的后台的设计、研发工作。
任职资格：
1.本科以上学历，26-36之间，3年以上Web应用系统开发经验，精通java；（此项为硬性要求，不符勿投） 2.对java并发，java集合范型有深入的了解； 3.熟练使用ssh/ssi，对框架的功能及源码有一定的了解； 4.熟悉apache、nginx等常用web服务器； 5.熟悉Redis等缓存技术优先； 6.对ES、Solr等搜索应用服务器有一定了解或有相关项目经验、调优经验的优先； 7.对统计、数据挖掘相关知识或有相关项目经验的加分； 8.对互联网产品和Web技术有浓厚兴趣，有较强的学习能力和强烈的进取心； 9.有较强的沟通能力，及分析和解决问题的能力，具备良好的团队合作精神和服务意识。

工作职责：
1.同程业务、用户行为或其他日志信息数据抓取；2.基于历史数据进行平台统计、分析（离线和实时）；3.基于线上海量日志数据的用户行为分析； 4.辅助维护现有数据平台正常运行，以Hadoop和MPP为主；5.负责整个数据平台系统的优化；6.负责云仓系统（大数据平台）UDF开发变现；7.负责数据中心大数据方面的其他应用开发。任职资格：1、熟悉Hadoop、HBase、Hive、Spark、Mapreduce、Druid、Kafka、Storm或Jstorm、ETL等相关技术或者工具至少3个以上；2、 熟练掌握基础算法和数据结构和linux开发环境；3、熟悉hadoop、hbase、spark的源码的优先；4、精通Java、Python，了解数据挖掘、机器学习、并行计算相关理论；5、有风控、推荐、人群画像等领域模型构建和调优工作经验者优先；6、学习能力强，喜欢研究新技术，有团队观念，具备独立解决问题的能力；

职位描述：数据平台，大日志等的开发与维护；不断学习大数据相关的新技术，应用于内容数据处理平台的性能提升和复杂问题的处理；任职资格： 2-5年工作经验；熟悉Scala、JAVA、python等开发语言，编程能力扎实；熟悉hadoop/spark/hive/红包ase/es，拥有优秀的海量数据处理和解决实际问题的能力；良好的逻辑思维能力，良好的团队合作和沟通能力。加分项：有丰富的大数据处理相关工作经历；精通大数据处理框架（Spark）

岗位职责：

1、参与数据运营平台的开发与管理
2、有机会参与海量大数据的分析与管理


岗位要求：

1、逻辑思维能力强，有较强的学习能力
2、数据java基础，数据库知识
3、计算机相关专业背景
4、对大数据有很强的热情

加分项：

• 参与开源社区活动，有相关的开发或运维经验者优先；
• 研一/研二在读
• 极客精神
• DOTA &amp; LOL

我们将能提供： 

• 海量高并发平台（日请求亿级）下的高速成长
• 一对一的师兄指导
• 宽松的办公环境
• 足够多的水果和零食
• 免费的咖啡和茶
• 充分的学习机会（培训与分享）
• 定期的运动日（篮球或其他）公司负责场地
• 塑造肌肉和翘臀的健身房
• 游戏机
• 餐补
• 室内PM2.5小于50的清新空气
• 无限流量的VPN


我们希望你能够构建常用的大数据计算平台，在平台上开发各类结合业务需求的商业智能应用的产品。欢迎有志于数据应用的挑战者加入我们。

一、职位描述
此职位需要的具体工作内容如下：
1.在大数据平台上开发各类复杂应用；
2.有能力提出各类产品的合理架构的建议。

二、岗位要求
1.本科及以上学历、计算机相关专业，基础扎实；3年以上相关经验。
2.有大数据项目开发经验，熟悉Hadoop，Spark，HBase及Hive等；
3.有使用Spark SQL进行数据处理, 并具有Spark SQL优化经验;
4.使用过消息队列，如Kafka等。
5.使用过Spark Streaming或者Storm等；
6.熟悉Linux的shell命令；
7.能快速学习新技术。

加分项：
具有丰富的海量数据ETL加工处理经验；
有Spark MLlib等的开发经验优先。

工作地址：

杨浦区同济大学附近
浦东陆家嘴软件园（浦电路）




所属部门：技术中心-BI

工作职责：
1、负责公司大数据离线、实时平台（如Hadoop/Hive/Storm/Spark）的建设、优化；
2、负责开发大数据工具，如报表平台、多维度分析工具、ETL平台、调度平台的研发；

岗位要求：
1、熟悉Hadoop、Hive、Spark、Storm的原理、优化；主导过大型数据平台建设者优先
2、熟悉数据仓库理论，对多维数据建模有深入理解和实际经验；
3、熟悉开源大数据平台如HBase、ES、Kylin、Druid等，有实际的报表平台、多维度分析工具、etl平台、调度平台中至少一种工具的实际建设经验；多种经验者优先；
4、熟练进行Java、Python的代码编写，良好的代码编写素养，良好的数据结构算法技能；
5、思维敏捷，有较强的钻研学习能力；
6、较好的沟通能力、团队合作；

自主研发项目

岗位职责：
1、负责大数据分析需求设计和开发，承担数据抽取、清洗、转化等数据处理程序开发；
2、开发数据统计系统，完成项目数据统计与分析任务，为业务运营提供数据支持服务；
3、根据项目需求预研并引入新的大数据分析技术。
任职要求：
1、本科或以上学历2年以上工作经验，数学/统计/计算机及相关专业优先；
2、熟悉互联网、移动互联网相关业务，了解相应主流技术；
3、有扎实的数据结构和算法基础
4、熟练使用Java，并具备2年以上JavaEE开发经验，有MapReduce，数据挖掘项目经验者优先；
6、熟悉MySQL和Redis，了解MongoDB等NoSQL技术者优先；
7、熟悉Elastic Search及使用ELK技术栈实现过数据报表者优先；
9、良好的沟通能力、团队精神及良好的服务意识，勇于接受挑战，能承受较大的工作压力；
10、具有较强的自主学习能力，具有高度责任心，较高的职业化态度；
11、具有良好逻辑思维能力。

        工作职责：
1.参与系统需求分析与架构设计，负责大数据存储规划，完成核心代码编写；
2.理解系统的业务需求，制定系统的整体技术框架、业务框架和系统架构；
3.负责给产品开发、实施、运维团队提供技术保障；
4.对系统框架相关技术和业务进行培训，指导开发人员开发，解决系统开发、运行中出现的各种问题；
5.和团队一起攻克大数据量、大用户量、实时业务、高并发、高吞吐、高可靠性等各种不同技术场景下的技术挑战。


任职资格：
1.自我驱动，对技术由衷热爱，对新技术、新方向有敏感的前瞻性，对技术和产品充满热情，极致追求；
2.熟悉大数据量、大用户量、实时业务、高并发、高吞吐、高可靠性分布式系统以及具备海量数据存储系统的架构和开发经验的优先；
3.熟悉Hadoop、HBASE等开源工具的架构，了解STORM、SPARK的工作原理，具备丰富分布式数据存储实战经验；
4.掌握Hadoop、Kafka、Zookeeper、Hbase、Spark的安装与调试；精通Javascala语言者优先；
5.熟悉关系型数据库和NoSQL数据库的应用；
6.热爱开源技术和框架，动手能力强，具备出色的逻辑思维能力及优秀的学习能力。


Job description:
1.      负责大数据平台的架构设计、技术选型、搭建和维护、系统问题定位及优化；
2.      负责基于大数据的数据仓库的建模、实施、ETL开发；
3.      负责数据产品和数据服务接口的开发和维护工作。
 
Requirements:
1.      计算机，数据分析相关专业，本科及以上学历，3年以上工作经验，至少1年以上大数据开发相关经验；
2.      熟悉Linux操作系统和Shell编程，熟练掌握Java、Scala、Python等编程语言；
3.      精通数据采集、数据ETL、基于hadoop的数据仓库建模，熟悉Flume、Kafka等；
4.      了解Hadoop大数据平台架构，熟悉HDFS/HBase/Hive/MapReduce/Spark等，具有较丰富数据分析、挖掘的大数据应用项目实践经验；
5.      对数据有一定敏感度，对大数据思想有自己的理解和认知者优先；
6.      熟悉用户行为分析模型，有风控、推荐、人物画像等领域模型构建和调优工作经验优先，有金融业数据处理工作经验，数据分析和挖掘经验者优先；
7.      工作认真负责，细心，有条理；积极性高，求知欲强；具有较强的沟通能力及团队合作精神。

岗位职责：
1、编写网络爬虫自动采集网络安全相关数据
2、大数据平台的开发、优化和维护工作
3、基于安全大数据进行的数据分析工作
 
岗位要求：
1、本科以上学历，优秀学校毕业背景优先，有安全行业从业经验者优先。
2、熟悉linux上C/C++开发，有相关的项目经验
4、新技术学习能力强，有良好的分析和解决问题的能力，
5、积极向上，良好的团队沟通合作精神
 
具备以下技能优先考虑：
1、有网络爬虫相关开发经验
2、有python开发经验，熟悉hadoop、spark等开源大数据技术

岗位职责：1、负责分布式数据仓库的主题模型设计和宽表开发工作；2、负责大数据分析需求设计和开发，承担数据抽取、清洗、转化等数据处理程序开发；
岗位要求：1、本科及以上学历，计算机/数学等相关专业，具有2年及以上大数据开发经验；2、熟悉Java或scala开发，熟悉linux操作；3、熟悉Hadoop、Hive、HBase、Spark等相关技术，具有多个以上大数据平台项目实施经验；4、具有丰富的数据仓库系统的开发实施经验，熟练设计数据模型、ETL设计；5、有较强的学习能力，对技术有钻研精神，并有较高的热情，热衷于新技术学习和实践；6、优秀的团队合作精神，对工作有热情，能够承受住压力；7、具有大数据金融风控开发经验的优先。8、具有ODPS 使用经验优先。    


负责大数据平台的研发工作，设计和开发分布式存储，数据处理和分析架构；
完成大数据智能分析工作的流程、规范和方法建立；
指导技术工程师开发，解决平台开发、运行中出现的各种问题。

任职要求：

具有5年以上大数据开发经验，对各种分布式数据架构有深入理解；
熟悉Scala，Java等开发语言，扎实的算法和编程功底，对面向对象编程有深刻的理解；
熟悉Hadoop生态和常见的开源分布式计算/存储相关技术，包括但不限于YARN，MapReduce，Impala，Spark，Kafaka等；
掌握数据仓库(DW)/ 商业智能(BI)/ 数据统计理论，并灵活的应用；
精通SQL，有较好的SQL性能调优经验，理解Hive/Mysql 基本原理和调优策略；
有开源贡献者优先。


【岗位职责】
1、针对业务需求，负责开发可扩展的、分布式的大数据系统；
2、面向业务目标，从数据模型、数据分布、数据传输、数据存储等方面进行大数据系统的开发；
3、研究前沿的数据分析建模，数据挖掘及机器学习算法，探索具有数据分析、数据挖掘能力的创新型产品。
【岗位要求】
1、至少2年以上hadoop，hive，spark开发经验；
2、精通Hadoop生态系统及相关组件，拥有Apache Hadoop实施经验；
3、精通Spark计算框架的实时采集和流处理；
4、精通Java、scala编程；
5、熟悉整个大数据的处理流程，包括数据的管理，数据的分析挖掘，服务器扩展；
6、优秀的客户服务意识，客户管理意识；思想意识开阔；
7、逻辑思维能力强，具备优秀的文档编写和良好的沟通与表达能力；
8、具有较强的沟通协调、团队合作和抗压能力。

岗位职责：
1、负责大数据平台的整体架构设计，确保系统能支持业务不断发展过程中对数据存储及计算的要求；2、负责Hadoop、HBase、Spark、Storm等系统的搭建、优化、维护及升级工作，保证平台的稳定运行。
任职要求：

1、计算机、自动化、软件、网络、通信等相关理工科专业，本科及以上学历，211院校毕业优先考虑；
2、熟悉分布式系统的架构，有分布式实时计算和云计算平台架构和开发相关经验，有Hadoop系统架构设计经验，至少1个以上大型成熟项目的经验；
3、熟练使用并理解Hadoop生态圈（Yarn、Hive、Spark、Kafka、HBase、HDFS、Sqoop、Flume、Presto、Zeppelin等）的某些部分，可进行平台调优和业务支撑设计；
4、熟悉实时计算框架Storm、Flink、Spark Streaming其中之一；
5、熟悉软件开发流程，能够根据要求编制需求、设计、开发手册等项目过程文档；
6、有较强的编码能力、数据库管理能力；
7、具备数据中心应用系统开发经验，有金融行业信息系统开发经验优先考虑。
 



岗位描述 
用户行为分析、用户建模等策略分析和制定；
推荐效果优化，召回、排序技术的研发；
机器学习项目的效果和工程优化；
推荐系统生态闭环建设与优化；
系统性地用ML、DM的方法优化推荐系统闭环。 

岗位要求  
统招本科以上学历，推荐或相关行业三年以上工作经验； 
数据结构和算法基础扎实，编码动手能力强；
熟悉linux开发环境，能够使用java，Python及相关库进行快速开发迭代，熟悉R者优先；代码风格优良，编码规范意识强；
有推荐、广告、NLP、机器学习等相关经历和背景；
能够熟练使用Hadoop进行大数据处理，熟悉Storm，Spark者优先；
问题分析能力强，能灵活使用合适算法解决问题，不轻易陷入算法、模型局限性；
能够适应多人协作快速开发的模式，团队意识强烈。 


熟练使用Java Core各个主要类库，包括IO，Collection, Reflection等
熟练使用各常用设计模式，能说出各主流框架和Java Core 使用的设计模式
有Java Concurrent 开发和NIO/BIO的相关经验
对JVM，GC，Classloading有所了解
熟练使用过诸如Spring， Hibernate等Java生态圈主流框架
对数据库有一定了解，知道隔离级别，索引的作用和实现


写过大型Hadoop集群的Map Reduce Job，能够熟料使用配置HDFS，Hbase，Hive，Flume，Zookeeper等Hadoop生态圈的各个产品。


福利待遇：
五险一金、股票期权、带薪年假、年底旅游、扁平管理、弹性工作、年底双薪、健身福利、团队聚餐、萌妹子共事……只要你有能力、有梦想、有激情，那就加入我们，福利大大滴有！

岗位职责1、配合销售进行售前技术支持：包括产品及案例介绍，功能演示，用户答疑，用户解决方案编写等；2、配合销售进行项目投标相关工作：包括投标方案，投标参数编写等；3、进行用户POC测试：包括前期用户测试需求沟通，现场产品部署，POC测试，测试报告编写等；4、用户需求反馈：包括用户需求功能真实反馈给研发，并对研发开发出来的功能进行验证，保证功能能满足用户需求任职要求1、熟悉Linux系统操作；2、 计算机、信息技术或电子类相关专业；3、有大型运维，安全相关产品售前经验，有较强用户沟通和方案编写能力；4、了解运维，网络，安全相关方面的产品功能，对相关产品的日志有一定了解；5、了解市面上日志分析产品功能者优先；6、有金融，运营商行业经验者优先。

岗位职责：-负责大数据相关平台及策略算法的测试设计、工具开发、技术改进、效果评估以及数据挖掘分析、BI等相关工作 -参与程序架构和代码的评审工作，并提出改进意见-负责测试方案制定、测试工具开发、测试质量跟进、测试环境搭建任职资格：-本科（含）以上，计算机及相关专业毕业 -计算机相关专业、热爱技术-对互联网有热情-熟悉java、 php 、 python、shell中至少两门语言-有数据挖掘、大数据处理相关了解最佳

职位描述：
1.负责公司大数据运维平台的建设、生产效率提升和优化，通过2.大数据平台，针对用户行为及内容数据分析，给客户提供基于3.用户的个性化推荐及基于UGC内容的个性化推荐，提升用户转化率和留存；
4.应用机器学习、数据挖掘技术，对用户及UGC数据形成画像，完善特征抽取；
5.技术大数据分析，为客户提供大数据分析报表，提供可视化数据方案，并提供建设性意见。


岗位要求：
1.熟悉Hadoop/Hbase/Storm/Spark等分布式计算技术，熟悉其运行机制和体系结构；
2.思路清晰，对数据敏感，有良好的沟通表达能力和跨团队协调能力，有一定的技术团队管理经验，乐于寻求挑战和突破自我；
3.具备一种或多种开发语言（如C++，Python,      Java等）的程序和算法开发能力，掌握常用数据结构和算法；
4.有一定的数据分析和挖掘能力，能从海量数据提炼核心结果，及时发现和分析其中隐含的变化和问题，有数据分析、挖掘、清洗和建模的经验优先；
5.具备清晰的策划思路，良好的沟通能力以及团队合作精神。

岗位职责:1、负责集团数据分析项目应用开发, 负责软件设计、开发、单元测试等各项工作，参与项目前期的的需求分析；2、参与技术攻关和系统优化等工作； 3、责任心强，指导其他开发人员完成工作。4、能按时、独立、高质量地完成开发任务，对代码质量要求严格
任职资格:1、3年以上相关工作经验，专科以上学历；2、精通java编程，熟悉常用开源框架，如：springMVC,spring,MyBatis,Hibernate,ActiveMQ,cas,Shiro,zookeeper,Activiti等；3、熟悉常用关系数据库和非关系型数据库，如mysql/hbase/impala/hive 等,有相关优化经验优先；4、有抽象设计能力，熟悉代码重构，能够用面向对象原则组织代码，熟悉MVC开发模式，有代码洁癖优先；5、熟悉缓存技术，如memcached,redis等；6. 有搜索，消息队列，工作流，大数据，分布式开发经验优先；7、有指导其他开发人员的经验"

价格决策作为考拉价格体系的发动机，肩负着考拉的GMV与毛利额及用户体验向着更好的方向发展的使命。 你将会和一群经验丰富的算法工程师（来自JD 、Amazon、IBM）及极富创造力的团队一起工作。在定价方面他们是电商领域的先锋。你的工作将会直接影响几万种商品的价格走势，并最终体现在客户体验上。如果您有志向在电商的人工智能领域有所建树，我们非常期待你的加入。
职位描述：1：大数据的抽取与整理 2：定位业务问题，并找到相应的模型去解决 3：模型的开发与验证及评估标准的制定 4：模型线上化
资格要求：
1：硕士以上学历（优秀本科也可） 2：5年以上算法工作经验 3：熟悉常用的模型： Logit ，LR， 支持向量机， K-mean, 关联规则等；4：数量使用 R ，MATLAB 等建模语言 5：熟悉 Hadoop，spark ，hive 等大数据的应用 6：精通 Java 及常用的开源框架7 ：精通 SQL 8：对模型的上线应用的整个流程及方法论用深入了解 9：有带团队的经验 （加分项）

岗位职责：
1、销售项目售前支持与策划，完成与用户的业务洽谈，技术交流，方案宣讲，应用系统演示等工作；
2、熟悉财政业务，准确有效的挖掘用户需求，结合客户所处行业提供业务咨询，行业分析，方案设计，项目规划等多项售前工作；
3、负责销售项目的招投标，市场活动，演示讲解及相关会谈等工作，主持标书系列文档的编写和演示；
4、财政业务，大数据，云计算等领域的前沿知识，分析竞争对手产品及解决方案，为公司产品发展，销售规划提供售前咨询；
5、根据公司项目案例总结提炼，形成标准化解决方案，为销售人员提供方案讲解，业务培训，产品咨询等指导性工作。
应聘要求：
1、本科以上学历，计算机、电子商务、工商管理相关专业，相关工作经验2年以上；
2、熟练掌握Office系列的编辑工具（PPT、word、Visio），擅长文档编写及PPT方案制作；
3、学习理解能力强，能够快速学习互联网，电商领域的业务模式，创新应用以及传统行业的业务特征，发展趋势等，能够进行梳理分析，归纳提炼；
4、具备较强的文字与口头表达能力及沟通协作能力，演讲和文档呈现能力强；
5、从事过软件，政府信息化等大型项目的售前支持，需求分析，项目实施等工作人员优先。

岗位描述：（职责）
1.  负责产品架构和核心模块设计； 
2.  负责产品核心代码编写； 
3.  负责研发团队技术指导； 
任职资格：（可量化、可考核）
1.学历：本科及以上学历；  2.专业：计算机软件、通信、电子及相关专业，有扎实的计算机基础知识；  3. 至少五年以上的研发背景，至少承担过三个以上大中型软件产品的架构设计；
4. 至少两年以上实时大数据研发经验，熟悉ELK、Storm、Spark、Hadoop、NoSQL数据库等产品，至少承担过两个以上实时大数据产品的架构设计工作；
5. 参加过正规架构师或系统分析师培训，有架构师或高级程序员证书者优先； 6.有中国移动业支BOMC、计费、CRM相关产品的架构设计经验者优先；

岗位要求：
1、大学本科以上学历、计算机、数学专业；
2、深刻理解维度建模、实体建模方法论；
3、至少2个以上大型数据仓库模型设计经验；
4、3-5年数据仓库ETL开发经验；
5、有海量数据处理与存储经验；
6、熟悉Hadoop生态圈架构，如Spark、Hive、KafKa、Hbase、Parquet等开源组件；
7、有大数据项目运维经验；熟悉阿里云数加产品（有项目经验尤佳

岗位职责：
1、协助架构师完成中台架构；
2、协助架构师完成数据建模；
3、负责协助架构师搭建中台开发平台；
4、负责指导低级别开发人员大数据开发；


岗位描述:  
1、参与数据管理平台的开发及维护；
2、参与数据平台数据产品ETL设计、开发及自动化工作； 
3、负责数据平台数据及相关的应用开发，调优及维护；
4、数据平台各类数据业务抽象及模型化。
 
职位要求：
1、具有3年以上大数据开发经验，至少熟悉一种数据库开发技术(Hive、Oracle、
Teradata、Greenplum、MySQL、PostgreSQL等)；
2、熟悉数据仓库领域知识及ETL整体流程；
3、熟练掌握一门或多门编程语言(Java、Python、Scala等)，并有大型项目建设经验者优先； 
4、熟悉Hadoop生态系统，并有Hadoop集群维护优化经验者优先；
5、有较强的书面与口头沟通表达能力，独立分析、解决问题的能力。

主要职责：(按重要程度排序) 
 
1.海量数据的处理汇总，抽取成各种数据需求 
2.参与数据仓库架构的设计及开发 
3.参与数据仓库数据处理流程优化及解决数据处理中的相关技术问题 
4.负责大数据方面的开发和优化，不断提高系统的稳定性、性能 

主要素质要求及任职资格JOB SPECICATION： 
 
1. 本科及以上学历，计算机等相关专业毕业； 
2. 2年及以上JAVA开发相关经验； 
3. 熟悉hadoop或spark、具有M/R程序开发经验、具备分布式数据存储与计算平台搭建/应用开发/运维 相关实践经验； 
4. 掌握或了解非结构化数据的保存、分析、访问、调优，在生产环境下使用过NoSQL开源产品者优先。如mongodb, redis, HBase等； 
5. 熟悉Mongodb，Redis等非关系型数据库和内存数据库优先； 
6. 具备优秀的业务理解能力，对数字敏感，有较强逻辑分析能力； 
7. 有TB级以上大数据处理开发经验者优先； 
8. 具有SPARK平台经验者优先；

岗位职责: 
1、参与数据挖掘、数据建模、数据画像等平台相关的产品规划、设计、优化。
2、接口公司BI部门，参与业务专题分析，深入研究用户行为，定期提供各产品、运营数据分析解读，提供决策指导
3、挖掘业务数据，寻找数据价值点，联合BI等公司数据分析资源在业务中实现数据价值落地。
 
任职要求: 
1、 计算机或相关专业，本科及以上学历，3年以上工作经验；
2、熟悉Hadoop、HBASE、Hive、Spark等分布式计算平台，有大数据应用系统开发经验者优先； 
3、熟悉JAVA，熟悉linux，至少熟练使用Shell、Python、Perl等脚本语言之一；
4、精通SQL，有较好的SQL性能调优经验，最好有hadoop,hive,hbase开发经验。
5、熟悉BI开发流程，参与过大型数据仓库类项目；
6、熟电子商务相关业务流程，具有业务分析及建模能力； 
7、良好的逻辑分析能力、分析问题和解决问题的能力，对数据敏感，良好的沟通能力； 
8、工作认真、负责、仔细，有良好的团队合作精神，良好的分析能力、沟通技巧。

工作职责：
负责大数据中心数据风控，运营数据分析相关系统的开发及维护。
负责微服务，知识图谱方向的项目开发实现。
负责需求立项和功能开发，承担核心架构的代码编写，负责系统改造和升级；
与相关团队协作定义，设计和实现应用新功能；
岗位要求：
3年以上Java开发经验，掌握大数据相关技术hdfs,hive,hbase。有大数据开发经验者优先
熟悉IO，多线程、集合等基础框架，熟悉分布式，缓存等机制
熟悉Spring MVC ,Spring Boot ,Spring Cloud , Mybatis ，Zookeeper，MongoDB, Linux
了解 docker, 微服务架构设计
有互联网金融指标计算，数据分析相关系统开发经验者优先。
能够及时关注业界最新技术动态和发展方向，能够独立研究并乐于分享技术,同时，要有强烈的责任心、主动性和团队合作精神； 


职位描述：

1，参与企业级数据仓库的搭建，根据数据仓库及BI项目的需求，制定ETL相关的设计方案和开发计划，并进行后续的设计、实施
2，参与数据仓库及BI项目基础架构规划、安全规划、ETL架构和规范制定,
3，根据各个产品线核心指标，分析这些核心指标背后的原因例如产品的逾期率，通过率等
4，通过数据分析、调研等手段，解决业务问题，根据资源及项目目标，确定解决方案并推进实现

职位要求：

1、计算机相关专业，本科及以上学历,2年以上相关工作经验
2、有大数据BI项目实际开发经验，熟悉saiku、mondrian、kylin
3，有丰富的数据分析经验，能够用最快速最简单的方法得出结论，驱动业务,
4、熟悉Git等开发管理工具，熟悉Unix/Linux系统
5、熟悉Hadoop系统，对HDFS、HBASE、HIVE者优先
6、语言方面熟悉Python、Java、Go者优先

岗位职责：
1.负责大数据平台搭建，数据仓库建模，及相关运维工作； 
2.利用大数据相关技术实现对数据的分析、挖掘、处理、及数据可视化等相关工作； 
3.维护大数据平台并能解决相关问题, 保障平台正常运行； 
4.学习和研究新技术以满足系统需求。 
5.其他部分开发任务。

任职资格：
1.本科及以上学历，计算机相关专业，三年或以上相关工作经验 
2.具有良好的分析和解决问题能力，对攻关疑难问题具有浓厚兴趣 
3.良好的团队合作精神，沟通能力、学习能力 
4.Java 开发3年以上经验,熟悉Spring框架
5.熟悉SQL语言，熟悉Oracle/DB2/SQLServer/Mysql至少一种数据库
6.熟悉Linux操作系统，掌握Shell或Python脚本 
7.熟悉Hadoop/Yarn/Hbase/Hive/Kafka/Spark/Flume等常用大数据组件 
8.有大数据平台建设经验者优先录用。

职位描述1.参与用户画像/标签体系系统的设计与研发工作；2.理解相关数据业务的本质需求，把握用户画像的建设方向，设计和构建基于用户行为特征标签3.建立用户画像的评估机制和监控体系4.研究用户画像与第三方的数据合作5.为个性化推荐提供标签支持基本要求1.java / python开发语言至少熟悉一种2.了解至少一种非关系数据库3.了解 mysql 、 hive的使用 、熟悉sql优化4.至少擅长一种数据分析 如 mahout、 spark-ml 、tensorflow等5.需要具有推荐系统或用户画像项目经验 （重要）6.有较多特征工程处理、机器学习相关经验者优先7.有大规模海量数据机器学习/数据挖掘/计算广告/搜索排位相关经验者优先8.有过爬虫项目经验者可优先

岗位职责：
1. 负责个性化推荐算法模型开发。
2. 负责个性化推荐服务需求开发。
3. 负责用户画像的分析与挖掘；
4. 为已有推荐产品的模型做迭代优化。 
岗位要求：
1. 本科及以上学历，3年以上工作经验；
2. 对数据结构和算法设计有深刻的理解，思路活跃，逻辑性强；
3. 熟悉Hadoop/Hive/Spark等大数据技术；
4. 熟悉c,c++, 代码功底扎实,有后台服务开发经验；
5. 熟悉常用的机器学习算法（贝叶斯，聚类，逻辑回归，SVM）
6. 有推荐系统、机器学习相关知识背景与技术经验者优先。

工作职责：1 参与以下大数据后台的架构制定、技术选型、设计开发2 海量数据离线分析和实时分析系统架构的建设和维护3 基于大数据平台的分析架构规划及研发4 相关技术文档编写岗位要求：1 计算机、通信及相关专业本科及以上学历2 有2年以上JavaSE 后台开发经验3 具备Java、python、scala开发能力4 具备大数据框架Spark、Storm、Hadoop、HBase、Hive、Flume、Kafka等项目开发经验5 具备基本SQL能力6 具备基本Linux shell命令能力7 具备很强的学习和独立解决问题的能力8 具备较好的团队协作及沟通能力9 具备阅读英文文档的能力10 具备良好的文档编写能力优先：1 具备统计、数据挖掘、机器学习背景者优先2 熟悉Python或Scala语言者优先3 具备Spark 开发经验者优先4 了解XML Schema、RESTful或WSDL、OWL概念者优先5 熟悉Hadoop、Spark、Zookeeper等部署配置者优先6 具备Cassandra 、ElasticSearch 、Solr、Neo4j等非关系型数据库使用经验者优先7 具备RabbitMQ、ActiveMQ、ZeroMQ等消息队列使用经验者优先8 研究过大数据框架源码者优先9 211/985院校优先，海归背景优先

工作地点：深圳
工作职责：
1、负责渠道系统个险风险项目数据挖掘开发工作
2、负责渠道系统常规需求大数据应用开发工作
3、负责制定项目计划并能够按计划完成任务
4、负责系统架构设计和优化，以及性能调优
5、提升团队大数据应用开发能力，评估大数据应用使用场景
应聘要求：
学位、专业：
计算机相关专业本科及以上学历
工作经验：
3年以上hadoop的应用开发经验，至少一个企业级数据仓库项目开发经验或者大数据处理项目经验
专业技能：
良好的编程习惯和开发能力，精通Java等开发语言
基本能力：
熟悉常用开源分布式系统，Hadoop/Hive/Spark/Yarn，精通源代码尤佳
其他：
3年以上mysql, oracle等数据库经验，具备优秀的SQL编写和调优能力
 
有意者请将个人简历、学历、学位及身份证正反面扫描件，近期生活彩照，一并发送到以下邮箱。
 


岗位职责：
负责大数据项目相关的产品研发。
任职要求：
1.能熟练使用Java语言进行功能模块的开发。2.熟练使用Spring、Mybatis等常用开发框架，熟练进行WEB项目的开发。3.熟练掌握Oracle数据库的SQL查询语言。4.熟悉HTML、CSS，熟练掌握Javascript语言，熟练使用JQuery框架。5.熟悉Linux的基本理论和操作。6.有工作经验，有技术特长，有过数据类型项目经验的优先。7.计算机相关理论学科基础扎实的优先。8.工作主动性强

职位描述： 1. 负责大数据集群的Hadoop/Spark/ Hbase/Hive研发工作 2. 负责海量数据的处理、分析、挖掘 3. 研究Hadoop/Spark/Hbase/Hive等开源项目，对线上任务进行调优，并开发通用组件 4. 维持线上服务高效稳定，支撑业务和数据量的快速扩张
 
任职要求： 1. 具有丰富的数据仓库开发经验，有2年以上基于hadoop/Hbase/Storm/Hive/Spark 的应用开发经验，对分布式计算，数据仓库理论有深刻理解。 2. 熟练掌握Linux常规命令与工具 3. 对Hadoop ,Hive， Storm 等源码有研究优先 4. 精通Java，Mapreduce, Python,有并发应用或分布式应用软件开发经验者优先
5. 良好的系统分析能力 6. 对数据敏感，对新技术敏感，有数据挖掘技能者优先 7. 对商业和业务逻辑敏感，具备良好的分析，组织，沟通能力和团队精神

岗位职责：
1.销售拓展阿里云产品和解决方案，包括云服务器、云数据库、云存储等产品的业务 
2.制定市场推广方案，策划年、季、月及专项市场推广计划，组织市场推广活动；
3.依靠自身销售技巧，通过现场、网络、电话各种方式开发有产品需求的用户，有效跟踪客户，直至签订合同；4.能够独立开发新客户，完成月度、季度业绩指标考核；

任职要求：
1、大专以上计算机相关专业毕业，性别不限； 2、有IT行业销售经验，对IT行业有一定的认知； 3、具有独立开发客户能力，有行业大客户切入与维护管理经验； 4、有责任心；积极、热情、乐观、坦诚、自信；有良好的敬业精神，团队合作精神； 5、具有良好的沟通技巧，说服力，亲和力，能够承受压力，接受挑战； 6、有IDC，电子商务，网络教育，网络游戏，系统集成，网络硬件设备销售等相关工作经验者优先。
7、有阿里云技术认证ACP、ACA（阿里云高级认证）者优先。

职位描述：
1、保证实时数据处理平台能稳定支撑PB级别的日数据处理，对平台进行性能优化、架构改进、算法研发等
2、实现实时数据处理平台及相关子系统的功能，如压力平衡、动态调价、ETL、数据报表、监控大屏、ad-hoc 查询、OLAP
3、开发数据化运营产品，协助工具组进行链路分析、监控报警、性能优化、故障定位等，参与产品需求沟通、规划、推进、运营等全过程
4. 负责线上系统的技术支持工作，保障系统稳定运行

任职要求：
有 Storm/Spark 实施经验，对相关技术有深入了解者优先
熟悉 Linux 系统，精通 Java
优先考虑在开源社群活跃并有积极贡献者


网易大数据平台是服务于网易各大互联网业务的大数据开发计算平台，负责数据仓库类研发工作

资格要求：
1. 本科以上学历，2年以上工作经验2. 熟悉Linux/Unix下C/C++开发3. 良好的模块代码编写和算法能力4. 熟悉数据仓库类产品，如Kudu、GreenPlum等5. 熟悉其他大数据平台如Hadoop、HBase、Spark、Hive更佳6. 良好的沟通能力和积极主动的工作态度7. 开源社区贡献者优先考虑

岗位职责：
规划与设计金山云智能推荐系统离线数据平台，包含ETL、数据存储、数据处理以及应用支持相关。
任职要求:
1.本科及以上学历，计算机相关专业优先，拥有大数据平台开发实际经验，有Spark平台经验更佳；
2.精通c++/java,python等编程语言,熟悉MapReduce及Hadoop的使用；
3.对于Hadoop、Hive、Spark、HBase等有实际的编码能力和项目经验；
4.熟悉Linux系统，能够使用Java、Python等语言进行独立开发；
5.参与过分布式高性能服务的设计开发过程，有大规模分布式系统的实践经验优；
6.对数据敏感，对多维分析、数据建模有较为深刻的理解；
7.工作态度积极主动，具有良好的团队合作意识、快速学习能力、逻辑思维能力、组织沟通能力以及优秀的问题解决能力；能够承担较大工作压力。

主要负责研究大数据的处理技术及其应用，云计算技术、自然语言处理、深度学习，主动写作与分析。
单位设4个研发中心、2个公共技术服务平台。4个研发中心包括：传感技术研发中心、工业智能化中心、海洋感知研发中心、智能信息研发中心；2个服务平台包括：智慧城市公共技术服务平台、智慧海洋公共技术服务平台。人员规模200人，其中博士学位以上40人，已引进包括加拿大皇家学院院士在内的高层次人才团队，其中国家千人计划1人，省千人计划2人，市3315创新创业团队3支。承担国家科技重大专项等国家级项目9项；宁波市重大攻关项目等市级项目5项，并已成立博士后科研工作站，并积极开展招收和培养博士后研究人员工作。

【福利】入职即上五险一金，另有餐补、交通补、全勤奖、优秀奖、年终奖金、明星见面会、还有各种做梦都想不到的福利在等你......
 
岗位职责：1、负责后台统计、数据采集系统的开发和运营维护；2、负责个性化推荐算法优化；
 
职位要求： 1、精通java语言开发，5年以上开发经验；2、熟悉 spring MVC框架；3、熟悉机器学习算法，深度学习算法；4、熟悉Hadoop/Hive/Presto等大数据技术，有相关工作经验；5、熟悉redis/mongodb等NoSQL存储技术；6、熟悉mysql数据 库开发与优化；7、熟悉主流前端技术；8、熟悉Linux服务器的操作及基本shell编程；9、有很强的分析、解决问题的能力及强烈的责任心和良好的团队合作能力。


岗位职责：
1、负责公司云计算大数据实验实训平台的总体架构设计，解决方案研发；
2、负责云计算大数据实验实训平台相关软件开发，包括基础设计、功能实现、技术实施和运营等；
3、负责开源云产品的技术追踪及研究；
4、提出新产品或新模块的架构设计或架构改进方案；
5、组织编写和审核产品开发设计等相关文档；
6、根据公司战略需求组织团队研发与管理，并进行相关技术培训。

任职资格：
1、计算机相关专业，本科以上学历，（重点院校优先考虑），具有3年以上Java开发经验；
2、熟悉Linux系统，熟练使用shell/perl/python脚本处理问题；
3、具备中大型商用软件项目的总体规划、方案设计、开发经验，并已成功上线运行；
4、具备云计算大数据高校实验实训开发经验者优先考虑；
5、熟悉云计算开源平台如OpenStack，熟练运用大数据分析处理工具（Hadoop，HDFS, MapReduce，Hbase，Hive，Flume，impala,kafka）等；
5、具备大中型开发项目的总体规划、方案设计经验者优先考虑。

岗位职责：1、负责基于Kibana+ElasticSearch相关子系统的配置及开发上线；2、负责对ElasticSearch优化，提升数据操作效率；3、对出现的与ElasticSearch相关的技术问题提供支持；4、参与制定与用户行为分析、业务指标分析，运维指标分析等相关的技术解决方案；5、负责相关技术文档的编写。任职要求：1、本科以上学历，3-5年工作经验，2-3年ELK使用经验，有监控分析或互联网项目经验者优先；2、有较好的java基础，对常用各种开源的框架如Spring、Hibernate等有一定了解；3、精通Logstash、Flume、Redis、ElasticSearch、Kafka、Kibana等Elastic生态组件，阅读过组件源码、具有组件扩展能力者优先；4、对hadoop、spark或storm生态组件有一定了解；5、了解linux平台下的常用命令，能够启停常用应用服务器和开源组件；6、良好的沟通表达能力，具备团队合作精神；热爱技术研究，理解能力强，学习能力强，专注，诚实；

职责描述：1. 企业级大数据智能安全运营与可视化产品的市场推广及售前工作；2. 熟悉产品功能并能向客户演示Demo，结合客户实际业务进行售前沟通，提供技术支持、方案制定/讲解等相关售前事宜3. 负责产品相关功能文档及售前文档的编写和完善。较强的文字组织能力，可独立完成项目建议书、工程实施方案、招投标文件等技术文档的设计和编写工作。4. 具备专业素养、气质好，定期组织和策划分区域的客户营销活动；岗位要求：1. 全日制本科及以上学历，专业不限；2. 有1年以上数据分析的工作经验、或熟悉大数据分析、安全与运维、可视化、软件应用集成项目；3. 强烈责任心，良好的沟通表达能力，组织策划能力以及团队合作精神；4. 工作地点以上海及其周边省份；5. 熟悉大数据、BI 等数据可视化软件者优先。

岗位职责：
1.负责业务需求的需求理解、数据开发，提供面向业务的数据服务；2.根据业务和产品情况对数据模型进行设计和规划并参与团队数据模型优化；3.从系统应用的角度，利用数据挖掘/统计学习的理论和方法解决实际问题；4.大规模数据的分类、聚类等算法的比较研究。
任职要求：
1、精通Java开发，熟练使用常用算法和数据结构，有较强的实现能力；2、熟悉Hdfs、Hbase、Hive等hadoop家族产品，两年以上Hadoop开发经验 ,熟悉spark生态环境，有实际开发经验的优先；3、3年以上机器学习、数据挖掘工作经验； 4、熟悉Linux开发环境， 熟悉使用常用shell命令；5、具有数据分析、数据挖掘、推荐系统相关经验者优先 ；6、5年及以上工作经验。

工作职责：
大数据可视化产品研发

职位要求：
1.985/211重点大学本科及以上学历，计算机相关专业，3年以上纯后台开发经验。
2.精通Java，具备一定的纯后台程序设计开发经验。
3.熟悉线程池或者其他并发框架，熟悉并发优化。
 
优先条件：
1．具有多线程处理经验者优先。 
2．具有NoSQL数据库项目经验优先，比如mongodb,hbase等。
3．具有搜索引擎相关二次开发经验者优先，比如solr,elasticsearch。
4．具有使用过消息队列，了解AMQP或者rabbitmq，有微服务之间或者说进程间通信经验优先。
5．熟悉Spark做过二次开发或者对spark程序有优化经验的优先（不能是只使用过里边的api或者算法）。
6．具有scala开发经验优先。

工作内容：
1、负责电商领域大数据产品功能开发。 2、研究业界最新技术及其应用，解决创新研发过程中的关键问题和技术难点； 3、分析需求，根据规范进行系统概要设计和详细设计。 4、根据项目任务计划按时完成编码实现，确保安全、质量和性能。 5、负责对结构化和非结构化数据中建立基于标签描述和层次体系的数据模型设计和挖掘。 6、参与产品技术架构讨论和技术选型。
7、如果你是具有业务思维，敢于挑战未知领域的，I Want You!
任职资格：
1、计算机相关专业，本科及以上学历，5年以上java开发经验。 2、熟悉Mongodb、Hive、Hbase、redis等NOSQL数据库开发和调优熟悉图形数据库的优先。 3、熟悉分布式开源框架和工具如ZooKeeper、Strom、Spark、Hadoop、Impala 等(计算框架会其一即可)。 4、熟悉高并发，高可用性多线程服务器端架构和开发调优。 5、熟悉JVM原理，有JAVA性能调优实践经验。 6、熟悉Active MQ、Kafka等MQ框架和协议。 7、熟悉软件设计流程和软件工程规范，具备良好而规范的设计和技术文档编写能力。 8、具有良好的沟通能力，有较强的独立工作能力和解决问题的能力。 9、对业务有敏锐的洞察力，有较强的业务理解与分析能力。 10、有大型互联网项目、电商、CRM、推荐引擎设计相关实践经验者优先！

1、按照需求，负责服务端项目的设计、维护，以及代码开发工作；2、优化系统性能， 保证服务器质量和性能；3、负责网易大数据平台技术架构，核心模块开发。

资格要求：
1、本科或以上学历，计算机软件或相关专业；2、精通java语言，熟悉常用的java开源框架，有3年及以上Java服务端项目开发经验；3、熟悉多线程编程，熟练使用java并发包下的各项常用基础设施；4、掌握mysql或oracle等数据库开发技术；5、熟练掌握Linux下的常用命令，能够利用常用的工具对程序进行跟踪诊断；6、具备良好学习、沟通能力及团队协作精神，对工作积极严谨；7、加分项：a)有使用Hadoop、Hive、Spark的相关经验； b)熟悉高性能，可扩展，高并发系统架构。

安恒AILPHA大数据团队核心研发成员来自于国际知名大数据和安全公司，比如Facebook，阿里巴巴，海康等等。50%研发人员拥有国内外重点院校硕士学位。追求卓越，不断创新是我们研发的精髓。团队结合安恒10年安全研究和产品经验，帮助客户利用大数据技术解决复杂的安全风险问题。非常期待有能力的研发技术人员加入，携手打造国内外领先的大数据技术和产品。
岗位要求：
1.三年以上的Java Web开发经验，基础扎实；
2.熟练运用Spring MVC，MyBaits等框架进行业务开发；
3.熟悉至少一种关系型数据库(如:MySQL)，能进行数据库优化；
4.熟练掌握至少一种非关系型数据库(如:HBase)；
5.能利用jQuery等插件进行前端页面开发；
6.使用过svn，git，maven等项目管理工具；
7.熟悉Linux环境下开发部署，熟悉Shell编程 。


岗位职责： 1、负责分布式网络爬虫系统设计，搭建系统框架，开发分布式网络爬虫系统； 2、完成数据采集爬取、解析提取、清洗入库等数据生产工作； 3、研究网页特点和规律，对网页信息进行分类、抽取、数据清洗、存储结构等研发和优化工作； 4、负责领域知识的定向爬取、深度提取和挖掘； 5、配合数据的清洗、整理、去重及合并等工作；
 任职资格： 1、计算机科学与技术、软件工程、信息管理及相关专业；
2、熟悉网页爬取原理及技术，熟悉深度抓取、动态网页抓取技术、熟悉请求伪装，模拟登陆，代理应用，爬虫和反爬技术； 3、精通正则表达式、Javascript、HTTP协议、HTML，善于从各种结构化和非结构化数据中抽取有用的信息； 4、熟悉http client、netty、ajax、htmlunit、Nutch、selenium、HtmlParser、Jsoup、XPATH等技术； 5、熟练多线程技术、网络编程技术、自然语言处理、信息检索、机器学习等相关优势经验者优先； 6、熟悉hadoop、hbase、Zookeeper、spark、storm、Solr、hive、kafka、redis、mongodb等相关技术者优先；

岗位职责：1、负责公司内部大数据存储计算平台等基础设施的搭建、维护、优化、改造，如hadoop, storm等 ；
 2、负责各种数据源的处理流程，并提供基础数据服务 ；
 3、协同数据仓库的设计 ；

4、能够根据需求设计和实现底层通用性工具。

任职要求：1、三年以上开发经验；
 2、工程能力强，基础扎实，使用Java/C++/C/Python等编写过足量代码； 
 3、Hadoop/Hbase/Hive/Pig开发维护经验，熟悉Map/Reduce编程； 
 4、对常见开源系统的架构设计有研究； 
 5、喜欢钻研新技术、新系统、新工具。


岗位职责：
1、业务数据仓库架构设计、建模和ETL开发，构建可扩展的数据仓库和分析解决方案；
2、为前端展示提供数据支持，为业务人员提供数据查询； 
3、大数据仓库日常管理、跑批、维护、监控。
任职要求：
1、3年以上大数据仓库项目开发经验、熟悉主流的大数据架构；
2、具有hadoop集群运维经验，熟悉Hadoop, Spark，Flume、Hive、Impala和HBase等主要工具的使用及安装配置管理；
3、熟悉Hadoop集群所需要的硬件配置。能够完成对Hadoop集群进行相应的监控、维护和性能调优；
4、熟悉hbase、hive等大数据分布式数据存储，熟悉sqoop、flume、azkaban等大数据ETL调度工具；
5、熟悉主流的消息队列中间(主流MQ、Kafka等)；
6、具有较好的故障排查和解决问题的能力，能快速分析系统相关的故障原因和解决方法；
7、有OLAP应用开发经验优先，如Kylin；
8、有大数据系统架构设计、数据分析挖掘经验者优先；
9、责任心强、思路清晰、学习力强。

主要职责：参与目前产品索引(SOLR+HBASE)的维护和优化工作，根据系统业务需要，开发对应功能。同时引入其他大数据处理技术，不断完善索引功能，提高扩展性和使用价值。 技术要求： 1.三年以上Java开发经验，Java基础扎实； 2.主导过运用Hadoop及相关产品对海量数据处理的项目； 3.熟悉HDFS、MR原理，精通MapReduce java开发或者Hadoop Streaming开发； 4.熟悉Linux环境，熟悉Linux shell/python/perl任一脚本； 5.熟悉Hive、Pig、HBase、redis、sqoop、flume等开源项目，了解HBase原理； 6.良好的沟通能力和团队组织管理能力，能独立解决问题；

职位描述：
1、 开发MapReduce/Spark/Storm程序，能解决实际线上生产系统（Hadoop，HBase，Zookeeper，Redis以及各种生产任务等）的各种问题；2、设计开发自有离线/实时/流式数据计算平台等；3、维护线上任务的稳定产出，跟踪hadoop社区新动态；4、对Hadoop平台运维不断优化，提升数据产品的质量和响应速度；5、开发各种Hadoop大数据自动化运维与监控工具。

能力要求：
1、一年或以上Hadoop项目开发经验；2、熟悉Hadoop、Hive、HBase等分布式开源项目及工作原理，有Hadoop集群优化、开发和维护管理经验；3、熟悉Linux操作系统，网络协议，熟练使用Shell；4、软件基础理论知识扎实，具有良好的数据结构、算法功底；5、有实时数据处理经验者或交通行业海量数据处理经验优先；6、学历本科或者以上。

岗位描述：
1、大数据软件功能组件的优化方案设计和开发工作；
2、根据需求设计、开发、测试和集成软件功能模块；
3、撰写大数据软件产品相关文档；
任职要求：
1、本科及以上学历，计算机、通信电子等相关专业；
2、熟悉Java/Python/node等开发语言，至少精通一种，具有2年以上编程开发经验；
3、熟悉Linux操作系统者优先；
4、熟悉大数据/Hadoop相关技术者优先；
5、熟悉Oracle/SqlServer/MySql/PostgreSQL/MPP等数据库产品优先；
6、有机器学习、数据挖掘等相关工作经验者优先；
7、有较强学习能力，性格积极乐观，沟通协调能力较好，且能够在压力环境下工作。

岗位职责
1.大数据产品的设计和开发；
2.在深入理解大数据产品系统基础上，不断追求高性能、低价格、高可用、高可靠；
3.编写详细设计、用户手册等相关文档。
任职要求
1.有至少三年以上大数据项目实施经验；
2.熟悉Linux操作系统下程序开发；
3.精通大数据编程语言，有分布式并行计算的开发经验；
4.精通spark分布式并行架构；
5.有团队合作能力，具备良好的分析解决问题能力，能独立承担任务

岗位职责
1.负责公司Spark集群的架构设计和开发；
2.实现基于Spark框架的分布式计算框架的开发；
3.Spark技术研究和通用数据平台的性能调优；

职位要求
1.本科及以上学历要求，计算机或相关专业背景；
2.四年以上数据领域技术开发经验，其中两年以上Spark开发经验；
3.熟悉Python、Scala语言；
4.熟悉Spark Streaming和Spark SQL，对Spark原理及底层技术有深入了解；
5.良好的团队合作意识、沟通能力；
6.有过海量数据系统开发经验者优先；
7.有智能家居、物联网或一线互联网公司从业经验者优先。

1、负责公司大数据离线、实时平台（如Hadoop/Hive/Storm/Spark）的建设、优化；
2、负责开发大数据工具，如报表平台、多维度分析工具、ETL平台、调度平台的研发；

岗位要求：
1、熟悉Hadoop、Hive、Spark、Storm的原理、优化；主导过大型数据平台建设者优先
2、熟悉数据仓库理论，对多维数据建模有深入理解和实际经验；
3、熟悉开源大数据平台如HBase、ES、Kylin、Druid等，有实际的报表平台、多维度分析工具、etl平台、调度平台中至少一种工具的实际建设经验；多种经验者优先；
4、熟练进行Java、Python的代码编写，良好的代码编写素养，良好的数据结构算法技能；
5、思维敏捷，有较强的钻研学习能力；
6、较好的沟通能力、团队合作；

岗位职责：
1、作为技术骨干，承担云PaaS产品的规划、研发及产品工程实施等；
2、支撑云大数据PaaS产品的现场运维，保障生产系统的稳定及高效运行；
3、参与客户交流、及方案编写和评审等工作，能支撑PaaS产品的客户交流活动；
4、愿意技术交流及分享，对工程师及助理工程师进行培训、指导、帮助，提高其技术水平；
5、具备良好的沟通能力，能跨部门协作。
 
任职要求：
1、熟练掌握java编程技术，熟悉Struts/Spring/Hibernate等主流开发框架；
2、熟悉linux操作系统，熟练应用shell命令，熟练掌握shell等脚本语言；
3、熟练掌握SQL，熟练使用数据库（Oracle或MySQL等），能进行常见问题定位及调优；4、熟悉Weblogic或Tomcat等应用服务器，了解分布式集群部署方案，能熟练掌握应用部署、运维及调优等；5、计算机或相关专业本科及以上学历。

岗位职责：
1、利用大数据平台进行数据分析挖掘； 
2、从事大数据后台用户画像建设和优化工作。

任职资格： 
1、 全日制本科及以上学历，至少2年相关工作经验，熟悉Linux开发环境，熟练掌握Shell、SQL、Python，熟悉Java者优先； 
2、 熟悉Hadoop、Hive、Spark等大数据平台；
3、熟悉常见的数据挖掘算法，有大规模用户画像项目经验者优先； 
4、有较好的问题分析和问题解决的思路； 
5、责任心强，耐心细致，能承受一定的工作压力。

1、3-5年以上JAVA WEB编程经验。
2、熟练J2EE编程开发技术（JSP、JSTL、JDBC、JavaScript等相关技术）。
3、熟练掌握Spring、Spring MVC、JPA或Hibernate等主流的开发框架。
4、熟悉主流JavaScript，掌握jquery、bootstrap等（优先）
5、能够熟练编写Shell/Perl/Python/scala程序，了解Django框架
6、熟悉cloudear-hue的部署、使用
7、了解Docker的原理，掌握Docker等相关容器的实施
8、有以下一种数据库的开发经验：oracle、mysql、PostGreSQL
9、有能力对大规模分布式集群的CPU/内存总体情况、网络吞吐、I/O吞吐进行监控、测试、调优（优先）
10、有Linux服务器的性能调优能力，大规模服务器的运维经验（优先）
11、熟悉Hadoop/Spark，包括原理、架构、代码，具有相关研发经验，能够进行性能调优、功能扩展以及故障排除（优先）
12、了解Hadoop/Spark配置的参数意义及相互关系
13、熟悉hdfs、hive、hbase等框架，可以独立完成相关开发任务
14、掌握以下任意一种java消息中间件的开发和运维技术：包括zeromq、kafka、rocketmq
13、有较强的团队协作和沟通能力，具备较强的技术研究能力和攻关能力，善于学习新事物。
14、工作责任心强，能承受一定的工作压力。

职位要求：1、全日制本科及以上学历，计算机相关专业；2、3年以上java语言编程经验；3、1年及以上Hadoop开发与应用经验，熟悉MapReduce、Storm、spark、Pig、Sqoop、hbase、hive等主流大数据技术；4、对数据敏感，善于发现数据中的潜在规律；有大数据分析、java架构和实施经验者优先；5、工作有计划性，责任心和执行能力强，具备高度的责任心、诚信的工作作风、优秀沟通能力及团队精神；6、具有良好的语言表达和文档撰写能力；良好的自学能力，可以快速学习和掌握新的方法和技术。

职位描述：
1、进行hadoop/spark平台技术引进和推广，并能结合用户需求快速落地推广；
2、负责大数据分析需求设计和开发，包括数据集市、实时分析、数据展示等的开发，并交付生产，确保输出成果；
3、不断积累和构建数据平台组件，对各项指标统计服务进行复用，提升公司的技术和应用能力。
 
招聘要求：
1、熟练使用Scala，java语言；
2、具有2年以上大数据相关工作经验，熟练掌握spark，hive，hadoop开发，有一定调优经验；
3、对数据统计，报表展示业务需求进行负责；
4、有良好的口头和书面表达能力；
5、良好的结构化问题解决能力。

岗位职责：
1、根据需求，负责相关大数据应用模块设计；
2、负责大数据平台及应用研发工作；
3、负责代码实现、单元测试、代码修改和维护等工作；
任职要求：
1、3年以上开发经验；
2、扎实的计算机编程能力和良好的编程习惯，熟悉linux环境下编程，精通java/python/scala语言，熟悉常用的shell命令工具，熟悉Git/SVN等源代码版本控制工具，熟练使用Eclipse，idea，Tomcat，Apache等工具；熟悉linux操作系统及命令；
3、掌握多线程及高性能程序设计编码及性能调优，有高并发应用开发经验优先；
4、从事过分布式系统的设计、开发、调优工作优先，熟悉Hadoop、Spark 、ambari 、Hbase、Hive、MongoDB、ElasticSearch、Redis、RabbitMQ等开源项目优先，具有数据挖掘机器学习经验者优先。；
5、良好的沟通交流能力，文字语言表达能力，较好的逻辑分析能力；强烈责任心，开放的性格； 擅于协作，具备良好的团队合作精神；善于学习；

岗位职责1、负责公司大数据平台的开发和维护，负责大数据平台持续集成相关工具平台的架构设计与产品开发等工作；
2、主要从事网络日志的大数据分析工作，包括:网络日志的数据提取、数据融合及分析；专注于实时计算、流式计算、数据可视化等技术的研发； 3、具有很强的学习和独立分析能力、工作责任心、良好的沟通能力和团体合作精神。任职要求1、三年以上JAVA开发的经验，统招大专以上学历，计算机、软件相关专业； 
2、熟悉Hadoop、Hive、Spark、Storm等大数据技术，并有一定的开发经验；3、对MySQL、Redis、HBase等数据库有一定的了解和使用经验；4、熟悉Linux系统及shell、python、scala等语言； 
5、具备极强的团队精神和合作精神，对工作有热情，能够在一定压力下工作。

岗位职责：
1、搭建、调优并管理公司分布式存储平台；
2、从公司内部各个相关业务系统中抽取数据，对数据进行清洗和必要的加工处理（ETL），并存储至平台中提供统一的访问机制；
3、根据对业务需求，从稳定性、功能、性能、可用性、安全性等方面，负责实现、改进调度系统的各个模块；
4、维护分布式存储平台高性能，低延迟；
5、为各种线上应用提供及时的技术支持，能从中提取出有价值的用户需求，并能反馈至模块中。任职要求：
1、3年以上数据库管理和开发经历，熟练的系统架构、复杂系统软件的设计能力和调试能力，有分布式文件系统经验优先；
2、精通pl/sql编程及数据仓库ETL开发, 有海量数据处理相关经验，具备数据库迁移、同步、集成等中间件开发经验者优先；
3、熟练使用Python，Java，Scala， C++等至少一种编程语言；
4、熟悉 Hbase、Cassandra、Hive、Google File System、HDFS 至少其中一种；
5、善于独立思考，能够主动发现问题、分析问题，有系统化的问题分析能力和解决问题的能力；
6、对未知领域有一定的学习、探索和研究能力；
7、喜欢挑战性的工作，饱满的工作激情，能承受工作压力，有较强的自我驱动能力；
8、 较强的团队合作经验，能够很好的团队合作及沟通并达成共赢。

工作职责：1. 参与业务需求的数据分析，协助模型设计师完成数据源分析工作2. 负责数据仓库建模、ETL的设计和开发 3. 负责数据仓库ETL流程的优化及解决ETL相关技术问题4. 构建用户画像并持续优化5. 推荐算法的持续优化任职要求：1.计算机相关专业；2. 本科以上学历，3年以上BI从业经验；3. 熟练掌握hadoop2.0生态体系；4. 对hive，hbase，hdfs，mapreduce有实际使用经验，对spark等有实际项目经验的优先考虑5. 熟悉数据ETL原理，熟练应用Datastage，Informatica及开源kettle工具； 6. 熟悉Oracle/mysql数据库，熟练pll编程，有较好的sql性能调优经验；7. 丰富的调度系统设计与开发经验,能够持续优化并提升调度系统； 8. 良好的沟通表达（口头及书面）和文档交付能力；

工作职责：
1.负责业务线数据实时计算的研发工作。
2.对接业务需求，提供实时特征更新机制。
3.持续改进系统架构、保证系统高性能、高可用性和高可扩展性。
工作要求：
1.精通Java语言，熟练掌握NoSQL数据库等技术，有大规模分布式系统使用经验。
2.熟悉Storm流式计算平台，熟悉Hadoop、Hive、Spark等分布式数据处理平台。
3.熟悉常用的设计模式，注重代码质量与可维护性。
4.优秀的分析及解决问题的能力，责任心强，细心耐心。
5.有搜索、推荐、排序等策略系统经验者优先。
6.优秀的分析及解决问题的能力，责任心强，细心耐心，对美食和吃文化有热情者优先


熟练使用Java Core各个主要类库，包括IO，Collection, Reflection等
了解设计模式，至少能说出1，2个设计模式的常用使用场景
了解数据库编程，能独立写SQL语句，使用JDBC，Transaction来和数据库交互
使用过Spring， Hibernate等Java生态的框架会是一个Big Plus
写过Map Reduce Job，对Hadoop 生态的各个产品HDFS，Hbase，Hive等有一定了解


福利待遇：
五险一金、股票期权、带薪年假、年底旅游、扁平管理、弹性工作、年底双薪、健身福利、团队聚餐、萌妹子共事……只要你有能力、有梦想、有激情，那就加入我们，福利大大滴有！


岗位职责：
 
1. 进行大数据批量清洗，入库及处理相关 ETL 工作，并作线上维护；
 
2. 实现实时数据处理过程，提供可靠实时数据服务；
 
3. 对业务和数据进行梳理，设计大数据模型，构建应用主题集市；
 
4. 实现简单的数据挖掘及机器学习算法，支撑智能型项目数据相关模块的开发；
 
5. 对上线的数据指标及服务进行运营和维护；确保数据服务的质量；
 
 
任职要求：
 
1. 2年以上大数据处理相关经验；
 
2. 熟悉主流数据仓库模型设计，有分布式计算平台（Hadoop,Hive，spark 等）实践经验；
 
3. 精通SQL，理解 Hive/Mysql 基本原理和调优策略并有丰富的实践经验；
 
4. 熟悉Java／python／R编程中的一种，能熟练进行Storm、Spark和Hadoop之上的开发；
 
5. 具备优秀的业务理解能力，对数字敏感，有较强逻辑分析能力；
 
6. 有移动互联网或手机证券大数据开发经验优先;
 
7. 个性乐观开朗，激情、愿意分享，自驱能力强，良好的结果导向和抗压能力
 
8. 诚恳、踏实、谨慎细致、对工作充满热情、优秀的学习能力，具有良好的自律意识和上进心；

岗位职责:1、按照公司项目实施管理有关规定对项目进行实施；2、带领项目组进行项目实施，对整个项目的进度、成本、质量负责；3、负责项目组人员的管理、指导、培训及评估。
任职资格:1、全日制本科及以上学历，计算机统计学应用数学等相关专业优先；2、3年及以上BI项目实施、项目管理相关工作经验，具有大型企业集团经验者优先；3、熟悉IT项目实施方法论，具备PMP认证者优先；4、业务理解能力强，认真负责、逻辑性强、具有良好的沟通表达能力，团队合作意识佳。

岗位职责：
1、负责基于Spark技术的海量数据的处理、分析、统计、挖掘工作；
2、基于Spark框架的数据仓库的设计，开发，维护；
3、根据需求使用Spark Streaming和Spark SQL进行数据处理、查询、统计等工作。

岗位要求：
1、本科及以上学历，软件工程、计算机等相关专业，优秀硕士研究生优先考虑；
2、熟悉RDD/DataFrame编程，对Spark体系结构、运行机制有深入研究，熟悉源码；
3、熟悉Spark相关技术；
4、熟悉linux、shell脚本或python脚本编程；
5、熟悉Spark Streaming和Spark SQL，有过程序开发经验；
6、具有良好的Trouble Shooting能力；
7、能够用python开发数据算法，熟悉python算法库的优先；
8、具有海量数据系统开发经验，且在开源社群活跃并有积极贡献者优先考虑。

职位描述：
1.负责公司内部大数据平台的建设与维护，优化数据处理流程；
2.负责数据平台的建设，统筹管理接入、存储、查询、挖掘等体系；
3.追踪现有大数据前沿技术，优化现有大数据架构 ；
4.在游戏领域展开数据挖掘方向的技术突破与实施。

职位要求：
1.2年以上大数据研发经验；
2.数学、统计、计算机相关专业；
3.拥有完整的从数据收集端到展示端实际项目经历，熟悉Hbase/Hive/Hadoop/Spark或等主流分布式开发平台，有高性能集群设计和开发经验；
4.精通Linux，熟练掌握Python/C/Shell/Java，熟练掌握SQL数据库语言HiveSQL/Mysql；
5.有数据挖掘算法实施经验，熟练掌握大规模数据挖掘、机器学习。


岗位职责：
1、通过但不限于EDM、SMS、PUSH等方式对目标客户进行精准营销，优化营销内容，收集营销实施效果；
2、通过大数据分析、场景化运营持续提升用户活跃度，召回预流失和已流失用户，针对不同类型用户设计有效激励机制；
3、通过数据库挖掘和市场分析，挖掘潜在目标客户的特征与属性，建立客户分层，并制定相应的精准营销策略；
 
任职要求：
1、本科以上学历，3年以上互联网、电商运营经验；
2、精通会员营销的相关工具、手段，熟悉会员营销及活动策划的相关流程与环节；
3、具有策划、分析、推广及营运经验，有丰富的运营经验，以结果为导向；
4、善于挖掘真正的用户需求，注重细节优化，逻辑性强，具有较强的主观能动性。

北京捷通华声科技股份有限公司成立于2000年，是一家专注于智能语音、智能图像、语义理解等人工智能技术的研究与应用的高新技术企业。公司率先推出了全球首个全方位人工智能开放平台—灵云平台（aicloud.com），将语音交互、图像识别、语义理解、生物特征识别等技术完美整合，实现并提供全方位一体化的人工智能技术解决方案与服务，并在滴滴打车、携程、京东、小米、百度、农业银行、中信银行、太平洋保险、奔驰等多家知名企业得到广泛应用。2013年，清华大学产业基金入资捷通华声，成为公司第二大股东，随后双方共同创立“清华灵云人工智能研究中心”。    
职位描述：    1.负责灵云人工智能大数据系统设计、功能模块设计，数据平台的搭建、维护和优化；    2.负责规划数据挖掘的整体流程，并参与用户产品和数据产品的决策；    3.与业务部门密切配合，寻求数据层面的业务价值，利用数据分析结论推动产品优化；    4.带领团队对于产品数据进行分析，指导工程师完成数据挖掘相关的算法、应用的设计与开发；    5.技术团队的管理，制定开发规范，撰写相关技术文档指导和培训工程师；    6.负责解决核心技术问题，对技术方案进行决策。        任职资格：    1.学历要求：     -毕业于211或985院校、统招本科及以上学历，数学、统计学、计算机信息类等专业背景；    2.工作经验及能力要求：     -5年以上工作经验，2年以上团队管理经验；     -对数字，数据敏感，具备良好的逻辑思维能力，能够从海量数据中发现有价值的规律；     -优秀的分析问题和解决问题的能力，具有较好的归纳能力与较好的文字和语言表达能力；     -熟悉数据结构,熟悉数据挖掘和机器学习算法等常用算法,并对机器学习算法和理论有较深入的研究（如对熟悉决策树、聚类、逻辑回归，序列标注,关联分析、SVM，贝叶斯等数据挖掘算法有较深理解和实践经验）；     -熟悉java/Python，有算法研究背景经验；     -熟悉文本挖掘分析方法及分布式数据分析工具使用；     -熟悉Hadoop、Spark平台，熟悉storm的流式处理框架，熟悉Hive工具，有百T左右数据处理经验；    3.优先考虑：     -有社会性网络数据的挖掘经验者优先。    

岗位职责：
1、 规划及建设大数据平台；
2、 负责大数据存储系统、分布式计算系统、挖掘算法等设计、研发以及维护、优化工作；
3、负责分析、挖掘、对抗各种产品安全层面的恶意行为；
4、 参与项目的系统设计和核心代码开发，指导和培训其他工程师；
5、 整理和提交技术文档，负责核心功能模块的代码编写和测试工作。

岗位要求：
1、 计算机、统计学等相关专业本科及以上学历，具有深厚的数学、统计学和计算机相关知识，精通数据仓库和数据挖掘的相关技术，3年以上大数据开发相关经验；
2、具有非常扎实的Java基础，熟悉Shell、Python、R、Scala等一种以上语言；
3、算法基础扎实，熟悉常见的数据结构，了解分布式算法和分布式系统的技术原理；
4、精通MapReduce设计方法或Spark计算框架、对NoSQL，Hadoop、Hbase、Spark、Hive等主流云计算，大数据相关软件有充分的了解，并且有实践经验，能解决应用中的复杂问题；
5、熟悉大数据处理相关技术，包括但不限于Hadoop、Hive、Hbase、Impala、Spark，Kafaka、Flume、Sqoop、Storm、Redis等；
6、研读过Hadoop、Hbase、Hive源代码者，能够在特定业务中进行定制改造者优先；
7、具有海量数据处理、数据挖掘、数据分析相关项目的工作经验者优先。

岗位职责：

负责大数据分析系统的需求分析和整体架构设计，负责确定软硬件实施方案；

2. 负责核心技术问题的攻关，解决项目开发过程中的技术难题；
3. 负责大数据分析系统相关具体应用算法的设计，开发；
4. 根据公司产品和业务发展特点，负责研究相关大数据产品和技术发展方向。

任职要求：
1. 计算机、信息系统相关专业本科以上学历，3年以上相关工作经验；
2. 掌握Java语言，对Hadoop相关的技术和组件(HDFS, MR, Hbase, Hive, Spark, Storm, Kafka等）有全面深入了解，能够熟练安装，配置，部署和优化大型Hadoop 集群系统；
3. 有TB级大数据处理实战经验，熟悉整个大数据的完整处理流程，包括数据的采集，清洗，预处理，存储，分析挖掘；
4. 熟悉互联网常见的业务模式和用户行为分析模型，熟悉常用的数据挖掘技术和算法，如路径分析、关联规则挖掘、分类、聚类、协同过滤等。

5. 身体健康，有上进心，有良好的沟通能力，逻辑思维能力和团队协作能力。

职责：
1，负责相关的统计学算法设计与建模实施；
2，负责使用统计学方法对业务进行剖析和数据指导；
3，负责前沿统计学方法研究与算法难题攻坚；
要求：
1，本科三年以上工作经验，或研究生，数学／统计学／机器学习相关专业者优先；
2，精通至少一门编程语言：C++／Java／Python，熟练掌握Linux日常操作；
3，能够熟练使用所掌握编程语言的统计学算法库与计算框架；
4，良好的数学基础，熟练掌握常规统计学方法的原理与特性区别，能够熟练应用并解决实际问题，包括但不限于：聚类／分类／数据挖掘／机器学习／一般统计学方法／运筹学；
5，具备独立的算法设计、实施、验证能力；
6，熟练掌握数据建模的过程：样本选择、特征工程、假设检验、参数寻优；
7，了解大数据与人工智能行业技术背景，主流问题；
8，在相关领域取得业务成绩或突破性成果者优先；
9，一般互联网文化素质要求；

薪资15-40K，各级都要，因网站限制，故薪资栏写的20-40

岗位职责：
1、参与分布式应用系统和平台的架构设计。
2、参与分布式存储系统的架构设计。
3、参与大规模分布式机器学习算法的设计。
4、跟进大数据领域的新技术并将合适的应用到系统中。
5、充分考虑系统架构的质量。
6、参与核心模块的开发。
7、指导和培训工程师。
8、主导新课题的研究，形成研究成果。
任职要求：
1、三年以上软件开发工作经验，计算机、数学或相关专业本科及以上学历；
2、熟悉Linux操作系统和开发环境；
3、熟悉Java开发，熟悉JAVA平台多种常用框架；
4、熟悉常见网络协议、数据结构和算法、面向对象的设计模式；
5、熟悉Hadoop、Spark等大数据框架并有设计和开发经验；
6、了解数据挖掘、机器学习的概念和算法；
7、对大数据研发有浓厚兴趣；
8、有大型分布式计算开发、部署等相关经验；
9、能迅速领会业务需求并发现潜在的问题；
10、能迅速将业务需求转化为系统架构，并充分考虑系统架构的质量；
其它要求：
1、对业务领域内的新技术或新的技术趋势及时掌握, 善于研究前沿技术和处理技术困难，有较强的创新意识。
2、善于学习，进取心强烈，具有独立分析、解决问题的能力。
3、对新技术敏感，有一定独立分析，技术研究能力，具有良好的团队合作精神。

职位描述：1、以用户产生的海量行为日志为基础，进行个性化推荐；2、熟练掌握推荐算法模型，了解算法的核心内容，负责智能推荐相关算法的设计和优化；3、对推荐效果进行跟踪，对推荐策略持续优化。
职位资格1、3年以上工作经验，本科及本科以上学历；2、熟悉java后台程序设计，有实际系统的问题排查与调优经验；3、掌握hadoop、hbase、kafka、spark等分布式数据存储和分布式计算平台原理，具有相关系统的调优、 运维、开发经验；4、熟悉linux开发环境，熟悉python、shell、perl中的一种；5、对数据结构、算法有深刻理解，有hadoop等系统的源代码阅读经验者优先。

岗位职责：
在大数据相关项目中，进行需求调研和需求分析工作
1.根据项目要求和产品规划，负责组织收集客户需求、公司内部需求，整理需求分析文档。
2.工作在整个项目生命周期中，进行客户沟通、需求分析、系统分析、梳理系统流程、梳理数据流程，辅助开发人员理解需求，在开发完成后进行需求验证，并负责需求跟进和需求变更管理。
3.做好工作流程上的衔接，对接项目组的其他岗位人员进行协作，如数据开发人员、WEB应用开发人员、产品经理等。 
岗位要求
1.计算机、数据、统计相关专业，本科及以上学历，有强烈的责任心和团队合作精神，具备良好的沟通能力、快速学习能力、分析判断能力、创新能力。
2.有较强的分析能力，对需求有较强的理解、沟通能力，能引导并解决客户的业务问题，控制客户需求及范围
3.有数据从业背景，对数据有敏感性，能够深度理解数据应用和数据流程，熟悉常用数据库使用和sql语言编写，能够深刻理解和严密描述数据指标的计算逻辑。
4.熟悉系统分析方法，熟悉uml工具，善于编写文档，具备java应用开发或者数据开发经验。
5.3年以上工作经验，参与过中大型项目的实施工作，有一定项目管理能力。
6.能够中短期出差到客户现场工作

岗位职责：
 
1.进行大数据批量清洗，入库及处理相关 ETL 工作，并作线上维护；
 
2.实现实时数据处理过程，提供可靠实时数据服务；
 
3. 对业务和数据进行梳理，设计大数据模型，构建应用主题集市；
 
4. 实现简单的数据挖掘及机器学习算法，支撑智能型项目数据相关模块的开发；
 
5. 对上线的数据指标及服务进行运营和维护；确保数据服务的质量；
 
 
任职要求：
 
1. 2年以上大数据处理相关经验；
 
2. 熟悉主流数据仓库模型设计，有分布式计算平台（Hadoop,Hive，spark 等）实践经验；
 
3. 精通SQL，理解 Hive/Mysql 基本原理和调优策略并有丰富的实践经验；
 
4. 熟悉Java／python／R编程中的一种，能熟练进行Storm、Spark和Hadoop之上的开发；
 
5. 具备优秀的业务理解能力，对数字敏感，有较强逻辑分析能力；
 
6. 有移动互联网或手机证券大数据开发经验优先;
 
7. 个性乐观开朗，激情、愿意分享，自驱能力强，良好的结果导向和抗压能力
 
8. 诚恳、踏实、谨慎细致、对工作充满热情、优秀的学习能力，具有良好的自律意识和上进心；

岗位职责 1、负责公司大数据平台产品的技术工作，包括存储、处理、分析、挖掘、架构设计、研发工作； 2、负责设计、构建和优化基于hadoop/Hbase的存储平台架构； 3、负责整体提升hadoop/Hbase/Storm/Spark集群的高可用性、高性能、高扩展特性； 4、根据业务需求，提出最优的技术解决方案；

任职资格
1、精通Java/C++开发，至少1年以上Hadoop相关开发经验； 2、了解HDFS读写机制，对Hadoop源码有深入研究； 3、对hadoop的Map/Reduce有相关项目的实际开发经验； 4、熟悉Hadoop、Hive和hbase、storm等开源项目； 5、对基于hadoop的大数据处理体系有深入认识，具备相关产品（hadoop/storm /hive/hbase）项目应用研发经验；
6、熟悉分布式系统、分布式计算系统的工作机制，能熟练掌握相关核心技术的工作机理；
7、具有大规模数据平台，高并发大型系统，大数据等架构设计和开发经验。  

职位描述：
1、参与网络数据资源的收集，分析工作；
2、参与网络数据源的采集程序开发工作；
3、参与采集系统功能模块的代码编写、单元测试工作；
4、参与大数据平台的数据清洗、分析工作。
任职资格：
1、计算机，软件工程或相关专业本科或以上学历；
2、三年以上java软件开发经验，熟悉Struts、Spring、Hibernate等开源框架；
3、熟悉多线程技术、代理技术、网络编程技术。
4、有爬虫和反爬技术、网页信息抓取技术、深度抓取、动态网页抓取技术、浏览器模拟抓取技术、从结构化的和非结构化数据中获取信息、自然语言处理、信息检索、机器学习等相关任何优势经验者优先；
5、熟悉分布式系统、hadoop、hbase、Zookeeper、Solr、Redis等相关数据集群技术者优先；
6、具备较强的交流、沟通和表达能力以及良好的团队合作精神；
7、为人诚恳实在，能吃苦耐劳，职业道德素质高，人品过硬，工作认真，细心，有条理。

我们可以提供：
1、挑战性的工作机会和良好的个人发展晋升空间。
2、舒适的办公环境、良好的团队合作氛围和自由的技术发挥平台，充分重视员工的自我价值实现。
3、五险一金、员工福利、运动会、嘉年会、每周羽毛球、拓展等各类活动、集体旅游......
4、绩效奖励及其它晋升、调薪福利结构。
5、五天工作制，周末双休。
鹏元之道、以诚为本、以人为本，广纳英才，期待您的加盟共创美好明天！

1、3-5年以上JAVA WEB编程经验。
2、熟练J2EE编程开发技术（JSP、JSTL、JDBC、JavaScript等相关技术）。
3、熟练掌握Spring、Spring MVC、JPA或Hibernate等主流的开发框架。
4、熟悉主流JavaScript，掌握jquery、bootstrap等（优先）
5、能够熟练编写Shell/Perl/Python/scala程序，了解Django框架
6、熟悉cloudear-hue的部署、使用
7、了解Docker的原理，掌握Docker等相关容器的实施
8、有以下一种数据库的开发经验：oracle、mysql、PostGreSQL
9、有能力对大规模分布式集群的CPU/内存总体情况、网络吞吐、I/O吞吐进行监控、测试、调优（优先）
10、有Linux服务器的性能调优能力，大规模服务器的运维经验（优先）
11、熟悉Hadoop/Spark，包括原理、架构、代码，具有相关研发经验，能够进行性能调优、功能扩展以及故障排除（优先）
12、了解Hadoop/Spark配置的参数意义及相互关系
13、熟悉hdfs、hive、hbase等框架，可以独立完成相关开发任务
14、掌握以下任意一种java消息中间件的开发和运维技术：包括zeromq、kafka、rocketmq
13、有较强的团队协作和沟通能力，具备较强的技术研究能力和攻关能力，善于学习新事物。
14、工作责任心强，能承受一定的工作压力。

岗位职责：

1、负责大数据平台的设计和开发；2、负责海量数据的处理、分析、挖掘；3、负责高并发、大存储的数据系统，实时计算处理系统的研发。

任职要求：

1.本科或以上学历，计算机软件相关专业优先；2.2年以上大数据处理，大规模的数据分析和算法实践；3.精通hadoop / Spark编程，或者具有其他并行计算的实践经验；4.熟悉Mysql/Redis 等常用SQL和NoSQL数据库；5.至少熟练掌握Java、Python等两种以上语言；6.熟悉Hadoop、Spark生态圈，能运用其解决问题；7.有丰富的大数据集群部署和维护管理经验；8.良好的沟通，团队合作意识，非常强的学习能力。

福利待遇：

1.超出行业平均水平的薪资，多少全凭能力决定； 2.享受五险一金，并提供餐补、交通补贴等； 3.公司发展离不开员工的努力，员工重大事件公司将慰问及关怀； 4.弹性工作制，全天7H工作时间，完美避开上下班高峰时段； 5.享受国家法定假日及周末双休，享有带薪年假、病假、调休假等； 6.每月举行一次Birthday Party，日常工作日茶餐厅提供饮料、零食、水果等； 7.传统佳节会有高标准的节日礼金或礼品； 8.每年将进行豪华套餐的健康体检； 9.在超过2000平舒适的工作区域工作，保证最佳工作状态。



工作地址：成都市高新区天府软件园E区E3-1-3F

岗位职责：
1、基于hadoop生态的大数据存储平台搭建和部署; 
2、承担数据抽取、清洗、转化等数据处理程序开发； 
3、商用平台指标数据挖掘。
4、基于大数据平台(Hadoop)完成各类统计和开发任务。
5、完成日常数据分析查询需求
6、大数据的设计，开发，维护

任职要求：
1、计算机或者相关专业本科及以上学历, 2 - 3年以上相关工作经验;
2、精通java语言开发，同时熟悉groovy/scala语言开发优先考虑； 
3、熟悉Hadoop工作流程，熟悉MR执行流程，能够编写MapReduce程序，同时具有storm/spark开发经验优先考虑； 
4、熟练使用SQL，熟悉数据库原理，熟练使用至少一种主流关系型数据库； 
5、熟悉ETL开发，能熟练使用至少一种ETL(talend,kettle等)转化开源工具优先考虑； 
6、熟悉Linux操作系统，熟练使用常用命令，熟练使用shell脚本。

参与京东商城Y事业部收益管理与供应链运筹优化项目中大数据方面的开发工作：
1.      负责数据分析、加工、清理、处理程序的开发
2.      从事海量数据分析、挖掘相关工作
3.      负责数据相关平台的搭建、开发、维护、优化  
任职条件: 
1.      计算机相关专业，本科及以上学历，5年以上Java开发工作经验，学习能力突出；
2.      熟悉hadoop生态系统内常见项目的使用（hdfs、hive、hbase、spark、zookeeper,yarn等），具有MapReduce开发经验，有实际大数据项目经验优先
3.      熟练掌握Oracle、MySql等主流数据库
4.      精通JAVA，熟悉基于J2EE的WEB架构设计，熟悉Web开发流程，有丰富的Web MVC（Struts、Spring，Hibernate等）开发经验；
5.      熟悉Linux/Unix系统环境下的操作；熟悉Tomcat等应用服务器的配置和优化；
6.      具有良好的沟通能力、组织能力及团队协作精神，有较强的分析和解决问题的能力；
加分项：
1. 有海量大数据开发经验
2. 有Hadoop、Spark、HBase深入源代码分析经验
3. 熟悉机器学习、数据挖掘、分布式计算
4. 基础能力+学习能力特别优秀者
 
福利待遇：
大平台/顶级教授讲座/全城班车/健身房/餐补

工作职责：
建立和维护大数据基础设施，整合来自非结构数据源的数据
开展数据分析平台的可视化和探索数据任务
为团队和我们的客户提供数据服务
创建内部工具来帮助团队加快开发速度

要求：
热爱数据和交易
本科及以上学历，计算机科学/工程/数学或相关领域学位
能适应创业公司环境，快速学习，成为多面手
良好的编程技能，编写干净的代码
熟练掌握Python，Java，Scala，Clojure或Golang
熟悉Hadoop生态系统，如HDFS / Hbase / Yarn / Spark  
熟悉操作数据库，特别是NoSQL数据库
熟悉算法和数据结构
2-5年以上撰写快速生产代码和代码优化的经验
熟悉Linux和命令行

有以下技能者优先考虑
机器学习和数据挖掘知识
云平台Aliyun / AWS经验
德州扑克大咖







岗位职责：
根据客户数据分析需求和产品运营要求,对数据分析系统进行建模,优化数据分析过程。

任职资格：
1.计算机相关专业大学本科及以上学历；
2.熟悉spark,storm等一种或多种实时数据处理框架；
3.熟悉Hadoop生态圈的zookeeper、hive、hbase、spooq、flume、pig等框架；
4.熟悉Redis，Memcached，Hbase，Mongodb等一种或多种NOSQL的设计和开发；
5.熟练掌握消息中间件原理，如activemq，rabbitmq或kafka等；
6.有分布式系统开发经验，熟悉分布式服务治理，分布式数据库，负载均衡等；
7.对于服务治理,数据治理有一定的认知和理解；
7.热衷于互联网技术的研究和创新。

岗位职责：
1、学习大数据研发的知识；
2、完成大数据研发的相关工作。

任职资格：
1、有java编程基础，热爱大数据行业。

职位描述： 1.负责大数据平台软件需求分析、设计； 2.参与产品需求讨论、应用产品系统架构的设计、开发； 3.负责编写相应的需求、设计与技术文档； 4.参与线上系统环境的升级、运维监控、性能调优,向系统使用者提供技术支持服务。  岗位要求：  1. 熟悉分布式系统的架构，至少1个以上大型成熟项目的经验； 2. 熟悉 Java、HFDS、MapReduce，并有相关的开发及优化经验；
3. 熟悉搜索引擎原理和网络爬虫等相关技术，熟悉Lucene、solr、ES，能做二次开发； 4. 熟悉Hadoop、HBase、Hive、Spark、Storm等软件，至少精读过一个源码； 5. 有电商大数据开发经验；

职位描述：
1.大数据系统平台的设计、研发；
2.使用Spark进行数据处理；
职位要求：
1.本科及以上学历，精通Java、Python、Scala、Shell等一种或多种开发语言；
2.扎实的计算机基础和动手能力，对数据结构，算法效率，性能优化和扩展性有深入理解；
3. 掌握实时计算技术体系包括数据采集、计算引擎storm(或者SparkStreaming)，对实时计算所涉及的事务、容错、可靠性有深入理解；
4.良好的平台思维，具有出色的抽象设计能力，对大数据技术充满热情；
5.熟悉Linux开发环境;
6.熟悉Hadoop、HBase、Spark源码的优先考虑。
 

1.负责基于Hadoop/Spark等大数据相关生态系统软件的开发与维护； 
2.追踪大数据行业最前沿技术，并整合到产品中。
任职资格：
1.大学本科及以上学历； 
2.三年大数据工作经验。 
3.熟悉Spark框架，有Scala编程经验的加分； 
4.熟悉Hadoop/Spark/HBase等大数据生态系统软件； 
5.具有良好的学习能力、沟通能力，乐于承担工作压力。

岗位职责1、参与项目需求分析和设计；2、完成软件系统代码的实现，编写代码注释和开发文档；3、辅助进行系统的功能定义,程序设计；4、根据设计文档或需求说明完成代码编写，调试，测试和维护；5、分析并解决软件开发过程中的问题；6、协助测试工程师制定测试计划，定位发现的问题；任职条件1.必须是大学统招本科或以上学历，计算机相关专业；2.3年及以上JAVA开发经验；3.熟练掌握Java、JavaScript、Html、JQuery技术并有实际项目开发经验；4.熟练使用主流开源框架，如spring、struts2、Hibernate等；

岗位职责：
1、开发实时/准实时大数据产品
2、基于主流的流计算方案，如spark streaming ,storm
3、提供有价值的商业数据、模型、算法支持
4、参与公司平台化产品的开发
 
任职要求：
1、4年及以上的Java开发经验
2、熟悉分布式缓存、消息队列、对基于java的高并发大流量系统性能优化有一定的经验
3、熟悉Hadoop大数据平台架构，有Map/Reduce开发运维经验
4、具有使用java在Storm、Spark、Hbase等大数据平台上开发真实项目的经验；
4、熟悉Linux的基本操作及应用部署，了解Shell命令
5、良好的沟通与团队合作能力，以及积极的学习成长心态

岗位职责1.担任项目或者产品技术负责人；2.负责系统及模块设计工作；3.负责核心模块编码工作及撰写技术文档；4.指导工程师完成项目及产品编码工作。
职位要求1.计算机相关专业，本科及以上学历；2.5年以上Java设计和开发经历，熟悉Html/CSS/Javascript及Jquery、Spring、HTML编程；3.熟悉B/S架构应用系统的开发，熟悉Tomcat、 WebLogic等应用服务器，掌握eclipse开发工具 ；4.能使用和开发Mysql/Oracle数据库系统的编程；5.精通Spring、ibatis、struts等主流开源框架和技术；6.熟练使用SVN版本管理工具、PowerDesigner进行数据库模型设计；7.具备良好的学习能力和抗压能力，对技术研究有热情；8.熟悉云计算与与大数据信息处理相关技术优先。本职位同期在：成都、重庆等城市招聘同步招聘，如您考虑在以上城市工作，请在投递简历时标注期望的工作地点。

岗位职责：
在大数据相关（基于hadoop/spark的数据平台和应用）项目中，进行需求调研和需求分析工作
1.  根据项目要求和产品规划，负责组织收集客户需求、公司内部需求，整理需求分析文档。
2.  工作在整个项目生命周期中，进行客户沟通、需求分析、系统分析、梳理系统流程、梳理数据流程，辅助开发人员理解需求，在开发完成后进行需求验证，并负责需求跟进和需求变更管理。
3.  做好工作流程上的衔接，对接项目组的其他岗位人员进行协作，如数据开发人员、WEB应用开发人员、产品经理等。 
岗位要求
1.   计算机、数据、统计相关专业，本科及以上学历，有强烈的责任心和团队合作精神，具备良好的沟通能力、快速学习能力、分析判断能力、创新能力。
2.   有较强的分析能力，对需求有较强的理解、沟通能力，能引导并解决客户的业务问题，控制客户需求及范围
3.   有数据从业背景，对数据有敏感性，能够深度理解数据应用和数据流程，熟悉常用数据库使用和sql语言编写，能够深刻理解和严密描述数据指标的计算逻辑。
4.   熟悉系统分析方法，熟悉uml工具，善于编写文档，具备java应用开发或者数据开发经验。
5.   3年以上工作经验，参与过中大型项目的实施工作，有一定项目管理能力。
6.   能够中短期出差到客户现场工作。

工作内容：
参与大数据一体机技术开发、验证、测试
负责大数据一体机项目支持

要求：
三年以上工作经验
具有X86服务器产品技术支持经验
熟悉X86服务器产品架构和产品配置
熟悉和操作Linux操作系统
有能力分析服务器故障原因，具备系统优化能力
了解Oracle、MySQL等数据库并有一些项目实践经验

岗位职责：
1、对非结构数据进行清洗、转化、入库；
2、提供支持或基于数据的解决方案；
3、基于用户行为数据，建立并优化用户画像模型；
4、其他数据分析需求, 如关联分析、特征统计、撰写统计报告等。
任职要求：
1、本科以上学历，三年以上数据分析经验，计算机系、数学系专业；
2、熟练使用Linux 系统，熟悉一门编程语言（Python/JAVA/PHP）；
3、具有大数据相关平台知识（ hadoop/Storm/Spark）以及机器学习算法知识和经验；
4、熟悉常用数据分析模型的原理及其实现；
5、熟悉大型电商平台， 有过相关产品分析经验优先。

Responsibilities:
· Act fearlessly; Serve as a technical lead on our most demanding, cross-functional projects.
· Drive highest quality; Ensure the quality of architecture and design of systems.
· Invent and Simplify; Decompose complex problems into simple, straight-forward solutions.
· Possess expert knowledge in performance (millisecond latencies), scalability (millions of request per min), availability (99.99% uptime), enterprise architecture, and engineering best practices.
· Leverage knowledge of internal and industry best practices in design.
· Assist in the career development of others, actively mentoring individuals and the community on advanced technical issues and helping managers guide the career growth of their team members.
· Exert technical influence over multiple teams, increasing their productivity and effectiveness by sharing your deep knowledge and experience.
 
Qualifications:
· Bachelor's degree and/or Master's degree in Computer Science or equivalent.
·10+ years of software engineering experience and best practices in Java or other high level language.
· 5+ years of experience leading large-scale projects.
· 3+ years of experience mentoring junior engineers to success.
· Experience in building high-performance, highly-available and scalable distributed systems.
· Experience with data sources for both non-transactional (Cassandra, DynamoDB) and transaction (RDS, MySQL) needs.
· Experience with massive data processing techniques (EMR/Hadoop/Spark, SWF, Storm/Kinesis, etc.)
· 2+ years of hands-on experience as a Principal-level Software Development Engineer.
· Excellent written and verbal communication skills
· Desire to do deep data analysis while solving problems.
· Desire to guide junior engineers through design and architecture.

职位描述：具体描述写，数据统计分析、数据服务开发、DMP平台建设等                  
岗位职责：
负责海量日志的统计分析工作。
负责数据相关服务的开发。
负责内部一些数据分析、数据挖掘等算法项目的开发。
岗位要求：
统招本科及以上学历，计算机或数学专业。
1~3年工作经验，对日志统计有很敏感的嗅觉。
熟悉hadoop生态系统，熟悉HDFS、Hive和HBase等相关组件。
至少熟悉两种常用的数据库：redis、mongo、mysql、sqlite等。
对流式处理相关架构和组件熟悉者优先。
有机器学习相关项目实现有实际经验者优先。


负责网易私有云和公有云实时计算产品研发
 深入理解实时计算场景，结合实际需求完成实时计算平台架构设计、开发工作。
负责线上系统的技术支持工作，保障系统稳定运行。


资格要求：
1. 两年以上平台设计和开发经验，具备优秀的编程能力和良好的开发习惯。2. 具备独立沟通需求、设计、架构、开发、测试、运维的能力，有过大规模系统设计和工程实现的经验。3. 熟悉至少一种大数据处理引擎，例如Hadoop、Storm、Spark、Flink等。4. 熟悉Linux平台上的Java、Scala编程。5. 优先考虑在开源社群活跃并有积极贡献者。6. 具有认真的技术态度，积极沟通，懂得团队协作。

职位描述：
1、参与广告系统大数据处理平台的研发工作；
2、根据业务需求进行数据模型的调研、设计、研发工作，并持续进行模型的优化；
3、负责大数据平台架构的设计和研发，构建数据抽取、清洗、校验等数据处理平台；
4、持续对系统的技术架构进行改进和优化，提升海量数据的查询性能和用户体验。

职位要求：
1、统招本科或以上学历，计算机、数据挖掘等相关专业，工作至少3年以上；
2、熟悉Java开发，有脚本语言（shell,python)开发经验者优先；
3、熟悉Hadoop、Spark等大数据处理平台，，掌握Storm等流式开发技术，对kafka等常用的消息队列、Mesos等调度系统有较丰富的经验；
4、掌握HBase、Redis、Pig、Hive、Elastic Search等开源大数据存储和检索技术，并能结合不同的业务场景深入使用；
5、对解决具有挑战性的问题充满激情，具有良好的分析问题能力。

岗位职责：1、参与公司大数据平台的开发与维护2、利用大数据平台实现对数据的分析和处理任职条件：1、计算机、通信、软件、数学等相关专业本科及以上学历，有2年及以上工作经验；2、熟练掌握Java；熟悉Java多线程编程；3、熟悉Linux操作命令，能编写常用Shell或Python脚本；4、熟悉hadoop组件技术，了解Mapreduce编程；有spark开发经验者优先；5、熟悉Oracle、MYSQL、Postgre、Greenplum等相关数据库应用开发、原理及优化；6、热衷于技术，对代码有一些“洁癖”，勇于挑战难题。
公司提供：1、宽松、开放、人性化的工作氛围2、有利于员工成长的职业规划3、完善的五险一金，并为员工提供补充商业医疗、意外保险4、提供餐补、通讯补贴以及交通补贴5、弹性考勤、带薪年假、周末加班可调休6、公司为员工提供定期体检、生日慰问品等



工作职责：

负责从业务数据库到数据仓库的ETL；
负责基于Hadoop生态的开发和维护；
完成大数据平台的其他运维及开发工作。


任职要求：

掌握Java或Python语言，熟练多线程及常用设计模式
熟练使用Java 常见组件：JavaBeans, jdbc, rmi, reflection
掌握Hadoop、HBase、Hive、MapReduce等编程
熟练使用MySQL等开源数据库、熟练SQL；
熟悉使用MySQL等开源数据库、熟练SQL；
熟练掌握Linux/Unix开发环境；
踏实、积极、善于团队合作，善于发现问题，解决问题，有不断学习新技术的热情。


工作职责：
1、 负责数据分析、加工、清理、处理程序的开发；
2、 负责数据相关平台的搭建、开发、维护、优化；
3、 分布式平台应用开发（Hadoop/Spark/Hive/Hbase）；
4、 开发数据统计系统，各类统计程序报表。

任职要求：
1、 2年以上Java或Python开发经验；
2、 熟练使用Hadoop/Spark生态圈技术，如：Hive、Hbase、MapReduce等；
3、 熟悉数据挖掘、机器学习、网络数据分析等技术优先；
4、 具备良好的逻辑分析能力和解决实际问题的能力；
5、 良好的沟通技巧和团队合作意识。

        职位职责：
1、基于海量数据，支持业务对数据的分析和使用：
2、支持业务处理数据的流式处理、构建数据仓库、分析用户行为等。

职位要求：
1、有扎实的编程能力，有优秀的设计和代码品位，对解决具有挑战性问题充满激情；
2、对大数据处理有丰富的经验和广阔的视野；
3、熟悉常用的开源组件：Hadoop/Hive/Spark/Storm，并了解其特性和使用场景；
4、优秀的沟通理解能力，能快速理解业务，用数据解读业务；
5、推荐或机器学习相关的开发工作优先。
        
岗位职责：
1. 负责餐饮大数据领域的核心数据产品的后端设计和开发；
2. 运用大数据生态技术栈，构建实时与关键数据服务系统；
3. 带领团队初级，中级工程师成长，沉淀大数据领域的数据产品解决方案；
 
任职要求：
1. 扎实的计算机专业基本功，熟练掌握 Java 及面向对象设计，良好的coding能力；
2. 了解 SOA 架构理念、实现技术；熟悉常见设计模式，熟练掌握 Spring、myBatis 等框架；
3. 熟悉并理解缓存、消息、RPC调用框架、搜索引擎、jvm 调优、序列化、nio等原理；
4. 有大型服务端开发以及API设计开发经验；
5. 热爱大数据行业，熟悉相关技术栈，认同数据驱动业务理念；
 

岗位职责：
1、 参与公司数据类产品战略和发展规划的制定
2、 市场趋势研究、行业分析、竞品动态了解，并据此优化产品，提出产品改进计划
3、 推动产品目标实现，管理产品生命周期，完成平台及组件的设计和迭代升级
4、 完善平台及产品的说明书等文档，并归档整理
5、 用户需求、运营需求和公司战略需求的挖掘和分析
6、 协助销售部门推广产品
岗位要求：
1、熟悉互联网产品的设计方法和设计工具；
2、有良好的逻辑思维能力和想象力，善于解决复杂问题；
3、有良好的学习能力，积极了解业界发展、互联网相关新技术及趋势；
4、对数据有敏锐的洞察力，具备大数据、管理平台等相关经验者优先；
5、本科以上学历背景，具备3年以上互联网公司产品经理工作经验；
4、有优秀的沟通、协调和团队合作能力，能够跨多个部门协调各方资源，推动完成产品的工作。

【岗位职责】

1、针对业务需求，负责开发可扩展的、分布式的大数据系统；

2、面向业务目标，从数据模型、数据分布、数据传输、数据存储等方面进行大数据系统的开发；

3、研究前沿的数据分析建模，数据挖掘及机器学习算法，探索具有数据分析、数据挖掘能力的创新型产品。

【岗位要求】

1、至少3年以上hadoop，hive，spark开发经验；

2、精通Hadoop生态系统及相关组件，拥有Apache Hadoop实施经验；

3、精通Spark计算框架的实时采集和流处理；

4、精通Java、scala编程；

5、熟悉整个大数据的处理流程，包括数据的管理，数据的分析挖掘，服务器扩展；

6、优秀的客户服务意识，客户管理意识；思想意识开阔；

7、逻辑思维能力强，具备优秀的文档编写和良好的沟通与表达能力；

8、具有较强的沟通协调、团队合作和抗压能力。

岗位工作范围和职责：
1、 参与大数据软件产品的需求分析、概要设计、编码、测试、部署上线等工作；
2、 对关系型数据库和大数据平台进行数据迁移。
专业知识和技能要求：
1、两年及以上大数据技术相关开发经验；
2、 熟悉Java语言，熟悉虚拟机工作原理，数据结构和算法分析等基础扎实，熟练掌握并应用面向对的编程思想；
3、熟悉Hadoop以及相关开源的大数据技术，如Hive、Hbase、Storm、Spark、kafka、Zookeeper、机器学习等技术框架；
4、 熟悉Linux/Unix系统，至少熟悉perl/shell/python中的一种脚本语言。

岗位职责：
1、基于海量用户行为，对海量用户行为数据进行离线、实时处理；2、参与大数据的架构设计、开发、部署、自动化运维和数据分析BI等工作；3、利用大数据相关的新技术，提升系统性能。
任职资格：
1、熟练使用Java/Python等语言进行开发；2、熟练掌握 Linux 操作系统的配置，管理及优化；3、熟悉主流分布式处理框架——Hadoop、HBase、hive等，掌握MapReduce、Storm或者Spark编程（至少其中一项）；4、加分项：熟悉阿里云的大数据平台相关解决方案的。

【岗位职责】 

负责腾讯游戏运维数据云平台的建设；
负责海量数据的实时计算、离线计算、存储、查询；
参与数据平台自助化建设。

【岗位要求】

计算机相关专业，3年及以上相关工作经验,有扎实的计算机理论基础；
熟练Java、Python服务端编程，有良好的编码习惯； 
深入理解MapReduce，熟练使用Storm、Hadoop、Spark，并阅读部分源码；
熟练使用HDFS、Hbase、Kafka、ElasticSearch、Opentsdb；
深入理解Lucene，有优化经验者优先；
具备良好的学习能力、分析解决问题能力；
具有高度的责任心和团队合作精神。


【招聘人数】3人

在这里，你能为蚂蚁金服的智能金融机器人、运营决策大脑、全网舆情、信息风险管控、财资挖掘等高精尖前沿应用添砖加瓦；在这里，你能手握真实的海量用户数据利用各种大数据和算法技术反复把玩；在这里，你能遇见一群有情有义的创客，远离办公室政治，大家一起享受攻坚后的喜悦，品味失败后的苦涩，职业生涯独一无二的回忆；你将和我们携手探索智能运营的无限可能和广阔前景。
1. 负责部门大数据相关的研发工作，如：数据整合、数据挖掘和数据服务。2. 在产品预研，开发，发布和迭代的过程中负责各个关联团队之间的交流与合作，确保合作的畅通与高效。
岗位要求:

有互联网经验者优先。
熟悉Hive、Hadoop、Spark、Storm等优先
有较强的场景抽象能力，有架构师工作经验者优先。
熟悉大数据、云计算、大型分布式系统的技术架构，有数据相关经验优先。
熟悉各行业大数据应用场景，有数据仓库、BI、数据挖掘等方面的工作经验者优先。
善于沟通，有极强的跨团队协作能力和执行力。


1）结合公司业务特点，研发高质量的搜索、个性化推荐算法和内容处理算法；  
2）追踪搜索引擎、个性化推荐、NLP和机器学习领域的前沿技术，将前沿技术应用于实际业务。
1，具备扎实的算法及代码实现能力；
2，在以下至少一个领域有深入的研究： 
（1）搜索技术，如信息检索、索引、分词、相关性等；
（2）统计机器学习相关方法，如深度神经网络、概率图模型，最优化方法等； 
（3）语义理解技术，如知识图谱、语义解析、知识挖掘等； 
3.良好的分析问题与发现问题的能力，善于归纳技术方案的特性，并找出其不足与改进方法； 
4.熟悉Hadoop、Spark等分布式计算框架者更佳； 
5.具有良好的沟通能力，和良好的团队合作精神。

职位描述：
1、支持研究部门需求，挖掘数据中隐藏的线索；
2、通过数据挖掘建模，形成能指导业务的数据产品；
3、根据业务需求，开发可视化报表；
4、向数据仓库及其他支持部门提出建设性需求，并推动落实；
5、其他数据支持。
应聘要求：
1、本科及以上学历，计算机、数学或相关专业，沟通、学习能力强；
2、2年以上相关工作经验，有BI项目经验优先；
3、熟练使用主流数据库系统工作，例如mysql/oracle/sqlserver；
4、至少熟练使用Python、R中的一种；
5、熟悉主流的报表工具，如SSRS，OBIEE等。

职位描述
1.参与公司大数据平台设计与工程实现
2.满足公司不同业务线的数据分析需求
 
任职要求
1.重点大学计算机相关专业本科及以上学历, 良好的计算机、统计学基础知识
2.熟悉Linux开发环境
3.熟练掌握Java、Python之一
4.熟悉Java并发编程、对分布式应用开发、Java内存模型、JVM故障排查有一定接触
5.熟悉Hadoop、hive、kafka、flume、hbase、spark、storm中的至少一个
6.熟悉主流关系型和非关系型数据库，擅长sql脚本或者具有数据可视化的前端开发经验
7.英语良好，能正常阅读英语技术文档

岗位职责： 1、负责互联网金融产品的信用和欺诈风险分析； 2、依据风险特征和模型评分结果设置相应的风控策略，对风险进行控制； 3、根据风险特征，设计模型开发需求以及模型在策略中的应用方案，并将其产品化； 4、对贷前和贷中风控模型优化提出合理的建议，能够通过数据分析结果提示和预警相关风险，并提供相应的管理策略； 6、根据风控日常需求撰写产品文档，对风险系统或运营流程进行优化。  
任职要求： 1、金融、统计学、计量经济学、数学等专业本科优先； 2、3年以上数据分析，建模或风险把控的工作经验； 3、熟悉信贷类产品的信用与欺诈风险的管理方法，同时对互联网信贷产品有基本了解优先； 4、对数据敏感，有产品，风控工作经验优先； 5、积极上进，有责任心，有较强的学习能力和良好的团队合作精神。

大数据spark开发工程师
岗位职责：
1.负责基于spark、Hadoop/storm的并行计算平台的开发与优化工作。
2.根据业务要求实现数据采集平台的开发工作；
3.完成大数据平台数据应用业务的代码设计和实现；
4.能独立发现和解决存在的技术瓶颈和问题。
任职资格
1.3年以上大数据开发经验，本科；
2.熟悉spark框架，熟悉掌握RDD/SQL/Streaming编程；
3.熟悉ZooKeeper/Hive/kafka/Hadoop/HBase/Flume/Storm等平台及其工作原理，并有实际开发经验；
4.熟悉Linux开发环境，熟悉使用一下脚本语言：Python/shell/scala;
5.熟悉数据可视化相关技术者优先。

  负责腾讯游戏运营大数据平台的规划、设计、开发和优化工作；  负责海量数据的实时计算、离线计算、存储服务等开发工作。【工作要求】  计算机相关专业，3年及以上相关工作经验,有扎实的计算机理论基础；1、三年以上Linux环境服务器开发的经验，精通Socket网络编程、高并发服务开发。2、三年以上使用Java语言开发的经验，熟悉IO、多线程、RPC等基础框架3、熟悉Hadoop、Spark、Strom等相关技术者，优先 4、有Storm开发经验，或者使用类似平台的流计算开发经验者，优先5、良好的学习能力、沟通能力、适应能力，责任心强，能在压力下独立解决问题。6、热爱互联网，喜欢大数据，喜欢挑战者优先。具备良好的学习能力、分析解决问题能力；
【招聘人数】4人

岗位职责： 
1. 负责金融风控大数据建模；
2. 负责机器学习算法优化。

任职资格：
1. 本科及以上学历，5年以上工作经验，扎实的统计学和应用数学功底，数据挖掘理论基础，有大数据信用风险管理模型优先；
2. 精通数据结构和常用机器学习算法（如逻辑回归、聚类、神经网络、决策树、贝叶斯等），良好的机器学习原理和最优化理论基础，深入理解机器学习问题求解方法；
3. 理解机器学习基本算法的设计思想和求解手段，如SVM, LR, RF, Boosting等；
4. 熟悉HADOOP、SPARK、R和python其一或全部；
5. 有金融行业风控建模和反欺诈策略经验优先；
6、抗压力强，有责任心，心态开放，思路清晰；
7. 优秀的团队合作能力和沟通能力。

- 岗位职责：
    - 客户拓展：根据我们的数据优势和生产能力，有针对性的拓展客户，挖掘并引导客户潜在需求；
    - 报告撰写及交付：与分析师团队合作落实报告的生产，并负责项目的后期交付；
    - 产品及服务梳理：针对阿里大数据的优势与外部客户的需求，提炼标准化的服务模块，制定产品手册；
- 岗位要求：
    - 关注大数据行业动向，对基于大数据的商业化应用有深刻认知；
    - 丰富的市场研究、咨询服务行业从业经验，在消费品行业有较为深厚的积累；
    - 优秀的沟通和表达能力，掌握结构化思维方式，强烈的自我驱动意识；


熟练掌握es5，es6
熟练掌握html4，html5，css3知识
熟练掌握angularjs
熟练掌握node开发，有express经验
熟练掌握 gulp，grunt等前端构建工具
熟练操作linux系统
掌握前端浏览器兼容性解决方案
掌握前端页面各种优化技巧

备注：其中有以下项加分
1.自己写过github开源插件
2.熟悉个类库源码，例如jquery，angularjs，vue等
3.熟练使用echarts或Highcharts或d3
 

岗位职责：
1.负责大数据平台解决方案设计与开发；
2.负责大数据平台运营工具系统开发；
3.负责大数据平台搭建及数据仓库建模；
 
任职要求：
教育背景：
1.全日制统招本科及以上学历，计算机、软件工程相关专业优先。
所需经验：
1.两年以上相关工作经验；
2.熟悉主流分布式处理框架，熟悉Hadoop、Spark、Hbase等开源软件源码优先；
3.具备大型数据仓库架构设计、模型设计和性能调优等相关经验；
4.有BI产品、数据可视化产品开发经验者优先；
5.精通Python或JAVA开发；
6.有良好的程序研发、调试与分析问题的能力,熟悉主流开发工具与技术架构；
7.有互联网行业数据仓库项目经验优先；
8.有实时计算系统实际项目经验者优先；
9.有数据挖掘，机器学习实际项目经验者优先。

工作职责：职位描述：1.Hadoop集群以及Hive、HBase、Pig等相关软件配置、优化、维护、管理；2.负责Hadoop数据分析模块与其它系统模块之间的衔接，为BI提供基础数据分析；3.运用常用数据挖掘算法，解决海量数据分析、挖掘方面的业务需求。任职资格：任职要求：1.计算机、数学或统计等相关专业本科及以上学历；2.有线上Hadoop集群的搭建，管理及调优经验；3.熟悉Hadoop和Hive，有MapReduce编程经验；4.具有优秀的学习能力、独立分析问题和解决问题能力；5.有“用户画像”或者推荐引擎相关数据挖掘经验者优先；6.有Spark、Storm、Pig等开源组件的使用经验者优先。

岗位职责：
1、匹配业务场景，使用机器学习、文本挖掘等技术，设计数据建模（模型/算法）解决方案；
2、对业务数据进行分析和建模，并负责各类数据挖掘模型的开发、应用、监控优化，支撑公司数据挖掘课题落地；
3、开展数据挖掘分析算法、工具研究工作，研发创新方法解决业务问题，并组织相应方法、工具的引入，技术规范制定和推广。
任职资格：
1、熟悉数理统计、机器学习具体实施方法；
2、擅长常用统计，如线性回归、逻辑回归、时间序列、聚类及神经网络等；
3、熟悉R、Python、SAS；熟练使用SAS/SPSS/R/Matlab；掌握Hadoop、spark、storm；
4、能有效完成报告呈现和数据解读；
5、海量数据处理和挖掘经验者优先。

熟练运用以下算法优先
———————————
决策树
Dijkstra
蚁群算法
随机森林算法
逻辑回归
SVM
朴素贝叶斯
K最近邻算法
K均值算法
Adaboost 算法
神经网络
马尔可夫

岗位职责：
1、负责大数据相关技术的研究。
2、负责大数据项目的设计与研发工作。
3、负责大数据新技术的跟踪与预研工作。

任职要求：
专业：计算机、软件工程的相关专业优先。
1、全日制本科以上学历，计算机、软件工程相关专业；
2、5年以上JAVA开发经验,有具体的项目经验，且在项目中担任主要开发工作。
3、对大数据技术感兴趣，有意向在大数据技术方向上发展；
4、有hadoop等大数据框架开发经验者优先，如HIVE、SPARK、STORM等。
5、精通Oracle数据库,对NOSQL数据库有开发经验者优先。
6、具有良好的沟通能力和团队精神，有较强的学习研究能力。

福利待遇：双休、免费午餐、法定节假日，年节福利，年底奖金等福利。

职位描述：
1、能独立搭建大数据平台，并对大数据环境进行维护；
2、基于Spark技术的海量数据的处理（抽取、过滤、清洗、转换、存储等）；
3、根据实际业务设计模型与规则进行数据监控、统计分析、报表展现等；
4、研究SparkHadoop集群技术，持续优化集群架构，发现并解决重大故障及性能瓶颈。

职位要求：
1、精通Java多线程编程，常用设计模式，以及常用海量数据处理方法；
2、精通Hadoop生态系统组件，如：Spark、Flume、Kafka、HBase、Hive、ZooKeeper等；
3、有丰富的数据库设计、开发经验，熟悉关系型数据库、NoSql等；
4、熟悉Linux环境开发，熟练使用Shell、Python等脚本语言之一；
5、具有ETL、OLAP、OLTP实际工作经验之一优先考虑。
6、熟悉ELK日志分析或者CDH优先考虑


工作职责：
1、负责Hadoop大数据平台的规划与设计；
2、负责研究大数据组件的安全加固方案。


职位要求：
1、计算机相关专业本科毕业，技术水平好可放宽学历要求；
2、精通Java/C++/GO等其中一种语言即可；
3、有对Hadoop等组件有过源码分析，深入研究过实现原理机制；
4、熟悉分布式原理，做过分布式应用架构设计优先考虑；
5、有信息安全行业工作经历者优先考虑。

岗位职责
1、从事相关软件产品的设计、开发工作 
2、主要研发方向为大数据平台的开发，特别是数据分析、数据挖掘方向
3、维护和优化软件，确保可用性和稳定性
4、参与相关质量活动，协助确保软件设计及实现按时保质完成
5、参与相关项目及产品文档编制
任职要求
1、学历：研究生，计算机相关专业；
2、2年及以上JAVA开发相关经验，有扎实的开发功底
3、熟悉分布式系统的基础理论知识，了解大数据处理的常用算法
4、熟悉Java或Scala语言，
5、熟悉Spark/Hadoop，Cassandra/Hbase，Storm，Kafka等大数据处理框架
6、熟悉Hbase、Oracle、MySql、SQLServer等数据库开发与应用，有大型数据库开发经验优先；
7、爱技术，有参与过开源系统、或研究过上述系统源代码、或有技术博客者优先

岗位描述：1. 海量交通领域大数据的分析/处理，包括海量数据的存储、计算和检索；2. 基于分布式平台（MR/storm/Spark/flink）的业务数据分析和逻辑job的开发；3. 开发数据统计系统。
岗位要求：1. 计算机、数学或统计学相关专业本科以上学历；3年以上数据的开发相关经验，特别是(1) 离线领域hadoop的ETL开发经验或者 (2)实时计算领域包括storm、spark、flink等的开发经验其中之一经验者；2. 有很好的海量数据开发经验，理解元数据管理。具有一定数据模型和数据架构基础；交通领域大数据工作者更佳；3. 熟悉unix或者linux，具备优秀的编程能力，熟练掌握java或者scala开发，有storm、spark、flink等等语言中的一种或几种经验者优先；4. 对数据敏感、对技术敏感，有研究的意识和直觉者更佳；5. 有良好的团队合作意识，沟通表达能力和综合协调能力。

职位描述
负责数据产品的需求调研和功能规划；
了解用户需求，进行总结归纳，产出数据分析报告，并转化为各种展现形式的上线产品；
进行用户行为分析与用户刻画；
协助完善公司大数据体系。 

岗位要求  
统招本科学历，6年以上互联网产品工作经验；
具备一定的商业嗅觉和数据敏感度，能从数据的角度解构业务需求；
沟通能力强，有较强的团队协作意识，富有强烈的创新精神；
了解应用层数据分析和算法的基本概念，熟悉常用的数据挖掘方法、多维建模，对数据产品有较好的理解，有成功上线产品经历。

负责腾讯云CDN海量日志大数据平台的研发；
负责腾讯云CDN实时分析系统的研发；

职位要求：
有Linux下大数据平台研发相关经验；
精通Spark、Cassandra、Hadoop等开源组件；
熟悉Python和Scala编程语言；
具备良好的团队合作及较强的沟通能力，对解决挑战型问题充满激情。


高级大数据研发工程师

职责描述：
1，参与爱奇艺智能大数据平台的架构设计和开发
2，基于业务需求和应用场景，设计和实现爱奇艺大数据相关产品
3，为爱奇艺所有业务线提供数据支持和服务
 
职位要求：
1，本科或以上学历，计算机专业，3年以上大数据项目开发经验。
2，具有Hadoop/Spark开发与应用经验，有较大规模的项目经历并应用在生产环境
3，熟悉hbase、hive、YARN、Storm、Pig、zookeeper等大数据相关工具，并有处理TB级以上数据的项目经验
4，具有独立完成从方案选型设计到原型系统开发实现的能力
5，有较强的沟通表达能力，善于学习，能迅速理解产品需求；有较强的责任心和事业心，能够自我驱动
6，熟悉docker/impala/elasticsearch/mongodb等技术的优先

岗位职责：
1.设计、搭建并维护离线大数据集群解决方案，兼有离线计算和实时计算。2.设计并构建数据仓库各层表结构。3.推广hive、spark等技术在团队内的学习和使用。4.建立数据质量监控体系。5.提出并维护业务相关日志规范和所有数据schema维护流程。

任职要求：
1.熟悉hadoop/hive/spark/kafka等大数据相关技术的使用和配置调优。2.熟悉Mysql/Redis/日志等的离线ETL方案。3.心思缜密，逻辑思维能力强，尊重并理解客观数据规律，对数据敏感。

岗位职责：
* 大数据开发与分析
* 任务调度与监控
* hql编写与优化
* 数据核对

岗位要求：
* 两年以上工作经验；
* 熟练掌握oracle pl/sql基本语法，熟悉hadoop,熟练掌握hive、spark等,了解hive脚本优化方法；
* 良好的逻辑思维能力、团队合作精神与沟通能力；
* 了解java或者shell；
* 海量数据处理经验优先；

福利待遇：
年终奖（至少一个月工资）+生日礼物+节日礼物+五险一金+带薪年假+团体聚餐 +团体旅游+技能培训+零食+考证补贴+其它福利等

        职位职责：
1、基于海量用户行为数据，构建高性能，低延迟的处理流程，产出基础数据；
2、业务数据仓库架构设计、建模和ETL开发，构建可扩展的数据仓库和分析解决方案。

职位要求：
1、出色的编码能力，熟悉 Linux 开发环境，熟悉 C++ 和 Python 语言优先；
2、优秀的分析问题和解决问题的能力，对解决具有挑战性问题充满激情；
3、优秀的沟通理解能力，能快速理解业务，用数据解读业务；
4、熟悉至少一项分布式计算平台，例如Hadoop，Spark，Hive，Storm等；
5、有参与开源项目对社区有贡献的经历，有互联网公司实习经历，有大数据处理或数据仓库建设经验者优先。
        
岗位描述
分布式爬虫系统的架构设计与开发；
网页信息抽取、数据清洗等研发和优化工作；
爬虫核心算法的策略优化研究，提升网页抓取的效率和质量。 

岗位要求 
大学本科学历以上，2年以上工作经验，计算数学、数理统计和计算机相关专业背景者优先；
工作认真细致踏实，学习能力强，以解决技术难题为乐趣，有想法，敢于挑战；
熟悉linux平台开发，掌握Python/C++/Java三种编程语言中的至少一种；
有网络爬虫、网页去重、网页信息抽取等相关经验者优先；
熟悉html, DOM, xpath，CSS者优先。

岗位职责：
1、负责数据分析系统需求开发及维护工作； 2、负责业务数据的挖掘、整合以及分析模型的建立、优化和评估，为业务人员日常工作提供可靠而明确的数据支撑； 3、负责应用平台中报表相关功能的设计、开发工作，并负责报表优化、维护、数据采集； 4、负责系统相关文档的制定和编写。

任职资格：
1、国家正规院校，计算机相关专业本科以上学历 ； 
2、熟悉电信业务，至少一年以上的电信行业经验，参与过经营分析、业务支撑系统（BOSS、BSS）的建设；  3、熟练掌握ORACLE，DB2或MYSQL数据库的操作与编程（SQL、PL/SQL等）； 了解nosql数据库； 
4、精通数据仓库相关概念，对数据仓库、经营分析、专题分析等有比较深入的理解；  5、1年以上JAVA/J2EE开发经验； 
6、良好的沟通能力，团队协作较好，较强的承压能力。

岗位职责：
参与企业数据中心的建设。负责大数据平台研发，包括平台组件选型及搭建、平台服务开发，使用大数据技术进行业务数据分析并生成报表，管理数据质量，并为业务BI人员和开发工程师提供更好的大数据环境。开发和维护数据接入层、存储层、计算层和输出层，提供统一规范的透明访问服务。
任职资格：
需要具备良好的业务理解能力，问题分析能力和高效的执行能力。对新技术和技术攻关有浓厚兴趣。良好的团队合作精神和沟通能力。
具备丰富的Java开发经验，精通多线程和I/O技术。
熟悉Yarn,Hadoop,HBase,Spark,Storm,Flume,kafka等开源技术，对其中某些技术精通。熟练使用Shell或Python。
本科及以上学历，良好的英文技术文献阅读能力，有互联网行业背景。

1.了解互联网金融业务，与业务人员沟通，深入思考，发现数据可以应用于业务的机会；
2.提取数据并做数据处理，开发风险规则、信用评分、客户标签、营销响应等模型，并参与模型上线部署、测试、追踪维护等工作；
3.根据业务需要，完成数据分析专题报告，能够独立深入解读数据内含的规律；
4.参与各种数据产品的设计。
任职要求：
1.理工科专业，大学本科及以上学历；
2.2年以上数据建模工作经验，可独立完成模型需求调研、模型构建；
3.数据敏感，能快速发现数据的价值；
4.对数据挖掘、机器学习有一定研究，熟悉决策树、逻辑回归、SVM、神经网络等算法；
5.熟悉数据库查询操作，熟练掌握SQL语言，至少掌握SAS、Python或R语言的一种；
6.具有结构化思维能力、快速的学习能力以及良好的沟通协作能力，积极主动，能承受一定的工作压力；
7.有互联网、金融行业数据挖掘经验者优先考虑。

岗位职责：
1.      参与hadoop/Spark大数据平台的开发工作
2.      参与公司业务需求调研和源数据调研
3.      参与大数据平台的数据建模和系统设计
4.      参与大数据平台的数据分析和数据挖掘
5.      参与维护和管理Hadoop/Spark集群和性能优化工作
 
任职要求：
1.     计算机、数学等相关理科专业本科及以上学历
2.     4年以上Hadoop大数据平台项目实际开发经验
3.     有丰富的大数据平台数据分析和数据挖掘的项目经验，精通数据挖掘各类算法，如决策树，分类算法，聚类算法，时间序列等
4.     熟悉主流的大数据处理技术，包括Hadoop、Spark、Hbase、Hive、Pig、Sqoop、Oozie、Flume、Zookeeper等，了解Hadoop/Spark集群管理及优化
5.     熟悉Java, Scala，有实际开发经验
6.     熟悉Linux，Shell &amp; Python脚本
7.     有强烈的责任感，主动性强，具有良好的团队合作精神和高度的责任心，能在较大压力下工作
岗位职责：
1.      参与hadoop/Spark大数据平台的开发工作
2.      参与公司业务需求调研和源数据调研
3.      参与大数据平台的数据建模和系统设计
4.      参与大数据平台的数据分析和数据挖掘
5.      参与维护和管理Hadoop/Spark集群和性能优化工作
 
任职要求：
1.     计算机、数学等相关理科专业本科及以上学历
2.     4年以上Hadoop大数据平台项目实际开发经验
3.     有丰富的大数据平台数据分析和数据挖掘的项目经验，精通数据挖掘各类算法，如决策树，分类算法，聚类算法，时间序列等
4.     熟悉主流的大数据处理技术，包括Hadoop、Spark、Hbase、Hive、Pig、Sqoop、Oozie、Flume、Zookeeper等，了解Hadoop/Spark集群管理及优化
5.     熟悉Java, Scala，有实际开发经验
6.     熟悉Linux，Shell &amp; Python脚本
7.     有强烈的责任感，主动性强，具有良好的团队合作精神和高度的责任心，能在较大压力下工作

职位描述：
1、负责和参与采集系统平台的开发、维护，保障采集服务的稳定性和可用性；
2、负责采集系统平台各个环节的监控系统规划、设计和开发；
任职要求：
1、3年以上Java开发经验，具备高性能、高可用、高扩展性分布式系统架构经验；熟悉linux下脚本、工具开发。
2、至少熟悉Python、Perl、Ruby、Bash 脚本语言中的一种；
3、熟悉前端JS开发框架优先。
4、有良好的系统性能优化及故障排除能力；
5、熟悉大数据周边相关的数据库系统，关系型数据库和 NoSQL。
6、熟悉MR、Hive至少一种，熟悉Hadoop生态圈，对其中至少两种以上的技术有过深入研究。

1、负责大数据平台搭建及数据仓库建模；
2、负责数据分析平台的设计和开发，实现对数据的分析、挖掘、处理，完成各类分析报告、报表；
3、负责实时处理系统的设计和开发；
4、负责研发和实施数据分析预测模型：如风险评估、客户生命周期和客户价值；
5、和团队成员一起完成大数据智能分析工作的流程、规范和方法建立
技能要求：
本岗位要求必须精通spark技术，不符合此项要求者请勿投简历；
1. 熟练掌握java编程，并熟悉Shell或Python，三年以上编程经验，至少两年以上大数据开发经验，具有独立设计数据仓库经验；
3. 熟悉HDFS、HBase、Hive、MapReduce、Storm、Spark等技术，有相关开发经验；4. 熟悉ActiveMQ、Kafka、Redis、Memcache等相关技术一种以上；5. 熟悉Sqoop、Flume、Spider、ElasticSearch、Solr等相关技术一种以上；
6. 具备良好的沟通能力，对数据敏感，有较强的学习能力和创新思维，团队精神及艰苦创业精神；
7. 具有车险业务分析或数据挖掘经验者优先；

工作内容：
1、根据客户需求制定并推进各业务系统的数据接入与流转流程规范和方案；
2、大数据平台搭建和运维；
3、大数据计算平台功能开发、性能调优。
 
岗位要求：
1、扎实的计算机理论基础，研究生优先考虑；
2、熟悉hadoop生态圈，如hadoop、hbase以及spark；
3、精通java开发，熟悉IO机制、网络通讯、多线程等基础知识框架，熟悉缓存、消息队列、索引查询等机制；
4、能够熟练对数据进行整合，熟悉Hive数据仓库建模；
5、精通sql知识，有sql调优经验；
6、熟悉主流的ETL工具，同时精通大数据平台下的采集数据同步工具sqoop、flume、kafka等。

岗位职责：
1. 业务数据报表设计、开发及日常维护 2. 对现有数据分析平台进行功能维护、性能优化和系统升级3. 及时响应数据统计分析需求，并根据数据分析结果提出业务策略建议 4. 结合业务特点，探索并建立分析主题，对数据进行深度分析和挖掘岗位要求：1. 本科或以上学历，计算机、统计、数学等相关专业毕业;2. 熟练使用SQL和R软件，熟练使用MySQL/PosgreSQL/Oracle中至少一种数据库;4. 熟悉Hadoop、spark/storm或在MPI并行环境有应用实践经验；5. 充分的数据敏感度，能从海量数据表现中提炼核心结果，及时分析数据中隐含的变化和问题;6. 优秀的分析问题和解决问题的能力，能够把合理的思路成功应用于实践;7. 表达能力强，具备优秀的快速学习能力、沟通协调能力及团队精神;8. 有较强的责任心和学习积极性. 

岗位描述：
1. 完成日常数据统计需求；
2. 进行基础的数据整理和分析；
3. 负责海量数据的处理、分析和挖掘工作；

岗位要求
1. 计算机相关专业，3年及以上相关工作经验,有扎实的计算机理论基础；
2. 熟练掌握 Java 编程语言，并熟悉 Shell，Python 等一门以上脚本语言；
3. 熟悉 Linux/Unix 环境；
4. 有 Hadoop 框架开发经验，深入理解MapReduce、HDFS；
5. 熟悉Hive、HBase、Spark者优先；
6. 逻辑思维能力强，对数据敏感，有较强的学习能力和创新思维；
7. 具备良好的学习能力、分析解决问题能力。

岗位职责：
1、从事大数据分布式存储/应用服务的设计和开发，挑战大规模、高并发、易运维的分布式系统设计构建； 
2、负责大数据应用产品的开发工作（营销、推荐、搜索、分析统计等），包括系统/算法的设计及实现；
3、对现有系统的不足进行分析，难点攻关，找到目前系统的瓶颈，改进系统架构设计，提高系统性能；
4、跟踪评估数据产品线上效果，参与各业务部门的产品设计讨论，促进大数据产品的广泛落地各产品线。

任职要求：
1、统招本科及以上学历，2年及以上工作经验，精通Java/Python服务端设计开发经验，良好的计算机领域理论基础；
2、具备较好的面向对象设计思想，熟悉高并发、分布式的系统架构设计；
3、熟悉业界先进的分布式计算平台和分布式文件系统，如hadoop、spark、hbase等，深入理解MapReduce；
4、具有良好的代码风格以及较强的代码荣誉感责任心，具有良好的表达能力能够清晰和准确地描述问题和良好的团队协作精神；
5、熟悉MySQL/Redis等系统原理机制以及线上应用经验原则；
6、有大数据产品线上大型系统设计开发/线上算法设计实践经验者优先。

工作职责：
1. 参与hadoop/Spark大数据平台的开发工作2. 参与公司业务需求调研和源数据调研3. 参与大数据平台的数据建模和系统设计4. 参与大数据平台的数据分析和数据挖掘5. 参与维护和管理Hadoop/Spark集群和性能优化工作

任职资格：
1. 计算机、数学等相关理科专业本科及以上学历
2. 4年以上Hadoop大数据平台项目实际开发经验3. 有丰富的大数据平台数据分析和数据挖掘的项目经验，精通数据挖掘各类算法，如决策树，分类算法，聚类算法，时间序列等4. 熟悉主流的大数据处理技术，包括Hadoop、Spark、Hbase、Hive、Pig、Sqoop、Oozie、Flume、Zookeeper等，了解Hadoop/Spark集群管理及优化5. 熟悉Java, Scala，有实际开发经验6. 熟悉Linux，Shell &amp; Python脚本7. 有强烈的责任感，主动性强，具有良好的团队合作精神和高度的责任心，能在较大压力下工作


智领云云计算大数据平台研发团队聚集了硅谷和本土的优秀创业人才，团队成员中有的在硅谷著名科技公司Ask.com，Twitter和EA担任过技术总监和研发经理，有的在中国的互联网公司担任过高级研发人员，他们都有着深厚的大数据平台研发背景。智领云研发团队按照硅谷的模式来组建团队，采用agile的开发流程，基于最新的开源软件（Mesos, Docker, Kafka, HDFS, Spark and Presto）来构建核心平台。加入智领云，你将会在硅谷技术公司的氛围中，和硅谷技术大牛一起coding一起攻克难题。如果你是有经验的大数据工程师，那么在智领云你将会有机会独立挑战技术难题并成为开源社区的committer；如果你是刚走出校园的编程高手，那么在智领云你将有机会成为具有系统分析能力的云计算大数据平台架构师。如果我们的诚意让你心动，那么不要犹豫，请赶快加入智领云，和我们这样怀抱梦想的团队一起成长！岗位职责：1.开发智领云核心大数据处理平台整体架构；2.参与分布式集群管理和容器技术的研究和实施；3.集成先进开源模块，提高系统性能和可靠性；4.解决客户的大数据分析需求；5.负责大数据运行流水线的实施和运维。任职要求：1.本科以上学历，计算机相关专业;2.熟悉Unix/Linux操作系统原理，常用工具，系统管理；3.熟悉下列后台开发工具和语言之一（Java, C++, Scala, Python, Shell Scripts）；4.快速学习能力，能根据工作需要快速掌握新的编程语言和系统框架;5.具备良好的分析解决问题能力，能独立承担任务和有系统进度把控能力;6.责任心强，良好的对外沟通和团队协作能力，主动，好学；7.有较好的英语读写能力，能够阅读英文技术文档；8.理解分布式计算基本原理，有分布式集群使用和开发经验者优先；9.有以下经验者优先: Docker/Mesos/OpenStack/Hadoop/Hive／Kafka／Spark

我们是处于快速发展期的行业独角兽，A轮融资2.04亿创行业之最，目前正在扩充核心技术团队，急需最高端的瓜子仁和我们一起勇攀高峰，创造奇迹。这里有最顶尖的技术团队、最好的个人发展平台以及给力高薪，足够优秀的公司需要足够优秀的你，期待你的加入。
职位描述：
岗位职责：
1.负责hadoop平台上的数据处理；
2.使用spark、mapreduce进行数据处理
任职要求：
1.熟悉Hadoop、HBase、Hive、Spark、Mapreduce
2.对数据结构、算法有深刻理解
3.精通Java、Python
4.熟悉linux开发环境
5.熟悉hadoop、hbase、spark的源码的优先
6.对新技术充满激情，认真负责、有良好的沟通和学习能力
7.计算机或数学相关专业本科及以上学历

岗位职责：
  负责腾讯云大数据实时计算平台搭建工作；
  负责系统架构的技术选型、架构设计，以及性能调优。
  熟悉业务形态，参与需求分析和方案设计。

岗位要求： 
  本科以上学历，计算机或相关专业，有流式实时计算的相关经验；
  精通至少一种数据分析/挖掘软件，如R/Python/SAS/Mahout等；
  至少一门脚本开发语言(如python/shell/ruby/javascript/tcl/perl等)使用经验；
  深入理解MapReduce，熟悉Hadoop/Hive/Kafka/Storm/flink/Spark/Yarn等大数据相关技术；
  熟悉高并发服务器端系统架构，熟悉网络编程、Redis，Mysql数据库等后台技术；
  技术视野开阔，有强烈的上进心和求知欲，善于学习和运用新知识；
  善于沟通和逻辑表达，良好的团队合作精神和积极主动的沟通意识。

工作职责：
1. 基于大数据的分布式、高并发应用的设计与开发；
2. 主导解决在分布式、高并发技术上的出现的各类问题；
3. 协助在分布式、高并发技术上的造型和决策。

岗位要求：
1. 三年以上研发工作经验，具有扎实的Java基础，熟悉Linux系统开发；
2. 熟悉面向对象和设计模式，具备spring/myBatis等开源框架应用经验；
3. 熟悉多线程、网络传输、分布式/高并发系统的设计开发及调优；
4. 熟悉缓存、消息等机制，能熟练运用Zookeeper、Kafka、Elasticsearch、Redis、Akka等进行开发；
5. 具有较强的理解能力、沟通能力及团队合作精神。

岗位职责：
软件产品（ITOA）研发与服务支持

任职要求：
1、深刻理解大数据技术架构体系，熟悉Hadoop生态系统的建构、管理及优化，有hadoop，mahout 或者 spark，mllib等大数据平台实践经验
2、理解MapReduce、HDFS原理、spark RDD原理，熟练使用Hive、Spark SQL、Hbase，具有良好的数据结构、算法功底，并有扎实的相关开发经验，能够熟练使用java，scala，C/C++等编程语言
3、深刻理解统计分析和机器学习的基本原理，熟练使用分类，聚类，推荐，自然语言处理等算法，并有2年以上机器学习应用实践经验
4、本科及以上学历，5年以上工作经验，具备良好的英文技术文档阅读能力，并能够独立研究
5、动手能力强，有极强的进取心和责任心，善于团队协作与沟通

1.通过海量数据挖掘、机器学习等方法进行核心策略的研究及开发；2.用户分析、理解及建模，持续提升用户产品体验；3.高性能、高并发的机器学习、数据挖掘方法及架构的研发；4.算法及数据挖掘在新业务领域的推进及应用。

1、年龄20—28岁，全日制本科（一本/二本）及以上学历，计算机相关专业；

2、对数据分析、数据挖掘感兴趣的优秀应届生；

3、熟悉C语言，对数据结构和算法设计有较为深刻的理解；

4、热爱数据分析工作，做事有耐心，细致，善总结；良好的沟通协调能力和团队合作精神；

5、较强的逻辑分析能力、动手能力和学习能力，善于总结；

6、优先条件：
①熟悉文本的检索和排序相关知识者优先；

②有文本信息挖掘和处理能力者优先； 

③有自然语言编程、机器学习等相关经验者优先。

职位描述：
1. 负责大数据平台并行计算模块相关工作，包括需求沟通，架构设计，功能的设计、实现、测试及相关文档编写等。
2. 负责大数据平台对应上游部门的并行计算支持，如需求沟通、业务模型并行化设计及实现等。
3. 负责大数据平台并行计算模块的日常维护工作，如资源分配、性能调优、日常故障排除等。
4. 负责大数据相关先进技术的调研，并定期进行团队内分享。
要求：
1. 同行业工作经验（年）：5年以上软件开发工作经验
2. 所需的核心工作经验（年）：2年以上MapReduce/Spark开发经验
3. 具有良好的逻辑能力、综合分析能力及文档能力
4. 具备一定的沟通能力，组织管理能力，有明确的目标感和时间意识
5. 熟练使用Java、Scala中任意一种编程语言
6. 熟悉MapReduce或Spark的并行计算原理及过程，具备并行算法设计能力，熟悉常用调优策略
7. 具备一定规模分布式集群的运行、维护经验，具备一定的集群架构设计能力
8. 了解常用数据分析、挖掘算法
（可选）具备AWS或其他云平台使用、维护经验者优先

岗位职责
1、参与公司大数据产品规划；
2、负责大数据平台的设计和开发工作；
3、为其他研发组提供大数据技术指导及分析手段支持；
4、负责大数据平台的性能参数调整和优化；
 
任职要求
1、计算机软件、应用数学、统计、数据挖掘、人工智能方向本科及以上学历，三年以上大数据开发经验；
2、熟悉常用数据分析算法（如分类、回归，聚类，关联规则等方面算法）并有实际项目代码实现经验；
3、熟悉hadoop（如，HDFS、YARN、HIVE）、spark（Spark Streaming，Spark SQL，Spark Mllib 、Kafka、Flume）生态并有实际项目开发经验；
4、熟悉数据库的开发及SQL、NOSQL性能优化（如Mysql、Hbase等）；
5、为人诚信，思维严谨，学习能力和独立工作能力强，能承受一定的工作压力，责任心强，具有良好的沟通能力和团队合作意识。

岗位职责：
1.负责大数据建模和分析、主题分析和数据可视化方案制定；
2.精通：深度挖掘/神经网络 or 图论/复杂网络理论 or 文本挖掘/地址模糊匹配 or 图象比对 or 声纹比对，其中之一；
3.针对金融行业特定领域、不同业务主题开展探索性分析建模和数据挖掘；
4.负责数据整合与分析模型的建立、优化以及跟进；
5.持续推动和跟踪成果的产品化落地；
6.跟踪最新的数据分析、数据挖掘领域的技术和成果。

任职要求：
1.本科及以上学历，数学、统计学、计算机及相关专业，3年以上数据采集、清洗整理、分析建模相关工作经验；
2.有优秀的洞察力，能从纷繁复杂的数据中发掘规律并构建模型，掌握各类算法，具备优秀的大数据建模功底；
3.具有扎实的的数学、统计学、数理建模知识，熟悉数据仓库和数据挖掘的相关技术及方法，熟悉数据可视化相关理论；
4.熟练使用R、SPSS或SAS等（至少一种）工具进行分析和建模，熟悉MySQL/Oracle, 熟悉Hadoop等产品；
6.精通某种算法最佳。

岗位要求：
1、本科以上学历，CET4(需要看英语文档)，211或985院校优先； 
2、具有2年以上JAVA相关工作经验，面向对象编程，其中2年以上的hadoop平台项目开发经验； 
3、以下条件符合其一：熟悉 hadoop/spark 生态组件及工作原理，熟练掌握JAVA语言，shell或python脚本；了解Hadoop、spark基本原理，熟练掌握 HIVE、spark-sql 的开发调优技能（重要），熟悉数据库相关知识，熟练掌握SQL、shell脚本
4、熟悉git、maven等项目协同管理工具；
5、有强烈的责任心和事业心，积极乐观认真细致，团队协作意识强，具有亲和力并能够承受一定的工作压力、富有工作激情；
完美条件：有kafka、streaming经验优先
优先条件：有参与开发已上线的大数据应用经验

岗位职责：
1）结合公司业务特点，研发高质量的搜索、个性化推荐算法和内容处理算法；  
2）追踪搜索引擎、个性化推荐、NLP和机器学习领域的前沿技术，将前沿技术应用于实际业务。

岗位要求：
1.具备扎实的算法及代码实现能力；
2.熟悉以下至少一个领域者优先考虑： 
（1）搜索技术，如信息检索、索引、分词、相关性等；
（2）统计机器学习相关方法，如深度神经网络、概率图模型，最优化方法等； 
（3）语义理解技术，如知识图谱、语义解析、知识挖掘等； 

3.良好的分析问题与发现问题的能力，善于归纳技术方案的特性，并找出其不足与改进方法； 
4.熟悉Hadoop、Spark等分布式计算框架者更佳； 
5.具有良好的沟通能力，和良好的团队合作精神。


我们的福利：
1、与业内顶尖大牛过招+各种内部分享活动，提升自己不等闲~~
2、超出同行业的薪酬水平+优秀人才配备期权，保证荷包鼓鼓~~
3、餐补+无限零食饮料下午茶，满足你挑剔的味蕾~~
4、每周私教健身+macbook pro+加班企业账号打车+年底奖金+图书馆，各种好玩的part等你来~~
5、弹性工作+soho办公+扁平管理的企业文化~~
6、五险一金是必须的~~~~

岗位描述：
1、负责设计实现大数据分析系统
2、负责设计与实现大数据分析平台相关API及服务
3、负责搭建，实施和部署大数据分析系统
岗位要求：
1、计算机科学或相关专业本科或以上学历
2、扎实的计算机专业基础知识
3、熟悉Java/Scala//C++ 等任一门语言
4、有互联网后端项目开发经验, 熟悉高并发网络编程, 熟悉分布式理论基础
5、热爱程序设计, 能快速学习, 有独立解决问题的能力
具备以下资格优先：
1、参与过开源项目
2、熟悉 Finagle / Netty 等网络编程框架
3、了解或熟悉 Storm / Hadoop / Spark / Akka / Kafka / Scribe 等分布式系统
4、熟悉 MongoDB / MySQL / Redis / Cassandra / HBase 等数据库系统
5、熟悉大规模数据处理、高并发或分布式系统相关知识，熟悉JVM性能优化, 有后端服务优化相关经验







岗位职责： 1）负责大数据应用产品的前端展示功能的研发，为用户提供优秀的交互体验和可视化效果 2）对Web前端新技术进行调研和学习，持续推动产品功能和用户体验的优化升级 任职资格： 1）熟练使用HTML、CSS 2）熟练使用Javascript、ajax 3）熟练使用jQuery及其常用组件库 4）具有良好的学习实践能力和沟通表达能力，具有强烈的责任心和团队协作意识 5）本科以上学历，三年以上相关工作经验

优选条件： 1）具有大数据可视化产品相关（如BI报表系统等）的研发背景 2）熟练使用Bootstrap、AngularJS、Highcharts中的一种或多种 3）具有前端架构设计能力和相关经验 4）具有移动端开发能力和相关经验

1.技术研究：大数据风控、机器学习、区块链等技术在风险业务领域的应用。
项目/产品研发落地；
2.从事风险团队相关技术研究及研发落地方面的工作，涉及到大数据、深度学习、R语言、区块链等方向，要求自主学习能力强，有以上方面的学习/项目经历最佳。

职位描述
•      负责基于 Hadoop/Spark 生态的系统研发
•      负责基于搜索引擎（如 ElasticSearch、Lucene 等）的研发
•      负责 Hadoop/Spark 集群调优
•      负责对数据进行建模分析
 
职位要求
•     本科以上学历，3年以上大数据开发／软件开发相关工作经验
•     熟悉 Java 后台服务开发（Spring, Mybatis, Spring Boot, Maven等)
•     熟悉 Hadoop/Spark 生态系统组件（HBase、Hive、ZooKeeper、Mahout 等）
•     熟悉 Flume、Kafka、SparkStreaming/Spark MLlib
•     熟悉 Linux，熟练使用 Java/Scala 语言以及 Python/Shell/R 等脚本语言
•     熟悉Cassandra、MongoDB、Redis等NoSQL数据库
•     有Hadoop/Spark 调优、统计学知识加分
•     有机器学习经验者加分
•     熟悉 ElasticSearch、Lucene 加分
•     有互联网爬虫经验者加分
•     理解英文文档，对新技术有持续的热情

工作职责：
1.与数据产品广泛沟通，快速提供日常基础数据，提高运营效率；
2.通过大量商业数据，分析实施商品挖掘、用户推荐、卖家分析、用户画像等；
3.个性化推荐系统、广告系统等你一起来完善建立。
  
任职要求：
1.本科或以上学历，计算机、数学相关专业毕业； 2.精通go、Python、Scala、shell 至少两门编程语言，了解Linux/Unix平台； 3.有较好的逻辑分析和数据分析能力，解决问题能力强； 4.熟练掌握基础算法和数据结构，了解数据挖掘、机器学习、并行计算相关理论； 5.有风控、推荐、人群画像等领域模型构建和调优工作经验者优先； 6.有spark、hadoop平台上的大数据处理工作经验者优先； 7.有大型互联网工作经验者优先；
8.有github,个人网站者优先。

岗位职责
1、负责基于大数据风控，分布式计算等的设计研发
2、负责java相关基础架构设计，解决系统中的扩展性、安全性、高性能等问题
 
任职要求
1、3年以上大型web研发经验
2、精通java，熟悉常用框架，如spring、ibatis等
3、优秀的数据库设计优化能力（HBASE优先），至少精通一种数据库应用
4、精通多线程及并发技术
5、熟悉大数据处理和高并发性能解决方案
6、熟悉数据安全解决方案
7、熟悉linux，能熟练应用shell/python等脚本语言
8、学习能力强，有较好的沟通能力，能迅速融入团队
9、有大数据平台（hadoop，spark），数据仓库经验者优先
10、较强的逻辑思维能力，具有较强产品意识者优先
 

岗位描述：
1. 海量交通领域大数据的分析/处理，包括海量数据的存储、计算和检索；
2. 基于分布式平台（MR/storm/Spark/flink）的业务数据分析和逻辑job的开发；
3. 开发数据统计系统。

岗位要求：
1. 计算机、数学或统计学相关专业本科以上学历；3年以上数据的开发相关经验，特别是(1) 离线领域hadoop的ETL开发经验或者 (2)实时计算领域包括storm、spark、flink等的开发经验其中之一经验者；
2. 有很好的海量数据开发经验，理解元数据管理。具有一定数据模型和数据架构基础；交通领域大数据工作者更佳；
3. 熟悉unix或者linux，具备优秀的编程能力，熟练掌握java或者scala开发，有storm、spark、flink等等语言中的一种或几种经验者优先；
4. 对数据敏感、对技术敏感，有研究的意识和直觉者更佳；
5. 有良好的团队合作意识，沟通表达能力和综合协调能力。


工作职责：1、负责公司数据产品的产品的功能规划、需求分析设计、技术实现和用户体验，2、负责所属模块的代码开发、调试与维护工作；3、积极响应数据分析师的需求并进行开发和交付；4、设计，重构公司数据产品的架构优化，性能优化并辅助其他模块进行技术实现；5、协助并完成其他各类技术开发任务。任职资格：1、计算机或者相关专业2、良好的问题理解能力，能够理解以及处理复杂逻辑。3、具备较强的自学能力，团队精神及抗压能力。4、三年以上的Java开发应用经验，掌握JSDK，J2EE的相关知识，精通JAVA、JSP、SERVERLET编程，熟悉多线程编程，熟练掌握AJAX，jquery，easyui5 、熟练掌握JAVASCRIPT脚本编写，了解XML，XSLT, CSS的相关知识。6、掌握运用gitlab 版本管理工具、maven、基本Linux操作命令 

岗位职责：
1.负责大数据开源产品（CDH、HDP、Pivotal）的研究、安装、部署、测试、调优、使用。2.负责大数据生态圈各组件的研究、项目中的应用，主要包括Hive、Hbase、Spark等。3.负责公司项目的售前、售后技术支持、指导、架构设计。3.负责大数据部的团队建设、培养。
任职要求：
1、对hive、hbase、hadoop、map/reduce、scribe有深入了解；2、精通主流数据库技术（如Oracle、SQLServer、MySQL等），精通SQL，有较强的SQL编码及数据存储、性能调优经验；3、能够对业务需求进行抽象并据此进行架构设计；
4、有电子政务、智慧城市领域经验的优先。

岗位职责：1）负责订单数据的数据处理、入库的研发和设计工作；2）负责用户画像的相关技术设计和开发；任职要求:1）统招本科或以上学历，计算机或相关专业；2）熟悉spark内核,熟练掌握Java或者Scala语言，追求代码质量和程序效率；3）熟悉Linux/Unix平台上的Java、python、scala，熟悉常用脚本语言 ；4）熟悉Spark SQL, spark Streaming等，对Spark体系结构、运行机制和源码有深入研究优先；5）熟悉ElasticSearch优先；6）有Spark平台、Hadoop平台开发经验者优先 ；7）有统计学知识,了解常用的挖掘算法的优先考虑；8）对技术有强烈的兴趣，喜欢钻研，具有良好的学习能力；9）责任心强，工作认真负责，能够承受一定的工作压力；

岗位职责：
1.参与大数据平台的建设维护，持续稳定支撑业务发展
2.实时／离线数据ETL过程设计和开发
3.多维度海量数据的分析应用
岗位要求：
1.对数据敏感，有意愿投身大数据事业
2.基础扎实，熟练掌握java／sql／shell等技能
3.熟悉至少一个开源框架(hfds/yarn/hive/hbase/storm/sqoop/kafka/elasticsearch)，有运维和hack源码更佳
4.1～3年工作经验，资深3年以上，有互联网，出行行业经验者优先
5.团队合作无障碍，强烈的自我驱动力和抗压力

职位描述：
1.负责业务以及日志数据的抽取、转换、加载
2.设计离线、实时数据的收集方案,并且能落地实施
3.依据业务需求，为数据分析和运营等人员搭建友好高效的数据产品
岗位要求:
1.3年以上工作经验，至少2年大数据工作经验
2.熟练使用Java、Python、Scala等其中一种语言
3.能熟练的使用Udf、Udfa、Python完成结构化数据与非结构化数据的清洗和转换
4.熟悉Hbase，HDFS，Storm，Kafka，Sqoop等大数据处理框架
5.有Spark开发以及调优经验的优先

岗位职责：
   1. 设计与开发大数据平台及应用；
   2. 完成单元与集成测试；
   3. 大数据平台的诊断与调优；
 
   岗位要求：
1. 基础要求：
   ① 有Hadoop或Spark经验；
   ② Java 或Scala编程2年以上经验；
2. 以下有则更佳：
   ① 有ambari开发经验者优先；
   ② 有Docker经验者优先；
   ③ 国家重点高校本科毕业，硕士优先；
   ④ 有大数据相关证书优先；
3. 任职要求
    ① 注重团队合作和沟通；
    ② 在大数据技术领域有极强的自我学习能力；

1.大学专科及以上学历，3年以上工作经验，计算机相关专业毕业优先；
2.熟悉Hadoop、Spark、Storm等开源大数据系统，基于其中1个或多个系统有应用开发经验；
3.精通Java开发，有2个以上实际项目经验；
4.能够独立完成大数据环境的搭建、管理及开发，有一定的分析、设计能力；
5.有机器学习经验，熟悉数据分析预测算法经验者优先。

岗位职责：
1、根据公司战略，结合业务深度，从大数据平台出发，推动商业模式的实现；
2、组织进行数据分析模型搭建、定义数据结构和高阶大数据分析，将数据结果转化为商业价值；
3、把握数据项目技术方向，调动各项资源，推动项目的进展，对项目负责；
4、负责数据团队的建设和管理工作，领导数据团队有效的支持和推动业务发展。
 
任职要求：
1、硕士以上学历，数据研究相关背景；
2、5年以上数据项目平台经验，在数据分析、数据挖掘有丰富的经验，精通数据仓库技术；
3、3年以上数据团队管理经验，知人善用；
4、对机器学习等大数据技术有深入研究，对新技术、新领域抱有开放的心态；
5、责任心强，自我驱动，创新进取力突出。
 
薪资：20-40K

工作职责：     负责青云QingCloud 大数据产品研发。 职位要求：     熟悉 Linux 操作系统及 Linux 环境编程；     熟悉分布式系统的架构与算法；     精通Spark、HBase、Hadoop、ElasticSearch、Kafka、Storm等开源大数据软件；     熟悉Python、C 或 Java；     良好的沟通能力、团队精神及服务意识，勇于接受挑战，能承受较大的工作压力     较强的自主学习能力和英文技术文档阅读能力     熟悉虚拟化技术，例如 KVM/Xen 等技术     熟悉块存储、分布式块存储及分布式文件系统技术     熟悉网络设备及技术，例如 交换机/路由器/Iptables/Ebtables/OpenFlow等配置及原理     熟悉数据库技术，例如 MySQL/PostgreSQL/MongoDB/Redis/Cassandra 等

岗位职责：
1.完善公司大数据平台建设，增强系统基础架构能力，提高平台易用性。
2.提高平台工具化、自动化水平。
3.跟踪大数据领域技术发展。提供合理的技术堆栈解决业务问题。4.对现有平台进行分析，找到系统瓶颈，并进行相应优化。
素质要求：
1. 本科以上学历，2年及以上工作经验。 
2. 熟悉hadoop、hive基本原理。熟悉spark、hbase、flume、kafka等相关技术。
3. 熟悉操作系统基本原理，精通资源调度算法。
4. 熟悉Java/Python至少一种；有MySQL相关开发经验； 
5. 具备较强的抽象能力。
6. 有互联网日志采集和分析系统开发经验者优先；
7. 熟悉数据仓库基本原理者优先；
8. 有web开发经验者优先；

我们为您提供：     
1、工资奖金 ——薪资在业内极有竞争力，一年13-15个月工资，且年度有2次调薪机会；     
2、五险一金 —— 按工资基数全额缴纳五险一金；     
3、多种福利——交通补助、餐补、每年5000元左右过节费、春节报销回家路费、春节开门红奖金等等；    
4、多种激励 —— 月度个人或项目评优、丰厚的人才推荐奖、高效团队合作奖等各种奖励；     
5、员工旅游 —— 春游、夏游、秋游、大型年会，当年被评为金牌员工可以享受出国游，让您旅游玩到high；     
6、健身中心——宽敞明亮随用随有的免费健身房，羽毛球、乒乓球、台球、跑步机等各种健身设施应有尽有，更有各种俱乐部，篮球、跆拳道等各种部落群让您找到志同道合的玩友！     
7、健康体检——每年一度的健康体检让您的身体定期做个检查；     
8、工作居住证——为符合北京市规定的员工办理北京市工作居住证；优秀的应届毕业生更有机会解决北京市户口；    
9、上班时间——每天弹性工作制，错峰上下班；    
10、培训分享 —— 新员工培训、沙龙、托展培训、外部培训等等，在JJ我们一起成长！

岗位职责：
1、根据公司提出的战略目标，组织制定公司中长期发展战略与经营方案，并推动实施。 2、带领产品研发管理和迭代计划，协调开发进度，推动数据平台的建设；3、负责完善、建立、设计适应互联网业务的数据挖掘、分析产品架构及运营模式；4、组织实现公司内部和外部对大数据服务的需求以及对相关产品推广、咨询、支持、培训等工作；5、主持大数据业务的全面经营管理工作，组织研发总监、销售总监分解实施总裁决议。 6、主持区域团队建设，配合集团推进企业文化的建设及宣导，建立人才梯队；  7、根据企业的年度经营目标，制定市场的年度经营计划，并组织团队实施，确保年度经营目标的实现，并承担经营绩效指标；8、负责重大项目的商务谈判，审核商务合同条款，组织起草合作协议；9、监控项目合作的开展，运营等工作，并对其效果进行评估；10、整合行业资源，构建良好的政府关系；11、负责客户管理及大客户的开发与维护；12、处理区域重大突发事件；"
任职要求：
1.本科或以上学历，5年以上数据（数据库，大数据，存储）行业从业经验，至少3年以上部门事业部负责人经验2、熟悉企业业务和运营流程，在团队管理方面有极强的领导技巧和才能，熟悉企业全面运作，企业经营管理、各部门工作流程；3、具有优秀的领导能力、出色的人际交往和社会活动能力；4、善于内外部的协调与沟通，具有强烈的责任心、事业心；5、具备亲和力、感召力、凝聚力；具有判断能力、决策能力、计划能力、谈判能力。

工作职责：1、负责POI及相关数据的数据对接；2、负责数据分析、挖掘及个性化推荐等相关工作。任职资格：1、本科及以上学历，统计、数学、计算机相关专业优先；2、良好计算机基础，熟悉算法设计/数据结构，熟悉机器学习及深度学习；3、有推荐系统相关工作经验；4、熟练掌握python,java,R开发，有linux环境下的开发经验优先；5、有hive及spark经验者优先；5、思维敏捷，良好的分析和沟通能力；6、责任心强，做事认真踏实。

岗位职责：
负责搭建深度学习框架，以及图像检索、分类、分割和识别等相关产品实现
职位描述： 
1. 计算机、统计学、人工智能、模式识别等相关专业硕士/博士；
2．掌握机器学习领域的相关知识，具有两年以上图像领域的研发经验；
3. 熟悉TensorFlow/MXNet/Caffe/Torch等深度学习框架中的一种，对CNN有深入的理论研究和实践经验；
4. 熟练掌握C/C++/Python/Matlab等语言及常用数据结构算法，优秀的工程实现能力；
5. 工作认真，细心，有激情，具备良好的沟通能力及团队合作精神；
加分项

参加过ImageNet等图像领域竞赛

研究过TensorFlow/Mxnet/Caffe等源码，具有CNN/LSTM等模型的线上部署经验

任职要求：
1. 熟悉大数据开源产品的架构和技术细节，具Spark(Streaming/MLlib)、Hadoop、Hive、YARN/Mesos、Flume、Kafka平台的项目开发经验，平台运营维护经验；2. 有扎实的Java基础，Java多线程、并发以及网络通信有深厚的经验；首先scala优先考虑；3. 有较强的实现能力及学习能力，拥有实际的Hadoop的项目经验;4. 工作认真，负责，良好的团队合作精神和解决问题分析能力。钻研技术克服困难，勇于挑战；5. 熟悉Linux/Unix操作系统，熟悉脚本编程(Shell/Python/Perl其中一种）。
工作内容：
1. 负责海量数据的自动化分析处理和统计工作； 2. 数据仓库的设计，开发，维护；3. 根据相关需求进行数据处理、查询，统计等工作。

岗位职责：

1、负责公司大数据平台的支撑和保障；    
2、负责大数据平台的架构审核、业务监控、持续交付、应急响应、容量规划等；    
3、为线上服务高效稳定运行负责，支撑业务和数据量的快速扩张；    
4、深入理解大数据平台架构，发现并解决重大故障及性能瓶颈，打造一流的大数据平台；    
5、持续的创新和优化能力，提升产品整体质量，改善用户体验，控制系统成本。    
 
任职要求：

1、计算机、数学、统计学相关专业本科及以上学历；    
2、精于容量规划、架构设计、性能优化；    
3、熟悉Hadoop大数据生态圈，包括但不限于HDFS、YARN、Hive、HBase、Spark等；    
4、有1年以上Hadoop相关运维开发经验，了解Hadoop各组件的原理，并有实际部署维护经验；    
5、有开发经验优先，精通一门以上脚本语言(shell/perl/python等)，熟悉java/C/C++等开发语言一种及以上；    
6、深入理解Hadoop各组件的原理和实现，有阅读源码能力者优先；    
7、具备很强的ownership，故障排查能力，有很好的技术敏感度和风险识别能力；    
8、良好的服务意识，善于团队协作，项目管理，主动思考，自我驱动力强。  

岗位职责：1、参与大数据平台的架构设计；2、负责大数据平台应用核心模块的详细设计和开发工作；3、探索云计算基础架构层、平台层方向技术趋势和核心技术；任职要求：1、计算机相关专业本科及以上学历，硕士优先；2、熟练掌握Linux系统，精通shell脚本开发；3、精通HDFS，MapReduce，hive，hbase，spark的一种或多种工作原理。4、具有hadoop/Spark的部署、优化、排错的能力；5、熟悉大数据ETL工具的使用；6、熟练使用hive，并能够编写hiveQL；7、有电信行业的云计算应用经验优先。


1、负责公司大数据方面产品的需求分析、产品规划及设计；
2、负责协调开发、设计、测试合作完成产品功能的落地，实施产品培训；
3、制定阶段目标、产品关键指标，提出新产品建设思路和方向，组织立项，发展新产品；
4、关注用户对于产品各项功能的反馈，制定迭代计划，不断增强用户体验；
5、在产品的整个生命周期内对产品的性能、质量以及竞争力进行管理。
 
任职要求：
1、本科及以上学历，两年以上需求分析、产品经理相关岗位工作经验，具备独立撰写产品文档的能力；
2、熟练使用office办公应用软件及Visio、Axure等原型设计软件，有UI设计经验优先；
3、对产品分析、数据分析、竞争分析等有独到的见解，善于倾听用户声音；
4、熟悉互联网或软件产品整体实现过程，包括从需求分析到产品发布，有大数据相关项目经验者优先；
5、具有良好的沟通协调能力，拥有强烈的责任心和团队合作精神，能承受较大的工作压力。

岗位职责：
1、移动端数据抓取和处理；
2、业务系统日志分析；
3、广告推荐系统；
职位要求：
1、3-5年相关工作经验；
2、大学本科及以上学历，熟悉JAVA编程；
3、熟悉SpringMVC、Spring、MyBatis等框架，熟悉IO、网络、多线程并发编程技术；
4、熟悉Hadoop、hive、storm、zookeeper、Spark、Elasticsearch、、kafka等一个或多个开源分布式系统，有应用开发经验者优先；
5、熟悉MySQL、Redis，Mongodb等常见存储和缓存系统；
6、良好的沟通能力和团队合作精神，有责任心，勤奋好学；
7、有统一日志处理、商务智能、数据挖掘、风控系统、移动端数据分析等大数据相关产品工作经验优先；

岗位描述
1. 负责数据分析系统的设计和开发工作
2. 负责海量数据的ETL、分析和挖掘工作
3. 负责实时数据处理系统的设计和开发工作

岗位要求
1. 计算机相关专业，硕士2年以上工作经验
2. 具有海量数据ETL开发经验
3. 熟练掌握Java技术，有Scala经验优先
4. 熟悉Python， Linux Shell脚本技术
5. 至少熟悉Hadoop， Spark， Storm， Flink其中一种技术
6. 熟悉Hive，HBase等大数据存储技术

 大数据开发工程师  职位要求：  1、全日制大学本科或以上学历，计算机相关专业  2、两年以上大型Web应用系统开发经验  3、熟练掌握JAVA或PHP，熟练JavaScript、Shell、SQL，熟悉L(A/N)MP架构、Mysql数据库集群  4、熟悉python者优先  5、熟悉机器学习/数据挖掘者优先  6、具有较强的逻辑思维能力，分析和解决问题的能力，沟通能力，学习能力，具备良好的团队合作精神和服务意识

【岗位职责】
1、负责大数据系统的设计和开发工作；
2、负责分布式数据仓库的主题模型设计和宽表开发工作；
3、支撑日常业务数据需求，负责系统优化，问题跟进并及时解决。 

【岗位要求】
1、熟悉Java或Python开发，具有2年及以上Java开发经验，熟悉linux操作；
2、具有3年以上大数据或分布式数据仓库系统开发经验；
3、熟悉Hadoop、Hive、HBase、Spark等相关技术，具有多个以上大数据平台项目实施经验；
4、具有丰富的数据仓库系统的开发实施经验，熟练设计数据模型、ETL设计、Cube多维建模、OLAP开发、报表开发等；具有良好的编程习惯和文档编写习惯；
5、有较强的学习能力，对技术有钻研精神，并有较高的热情，热衷于新技术学习和实践；
6、优秀的团队合作精神，对工作有热情，能够承受住压力。

工作职责：1. 负责公司现有数据的分析和数据挖掘, 以及推荐系统的设计和实现(基于Spark)2. 基于Spark框架的数据仓库的设计，开发，维护；任职要求：1. 熟悉常见聚类算法和推荐算法, 有过实际的算法设计和项目开发经验2. 熟悉Spark内核,熟练掌握Java，Scala或python3. 有过海量数据系统开发经验优先4. 有优秀的推荐系统、数据挖掘等领域的理论基础和研发经验有限
 

职位描述：

工作职责：负责青云QingCloud 大数据产品研发。 职位要求：熟悉 Linux 操作系统及 Linux 环境编程；熟悉分布式系统的架构与算法；精通Spark、HBase、Hadoop、ElasticSearch、Kafka、Storm等开源大数据软件；熟悉Python、C 或 Java；良好的沟通能力、团队精神及服务意识，勇于接受挑战，能承受较大的工作压力；较强的自主学习能力和英文技术文档阅读能力；熟悉虚拟化技术，例如 KVM/Xen 等技术；熟悉块存储、分布式块存储及分布式文件系统技术；熟悉网络设备及技术，例如 交换机/路由器/Iptables/Ebtables/OpenFlow等配置及原理；
熟悉数据库技术，例如 MySQL/PostgreSQL/MongoDB/Redis/Cassandra 等。

工作职责:
-负责大规模数据存储，高性能离线/实时计算平台的研发与维护
-理解和分析数据挖掘需求和数据特点，开发中间数据层及策略中间件
-用户行为分析、核心指标制定与相关性分析、竞争产品跟踪等大数据需求
职责要求:
-计算机相关专业本科以上学历，2年以上大数据领域项目经验
-熟悉常用数据结构和算法, 熟练Linux环境及shell脚本
-熟悉hadoop/hbase/spark等大数据相关开源工具中一门或几门
-精通C/C++/java/php里的一门或几门，具有扎实的面向对象开发经验
-乐于解决具有挑战性的问题, 具备优秀的分析问题、解决问题能力
-思维灵活，对数据敏感，擅长与产品经理、数据挖掘工程师等进行交流沟通及合作
-有数据挖掘、机器学习工作经验者优先

岗位职责：
1. 负责业务数据仓库的理解，设计并实现，为公司数据分析提供高质量的数据
2. 业务的数据模型设计，参与团队数据模型优化
3. 数据采集，数据清洗，数据挖掘等大数据处理任务
4. 支持数据的可视化展示
 
任职要求:
1、计算机相关专业，本科及以上学历，2年以上互联网工作经验
2、熟悉常用数据结构和算法
3、熟悉Hadoop/MapReduce/Spark,熟悉linux、shell、awk、python等脚本处理。
4、有日志采集、海量数据处理、数据库查询优化等经验者优先，熟悉hbase、hive、mysql等；
5、能使用一种常见的SSM等web开发框架，并能进行针对性的查询优化；
6、有一定编程基础，对数据结构和算法设计有较为深刻的理解，熟悉C++ /Java/Python至少一种语言；
7、有较强的业务理解能力，能快速将业务问题转化成具体的技术解决方案; 有较好的沟通交流能力,善于主动思考和行动,乐于解决具有挑战性的问题。
 

岗位职责：
1. 负责基于hadoop，spark，storm等开源软件进行定制化研发，构建统一的数据平台
2. 负责解决在业务发展中遇到的产品和平台架构问题；具备一定的前瞻性； 
岗位要求：
1. 一年以上互联网或海量数据处理工作经验，大数据挖掘、分析、建模经验；
2. 熟悉大数据基础平台技术的原理和内部机制，包括Hadoop、HDFS、MapReduce、Hive、Spark等；
3. 熟悉shell、python脚本编程； 
4. 熟悉聚类、分类、回归等机器学习算法实现，对核心算法理解透彻，有实际建模经验；
5. 能独立承担数据的模型设计、存储规划等工作，具备良好的沟通表达能力。


岗位职责
1、参与大数据课程产品的开发，包括讲义、案例和PPT的撰写，以及大数据相关教材的编写工作；
2、配合大数据讲师完成相关教学资料的研发和审核工作；
3、参与大数据分析平台的部分研发工作。
岗位要求
1、数学、统计、计算机或相关专业；
2、熟悉机器学习基本模型，如线性回归、逻辑回归、SVM、AdaBoost、神经网络、随机森林等；
3、 较强的编程能力，熟练掌握Python，熟悉Python数据分析包pandas、机器学习包scikit-learn；
4、具备良好的PPT制作习惯；
5、具备良好的沟通能力和团队写作能力。

职位描述：
1、负责大数据部门的数据采集与爬取、解析处理、入库及备份等数据日常工作；
2、数据采集工具软件平台的开发工作 3、负责分析新的数据需求, 完成数据处理的设计(文档)和实现；4、负责数据处理程序设计框架改善, 数据处理性能优化, 系统数据处理的能力提高；
任职资格：
1、计算机相关专业，专科或者以上学历；
2、熟悉网络爬虫原理，有网页抓取、网页信息抽取、网页结构分析工作经验；
3、精通 Mysql、Oracle等主流数据库之一，精通 SQL应用；
4、熟悉Linux开发环境，有python/shell脚本使用经验；
5、熟悉Nutch、Heritrix等开源爬虫者优先；
6、熟悉hadoop、hbase、spark 技术者优先；
7、具备较强的学习能力和团队协作精神。

工作职责：       1. 参与公司大数据产品规划,大数据处理分析平台的设计和开发;       2. 负责数据分析、加工、清理、处理程序的开发;       3.保质保量按时完成开发任务；测试阶段积极配合测试，及时对BUG进行修复       4. 大数据平台运行性能、可用性、扩展性等监控与优化

任职要求：       1. 全日制本科以上学历，计算机相关专业       2.三年以上java及WEB应用软件开发经验，并熟知软件开发流程       3.精通面向对象分析和设计技术，熟悉NIO，多线程编程技术       4.熟悉Hadoop系统，了解map-reduce原理       5.熟悉HDFS、YARN、Hive、Spark的体系结构和运行原理       6.熟悉和了解一种或多种Hadoop生态圈其他系统，包括Hive，Pig，HBase，Spark，Kafka，Oozie，Sqoop，Flume，ZooKeeper       7.熟悉常见NoSQL存储，如Hbase、memcached、redis、mongodb等；       8.熟悉git, maven,nexus等开发和管理工具，有Linux环境开发经验优先       9. 熟悉最基本的linux命令

岗位职责：
1. 负责大数据相关产品的需求调研和分析，理解产品目标和功能需求；
2. 负责大数据平台的产品规划和功能设计；
3. 建立并推动大数据产品的设计标准，跟进客户反馈，持续改善和优化改进产品；
4. 协调各个部门，把控与跟进产品从需求、设计、开发、测试、验收、发布和运营的整个过程；
5. 参与公司内/外部前端数据产品规划和设计，包括部分数据可视化的产品设计。
 
任职资格：1. 具有本科及以上学历；
2. 具有3年及以上软件产品或数据产品经理工作经验，有政府项目数据平台开发经验，数据统计分析，数据挖掘经验者优先；3. 熟悉各行业大数据应用场景，熟练运用各种内外部数据统计工具；4. 热衷产品设计，可以准备的把握用户需求，富有创新精神，善于沟通合作，自驱并乐观；5. 具有较强的项目组织能力，有较强的跨团队协作能力和执行力。
6. 优秀的交互设计能力和数据可视化设计能力

工作职责1、基于Hadoop/Spark分布式集群的架构设计和开发。2、解答用户提出的需求以及碰到问题时的解答。任职资格1、数学、统计学、人工智能、计算机相关专业，本科或以上学历。2、至少熟练运用Java、Scala语言中的1种。3、需要有Hadoop / Spark平台相关运维经验2年以上，有3年以上基于hadoop/Spark的实际项目开发经验。4、熟练掌握linux常规命令与工具，至少熟练应用shell、Python脚本语言中的1种。5、敏锐的洞察系统性能瓶颈，并能对io、网络通讯、任务调度中一个或多个方面的性能调优。6、对flume,kafka,yarn,hive,hbase,elk等技术有一定经验者优先。7、有爬虫经验者优先。8、具有较强的学习能力、逻辑分析能力、问题排查能力、沟通能力、自我驱动动力、自我管理能力。
 

岗位描述：
1 .保证实时数据处理平台能稳定支撑数据处理，对平台进行性能优化、架构改进等
2 .jstorm/storm/spark 内核研发，为内核开发新特性和性能优化
3 .实现实时数据处理平台及相关子系统的功能，如ETL 、数据报表、监控大屏、OLAP
4 .开发数据化运营产品，帮助集团内业务和云平台用户进行链路分析、监控报警、性能优化、故障定位等，参与产品需求沟通、规划、推进、运营等全过程
 
岗位要求：
1 .有 jstorm/Storm/Spark 实施经验，对相关技术有深入了解者优先
2 .熟悉 Linux 系统，熟悉 Java，对中间件使用场景有深入了解者优先
3 .对大规模分布式系统环境，有实时监控分析方面的开发经历者优先
4 .熟悉 Web 前端开发，熟悉 bootstrap、jquery，有 highchart、d3、js 等数据可视化开发的经验者优先
5 .本科工作3年及以上，研究生2年及以上

必备项：
熟练掌握Java等语言，熟悉常用的类库和框架
精通分布式系统相关框架和系统，如Spark (Streaming)，HBase等
精通数据挖掘、机器学习、关联规则等模型和算法
 
加分项：
熟悉ELK(ElasticSearch, Logstash, Kibana)等实时日志分析平台
熟悉深度学习算法，有tensorflow实战经验者为佳。
熟悉前端设计及可视化展示

工作内容:
1、  建设大数据平台并不断优化效率，能够高效支撑数据业务需求，具备大容量事物及交易类电商平台的数据库模型设计能力。
2、  利用各种资源不断优化大数据存储和处理效率，提升数据处理速度。
3、  建设消息流平台，具备解决高并发消息流效率问题的能力。
4、  主导数据产品功能化实现，实现数据产品可视化。
5、部门总经理或项目经理安排的其他工作。
   


任职资格:
U教育背景U:
◆计算机或相关专业本科及以上学历，特别匹配者可适当放宽要求。
U培训经历U:
◆无要求
U经      验U:
◆有过3年以上大数据架构相关经验，能够独立完成大数据架构设计；
U技能技巧U:
◆熟练使用spark，hadoop等分布式架构编程，能够解决数据流程执行效率问题。
◆Hive,Mapreduce,SQL,shell等数据处理平台建设并持续优化数据处理效率问题。
◆熟悉各类型主流数据库，至少具备oracle、mysql、db2、Sybase等其中一种数据库管理能力。
◆熟悉JAVA,C,C++一种或多种开发语言
◆具备数据挖掘能力者优先
U态      度U:
◆充分的技术热情，能够快速掌握新技术；
◆责任心强，解决问题能力强；
◆踏实的工作作风，能够适应互联网快节奏的工作效率；
◆具有良好的职业道德观念、沟通能力和团队合作意识。

工作职责：
百家号作者数据产品设计及研发
百家号海量数据建模，数据分析
百家号数据分析平台建设及优化
基础架构的建设和维护，包括调度系统，元数据管理，数据监控，测试平台等

职位要求：
熟悉php开发框架，熟悉mysql，有一年以上的开发经验
熟悉Mapreduce原理，hive sql，熟悉脚本语言如java,python等
学习能力强，有责任心
有大型互联网公司大数据平台及数据开发经验者优先
有流式计算，海量数据存储经验者优先

岗位职责：
1.负责大数据平台的搭建工作；
2.负责大数据平台的数据分析，用户行为分析等工作；
3.根据业务需求，设计和开发相关产品。

任职需求：
1.计算机、数学、统计学相关专业,3 年以上工作经验
2.熟练掌握主流的推荐算法，如协同过滤、矩阵分解等，并有相关实践经验
3.熟悉自然语言处理相关模型
4.有大规模用户数据或互联网数据处理经验者优先
5.熟悉Hadoop、Hbase、MapReduce、Hive者优先；
6.至少熟练掌握一门开发语言(C++ Java 等)；
7.有个性化推荐相关工作经验优先。
方圆奇正拥有一支年轻富有朝气的队伍，朝九晚五，周末双休，如果有幸能够与跟您长期合作，将会为您提供令您满意的薪资。

戳这里了解更多： http://www.bjfyqz.com如有意向可直接投简历至：hr@fyqizheng.com（请注明所投职位+所得招聘信息来源）

岗位职责：
1、 负责搭建大数据各个系统的运行环境；
2、 维护日常job的正常运行；
3、 负责撰写相应的统计分析代码；
4、 负责和业务方对接实现个性化的大数据分析应用。
任职资格：
1、 大学本科以上学历，计算机相关专业；
2、 一年以上相关工作经验优先；
3、 熟悉Linux/Unix平台上的C/C++或Java编程；
4、 熟悉分布式系统概念、架构；
5、 熟悉操作系统、文件系统的原理和实现；
6、 熟悉Spark/Hadoop/Hive/Impala等开源技术。

岗位职责：
1.负责数据清洗、加工、分类等开发工作，并能完成数据分析师对数据提取的需求；
2.负责从数据中挖掘出有价值的数据，把这些数据录入到数据中心，支持应用端资料分析与预测；
3.负责对团队初级同仁工作的分配和指导，确保项目的有效推进。
岗位要求：
1.本科以上学历，3年左右相关工作经验；
2.熟练掌握常用的数据挖掘算法；
3.熟练在Hadoop，spark等框架上进行数据处理工作；
4.熟练掌握Scala，R语言等数据分析语言。

加入鼎捷，您可以获得优厚的薪资福利待遇和完善的培训发展体系 
----固定的基本薪资、岗位技能/管理津贴、年终奖、绩效奖金、年度调薪
----法定年假、福利年假、法定节假日、带薪病假
----五险一金、商业保险（补充医疗险、意外伤害险）
----午餐补贴、通讯补贴、自备机补贴、出差补贴
----生日礼金、节假日福利、婚丧喜庆福利、定期体检
----健全完善的培训体系（新人训、专业训、部门内训、新人带教制度等）
----宽广的晋升发展平台

注意：应聘者需承诺提供的相关材料真实、合法，不存在虚假成分；如有虚假材料，视为不符合该岗位的录用条件。


1、 三年以上相关工作经验，至少两年大数据工作经验；   2、 熟悉Linux操作系统、脚本编程（Shell）、基本命令；   3、 良好的团队合作能力及较强的沟通能力，对解决挑战型问题充满激情；   4、 具有深厚的分布式系统或数据库系统的理论基础，具有分布式文件系统、分布式数据库系统、集群存储系统等架构设计经验
   


（1）、对Hadoop、Hbase、Map Reduce有深入理解及实际开发经验；   （2）、对Storm等有深入理解及实际开发经验；   （3）、对Spark有深入理解及实际开发经验；
    

职位描述:

1. 基于数极客平台数据和客户数据，深度分析数据中的规律，挖掘数据价值；
2. 参与数据/工具平台相关的功能接口、数据接口，实现业务功能；
3. 参与数据平台/工具平台的架构、设计以及实现；
4. 与数据计算/存储团队合作，优化数据平台的性能，解决兼容性、功能性Bug，提高稳定性。

职位要求:

1. 计算机(统计、应用数学)相关专业本科及以上学历；
2. 熟悉Java、Scala、Python等开发语言中的一种，多种为佳；
3. 熟悉Map-Reduce模型，对Hadoop、Spark、Storm等大规模数据存储与运算平台有实践经验优先；
4. 熟悉ElasticSearch、Kibana和Logstash方面的产品、工具；
5. 熟悉MySQL与SQL语言,熟悉No SQL数据库，有redis数据编程经验者优先；
6. 能独立了解数据需求，并可以转化成分析产品设计，并能独立进行代码实现。


工作内容/职位描述：
1、分析与设计业务风险控制规则，建立风险识别、监控与预警机制； 2、建立风险监测指标体系，对业务线进行日常监测与运营分析，提供运营分析报告； 3、对可疑交易/账户进行预警分析与问题定位，提供有价值的结果，提高运营有效性； 4、建设业务相关的数据库表，并能固化到指定的数据库中，提高查询效率； 5、建立针对欺诈行为的风险管理策略，构建欺诈行为识别与侦测机制； 6、将研究成果转化成风控规则并跟进落实，协调产品、研发、运营团队，推动风控规则与风险模型的实施。最终部署在控制决策系统中。
任职资格：
1、硕士以上学历，数学、统计、计量经济学、金融等相关专业； 2、5年以上支付机构、金融机构、风险管理相关经验者优先； 3、能够熟练使用Hive、SQL、R、SAS、SPSS及其他数据查询统计软件者优先；曾经参与过完整的数据采集、整理、分析工作； 4、具有一定的交易风险规则设计、风险模型开发经验； 5、具备较强的数据分析能力、逻辑思维能力、对内外组织沟通能力、执行能力和团队精神；诚信、愿意分享和承担责任，勇于探索与坚持创新。

岗位职责：
1、负责大数据平台架构设计及模块详细设计；
2、负责为大数据开发团队提供技术保障，指导开发人员开发和解决系统开发、运行中出现的各种问题；
3、参与大数据平台代码的编写、单元测试、修改和维护等工作；
4、撰写大数据平台相关技术文档。
职位要求：
1、具有通信、计算机、软件、数学等相关专业本科或以上学历；
2、具有海量数据管理经验，对数据结构及算法有相关经验；
3、熟悉java语言、熟悉JVM原理以及内存的管理；
4、熟悉Hadoop、Oozie、Sqoop或Spark等组件及其基本原理，有丰富的集群部署、开发和维护管理经验；
5、有带团队工作经验者优先。

岗位职责
1、负责设计符合业务需求的数据库、数据模型、ETL过程、数据仓库；
2、负责大数据相关技术研究，解决海量数据不断增长面临的挑战；
3、负责海量数据的处理、分析、挖掘和存储；
4、大数据挖掘计算平台集群管理、部署、优化、排错。

任职要求：
1、熟练掌握主流关系型数据库（oracle、MySql、SqlServer），能编写存储过程，SQL技能熟练；
2、良好的数据结构和算法基础，具有较强的开发，系统实现能力；精通Java/Python/R至少一种语言；
3、有hadoop/Spark Mlib/Mahout使用经验，精通HBase、MapReduce、Hive、Pig、Storm等大数据开发技术者优先考虑；
4、有数据挖掘或机器学习项目经验者优先。
5、动手能力强，具有良好的沟通能力、团队精神和服务意识，良好的逻辑思维能力，对数据敏感。

岗位职责：
1.负责大规模数据业务支撑平台的架构设计和开发工作；
2.持续改进并优化平台性能，支撑业务的快速发展；
3.调研新技术与相关平台，持续改进平台的现有功能。
任职要求：
1.本科以上学历，3年以上大数据领域工作经验，熟悉分布式系统开发；
2.扎实的数据结构及算法基础，理解面向对象设计的基本原则，熟悉常用的设计模式；
3.熟练使用linux, 精通Java开发语言， 熟悉shell、python等至少一种脚本编程；
4.熟悉Hadoop/HDFS以及Hadoop生态相关产品（Hive,Kafka,Storm,Spark)；
5.良好的沟通、组织协调能力和强烈的责任心，具备很强的分析和解决问题的能力；
6.有CDN业务经验者优先，有大数据开发经验者优先。

招聘:大数据研发工程师
1、5年以上开发经验，且2年以上Hadoop生态系统技术领域（MapReduce/HDFS/HBase/Mahout/Storm等）开发经验
2、熟悉Shell/Perl/Python等脚本语言
3、本科以上学历，英语可以熟练读写
福利待遇：10-20K，年终奖1-2个月，五险一金+商业医疗保险+带薪年假+年体检+公司活动+补贴
另需 3-4年开发经验，1年左右大数据开发经验，或者Java技术扎实的人才，公司会进行相应培训，并进入大数据项目，

【岗位职责】 
1.负责腾讯游戏运维数据云平台的建设；
2.负责海量数据的实时计算、离线计算、存储、查询；
3.参与数据平台自助化建设。

【岗位要求】
1.计算机相关专业，3年及以上相关工作经验,有扎实的计算机理论基础；
2.熟练Java、Python服务端编程，有良好的编码习惯； 
3.深入理解MapReduce，熟练使用Storm、Hadoop、Spark，并阅读部分源码；
4.熟练使用HDFS、Hbase、Kafka、ElasticSearch、Opentsdb；
5.深入理解Lucene，有优化经验者优先；
6.具备良好的学习能力、分析解决问题能力；
7.具有高度的责任心和团队合作精神。

【招聘人数】
3人

职责：
1. 负责数据处理程序的开发
2. 负责数据相关平台的搭建、开发、维护、优化
要求：
1. 本科以上学历，计算机相关专业，1年以上相关工作经验或优秀应届毕业生
2. 计算机基础能力扎实，如操作系统、算法、计算机网络等
3. 掌握Java
4. 熟悉大数据相关技术，如Hadoop、Spark、HBase等
5. 责任心和进取心、学习能力、团队意识和沟通能力，对技术有追求
加分项：
1. 有海量大数据开发经验
2. 有Hadoop、Spark、HBase深入源代码分析经验
3. 熟悉机器学习、数据挖掘、分布式计算
4. 基础能力+学习能力特别优秀者

岗位职责：
1、负责公司互联网数据ETL数据清洗工作；
2、负责公司各互联网产品的报表开发及版本迭代；
3、负责平台的整体数据架构设计，对数据有较高敏感性，完成从业务模型到数据模型的设计及开发工作；
4、负责Hadoop平台数据仓库、数据集成、数据管理的整体架构设计工作。
任职要求：
1、本科及以上学历，3年以上大数据开发经验；
2、熟悉hadoop相关各种开源项目，Hive/Hbase等有实际应用开发经验；
3、熟练使用HSql，有一定的SQL编写和优化调优经验；
4、熟练使用Linux系统，有Shell、Python等脚本编程经验；
5、有java编程经验者优先，有数据仓库、BI系统项目开发经验者优先。

岗位职责：  1、负责基于互联网金融的相关数据产品需求分析、原型设计和快速迭代;  2、负责多维报表，二维报表及可视化设计, 推动业务方达成对需求的一致理解，保证数据的逻辑一致性;  3、对产品上线后效果负责，负责与业务方持续沟通，通过挖掘数据产品需求，推动产品持续改进。   任职要求：  1、本科以上学历，数学、计算机专业优先;  2、2年以上互联网数据分析/产品设计相关经验，侧重数据系统、数据产品;  3、熟悉国内外主流BI工具,熟练使用如Tableau、BIEE等工具;  4、有较强的面向业务的数据架构能力，有较强的数据驱动力和敏感性，逻辑思维清晰缜密;  5、有较强的责任心和事业心，思路清晰，抗压性强，良好的沟通能力，具有团队合作精神;  6、有数据系统开发相关经验是一个加分项；

岗位职责：
1.建立和维护大数据相关的各种基础，包括ETL流程、数据整合清洗、数据应用的设计和开发等。
2.建设和维护大数据先关基础设施，集群搭建和管理，hadoop、spark 生态圈各种技术的相关应用开发。
3.参与应用选型研究、系统架构设计、软件开发工作。
 
任职要求：
1.3年以上工作经验，熟悉JAVA语言，编程基础扎实，对面向对象编程思想有深刻理解，熟悉数据结构和常用的编程算法。
2.熟悉Java/J2EE， 基础扎实，熟练掌握常用Java技术框架，能编写高质量简洁清晰的代码；
3.对于Java基础技术体系（包括JVM、类装载机制、多线程并发、IO、网络）有一定的掌握和应用经验；
4.熟练使用spring mvc、mybatis、redis等框架进行项目开发；
5.熟悉常用数据库，熟练掌握SQL语法，对MySQL有一定学习了解。熟悉linux操作系统，熟练使用shell/awk等脚本语言。
6.熟悉Hadoop以及Hadoop生态圈上的各种应用的几种，如Hbase、Hive、spark 等开源工具 者优先。
7.熟悉flume ,kafka，storm, elk 等开源工具者优先。有离线数据和流式数据处理分析工作经验者优先。
8.熟悉软件开发流程，拥有软件开发流程中的代码规范意识、配置管理规范意识、文档撰写规范意识和团队合作沟通交流意识。

职位描述负责金融行业客户的开发、维护和项目操作，具备良好的沟通能力、执行能力和学习能力，并最终达成公司在金融行业的销售目标。
岗位职责1、负责华北区域金融行业客户的销售策略制定与实施，针对银行、证券、保险、基金等金融类客户的销售及产品推广；2、挖掘并逐步引导行业需求，树立公司产品在该行业的品牌和产品优势地位；3、开拓新市场，发展新客户，增加产品销售范围；4、负责辖区市场信息的收集及竞争对手的分析；5、负责目标客户的关系拓展和维护，分析客户需求，寻找项目机会。任职要求1、本科以上学历能力优秀者放宽学历要求），计算机或相关专业优先；2、5年以上销售经验，3年以上IT领域金融/运营商行业销售经验。在金融/运营商行业系统集成商、金融/运营商业务系统开发商有过从业经验优先，有明确且较好的销售业绩；3、形象良好，语言表达和思维逻辑清晰、性格乐观、能承受压力；4、熟悉ITOM、信息安全等领域市场及技术者优先考虑；5、在金融行业的区域管理机构或总部有客户资源和良好的人脉关系。具有明确的银行、证券和保险等金融客户资源，有股份制银行、农信等行业销售经理优先考虑；6、熟悉市场状况与市场需求，具备项目运作及市场策划能力，对本行业内的组织结构、发展趋势、应用系统、业务特点、安全需求、项目及招投标流程有深刻理解；7、具有良好的沟通能力和团队协作精神。

【岗位职责】
1、负责制定旗下体育网站的运营思路和发展计划；
2、每月制定符合公司战略的营销计划和运营指标，并推进团队执行完成；
3、对各种线上推广资源进行开发、收集、整理，实施资源整合、置换及合作，提升网站访问量和用户数；
4、对项目产品定期进行规划，提出开发需求和优化建议；
5、建设运营团队，有效提升团队成员效率及执行力，配合完成工作目标。
【任职资格】
1、男女不限，大专以上学历，年龄25~40岁；
2、有相关网站运营的经验和案例，体育类网站经验尤佳；
3、具备挑战困难和克服难点的性格，具备方案类文档的编写能力；
4、有管理团队的经验优先，能利用好手头资源推广并发展项目；
5、关注互联网动态，关注体育产业变化和发展，具有创新和试错精神。

项目产品：捷报比分网

岗位名称：算法工程师岗位职责：1.负责搜索相关算法的开发与改进2.负责算法架构中基础组件的开发构建岗位要求：1.本科以上学历，计算机、数学相关专业，2年以上开发工作经验2.具有排序、NLP、语音识别中任意一种方向实践经验3.对常用算法如：逻辑回归、GBDT、SVM、LDA、CRF、HMM等任意一种的模型原理以及工程实践上有较多经验4.熟悉hadoop、spark任意一种框架，能够熟练编写mapreduce程序5.热爱学习新技术、新算法，能够熟练阅读英文文献，能够将新算法实现应用到现有的业务中6.对有挑战性的问题充满激情，具有良好的团队合作精神和较强的沟通能力以及抗压能力

工作职责
1. 主导杉数大数据平台的设计与开发，解决海量数据面临的挑战；
2. 管理、优化并维护Hadoop、Spark等集群，保证集群规模持续、稳定；
3. 负责HDFS/hive/HBase的功能、性能和扩展，解决并实现业务需求；
4. 协助建立数据模型，对数据进行挖掘、优化及统计。
职位要求
1、本科生及以上学历，3年及以上相关经验；
2、熟悉Hadoop/HBase/Spark/Storm/Hive，熟悉数据挖掘策略与算法；
3、熟悉分布式系统设计范型，有大规模系统设计和工程实现的经验 ；
4、数据控，善于发现问题、解决问题；
5、对新兴技术有好奇心，有利用技术解决实际问题的热情，开源社区积极参与者优先。

【岗位职责】
1. 负责大数据存储平台、大数据计算平台的搭建与优化；
2. 负责实时数据和离线数据的加工分析、统计报表、可视化；
3. 负责上述平台的权限控制、日志监控等方面的安全策略的规划与建设。
 
【职位要求】
1. 熟悉主流分布式系统/大数据平台的架构原理以及相关实现细节；
2. 有Hadoop/Hive/Storm/Spark等系统的开发经验；
3. 精通Java语言，3年以上Java开发经验；
4. 有机器学习、数据挖掘、数据可视化经验者优先；
5. 本科以上学历，3年以上工作经验；

岗位名称：大数据主任级开发工程师
岗位职责：
1. ETL逻辑调查与分析
1.1 与需求人员一起，确定业务需求所对应的数据逻辑；
1.2 负责制定ETL技术方案以及大数据收集。
2. 负责大数据系统开发
2.1 负责大数据系统的环境搭建；
2.2 参与大数据系统的架构设计；
2.3 负责主流大数据技术的开发。
3. 负责大数据平台的监测和维护优化
岗位要求：
1. 本科及以上，要求计算机及相关专业；
2. 具备3年及以上大数据项目经验；
3. 技术和技能方面：
（1）熟悉Java、Scala、Python、Shell编程；
（2）熟悉主流大数据框架技术，如hadoop、spark、storm、Zookeeper、Flume、kafka、redis、hive等；
（3） 对Hadoop、Spark的技术原理及优化有较深的钻研；
（4）熟悉Linux系统、SQL。

岗位名称：大数据主任级开发工程师
岗位职责：
1. ETL逻辑调查与分析
1.1 与需求人员一起，确定业务需求所对应的数据逻辑；
1.2 负责制定ETL技术方案以及大数据收集。
2. 负责大数据系统开发
2.1 负责大数据系统的环境搭建；
2.2 参与大数据系统的架构设计；
2.3 负责主流大数据技术的开发。
3. 负责大数据平台的监测和维护优化
岗位要求：
1. 本科及以上，要求计算机及相关专业；
2. 具备3年及以上大数据项目经验；
3. 技术和技能方面：
（1）熟悉Java、Scala、Python、Shell编程；
（2）熟悉主流大数据框架技术，如hadoop、spark、storm、Zookeeper、Flume、kafka、redis、hive等；
（3） 对Hadoop、Spark的技术原理及优化有较深的钻研；
（4）熟悉Linux系统、SQL。

工作职责：
1、负责大数据领域数据整合产品的研发；
2、负责大数据ETL类创新数据接入产品的功能调研和需求分析 。
岗位要求：
1、计算机相关专业，本科及以上学历，至少有一年工作或者实习经验；
2、熟悉主流的大数据数据接入技术（kafka、storm、flume、spark-streaming等）和数据分析技术（机器学习)并具有相关项目经验；
3、熟悉算法设计/数据结构，熟悉JAVA语言编程，熟悉Scala；
4、思路敏捷清晰，再学习能力强，团队意识高。
优先考虑：
1、熟悉informatic、DataStage、Trinity等传统ETL工具使用研发经验者优先；
2、熟悉公共安全领域数据结构者优先。

岗位职责：
1、负责大数据IT规划方案编写、讲解及用户沟通等工作；
2、负责数据分析业务产品的大数据技术架构规划；
3、与销售团队合作实现分析产品与咨询项目的客户达成；
4、参与大项目总体规划、需求跟踪以及后期效果总结、实现客户持续成功；
5、知识分享与传递、共建有竞争力的管理咨询体系。
 
任职要求：
1、良好的沟通能力，较强的学习能力和敬业精神，思路清晰，稳重细心；
2、具有良好客户服务意识，配合销售人员与客户技术交流，做好售前工作；
3、具有对客户项目技术方案讲解和引导能力；
4、良好的沟通能力，有条理、针对性；
5、具有独立撰写解决方案的能力；
6、具有5年以上Hadoop生态圈实际项目经验，深入了解大数据应用特点与技术实现，对大数据应用在精准营销、工业4.0领域有实际经验；
7、能适应适当的出差，有良好的应变及承压能力；
8、30-38岁，MBA优先。

岗位职责：
1、基于MySQL/Flume/Kafka/Hadoop/Hive/HBase等技术开发大数据分析平台的后台服务，支持部门的数据接入、落地，统计、分析、报告业务；
2、开发实时数据处理、统计功能，支撑上层业务，如：数据监控、统计分析、日报展现、业务方调用等。
任职要求：
1、熟练掌握 Java 编程语言、有丰富的后台服务开发经验，对系统架构设计与性能调优有经验；
2、熟练掌握 Hive、、MapReduce、Spark、Storm等大数据技术，并有相关的使用、开发经验，熟悉源码者优先；
3、熟悉MySQL及NoSQL的原理，有相关使用、调优经验者优先。

岗位职责：
1、基于MySQL/Flume/Kafka/Hadoop/Hive/HBase等技术开发大数据分析平台的后台服务，支持部门的数据接入、落地，统计、分析、报告业务；
2、开发实时数据处理、统计功能，支撑上层业务，如：数据监控、统计分析、日报展现、业务方调用等。
任职要求：
1、熟练掌握 Java 编程语言、有丰富的后台服务开发经验，对系统架构设计与性能调优有经验；
2、熟练掌握 Hive、、MapReduce、Spark、Storm等大数据技术，并有相关的使用、开发经验，熟悉源码者优先；
3、熟悉MySQL及NoSQL的原理，有相关使用、调优经验者优先。

岗位职责：
1、基于MySQL/Flume/Kafka/Hadoop/Hive/HBase等技术开发大数据分析平台的后台服务，支持部门的数据接入、落地，统计、分析、报告业务；
2、开发实时数据处理、统计功能，支撑上层业务，如：数据监控、统计分析、日报展现、业务方调用等。
任职要求：
1、熟练掌握 Java 编程语言、有丰富的后台服务开发经验，对系统架构设计与性能调优有经验；
2、熟练掌握 Hive、、MapReduce、Spark、Storm等大数据技术，并有相关的使用、开发经验，熟悉源码者优先；
3、熟悉MySQL及NoSQL的原理，有相关使用、调优经验者优先。

岗位职责：
1、基于MySQL/Flume/Kafka/Hadoop/Hive/HBase等技术开发大数据分析平台的后台服务，支持部门的数据接入、落地，统计、分析、报告业务；
2、开发实时数据处理、统计功能，支撑上层业务，如：数据监控、统计分析、日报展现、业务方调用等。
任职要求：
1、熟练掌握 Java 编程语言、有丰富的后台服务开发经验，对系统架构设计与性能调优有经验；
2、熟练掌握 Hive、、MapReduce、Spark、Storm等大数据技术，并有相关的使用、开发经验，熟悉源码者优先；
3、熟悉MySQL及NoSQL的原理，有相关使用、调优经验者优先。

岗位要求:
1. 对数据结构及算法有一定的了解，动手能力强
2. 掌握实时计算技术体系包括数据采集、消息队列 Kafka、计算引擎 Storm/Flink
3. 对实时计算所涉及的事务、容错、可靠性有深入理解
4. 精通 java，了解 JVM ，熟悉 linux 平台，掌握 shell 的日常使用，掌握 clojure 的加分。
5. 熟悉 Hadoop 生态圈：掌握 MapReduce、Hive
6. 熟悉 ElasticSearch 及其生态圈
7. 对大数据技术充满热情，有流式计算开源项目 Kafka、Storm 有源码级研究的更优。
8. 具有大型实时计算系统构建者，大数据引用经验者优先。

岗位职责：
1、大数据采集、存储、可视化框架研发；
2、负责大数据分析、挖掘、数据仓库项目开发；
3、负责海量数据的自动化分析处理和统计工作。
 
岗位要求：
1、本科以上学历，3年以上工作经验；
2、精通一种或多种主流编程及数据库语言，精通大型数据库设计，包括Oracle、MySQL、MongoDB、Berkeley DB 和Redis数据库系统；
3、2年以上数据挖掘、分析相关工作经验，熟悉hadoop研发、熟悉hadoop集群的搭建、管理及优化，熟悉linux操作系统；
4、熟悉HDFS/HBase/Hive/MapReduce/spark，有丰富的分布式编程经验；
5、精通数据仓库建模、开发等技术，有海量数据的分析能力和处理经验、对数据分析和数据挖掘有浓厚兴趣；
6、具有征信或电商推荐相关业务架构经验者优先考虑；
7、具有较强的分析能力和创新能力，团队合作能力优秀。
 

熟悉spark，至少熟悉spark streaming 有较强java实施能力能够封装spark接口为java接口，供后续调用（该类型人员如果满足要求，可一拖一）  2.熟悉 Oozie，有Oozie实施批量调度经验，针对Oozie调启服务有一定经验 

岗位职责：
1、对公司产品的各项运营、产品数据进行汇总分析，建立一套完整的采集-存储-分析体系；
2、协同运营人员对各种日常业务数据进行统计，为数据管理平台提供数据支持； 
3、利用大数据分析工具，进行用户行为分析，对产品功能改进提供数据支持。

任职要求 
1、本科以上学历，熟悉Mysql，Mongodb数据库，熟练使用SQL语言，具有集群数据库的开发经验； 
2、能使用Linux系统，有海量数据处理相关经验，有大数据集、分布式计算工具（Map/Reduce，Hadoop，Hive等）工作经历；
3、熟练使用SPSS、R、SAS、Python等任一统计分析工具；
4、从事大数据工作3年以上，移动医疗相关工作经历者优先。

岗位说明：
1、维护已有大数据平台相关功能的开发维护；
2、负责数据挖掘模型的构建、评估及优化工作，包括但不限于用户画像、道具产出消耗优化模型，为决策提供数据支持；
3、负责用户付费、流失、转化模型的构建，探索提升付费转化率的思路和方案；
4、负责个性化推荐系统及广告精投系统的构建及优化，跟踪推荐及广告效果，不断优化算法，提升推荐及广告转化率；
5、负责反作弊系统的构建及优化，销量、用户量预测系统的构建及优化；
6、应用统计建模、数据挖掘、机器学习方法建立数据模型解决其他实际问题。

任职条件：
1、数学、统计或计算机相关专业，本科及以上学历者优先；
2、具有2年以上大数据系统开发工作经验，熟悉大数据挖掘工具（MapReduce、Hive、Spark），熟练使用R、Python、SASS、SPSS等数据挖掘模块者尤佳；
3、熟悉常见机器学习算法（如k-Nearest、逻辑回归、SVM、神经网络、决策树、贝叶斯等）；
4、拥有处理大数据集，分布式计算工具（Map/Reduce, Hadoop, Hive/Pig等）的行业经验；
5、善于从不同的数据源操作和分析复杂、高容量和高维度的数据；
6、有良好的自学能力，独立思考能力，能够在短时间内学习并应用新技术；
7、有强烈的责任心，良好的沟通能力和良好的团队合作精神。

工作内容：
1、负责手机端数据采集应用的编写和优化；
2、负责对采集数据的模型分析和挖掘；
3、负责服务器端的逻辑编写和优化。
职位要求：
1、本科及以上学历，计算机相关专业，3年以上相关工作经验；
2、熟练掌握安卓应用的编写，熟悉安卓框架的基本服务及功能；
3、了解常用的perl, python脚本；
4、有数据挖掘、服务器开发背景者优先；
5、工作认真负责，逻辑清晰，抗压能力和学习能力较强。 

岗位职责：1、参与目前产品索引(SOLR+HBASE)的维护和优化工作；
2、根据系统业务需要，开发对应功能；
3、同时引入其他大数据处理技术，不断完善索引功能，提高扩展性和使用价值。
岗位要求：
1、本科及以上学历，计算机相关专业；
2、3年及以上Java开发经验，Java基础扎实；主导过运用Hadoop及相关产品对海量数据处理的项目；
3、熟悉HDFS、MR原理，精通MapReduce java开发或者Hadoop Streaming开发；
4、熟悉Linux环境，熟悉Linux shell/python/perl任一脚本；
5、熟悉Hive、Pig、HBase、redis、sqoop、flume等开源项目，了解HBase原理；
6、良好的沟通能力和团队组织管理能力，能独立解决问题。

职位描述：
1. 负责企业级高并发系统开发
2. 负责数据可视化系统开发
3. 负责爬虫系统的设计和搭建
4. 在大数据平台上实现算法工程化（平台主要是MR和Spark）
5. 负责大数据平台新技术的调研和落地
任职要求：
1. 本科及以上学历，计算机相关专业，211或985更佳，两年以上java开发经验，有Scala经验更佳
2. 要求有较强的学习能力
2. 有Spring、MyBatis，iBatis，netty等主流框架的开发经验的优先
3. 有爬虫经验的优先
4. 有Hadoop经验或者能熟练使用Hive的优先
5. 有Scala经验的优先

【岗位职责】 1、负责数据产品线团队的搭建、管理和绩效考核； 2、负责设计、建立、数据挖掘、分析的产品架构和运营模式； 3、指导产品的研发管理和迭代计划，协调开发进度，推动数据平台的建设； 4、组织实现公司内部和外部对大数据服务的需求，和相关产品推广、咨询、支持、培训等工作； 5、跟踪大数据应用动向，创新产品应用； 6、提出产品提升建议与发展方向。

【任职要求】
1、计算机、数学相关专业，本科或硕士以上学历（硕士、博士）； 2、8年以上分布式系统、大数据相关工作经验，5年以上团队管理经验； 3、熟悉Hadoop、Hive、HBase、storm等开源项目和社区，至少3年以上产品项目应用研发经验；
4、熟悉Hadoop/Spark等系统，有hands-on的产品设计、性能调优、开发经验，有MongoDB、Hadoop/Hbase/Cassandra/Storm/Spark/Hive 等多系统的开发经验者优先；
5、熟悉搜索引擎架构(分词器、爬虫系统)，熟悉hadoop/hbase/hive/zookeeper等分布式计算和存储系统，熟悉常见的key-value存储系统(redis,,hbase ,mongodb)； 6、有以下其中之一者，更加优先： (1)精通或者熟悉数据库设计，熟悉Oracle/MySQL/MySQL 集群等数据库，并具有较好的 SQL 编写及优化能力；熟悉NoSQL 者优先； (2)具有较强的数据挖掘、优化理论、机器学习的理论基础和实际项目经验，精通数据分析与各种算法与模型，例如分类、聚类、Boosting、SVM、神经网络中的至少一种；  (3)极强的系统设计和系统架构能力或者项目经验；必要的产品管理意识； (4)对分布式系统和云计算尤其是互联网云计算要有深刻的理解，最好有相关技术经验。

岗位职责：
1. 参与公司数据仓库设计与研发, 针对各业务场景提供大数据解决方案；2. 参与数据仓库ETL流程的优化及解决ETL相关技术问题;3. 参与公司数据产品与应用的数据研发;4. 根据数据模型完成业务的统计分析场景，助力数据化运营业务。任职要求：
1. 熟练掌握 Java, Scala, Python 中一种或多种开发语言；
2. 熟悉Hadoop生态相关技术并有相关实践经验着优先，熟悉Hdfs、Mapreduce、Hive、Hbase、Spark、等一种或者多种离线数据处理技术；
3. 有使用 kafka，storm，spark streaming 实时数据处理系统建设经验；
4. 熟悉Solr/ElasticSearch, 有实际搜索引擎开发经验者优先；
5. 有数据处理，ETL流程优化实战经验；
6. 对 数据建模 和 数据分析 有一定了解；
7. 对大数据处理和数据分析有浓厚的兴趣，对开源技术充满热爱；
8. 具有强烈的上进心和求知欲，优秀的自主学习能力，自我管理能力；

职位说明：
1、负责公司大数据处理处理和分析平台的架构和开发；
2、为项目组提供大数据分析手段支撑；
3、提供大数据平台上的数据挖掘产品规划，配合产品同事进行相关产品研发；
4、在部门内普及大数据处理知识和技能。

任职资格：
1、两年以上Java开发相关工作经验，熟悉Java核心技术；
2、熟悉常用的数据库如oralce、mysql等关系型数据库，有分布式缓存、分布式存储技术经验者优先；
3、熟悉大数据基础架构，对流式系统、并行计算、实时流计算等技术有较深的理解；
4、熟悉Hadoop、Hive、Hbase、Storm等技术和架构；
5、熟悉JavaScript/理解jQuery等框架/HTML5/Bootstrap者优先；
6、责任心强，具有良好的团队合作精神，学习能力强；
7、熟悉爬虫技术、文本挖掘算法和推荐算法者优先。

本职位同期在：杭州、合肥、南京、上海城市招聘，如您考虑在以上城市工作，请在投递简历时标注期望的工作地点。

岗位名称：大数据主任级开发工程师
岗位职责：
1. ETL逻辑调查与分析
1.1 与需求人员一起，确定业务需求所对应的数据逻辑；
1.2 负责制定ETL技术方案以及大数据收集。
2. 负责大数据系统开发
2.1 负责大数据系统的环境搭建；
2.2 参与大数据系统的架构设计；
2.3 负责主流大数据技术的开发。
3. 负责大数据平台的监测和维护优化
岗位要求：
1. 本科及以上，要求计算机及相关专业；
2. 具备3年及以上大数据项目经验；
3. 技术和技能方面：
（1）熟悉Java、Scala、Python、Shell编程；
（2）熟悉主流大数据框架技术，如hadoop、spark、storm、Zookeeper、Flume、kafka、redis、hive等；
（3） 对Hadoop、Spark的技术原理及优化有较深的钻研；
（4）熟悉Linux系统、SQL。

岗位职责：
1、负责大数据IT规划方案编写、讲解及用户沟通等工作；
2、负责数据分析业务产品的大数据技术架构规划；
3、与销售团队合作实现分析产品与咨询项目的客户达成；
4、参与大项目总体规划、需求跟踪以及后期效果总结、实现客户持续成功；
5、知识分享与传递、共建有竞争力的管理咨询体系。
 
任职要求：
1、良好的沟通能力，较强的学习能力和敬业精神，思路清晰，稳重细心；
2、具有良好客户服务意识，配合销售人员与客户技术交流，做好售前工作；
3、具有对客户项目技术方案讲解和引导能力；
4、良好的沟通能力，有条理、针对性；
5、具有独立撰写解决方案的能力；
6、具有5年以上Hadoop生态圈实际项目经验，深入了解大数据应用特点与技术实现，对大数据应用在精准营销、工业4.0领域有实际经验；
7、能适应适当的出差，有良好的应变及承压能力；
8、30-38岁，MBA优先。

公司简介
货车帮作为公路物流互联网领域内最大的综合货运交易平台，致力于搭建中国货运车辆共享运力池，重构中国公路物流产业生态，做中国公路物流的基础设施。
公司业务产品
货车帮-APP
物流QQ-APP/PC端
发展成就
1. 截至2016年初，货车帮诚信认证货主会员超50万户，诚信注册货车司机会员200万。全面整合了全国范围内的货源信息及中长途货运车辆，在全国拥有千家直营服务网点以及国内最领先的O2O智慧物流示范园区。
2. 货车帮已成为中国公路物流信息化领跑者和“互联网+”及大数据运用的领头企业。货车帮将围绕人、车、货三大要素，开展围绕新货车团购和二手车交易的抵押贷款、信用贷款、消费金融以及车后服务业务的消费金融和第三方支付等金融业务。
3.当前货车帮已完成3500万美元的A++轮融资，该轮融资由元生资本领投，腾讯、DCM等老股东跟投，货车帮的A轮融资（A轮、A+轮、A++轮）总额已超1亿美元，B轮融资目前已经正式展开，由华兴资本担任FA。
下一个万亿级市场，有你一起么？期待你的加入！！

=职位名称=
高级大数据工程师
=职位描述=
1．负责公司大数据处理平台的架构设计与构建，技术改进与性能优化；2．根据业务需求，制定系统的整体技术框架、业务框架和系统架构；3．负责设计改良数据质量, 根据实际情况解决核心数据质量问题；4．和团队成员一起完成大数据智能分析工作的流程、规范和方法建立；5．对系统框架相关技术和业务进行培训，指导开发人员开发，解决系统开发、运行中出现的各种问题；
=任职要求=1．具有大数据系统架构与设计、重大模块设计经验，对大数据的技术趋势有深入的理解；有很强的数据设计抽象能力，善于从复杂的数据问题中找到关键路径；2．对分布式原理有较深的理解，3年以上海量数据分布式计算开发经验，有丰富的高并发的调度系统、数据库优化经验；3．熟悉大型互联网产品的架构，2年以上架构设计经验，对大数据量的互联网产品有实际经验，熟悉大规模数据处理的机制和框架；4.负责实时计算平台基础架构设计、部署、监控、优化升级；5. 深入研究大数据相关技术和产品，跟进业界先进技术。

=你能得到=
1. 复杂业务场景的直接挑战。
2. 开放分享的技术氛围。
3. 对于业务、产品想法的快速实现。
4. 优厚的薪酬福利+期权计划，免费下午茶+晚餐，免费的滴滴打车福利。

岗位职责：
1、根据需求，负责前端软件模块设计开发
2、负责大数据可视化产品及组件研发
3、负责代码实现、单元测试、代码修改和维护等工作
任职要求：
1、3年以上前端软件开发经验
2、扎实的计算机编程能力和良好的编程习惯，精通javascript，html5，CSS3等前端开发技术，熟悉extjs，jquery，numberjs，easyui等至少一个js框架，要有实际项目开发经验
3、熟悉后端程序开发，熟悉nodejs者优先
4、熟悉hadoop、spark等开源大数据组件者优先
5、良好的沟通交流能力，文字语言表达能力，较好的逻辑分析能力；强烈责任心，开放的性格
6、擅于协作，具备良好的团队合作精神，善于学习

岗位职责
1、参与公司产品数据嗨客的后端开发；   2、按照项目计划如期完成开发工作；    3、按时提交代码给相关研发负责人审核；    4、根据测试人员反馈的bug，及时修复。
岗位要求
1、1年以上开发经验，能够熟练使用python语言，有过Django、tornado、flask等框架开发经验者优先；2、熟悉数据库的使用，能够熟练使用MySQL、PostgreSQL、MongoDB等开源数据库；3、熟悉linux，能进行基本的常用操作；4、了解互联网常用协议，有HTTP、TCP、UDP相关协议开发经验者优先；5、具备大型网站或高并发系统开发、设计工作经验者优先；6、有很强的学习能力，有强烈的责任心及良好的团队合作精神。

岗位职责
1. 负责数据仓库和大数据处理模块的架构设计和开发；
2. 负责基于Spark技术的海量数据的处理、分析、统计、挖掘工作；
3. 基于Spark框架的数据仓库的设计，开发，维护；
4. 根据需求使用Spark Streaming和Spark SQL进行数据处理、查询、统计等工作。
任职条件
1. 熟悉Spark相关技术，至少有1年的Spark开发经验；
2. 熟悉Scala语言，对Scala原理、底层技术有深入研究者优先；
3. 熟悉Spark Streaming和Spark SQL；
4. 有优良的Trouble Shooting能力；
5. 有过海量数据系统开发经验者优先；
6. 在开源社群活跃并有积极贡献者优先。

岗位职责：
1、负责基于海量用户数据构建用户画像，个性化推荐应用和研究，提高产品用户体验和效果；2、负责各算法和模型的分布式实现，丰富并行算法库；3、负责提供系统设计和代码文档，参与数据清洗和过滤、特征抽取、参数选择、算法实验、效果分析，参与与内外部客户的交流。

任职要求：
1、硕士或博士学历，计算机、应用数学、模式识别、人工智能、自控、统计、运筹学等专业；2、两年以上相关项目经验；3、对机器学习、概率统计、最优化等算法原理及其在互联网行业的应用，有深入的理解和浓厚的兴趣；4、有用户画像、推荐系统、精准营销、精准广告、信息检索等方面的实际工作经验；5、有大规模分布式计算平台的使用和并行算法的开发经验；6、熟练掌握至少两种编程语言，Shell、Java、Scala、C、R、Python；7、熟悉Linux工作环

工作内容：
1、负责手机端数据采集应用的编写和优化；
2、负责对采集数据的模型分析和挖掘；
3、负责服务器端的逻辑编写和优化。
职位要求：
1、本科及以上学历，计算机相关专业，3年以上相关工作经验；
2、熟练掌握安卓应用的编写，熟悉安卓框架的基本服务及功能；
3、了解常用的perl, python脚本；
4、有数据挖掘、服务器开发背景者优先；
5、工作认真负责，逻辑清晰，抗压能力和学习能力较强。 

岗位职责：
1. 参与公司数据仓库设计与研发, 针对各业务场景提供大数据解决方案；2. 参与数据仓库ETL流程的优化及解决ETL相关技术问题;3. 参与公司数据产品与应用的数据研发;4. 根据数据模型完成业务的统计分析场景，助力数据化运营业务。任职要求：
1. 熟练掌握 Java, Scala, Python 中一种或多种开发语言；
2. 熟悉Hadoop生态相关技术并有相关实践经验着优先，熟悉Hdfs、Mapreduce、Hive、Hbase、Spark、等一种或者多种离线数据处理技术；
3. 有使用 kafka，storm，spark streaming 实时数据处理系统建设经验；
4. 熟悉Solr/ElasticSearch, 有实际搜索引擎开发经验者优先；
5. 有数据处理，ETL流程优化实战经验；
6. 对 数据建模 和 数据分析 有一定了解；
7. 对大数据处理和数据分析有浓厚的兴趣，对开源技术充满热爱；
8. 具有强烈的上进心和求知欲，优秀的自主学习能力，自我管理能力；

岗位职责：    
1，负责京东云大数据平台的开发和性能优化    
2，负责针对决策层和业务人员在应用数据过程中提出的需求并进行功能设计与实现    
3，对京东海量电商数据进行数据挖掘和分析    
任职要求 ：    
1，熟练掌握 Java，熟悉 Shell，Python 等一门以上脚本语言，并灵活运用到实际工作中及解决技术问题    
2，熟悉两种以上大数据处理工具和技术(如Hadoop，Spark，Hive，Kafka，Storm)， 有实际大数据分析处理项目经验    
3，熟悉分布式系统的设计和应用    
4，从事过机器学习、数据挖掘、统计分析、推荐等算法相关的项目经验者优先    
5，3年以上工作经验，互联网行业从业者优先    

职位描述：
1. 负责深度机器学习平台的架构设计与研发
2. 根据业务需求设计高扩展性、高性能的系统架构和应用架构。 
技能要求：
1. 计算机或相关专业本科以上学历，具备良好的沟通能力和表达能力，平均一家公司工作时间两年以上。 
2. 熟悉常用的算法和数据结构。
3. 熟悉Linux系统，具备shell/python/java/scala/golang等一种或几种语言的开发能力。 
4. 熟悉常见的开源分布式计算/存储相关技术，包括yarn，mapreduce，spark，kafka，hive，kubernetes, mesos等。 
5. 有大数据系统项目经验，掌握如何搭建分布式处理系统，有海量数据处理和分析经验。
6. 学习能力强，喜欢研究开源新技术，有团队观念，具备独立解决问题的能力 。

有意向者请发简历到madianjun@jd.com，谢谢！

岗位职责：
1.基于海量数据的数据仓库建设、数据应用开发； 
2.分布式平台应用开发（Hadoop/Hive/Hbase）；
3.掌握爬虫技术，可以实现实时爬取和存储； 
4.从各种数据系统导出指定格式的文件 ，支撑各业务线数据需求；
5.配合指导数据分析团队完成大数据文本分析系统建设。

任职要求：
1.具有丰富的数据仓库开发经验，有2年以上互联网或移动互联网并基于Hadoop/Storm/HIVE/Hbase等应用开发经验，对分布式计算、数据仓库理论有深刻理解 ；
2.熟练掌握linux常规命令与工具 ；
3.精通JAVA、MapReduce、Python，有并发应用或者分布式应用软件开发经验优先 ；
4.熟悉主流的大数据产品（Hadoop、Spark、storm、elasticsearch、Flume、kafka等）并具有其中部分组件的应用或者开发经验； 
5.良好的系统分析、架构设计能力； 
6.对数据敏感、对新技术敏感，有数据挖掘技能者优先 ；
7.对商业和业务逻辑敏感，具备良好的分析、组织、沟通能力和团队精神。

岗位职责：1、负责大数据系统的开发工作；2、指导协助同事解决日常工作中的问题3、对系统存在的问题进行跟踪和定位并及时解决；4、严格执行工作计划，主动汇报并高效完成任务保证部门及个人工作目标实现。
任职要求：1、计算机、软件工程等相关专业，本科及以上学历，具有3年及以上Java开发经验；1年及以上互联网或大数据分析工作经验优先；2、 熟悉Hadoop或Spark生态相关技术，包括MapReduce、hdfs、Hive、Spark等，1个以上大数据平台项目实施经验； 熟悉Oracle或MySQL数据库技术；3、具有BI系统的开发实施经验，能够独立开发设计数据仓库、ETL设计、Cube建模、OLAP开发、报表开发等；一定的应用系统分析与设计能力，有良好、规范的编程习惯和文档编写习惯；4、有较强的学习能力，对技术有钻研精神，并有较高的热情，热衷于新技术、新理论、新开发实践的学习和实践。

【岗位职责】 1、负责数据产品线团队的搭建、管理和绩效考核； 2、负责设计、建立、数据挖掘、分析的产品架构和运营模式； 3、指导产品的研发管理和迭代计划，协调开发进度，推动数据平台的建设； 4、组织实现公司内部和外部对大数据服务的需求，和相关产品推广、咨询、支持、培训等工作； 5、跟踪大数据应用动向，创新产品应用； 6、提出产品提升建议与发展方向。

【任职要求】
1、计算机、数学相关专业，本科或硕士以上学历（硕士、博士）； 2、8年以上分布式系统、大数据相关工作经验，5年以上团队管理经验； 3、熟悉Hadoop、Hive、HBase、storm等开源项目和社区，至少3年以上产品项目应用研发经验；
4、熟悉Hadoop/Spark等系统，有hands-on的产品设计、性能调优、开发经验，有MongoDB、Hadoop/Hbase/Cassandra/Storm/Spark/Hive 等多系统的开发经验者优先；
5、熟悉搜索引擎架构(分词器、爬虫系统)，熟悉hadoop/hbase/hive/zookeeper等分布式计算和存储系统，熟悉常见的key-value存储系统(redis,,hbase ,mongodb)； 6、有以下其中之一者，更加优先： (1)精通或者熟悉数据库设计，熟悉Oracle/MySQL/MySQL 集群等数据库，并具有较好的 SQL 编写及优化能力；熟悉NoSQL 者优先； (2)具有较强的数据挖掘、优化理论、机器学习的理论基础和实际项目经验，精通数据分析与各种算法与模型，例如分类、聚类、Boosting、SVM、神经网络中的至少一种；  (3)极强的系统设计和系统架构能力或者项目经验；必要的产品管理意识； (4)对分布式系统和云计算尤其是互联网云计算要有深刻的理解，最好有相关技术经验。

岗位职责：
1.参与数据平台的方案设计；
2.负责数据平台数据的存储优化、维护及建模等工作；
3.算法设计，实现及验证；
4.编写相关技术文档。
任职要求：
1.大专及以上学历，计算机或者数学等相关专业，具备3-5年工作经验；
2.熟悉Java开发，熟练掌握各类常用数据结构和相关算法； 
3.熟悉Hadoop/Spark等分布式计算技术，熟悉Hive/SparkSQL等技术，具备数据仓库的建设和开发经验；
4.有统计建模、机器学习（聚类、分类、回归等）或数据挖掘应用的项目或研究经验者优先；
5.思路清晰，具备良好的沟通能力和团队协作精神，能快速理解、消化各种需求，并落实为具体的开发工作；
有较强的沟通表达能力和学习能力，对数据敏感，工作严谨。

岗位职责：
1、 规划及建设大数据平台；
2、 负责大数据存储系统、分布式计算系统、挖掘算法等设计、研发以及维护、优化工作；
3、负责分析、挖掘、对抗各种产品安全层面的恶意行为；
4、 参与项目的系统设计和核心代码开发，指导和培训其他工程师；
5、 整理和提交技术文档，负责核心功能模块的代码编写和测试工作；


岗位要求：
1、 计算机、数学等相关专业本科及以上学历，具有深厚的数学、统计学和计算机相关知识，精通数据仓库和数据挖掘的相关技术，3年以上大数据开发相关经验；
2、具有非常扎实的Java基础，熟悉Shell、Python、R、Scala等一种以上语言；
3、算法基础扎实，熟悉常见的数据结构，了解分布式算法和分布式系统的技术原理；
4、精通MapReduce设计方法、对NoSQL，Hadoop、Hbase、Hive等主流云计算，大数据相关软件有充分的了解，并且有实践经验，能解决应用中的复杂问题；
5、熟悉大数据处理相关技术，包括但不限于Hadoop、Hive、Hbase、Impala、Spark，Kafaka、Flume、Sqoop、Storm、Redis等；
6、研读过Hadoop、Hbase、Hive源代码者，能够在特定业务中进行定制改造者优先；
7、具有海量数据处理、数据挖掘、数据分析相关项目的工作经验者优先；

【岗位职责】
 
1、负责手机助手数据仓库模型建设、数据调度、数据维护；
2、负责手机助手业务需求分析、系统设计及开发；
3、负责基于助手用户行为分析、核心指标异常分析、雷达系统建设等；
 
【岗位要求】
 
1、精通Java/Scala/Python/PHP/SQL一种以上编程语言;
2、熟练使用hadoop、hive、spark、mr等大数据平台技术框架；
3、对数据具有敏锐的洞察力，有业务数数据分析想法和经验；
4、了解数据仓库模型，有相关建模经验，了解基本的数据挖掘算法者优先；
5、具有较好的沟通表达能力，学习能力强，有较强的分析和解决问题能力，较强的工作激情；
6、具有诚信正直的人格和鲜明的价值观。

岗位职责：
•负责公司数据平台的规划和架构设计；
•负责公司数据仓库、大数据平台、BI产品的需求调研和选型；
•负责公司数据开发相关项目实施；
•负责数据平台数据挖掘、机器学习。

岗位要求：
•计算机、信息、通讯、电子相关专业毕业，211高校本科以上学历；
•熟悉大数据平台与数据可视化和常见的BI产品；
•精通至少一门编程语言；
•熟悉Hadoop、Spark开发平台优先；
•思维敏捷，有责任心、具备良好的沟通协调和学习能力。

职位描述：
1、负责公司大数据基础平台的规划、部署、管理和优化，保障平台稳定可靠高效运行
2、深入理解公司大数据平台架构，发现并解决性能瓶颈，支撑业务和数据量的快速增长
3、了解产品业务，加入产品从原型设计到正式上线的整个过程，基于对产品的理解，从运维的角度给予持续的优化意见
4、开发大数据自动化运维、监控、故障处理工具
 
任职资格：
1、5年以上互联网运维相关工作经验，2年以上大数据相关工作经验
2、独立排错能力，熟练使用linux、python，熟悉TCP/IP
3、熟悉Linux软硬件环境、系统管理和优化，熟练部署、优化各种服务
4、熟悉Hadoop相关大数据生态圈包括但不限于：YARN/HDFS/Hive/ Pig/Oozie/Spark/Druid等，熟悉但不限于codis/es/solr/storm/kafka,并拥有持续调优能力
5、深入理解Hadoop各组件的原理和实现，有阅读源码能力优先
6、主动性强，具有良好的沟通、协调和组织能力，富有团队精神，有较强的文档编写能力

岗位职责：1. 深入研究新硬件技术，调试驱动、测试评估、优化（25G万兆、GPU、NVMe、SSD、CPU、FPGA），并在大数据、人工智能领域落地产能。2 内核、系统新技术研究和落地（cgroup、docker）。3. 集群容量规划、大规模机器交付、报修、生命周期管理和优化；4. 硬件、内核、系统问题定位和解决。
必须要求：1. 至少掌握C/Python/shell任何一种语言；2. 深入理解内核IO或网络子系统、并有相关优化、排错经验；3. 对新硬件技术有了解、并有实际问题解决经验；
加分项：1. 熟悉Hadoop/Hbase/Hive/Storm/Spark/Kafka/Elasticsearch/Flume等开源项目优先；2. 熟悉GPU、有编程、调试经验者优先。3. 熟悉交换机、网络、有网工经验者优先。4. 有管理大规模分布式系统经验者优先。

岗位职责：1.基于Hadoop的数据挖掘、Hadoop组件开发/维护/测试等。 2.负责大数据平台与产品和相关技术的跟踪及研究。
任职要求：1.大学本科及以上计算机或相关专业学历；2.扎实的Java基础，有Java实际开发经验优先； 3.有Hadoop分布式平台工作经验，熟练掌握Hive、Hbase、Pig、Hdfs、Map/Reduce、Storm中两种以上开发技术； 4.熟悉Linux/Unix操作系统； 5.具备良好的学习能力，良好的沟通能力和团队合作意识。

大数据/JAVA开发工程师1、计算机、数学或统计等相关专业本科及以上学历，有2年及以上工作经验；2、熟练掌握Java；熟悉Java多线程编程；有高并发编程经验优先；3、熟悉hadoop组件技术，了解Mapreduce编程；有spark开发经验者优先；4、熟练掌握MYSQL数据库及常用SQL；5、熟悉Linux操作命令，能编写常用Shell或Python脚本；6、了解机器学习算法，搜索引擎技术，或分布式计算技术，有相关经验者优先；7、对大数据技术有钻研热情，具备高度的责任心及团结协作精神，善于沟通交流。

岗位职责：
1，从事公司广告投放平台后台服务的开发；
2，参与系统架构设计，开发可支撑海量用户的广告投放平台。

岗位要求：
1，计算机及相关专业，本科以上学历；2，3年以上JAVA经验，扎实的java基础，熟悉redis及缓存使用; 3. 熟练掌握TCP/IP协议与HTTP协议4. 熟练使用Jetty或者netty的开发及调优5. 有一定的算法与数据结构基础6，熟悉常用设计模式，熟悉多线程开发，有高并发项目经验或网络爬虫相关项目经验优先；7，有hadoop,mr,spark,kafka,各种消息中间件开发使用经验者优先；8，良好的编码功底，熟悉网络编码；9，熟悉Unix/Linux操作系统，熟悉常用网络命令及Unix/Linux管理命令；10，认真负责，积极进取，团队意识和开拓精神；11，具备良好的表达和沟通的能力，协调能力及丰富的项目开发经验；

岗位职责：
1、负责大数据分析系统的需求分析和架构设计，设计软硬件实施方案。
2、负责核心技术问题的攻关，解决项目开发过程中的技术难题；
3、负责大数据分析系统相关具体应用算法的设计、开发和产品化。
4、根据公司产品和业务发展特点，负责研究相关大数据产品和技术发展方向。
岗位要求：
1、计算机、信息系统、数学或相近专业本科以上学历，5年以上从事软件开发工作经验，2年以上大数据系统分析、设计和实施经验；
2、拥有2年以上Hadoop开发设计和实施经验，对Hadoop相关的技术和组件（HDFS，MR，Hase，Hive，Spark，Storm等）有全面深入了解，能够熟练安装、配置、部署和优化大型Hadoop集群系统。
3. 有超10TB大数据处理实战经验，熟悉整个大数据的完整处理流程，包括数据的采集、清洗、预处理、存储、分析挖掘和数据可视化。
4. 熟悉互联网常见的业务模式和用户行为分析模型，熟悉常用的数据挖掘技术和算法，如路径分析、关联规则挖掘、分类、聚类分类、协同过滤等。
5、工作责任心强，具备良好的团队合作精神，良好的沟通及协作能力。

岗位要求：
1. 五年以上工作经验，至少两年以上大数据相关工作经验；
2. 能独立使用工具，完成结构化数据库与非结构化数据库数据转化；
3. 负责基于hadoop、spark、storm等开源软件进行定制化开发，构建统一的数据平台,并有实际大数据平台搭建和调优的经验；
4. 有大数据建模、大数据存储方面设计,并有大数据分析处理实际项目经验；
5. 熟悉至少一种NIO框架，例如：Mina、Netty，有RPC框架开发经验优先；
6. 精通Java面向对象编程，熟悉Struts、Spring、Hibernate等开源框架，熟练使用Eclipse、Intellij IDEA开发工具；
7. 优先考虑在开源社群活跃并有积极贡献者；
8. 有相关车联网大数据开发数据挖掘分析工作经验优先；
9. 具有认真的技术态度，积极沟通，懂得团队协作。

岗位职责：
1. 负责业务相关数据指标的抽取、转换、加载，数据维护相关工作；
2. 负责对业务数据进行分析、建模，为业务部门的数据化运营提供支持；
3. 依据业务需求，进行数据产品的规划和设计开发，为数据分析和运营等人员搭建友好高效的数据产品。

岗位职责：
1. 参与大数据课程产品的开发，包括讲义、案例和PPT的撰写，以及大数据相关教材的编写工作
2. 配合大数据讲师完成相关教学资料的研发和审核工作3. 参与大数据分析平台的部分研发工作任职要求：1. 数学、统计、计算机或相关专业2. 熟悉机器学习基本模型，如线性回归、逻辑回归、SVM、AdaBoost、神经网络、随机森林等3. 较强的编程能力，熟练掌握Python，熟悉Python数据分析包pandas、机器学习包scikit-learn4. 具备良好的PPT制作习惯5. 具备良好的沟通能力和团队写作能力

职位描述：
1、运用知识图谱相关技术构建通用知识图谱，领域知识图谱并对不同数据源的同领域知识图谱数据进行融合。
2、基于现实遇到的各种问题，探索自然语言处理、机器学习、深度学习等技术解决方案的可能性。
岗位要求： 
1、计算机、统计学相关专业本科以上学历，1年以上相关的实习或工作经验；
2、熟悉知识图谱实体融合、实体链接的关键技术，有中文NLP经验者优先；
3、了解文本处理的基本算法与概念，如：文本相似度等；
4、熟练使用以下大数据平台中的至少一种：Hadoop, Spark；
5、熟练使用以下脚本语言中的至少一种：Python, Perl, R等；
6、良好的编程能力、算法设计能力，具备大规模语料数据处理经验者优先；
7、有较强的分析问题解决问题能力， 良好的沟通能力和团队协作精神；
8、能吃苦耐劳，有创业精神，在研发过程中能够独当一面；
9、有开源项目经验优先；


职位描述：
1、大数据底层架构设计和实施；
2、对移动设备数据和社交数据进行挖掘分析和建模；
3、逐步构建基于用户行为、喜好的标签系统，并应 用于相关的个性化系统和业务分析中；
4、负责数据管理平台的核心技术实现与优化；
5、负责大数据在广告领域的创新应用，持续推动业务线的商 业效果改进。
 
任职资格
1、本科及以上，计算机、软件工程、统计学、数据挖掘、机器学习等相关专业；
2、2年及以上大数据流程架 构经验，熟悉Hbase/Hive/Hadoop/Spark或等主流分布式开发平台，有高性能集群设计和开发经验；
3、精通Linux，熟练掌握 Python/C/Shell/Java，熟练掌握SQL数据库语言 HiveSQL/Mysql/Sqlserver；
4、有数据挖掘算法实施经验，熟练掌握大规模数据挖掘、机器学习。对有广告营销大数据算法/开发经验者优先，有大型数据项目经验优先，有用户行为分析、用户建模、业务建模经验者优先；
5、具有良好的 逻辑分析能力、沟通能力和协调能力。 积极的工作态度，勤奋上进，有责任心。
 

岗位职责：
1、负责大数据团队建设；
2、负责大数据平台系统的稳定；
3、负责大数据项目开发和维护；
4、负责软件系统的功能模块设计及相关过程文档的编写；
5、参与研究大数据技术应用解决方案等；
6、应用模块、WEB、接口开发，编写相关文档；
7、完成DB/REDIS/接口设计文档；
8、完成上级领导交办的其他各项事宜。
任职要求：
1、精通Java/J2EE编程，熟练使用Eclipse/Git/MVN等开发工具，有2年以上开发经验； 2、有良好的代码书写、注释和单元测试习惯； 3、熟练使用oracle数据库，有redis，rabbitMQ，spring，zookeeper等经验者优先； 4、熟悉Linux操作系统，掌握常用的Linux命令，熟悉脚本编程Shell/Python优先；
5、熟练掌握hadoop、hbase、hive、oozie、sqoop等； 6、负责平台数据提取、数据挖掘及数据分析，具有良好的商业敏感度和优秀的数据分析技能，能够解决复杂的商业问题； 7、主动好学，具备良好的沟通合作技巧，较强的责任心及团队合作精神，并有一定领导经验；
8、熟练掌握数据结构，操作系统，数据库原理等。

岗位职责：
1. 负责大数据平台和相关应用系统的研发工作，具备独立的工作能力，能按产品需求进行系统设计和编码实现。 
任职要求：
1. 全日制大学本科（含）以上学历，具有CET-4(425分以上)或同等英语证书；
2. 2年以上JAVA开发经验，熟悉IO、多线程、集合等基础框架，了解JVM相关知识；
3. 熟悉Spring、MyBatis、SpingMVC等开源框架；
4. 熟悉Velocity模板引擎，常用JavaScript框架的日常开发与使用；
5. 熟悉linux，能够熟练使用常用命令；
6. 熟悉MySQL数据库，掌握常用的相关设计和开发知识；
7. 有数据仓库、数据挖掘、数据可视化、自然语言处理、机器学习、爬虫、搜索、推荐、广告相关项目经验者优先；
8. 有hadoop平台、高并发、分布式相关项目经验者优先；
9. 务实、逻辑思维缜密、工作细致有耐心，具有良好的分析和解决问题的能力，勇于面对挑战性问题，具有良好的学习能力、沟通能力和团队合作精神。

岗位职责：                                               
1、基于数据收集、业务分析工作；
2、基于 Hadoop 数据仓库ETL，数据挖掘工具研发、业务分析工作。
职位要求：
1、熟悉MapReduce开发，有Java/Python/Scala一种或者多种开发经验；
2、熟悉NoSQL，Spark，ElasticSearch中的一种或者多种，有Kafka/Storm，HBase，Pig/Hive经验者优先；
3、对常用的聚类、分类、逻辑回归等算法有较深的理解；
4、对计算机体系结构、分布式系统、协程和网络编程有深入了解；
5、有敏捷开发经验，熟练使用Git和Maven；
6、有很强的英语阅读能力。

岗位职责：
1、大数据分析平台的规划和建设；
2、协助相关业务数据服务接口的制定；；
3、负责大数据处理分析平台的服务框架的设计与开发。
4、参与定制数据挖掘处理方案、提出合理数据算法用于优化广告投放效果。
 
职位要求：
1、计算机相关专业；
2、对数据敏感，熟练掌握逻辑回归、决策树等常用数据模型，了解各类搜索排序算法及算法优化技术。
3、熟练应用 python、java、scala 等任意一门语言；
4、熟练使用hadoop,hbase,spark等系统框架完成数据处理；
5、有计算广告、推荐系统或搜索引擎领域工作经验者优先；
6、有网络编程经验，精通 TCP／IP 协议，了解系统网络、负责过线上服务，或互联网公司背景。

工作职责:
1.参与数据仓库的搭建、设计与开发；
2.根据业务部门提出的需求进行数据仓库模型设计并进行大数据作业的开发；
3.负责数据质量检验和监控；
4.参与需求分析.
任职要求：
1.本科及以上学历，具备大型数据仓库架构设计、模型设计和处理性能调优等相关经验者优先；
2.精通hadoop\hive\hbase\spark\storm\MapReduce等一种或多种框架，有2年以上相关开发经验;
3.至少掌握以下以一种开发语言java/Shell/python/Scala；
4.有MySQL/ORACLE/PostgreSQL任意一种数据库OLAP系统开发与SQL调优经验；
5.有金融行业背景优先；
6.具备基本的英文技术文档阅读能力.

1.熟悉java，scala，go等编程语言的一种或几种;
2.熟悉hadoop，spark等分布式处理平台的一种或几种;
3.熟悉docker等容器技术;
4.熟悉持续集成，敏捷开发等软件开发方式;
5.熟悉maven，jenkins等工具;
6.熟悉linux操作系统;
7.熟悉常用的设计模式;

1. 熟悉Spark 、Hadoop、Hbase、Hive、Elastic Search/Solr；
2. 熟悉Map/Reduce编程；
3. 熟悉java、Scala、熟悉Linux开发环境，能进行shell脚本的编写；
4. 有实际大数据项目的成功经验；
5. 熟练掌握Storm、Spark streaming等大数据实时处理框架的一种，具备实时处理框架的设计和开发能力；
6. 具有开源社区贡献者优先。

岗位职责
1） 负责基于Hadoop/Spark平台架构的开发、设计和布局；2） 完成系统框架的设计和核心代码的编写； 3） 针对海量的用户行为数据进行统计、分析与挖掘，不断提高系统运行效率；4） 负责对数据进行分析，为项目组提供大数据技术指导及分析手段支撑；5） 负责大数据平台的性能监控和持续优化；针对需求提供大数据分析技术解决方案；6） 大数据平台的运维工作，持续完善大数据平台，保证稳定性、安全性。
岗位要求：
1）本科及以上学历，计算机或相关专业；
2）5-8年互联网行业开发经验；
3）精通Hadoop大数据平台架构；
4）有Spark、Hive、Storm等计算框架经验；5）具有扎实的Java/Python等开发语言。    



工作职责：
负责海量数据处理平台的建设优化工作；
依托tcl大数据平台，为公司其他产品运营提供策略和算法支持；
负责相关产品数据体系及用户画像的建设
负责跟踪、分析数据，为产品决策提供支持。
工作要求：
计算机相关专业，本科及以上学历；
2年以上软件开发经验；
扎实的软件开发基础知识，扎实的数据结构知识，熟悉并行运算原理；
有一定大数据处理相关的使用经验，比如hadoop、MR、spark等；
深入理解常见机器学习或数据挖掘类的算法原理，熟悉常见的统计原理及方法；
有良好的业务及数据意识，能快速理解业务构建指标体系，建设高质量的用户画像体系；
熟悉关系型数据库，熟悉hadoop/spark核心算法、熟悉Scala开发等优先；
个性开放，易沟通，良好的表达能力，责任心强，考虑问题细致，执行力强。

岗位职责：
1、承担部门省内的项目管理、省内团队管理、核心业务需求调研与分析等工作；
2、负责系统设计工作，完成设计说明书编写；
3、制定项目开发计划，配置项目人员，组织实施开发项目，进行项目管理；
4、指导项目组人员按照要求完成文档编写，软件开发及测试、实施等工作；
5、负责与用户、高层管理及第三方沟通交流，并汇报相关信息；
6、控制项目的范围、质量、进度和成本，带领团队成员使项目的各项指标达到并超越目标要求。
 
任职要求：
1、本科及本科以上学历，计算机相关专业毕业；
2、4年以上的Java开发工作经验，3年以上的独立承担Java项目管理经验；
3、精通Java面向对象编程，J2EE架构 ，熟练使用MyEclipse开发工具；
4、熟悉数据库调优及数据库开发；
5、熟练掌握Springmvc、SSH框架；
6、熟悉APP终端的应用开发；
7、熟悉Webservice、XML的应用开发；
8、熟悉Tomcat、Websphere等应用服务器的建立及部署，了解Linux基本操作；
9、熟悉UML，系统分析和设计，能按照规范的软件开发流程，完成软件的需求、设计、编码和测试工作，具有规范的开发文档写作能力；
10、具备良好的项目管理能力和团队协作能力；
11、具有良好的沟通能力，高度的责任感；
12、具有较强的学习能力及快速解决问题的能力。

1、两年以上Yarn/HBase/Hive/Redis/Kafka编程经验；
2、熟练使用Java进行大数据开发, 熟练使用Spark/R/SparkR者优先；
3、熟练使用Flume/Storm/ELK/Spotfire者优先；
4、具备良好的团队合作意识和沟通能力；
5、国家统招二本学历

工作职责：
1.  负责构建数据仓库（设计、开发、维护），大数据处理架构；
2.  负责基于Hadoop、Spark技术的海量数据自动化分析处理和统计工作。   职位要求：
1.  有海量数据分析和统计相关经验；
2.  精通Hadoop、Hive、Hbase、MapReduce等常见大数据框架，有至少两年的大数据经验；
3.  精通Scala，有自动化脚本编写经验；
4.  有较强的动手能力及学习能力，熟悉Java、Python；
5.  有数据可视化相关经验或推荐系统相关经验的优先；
6.  熟悉Linux操作系统，熟悉脚本编程(Shell/Python/Perl其中一种）；
7.  具备良好的团队合作及较强的沟通能力，对解决挑战型问题充满激情。

职位描述：
1、负责新闻后台相关系统的设计研发及持续优化；
2、参与Java基础平台架构设计与优化，通用组件设计与开发；
3、参与解决海量数据分布式处理、高效即时查询、数据准确性、运行稳定性等方面的各种技术挑战。

任职资格：
1、计算机或相关专业本科或以上学历，1年以上大数据工作经验；
2、熟悉Linux开发环境，熟练掌握Java开发语言、开源框架及相关的调试技术， 熟悉脚本编程（如shell、python等）；
3、深度理解数据模型和数据仓库，有数据挖掘的背景和学习经历，对分类、聚类、关联挖掘和推荐有深刻的认识或经验；
4、对大数据分析、机器学习、推荐算法等有一定项目经验，有自然语言学习经验优先；
5、熟悉大型分布式、高并发、高可用性系统设计开发，有hadoop或spark生态经验；
6、强烈的责任心，对技术充满热情，高效率，良好的沟通能力。

职位描述
1、负责大数据平台和产品的架构设计和研发；
2、从事架构、核心代码编写，指导和带领敏捷小组；
3，技术预研、探索并应用大数据前沿技术。
任职资格：
1、精通PHP/Python/Java开发，精通SQL和常见优化;
2、熟悉开源大数据生态（如Hadoop、Spark，Storm等），或第三方大数据平台（阿里云、AWS等），有相关项目实战研发经验；
3、 熟悉关联规则挖掘、分类和聚类算法，并有相关项目实战经验；
4、很强的工作责任心和良好的沟通协调能力，能在压力下独立解决问题；
5、对新技术有钻研精神，特别是对云计算、大数据技术充满热情

我们希望您是：
       靠谱的工程师：较好的服务意识，极强的执行力和沟通力，极强的工作责任心；   
   有创业者基因：你渴望一个能够共同成长的团队，而不是找一份养家糊口工作。
 
我们会让你做：
       数据处理后台开发
       hadoop相关开发
       分布式计算相关开发
 
您必须要自带的技能：
       java基础较好，熟悉多线程、设计模式等。
       熟悉Mysql，Linux数据库，具备开源框架使用经验。
       有网络编程经验，熟悉常用网络编程模式。
       能够吃苦耐劳，工作积极主动，具备较宽知识面，做过中型以上项目。
       熟悉hadoop/hive/zookeeper优先。
       具备丰富的分布式程序开发经验优先。
       熟悉数据storm/spark优先。
       具备数据仓库和数据分析2年以及2年以上经验优先。
 
如果您还具备这些：
      有个人技术博客，或定期参与业内交流；
      有优秀个人作品，或带领过知名应用开发；
      长期混开源社区，参与知名项目；
      是猴子派来的逗比；
      以及其它任何你觉得独特的技能或经验；

工作描述：
1、负责核心产品的分析设计与开发工作；
2、可以指导新人开发，共同完成开发工作；
3、项目过程中可以输出技术解决方案。
任职资格：
1、3年以上PHP开发经验，精通OOP思想编程理解MVC模式并能在开发中运用；
2、精通PHP及熟悉主流开发框架，至少开发过一个大中型PHP项目，能够独立编写中等规模的PHP应用；
3、熟悉LINUX环境下编程，熟悉Nginx配置和优化，熟悉shell脚本；
4、精通MYSQL并拥有查询优化和存储优化的经验，能够根据业务需求进行数据库设计，并提供优化方案；
5、熟悉NOSQL相关技术，常用nosql解决方案，了解各自的优缺点以及使用场景；
6、严谨细致，有责任心，有良好的的团队合作意识，能够承担重要任务承受较强的工作压力。


【工作职责】1.深度研究基于大数据平台(Hadoop/Spark)的数据仓库工具Hive/Spark-SQL, ETL调度工具，数据同步工具的使用、集成和自动化运维；2.研发基于大数据平台的数据仓库平台产品。
【任职要求】1.计算机相关专业本科及以上，有两年以上产品研发经验；2.极强的学习能力和动力，对未知领域能快速掌握并实践；3.熟悉大数据平台（Hadoop/Spark...），数据仓库工具（Hive/SparkSQL...），ETL工具，数据同步工具；4.熟练掌握Python/Java及常用框架；5.熟练掌握RESTful API规范，并有丰富开发经验。
【有以下条件优先】1.有企业级数据仓库研发经验者优先；2.有数据实时同步工具研发或使用经验者优先。

岗位职责
1、负责公司的各类数据处理任务,熟悉数据的抽取（extract），转换（transform），加载（load）等流程，有数据仓库的使用和架构经验。
2、负责配合算法团队，一起开发相应的大数据分析平台。
任职要求
1、计算机或相关专业本科以上学历,3年以上相关工作经验。
2、熟悉Linux平台上的开发环境，熟悉常用脚本语言。
3、精通Java/Scala。
4、至少掌握一种计算框架Hadoop/Spark/Flink等。
5、至少掌握一种分布式存储技术HBase/Cassandra等。
6、至少掌握一种大数据ETL工具Hive/Spark等。
7、善于学习新的知识，对解决具有挑战性问题充满激情。
 
有Hadoop, Spark使用经验优先。

工作职责 1、基于Hadoop/Spark分布式集群的架构设计和开发。 2、解答用户提出的需求以及碰到问题时的解答。 任职资格 1、数学、统计学、人工智能、计算机相关专业，本科或以上学历。 2、至少熟练运用Java、Scala语言中的1种。 3、需要有Hadoop / Spark平台相关运维经验2年以上，有3年以上基于hadoop/Spark的实际项目开发经验。 4、熟练掌握linux常规命令与工具，至少熟练应用shell、Python脚本语言中的1种。 5、敏锐的洞察系统性能瓶颈，并能对io、网络通讯、任务调度中一个或多个方面的性能调优。 6、对flume,kafka,yarn,hive,hbase,elk等技术有一定经验者优先。 7、有爬虫经验者优先。 8、具有较强的学习能力、逻辑分析能力、问题排查能力、沟通能力、自我驱动动力、自我管理能力。

职位描述：
岗位描述： 1. 深入理解公司业务数据， 管理公司数据资产，提升数据的易用性2. 对现有数据分析平台（Hadoop/Spark）进行功能维护、性能优化和系统升级3. 及时响应数据统计分析需求，并根据数据分析结果提出业务策略建议  4. 结合业务特点，探索并建立分析主题，对数据进行深度分析和挖掘岗位要求： 1. 本科或以上学历，计算机、统计、数学等相关专业毕业， 有互联网相关数据研发工作经历2. 熟练使用Linux，能够熟练使用各种脚本工具 
3. 熟悉Hadoop/Mapreduce、Spark等分布式计算框架，有实践经验者优先
4. 有数据挖掘、推荐系统、机器学习经验，熟悉相关算法，工具和语言者优先
5. 充分的数据敏感度，能从海量数据表现中提炼核心结果，及时分析数据中隐含的变化和问题
6. 优秀的分析问题和解决问题的能力，能够把合理的思路成功应用于实践 
7. 表达能力强，具备优秀的快速学习能力、沟通协调能力及团队精神
8. 有较强的责任心和学习积极性

1、本科或以上学历，计算机软件或相关专业，1年以上Java开发经验；
2、对hadoop、spark有一定的理解；
3、熟悉Java Web开发或python开发，悉mysql、oracle等关系数据库，及redis、memcached等no-sql数据库；
4、对于Java基础技术体系（包括JVM、类装载机制、多线程并发、IO、网络）有一定的掌握和应用经验；
5、熟悉linux/unix shell 及常用命令；
6、具有比较强的问题分析和处理能力，思维灵敏，喜欢有挑战性的工作；
7、较强的沟通能力，表达能力，能深刻的理解客户需求。

职位描述：
1、基于Hadoop各种开发工具和框架实施数据采集、分析；
2、负责Hadoop集群的日常运维
3、负责基于Hadoop集群，spark集群编写分布式算法实现；

职位要求：
1、2年以上工作经验，本科及以上计算机等相关专业学历；
2、基础扎实，熟悉数据结构和算法； 
3、熟悉Java、Scala、Python语言，较强的独立开发能力，具备良好的代码风格；
4、具备MapReduce、Hive、Spark、Redis等NoSql平台开发能力；
5、良好的数据敏感能力，敏锐而富有耐心。与数据打交道而乐此不疲；
优秀的沟通能力，有创新精神，乐于接受挑战，能承受工作压力。

岗位职责1.参与项目及产品编码工作；2.参与相关项目文档编写工作。
职位要求1.计算机相关专业，本科及以上学历；2.2年以上Java开发经历，熟悉Html/CSS/Javascript及Jquery、Spring、HTML编程；3.熟悉B/S架构应用系统的开发，掌握eclipse开发工具 ；4.能使用和开发Mysql数据库系统的编程；5.精通Spring、ibatis、struts等主流开源框架和技术；6.熟练使用SVN版本管理工具；7.具备良好的学习能力和抗压能力，对技术研究有热情；8.熟悉云计算与与大数据信息处理相关技术优先。本职位同期在：成都、重庆等城市招聘同步招聘，如您考虑在以上城市工作，请在投递简历时标注期望的工作地点。

工作职责：
1. 大数据分时/实时分析处理项目开发；
2. 参与相关技术研究、选型、验证、应用；
3. 参与系统分析与设计工作；
4. 参与方案讨论和开发/测试环境维护；
5. 组织并分享业务和技术技能；
 
任职要求：
1. 本科及以上学历，5年及以上项目开发经验，1年以上Hadoop大数据架构设计及优化经验；
2. 具备1年以上Hadoop大数据项目开发经验以及Spark/Spark streaming分时/实时数据分析处理经验；
3. 具有Flume+Kafka日志实时采集、数据共享实施经验或具有日志索引分词及搜索实施经验；
4. 熟悉大数据生态圈相关技术的开发及使用，如：Flume、Kafka、Zookeeper、Hadoop、Spark、Spark Streaming、YARN、HBase、HDFS、Spark SQL、Hive、Impala、Redis等，熟悉上述三种或以上，能用JAVA进行大数据开发；
5. 具备部分大数据开源工具的部署经验及能力。

1.了解互联网金融业务，与业务人员沟通，深入思考，发现数据可以应用于业务的机会；
2.提取数据并做数据处理，开发风险规则、信用评分、客户标签、营销响应等模型，并参与模型上线部署、测试、追踪维护等工作；
3.根据业务需要，完成数据分析专题报告，能够独立深入解读数据内含的规律；
4.参与各种数据产品的设计。
任职要求：
1.理工科专业，大学本科及以上学历；
2.2年以上数据建模工作经验，可独立完成模型需求调研、模型构建；
3.数据敏感，能快速发现数据的价值；
4.对数据挖掘、机器学习有一定研究，熟悉决策树、逻辑回归、SVM、神经网络等算法；
5.熟悉数据库查询操作，熟练掌握SQL语言，至少掌握SAS、Python或R语言的一种；
6.具有结构化思维能力、快速的学习能力以及良好的沟通协作能力，积极主动，能承受一定的工作压力；
7.有互联网、金融行业数据挖掘经验者优先考虑。

岗位职责1、参与公司数据挖掘算法开发和实现；2、应用数据挖掘，机器学习，自然语言处理等技术，针对海量信息建模，挖掘数据价值；3、构建海量数据爬虫和搜索引擎平台，为公司创新产品提供数据支持；4、研究前沿算法，并将最新的研究成果产品化。任职要求1、1年以上工作经验，计算机相关专业本科及以上学历，有使用spark/hadoop/hive分析海量数据的能力；2、灵活掌握Java/R/Python/Scala至少一种高级编程语言，有实际的项目开发经验优先；3、对数据挖掘、机器学习、自然语言处理等基础算法有较深的理解和实际经验，有Tensorflow，Paddle等有使用经验者优先；4、有过大型搜索引擎，推荐系统，广告系统等方面经验优先考虑；5、优秀的独立分析问题和解决问题能力，良好的团队合作精神，较强的沟通能力，对解决具有挑战性问题充满激情。

岗位职责：
•负责公司数据平台的规划和架构设计；
•负责公司数据仓库、大数据平台、BI产品的需求调研和选型；
•负责公司数据开发相关项目实施；
•负责数据平台数据挖掘、机器学习。

岗位要求：
•计算机、信息、通讯、电子相关专业毕业，211高校本科以上学历；
•熟悉大数据平台，了解数据可视化和常见的BI产品；
•精通至少一门编程语言；
•熟悉Hadoop、Spark开发平台优先；
•思维敏捷，有责任心、具备良好的沟通协调和学习能力。

岗位职责：
1 参与大规模数据的架构设计和开发；
2 医疗大规模数据挖掘和处理；
3 研究大数据前沿技术，提升系统的运维效率；
4 实现大数据基础架构平台（Hadoop/Spark/MPP DB）的自动化运维；
任职要求：
1具有3年以上大数据开发经验，至少熟悉一种编程语言（Python/Java/Scala）；
2熟悉Hadoop等分布式系统开发，数据仓库技术；
3熟悉HDFS/HBase/Hive/MapReduce，掌握Mapreduce程序开发；
4强烈的责任心与求知欲，医疗行业经验；
5有较强的书面与口头沟通表达能力，独立分析、解决问题的能力。

岗位职责：1、负责公司大数据产品建设与开发；2、协助完成大数据项目需求分析、设计、业务建模；3、负责大数据的架构设计、规划、流程优化；4、负责大数据实施过程中相关技术问题解决。
任职资格： 1、3年以上工作经验，熟悉hadoop，有storm/spark实际开发经验和海量数据清洗、处理经验； 2、对数字，数据敏感，具备良好的逻辑思维能力，能够从海量数据中发现有价值的规律； 3、熟悉当前主流MQ, NoSql； 4、熟悉常用数据结构，有扎实的算法基础和丰富的编码经验； 5、熟悉JavaEE相关技术； 6、对业务有敏锐的洞察力，有较强的业务理解与分析能力； 7、有实际数据挖掘与推荐系统开发经验者优先；
税前年薪（万元）：20-40

职位描述：1、参与公司大数据产品规划；2、大数据处理分析平台的设计与开发；3、为其他项目组提供大数据技术指导及分析手段支持。

岗位要求：
1、工作经验要求不限，全日制本科大三以上或研究生阶段，或已毕业。每周到岗时间不少于2天。
2、数学系及相关专业（数学基础：高等数学，线性代数，概率论数理统计和随机过程，离散数学，数值分析）。
3、了解计算机算法：人工神经网络，或支持向量机，或遗传算法等等算法。
4、编程语言：需要掌握至少一门编程语言C/C++/Java/Visual Basic。

岗位职责：
1、负责公司大数据处理平台的总体技术工作，包括需求分析、架构设计、研发、以及性能分析工作；
2. 负责设计、构建和优化基于hadoop/Hbase的存储平台架构；
3. 负责整体提升hadoop/Hbase/Storm/Spark集群的高可用性、高性能、高扩展特性；
4. 根据业务需求，提出最优的技术解决方案；分解详细的开发任务，能配合其他项目制定开发计划、开发文档、开发流程图；
5. 负责带领项目及培训团队，指导技术团队完成数据规则的定义、数据模型的建立、数据清洗、数据迁移等工作。
6. 负责数据架构的规划，并制定实施标准和规范，确保得到有效的执行，同时保障数据以及文档的质量达到预定的标准；
任职资格：
1  计算机及其相关专业，本科及以上学历。
2  3年以上软件开发经验，精通Java开发。
3 .具备数据库系统基本理论知识，至少掌握一种主流商业数据库产品如Oralce的管理和应用，精通SQL语言，精通存储过程；
4、具备实时处理框架的设计和开发能力。
5、熟悉Hadoop、Hbase、Hive、Elastic Search/Solr等相关技术；
6、熟悉Linux开发环境，能进行shell脚本的编写；
7、具有较强的逻辑分析能力，高度的责任心及团队合作精神；
8、具有实际大数据项目的成功经验者优先考虑。

任职资格：
计算机或相关专业本科以上学历， 2-5年工作经验；
熟悉shell、php、C++、go、Scala、JAVA、python等开发语言，编程能力扎实；
熟悉hadoop/spark，拥有优秀的海量数据处理和解决实际问题的能力；
良好的逻辑思维能力，对数据敏感，良好的团队合作和沟通能力；
有大数据产品研发经验、有大型互联网服务的设计和开发经验者优先

岗位名称：大数据运维工程师
岗位职责：
1、负责公司服务器的稳定性，确保服务器不间断的运营，符合公司及客户的需要；
2、负责参与并审核产品架构设计的合理性和可运维性；
3、负责用自动化的技术或者平台确保产品可以高效的发布上线；
4、负责保障产品7*24H稳定运行；
5、协助进行研发发布部署和运维支持相关工作；
岗位要求：
1、本科及以上学历，3-10年以上运维工作经验；
2、精通Python/Java/Perl等1至2种编程语言；
3、熟练掌握MySQL，熟悉Redis，深入理解Linux操作系统；
4、熟悉开源的监控平台工具，比如Nagios、zabbix等；
5、熟练掌握Shell脚本；熟练掌握Awk、Sed等工具；
6、熟悉Docker等虚拟化技术优先。
7、对技术和工作有热情，积极主动，认真负责，能够承担工作压力。
8. 杰出的团队，优秀的队友，解决挑战性的问题，快速成长的空间和机会；
9. 餐补，交通补助，房补；
4. 超好的办公环境，健身房。

【物联网技术总监（云计算、大数据）】
职位描述：


5年以上通信互联网云计算相关研发经验，有个完整的平台架构设计经验；
精通云计算SaaS、PaaS架构；
精通物联网应用；
精通大数据应用架构；
熟悉了解业界领先的物联网应用平台；
有过融合通信平台产品架构设计者优先。


岗位职责：
1、负责J2EE项目开发和维护。
2、负责功能模块设计，应用模块、WEB、接口开发，及相关过程文档的编写。
5、完成上级领导交办的其他各项事宜。

任职要求：
● 工作经验：计算机相关专业，3-5年J2EE开发经验；
● 学历背景：本科及以上；
● 有大数据经验者优先；
● 有项目管理经验者优先；
● 精通MySQL数据库，熟悉Oracle更佳。
● 熟悉javascript、Ajax等前端技术优先；
● 有丰富的Java B/S 项目开发经验，精通J2EE架构，熟悉Eclipse等开发工具；
● 精通JFinal，Struts，Hibernate，Spring，MyBatis等开源框架；
● 熟悉Linux、Unix基本操作命令；
● 熟悉Git，了解jenkin优先考虑
● 善于团队协作和沟通，具备良好的编程风格和较强的文档编写能力，能根据公司的要求提供完整规范的研发文档和测试手册。

【项目介绍】
大数据是目前我们重点项目之一，主要是整合搜狗的大数据（输入法、搜索、商业等产品），形成搜狗的大数据中心。同时，推动搜狗对外的大数据合作，形成强大的大数据商业和用户产品。

【特别提示】搜狗欢迎专情的你，所以提醒你只能选择两个项目，请慎重投递。

【岗位职责】
1、负责大数据产品的需求沟通、需求分析、可行性分析、产品文档撰写、原型设计等，详细阐述产品功能和操作流程；
2、联络、协调与支持产品相关的内部与外部人员与项目团队配合，阐述产品的设计思路，提供产品实施方案，促进项目成功实施；
3、负责相关产品开发项目周期和进度把控，对完成进度和质量负责；
4、汇总分析产品的全方面数据，对产品改进提供数据支持，持续提升用户体验；关注行业信息和用户对产品的反馈，分析并提供产品持续提高和改进方案。
任职条件
1. 本科及以上学历，理工科背景优先，3年以上互联网产品经验，1年以上大数据工作经验。
2. 思维清晰敏捷，有很强的逻辑分析能力、良好的书面/口头表达能力与人际交往能力
3.出色的沟通与规划能力、执行能力，拥有强烈的责任心和团队合作精神
4.有商业产品相关经验者优先

岗位职责：
1.负责大数据平台软件需求分析、设计；
2.参与产品需求讨论、应用产品系统架构的设计、开发；
3.负责编写相应的需求、设计与技术文档；

岗位要求：
1，大专及以上学历，3年以上大数据相关研发经验
2，熟悉Spark、hadoop研发，至少一个以上大型成熟项目经验
3，熟悉java开发，有实际编程经验
4，熟练使用sql、shell脚本编程
5，强烈的责任心，良好的沟通协调能力,较强的学习能力

职位描述：
1. 负责数据平台的设计、开发、维护、优化，满足公司各级部门的数据分析需求； 2. 研究与跟踪大数据技术发展方向，参与大数据平台架构的设计。 
 
任职要求：
1. 三年以上工作经验 ，有电商、金融、P2P业务背景者优先 ；2. 熟练 Java/Python，了解Scala更佳， 追求代码质量和程序效率, 熟悉设计模式； 3. 熟悉Hadoop生态圈，有一年以上hdfs/hive 经验； 4. 熟悉 Spark SQL, Spark Streaming, Map Reduce等, 对Spark体系结构, 运行机制和源码有深入研究 ；5. 熟悉 ZooKeeper、Kafka、Redis、MongoDb ；6. 熟练使用Linux系统，熟悉Shell脚本语言 ；7. 熟悉Spark MLlib 优先，有实际用户画像和行为分析系统设计优先 。

岗位职责：
1.参与大数据平台架构的整体规划和设计；
2.根据上层业务逻辑整合优化平台数据流程，技术难点攻关；
3.对数据挖掘及业务开发团队提供技术支持，协助方案规划，及时解决项目开发或产品研发中的技术难题，保证最终性能和稳定性；
4.跟踪业界技术动态，推动技术的持续进步，学习并分享经验;

岗位要求：
1. 本科及以上，1年以上互联网行业从业经验
2. 熟悉Linux环境，熟练Java，掌握shell/python/perl等至少一门脚本语言 
3. 熟悉至少一种分布式系统，了解其原理
4. 热爱开源技术，熟悉一种或者多种大数据生态技术（Flume，Kafka、Hbase、Spark、Storm、Hadoop、Flink等），熟悉源码者优先
5.擅长troubleshooting 和 performance tuning
6. 有重构、性能调优工作经验者优先 
7. 参与过大型复杂分布式互联网 WEB 系统的设计开发者优先

岗位描述：
1.负责公司大数据处理系统的研发
2.建设下一代BI数据分析系统
3.建设用于广告投放的自有DMP
4.带领数据组，需要同时承担开发及管理工作
5.可选择在北京或珠海工作
岗位要求：
1.计算机、数学、统计或相关专业本科及以上学历
2.3年以上BI，DW方面的经验，对数据统计，数据建模，维度设计等各方面有深入理解
3.有大数据研发工具体系开发和设计经验；包括模型设计与管理、调度、BI分析等系统等
4.了解和熟悉当前大数据存储计算框架体系（包括hadoop、storm、spark等）最新进展，熟悉其相关设计原理，应用及调优
5.了解现代的软件工程方法，有敏捷，TDD，BDD经验
6.熟悉Java/Python/Scala/Golang至少一种开发语言
7.很强的学习能力，且乐于分享交流
8.有管理经验
加分项：
1.大型BI，DMP项目的管理实施经验
2.计算广告行业经验
3.敏捷开发经验， 有敏捷团队管理经验更佳
4.有远程团队协同开发经验
5.有参与开源数据系统开发的经验
6.熟悉Github使用工作流程

工作职责：

大数据环境下的开发，数据分析；
大数据平台数据清洗、转换、建模的开发工作，处理离线数据；
保证大数据平台数据与各源系统数据准确性；
大数据平台的运维工作，持续完善大数据平台，保证稳定性、安全性。

 
任职要求：

本科及以上学历，计算机等相关专业毕业；
熟悉Linux开发平台及工具链，熟悉Linux系统的配置管理；
至少熟练使用MySQL、Oracle中的一种；
扎实的Java或Python语言开发技能；
有Hadoop、HBase、Hive、Spark开发经验者优先。


1.       5年以上工作经验,其中2年以上Hadoop开发经验
2.       熟悉shell脚本，熟练掌握Java
3.       熟悉MapReduce思想，以及Yarn源码
4.       有分布式调度系统经验，Mesos经验更佳
5.       有一定的算法基础，有较强的学习能力，有独立分析和技术研究能力。
6.       优秀的团队合作精神，对工作有热情。




岗位职责：
1、负责大数据平台Hadoop,Spark生态圈的规划、部署、安装及开发。
2、负责大数据平台的数据采集-数据传输-数据存储-数据统计。
3、负责大数据平台管理及新技术测试和预研究。

任职要求：
1、计算机、数学或者统计学相关专业本科以上学历；
2、熟练使用Java开发语言3年以上，并熟悉高并发分布式应用及大数据架构者优先考虑；
3、熟悉Hadoop/HBase/Hive大数据开发平台，2年以上实际大数据平台开发经验；
4、优秀的团队沟通能力，有创新精神，乐于接受挑战，踏实勤奋，自学能力强，能承受工作压力。

岗位职责：
1、负责收集、分析政府、企业等领域大数据最新的政策、动态、技术发展趋势等，进行重点行业的行业研究和重点客户的业务研究，规划大数据行业解决方案；
2、负责与行业客户进行沟通，完成需求调研，了解业务问题和需求，进行信息化业务分析、业务建模及技术分析、数据建模，有针对性提出大数据解决方案； 
3、根据项目需求，编写相关售前咨询方案文档（项目规划、顶层设计、解决方案、运营方案、技术资料、投标技术文件等），参与竞标及技术谈判；
4、为销售团队提供方案培训及售前支持，完成项目前期的方案讲解、客户交流和答疑等售前支持工作，参与有关市场宣传或主题研讨活动；
5、参与公司重点项目实施过程中的资源协调，促进公司技术研发部门与用户之间保持顺畅沟通，推动项目进展。
 
任职要求：
1、计算机、管理学、经济学、统计学或相关专业本科及以上学历，3年以上工作经验；
2、对大数据架构有一定了解，对政府、军工等行业项目的解决方案有丰富的经验，有从事售前、咨询的工作经历； 
3、语言表达、逻辑思维和文字组织能力强，能独立撰写演示文档、技术及服务方案、项目投标书等文档；
4、具备独立引导客户需求，通过技术沟通、方案解说，将设计思路和工作成果清晰的传达给客户。
5、对电子政务行业趋势和政策有一定的理解和认识者优先，具有良好的数据敏感性和数据分析能力优先


岗位职责：
   


1.负责知识图谱的大规模存储与管理。
   


2.负责基于知识图谱的高效查询（偏OLTP）与挖掘分析（偏OLAP）。
   


岗位要求：
   


1.精通PythonCJava三种编程语言中的至少一种；
   


5.有Hadoop、Spark等大数据平台搭建和应用经验的优先；
   




岗位要求：
   


1.      计算机或通信处理相关专业硕士及以上学历。
   


2.      4年以上JAVA开发经验，1年以上hadoop开发经验；
   


3.      对大规模分布式系统有深入研究者优先，有开源代码贡献经历优先；
   


4.      对于深度学习库Tensorflow、Keras、Caffe、MXnet等熟悉使用者优先；
   


5.      精通Java并发编程，有较强的架构优化能力，有大规模高并发应用开发经验优先；
   


6.      熟悉主流的大数据处理架构（消息队列、kafka、hadoop、spark等），并精通其中一种系统的源码。
   


7.      熟悉Mysql，有过数据库调优和海量数据存储经验优先；
   


8.      有MongoDB、Redis和Neo4j等非关系型数据库相关经验的优先；
   


9.      有Solr或其他Lucence相关经验的优先；
   


工作职责：
负责大数据开放式集群的搭建、管理、监控、优化以及相关应用的开发等工作。
职位要求：
1、熟悉java高并发多线程开发；
2、精通Hadoop以及Hadoop生态圈上的各种应用的几种，如MapReduce、Hbase、Hive、Spark-SQL等；
3、拥有实际的3年以上Hadoop的项目经验；
4、研究过Hadoop、HBase、Hive、Spark等开源软件源码者优先；
5、有Storm、Spark、Kafka，flume等相关开发经验者优先；
6、5年及以上工作经验，计算机及相关专业本科以上；
7、良好的团队合作，较强的沟通能力，对解决挑战型问题充满激情；

一、入职条件：
1、本科以上学历，计算机相关专业。
2、有5年Java开发经验及2年以上大数据研发经验或3年以上Java开发经验想转型大数据研发的。
3、深入理解面向对象开发思想、精通设计模式、多层架构等编程模型。
4、精通java语言、精通spring、mybatis等主流开发框架。
5、精通java多线程及高并发编程、有高可用性应用的设计开发经验。
6、精通jms、redis、jta等分布式架构、有负载均衡系统架构的实施经验。
7、能熟练使用eclipse、ant、maven、subversion、junit等集成开发、构建、测试和管理工具。
8、精通sql编程、能熟练编写函数、存储过程及sql性能调优、熟悉mongo、mysql等数据库开发。
9、精通linux系统、精通mysql、dns、nginx、tomcat、jboss等常用服务的安装配置。
10、熟悉hadoop、spark等大数据相关技术。
二、岗位职责：
1、参与系统设计及架构设计，并负责重难点任务的技术攻关。
2、指导或协助其它开发工程师完成相关开发工作。
3、独立完成系统部署及联调及配置工作。
4、带领开发小组基于软件需求分析和设计成果、完成编码、单元测试等工作。
5、完成互联网平台核心组件的开发。

岗位职责:岗位职责：1、负责数据产品线研发和团队的搭建、管理和绩效考核；2、负责底层大数据平台和存储平台的设计和搭建工作，对接内外部对大数据服务的需求；3、带领团队设计、开发具有创新价值的大数据分析平台。任职要求：1、计算机、数学相关专业，全日制本科及以上学历；2、8年以上分布式系统、大数据相关工作经验，5年以上团队（10人＋）管理经验；3、熟悉Hadoop／Spark、Hive、HBase等主流的大数据技术，至少3年以上产品／平台项目研发经验；4、有极强的项目管理能力和资源协调能力，有很好的沟通能力（从C－level到工程师）；5、有以下其中之一者，更加优先：(1) 精通或者熟悉数据库设计，熟悉Oracle／MySQL/MySQL 集群等数据库，熟悉NoSQL 者更佳；(2) 具有较强的数据挖掘、机器学习的理论基础和实际项目经验，精通数据分析与各种算法与模型，例如分类、聚类、神经网络等；(3) 极强的系统设计和系统架构能力或者项目经验；(4) 必要的产品管理意识和产品设计的评估技能；(5) 了解容器技术以及相关的框架使用，例如k8s。

岗位职责：
1、负责大数据平台（后台系统、大数据）的测试工作，对产品的质量负责；
2、根据产品需求设计测试方案及用例，并执行测试用例，及时汇报测试进度；
3、制定测试计划，优化测试流程，对产品的缺陷进行评估，确定测试用例执行的优先级，输出测试报告；
4、负责和产品开发等其他团队的沟通协作，推动项目顺利进展，并持续优化研发和测试流程，提高工作效率。

任职要求：
1、统招本科及以上学历，计算机相关专业，2年及以上后台测试或1年大数据测试经验，熟悉敏捷模式；
2、掌握后台测试方法，熟练linux命令、MySQL操作，熟悉后台常见组件，有shell编程或存储过程编写经验者优先；
3、熟悉至少一门开发或者脚本语言，如python、java等，并有一定的实际应用经验；
4、有强大的自驱能力和追求卓越的心态，思维理解能力强，沟通顺畅，责任心强；
5、熟悉数据分析/BI数据仓库测试/报表测试经验者优先。

工作职责：
1. 负责和参与公司大数据基础架构平台的运维，保障数据平台服务的稳定性和可用性；
2. 负责和参与超大规模数据存储与计算任务的精细化管理系统的设计，造型和开发；
3. 负责和参与自动化运维系统及平台的建设

希望你：
1. 熟悉Linux
2. 掌握Python、Ruby、Scala、Java语言中的一种
3. 掌握Hadoop、Hbase与Spark等大数据模块的使用
4. 熟悉git
5. 熟悉大数据周边相关的数据库系统，关系型数据库和NoSQL
6. 具有机器学习特征工程经验的优先

岗位职责：

1、负责公司大数据产品迭代演进，Hadoop技术架构及相关分布式技术研究和开发；
2、规划Hadoop集群安装部署方案，并能指导项目上线兼顾维护，保障生产系统的稳定及高效运行；
3、参与客户交流、需求分析、及方案编写和评审等工作，能支撑大数据客户交流活动；
4、负责区域技术团队的梯队建设，培养相关Hadoop技术架构开发与应用人员，完成部门级培训文档及相关工作，打造有竞争力的队伍；
5、除技术团队外，与销售、产品经理、项目经理等跨部门同事默契配合。


任职要求：
1、统招本科以上学历，4年以上电信或互联网行业经验，有团队管理经验；
2、对电信及互联网行业领域的大数据生态有较深认识，有大型大数据项目实施经验；
3、精通Hadoop架构框架，掌握YARN及MapReduce算法与原理，具备二次设计与开发能力；
4、精通ZooKeeper、HDFS、Hbase等分布式开源软件，具备系统优化与性能调优能力；
5、熟悉分布式系统部署、开发、测试、维护过程与方法；精通Linux/Unix环境下的Java/scala编程，熟悉脚本编程(Shell/Python)等。

岗位职责：
1、负责MySQL系统的开发和维护。
2、设计、实现、优化包括MySQL引擎、源码分支、云平台和分布式存储系统在内的系统。
3、直接参与到系统设计和核心代码开发。
4、 直接参与公司风控模型的搭建。
任职要求:
1、数学、计算机专业本科及以上毕业。
2、 熟悉分布式系统开发部署。
3、热爱软件开发工作，熟悉软件开发流程，有良好的技术文档习惯，具有规范化，标准化的代码编写习惯，单元测试编写习惯。
4、良好的表达能力，能够清晰和准确地描述问题; 良好的发现并解决问题能力。
5、 优先条件：具有大数据量高负载产品/系统的设计或核心开发的经验; 拥有开源项目的开发经验; 用数据和理论分析系统的能力。

职位描述：岗位职责：1、带领研发团队完成预定的研发任务；2、安排、保障工程运维团队的工程任务圆满完成；3、支持售前人员完成售前技术交流工作；4、与其它部门、项目的协调沟通和技术交流工作等。任职要求：1、熟悉hadoop及其生态圈内相关开源产品；2、有两年以上10人以上的项目或团队管理经验，熟悉敏捷开发方法；3、有一年以上大数据架构经验；综合素质：1、能承受较大压力；能适应3周以内的短期出差；2、个性开朗，做事有条理，主次分明；3、逻辑思维能力强，沟通能力、团队合作精神优秀。
职能类别：技术主管

岗位职责：
1、参与数据基础平台架构和数据处理体系的升级和优化，不断提升系统的稳定性和效率；
2、根据公司的业务需求，提供数据计算服务和查询服务；
3、参与数据平台计算逻辑优化； 
工作职责：
1. 大学本科以上学历，二年以上互联网行业工作经验者优先；
2. 较强逻辑分析能力，优秀的沟通能力和团队协作能力；
3. 精通Java编程基础：集合框架、多线程并发、IO/NIO; 熟悉Spring, iBatis，MQ、 RPC、缓存等常用技术和框架；
4. 熟悉Linux系统部署操作；
5. 有Hadoop/HBase/Hive/Storm/Spark相关经验者优先；
6. 有大数据分析平台、任务调度系统、风控系统其中之一开发经验者优先;
7. 熟悉SQL编程，有一定数据仓库使用经验者优先。

一、岗位职责：
1、通过对现有业务的大数据进行数据挖掘及分析，为数据产品确定和指引方向；
2、负责数据服务类产品的规划，需求分析和产品设计；
3、关注房地产大数据应用相关方向的前沿研究，并将相关成果快速产品化、商品化, 将创新推向用户；
4、跟踪大数据应用市场动向，市场竞争对手分析，及时调整市场策略，创新产品。
 
二、任职要求：
1、本科以上计算机、统计学、机器学习、数据挖掘、数学、理科经济学等相关专业，3年以上相关工作经验；
2、有丰富的策略